A Theory of Fermat Paths for Non-Line-of-Sight Shape Reconstruction

Shumian Xin1, Sotiris Nousias2

,

3, Kiriakos N. Kutulakos2, Aswin C. Sankaranarayanan1,

Srinivasa G. Narasimhan1, and Ioannis Gkioulekas1

1Carnegie Mellon University 2University of Toronto 3University College London

Abstract

We present a novel theory of Fermat paths of light be-
tween a known visible scene and an unknown object not in
the line of sight of a transient camera. These light paths ei-
ther obey specular reﬂection or are reﬂected by the object’s
boundary, and hence encode the shape of the hidden object.
We prove that Fermat paths correspond to discontinuities
in the transient measurements. We then derive a novel con-
straint that relates the spatial derivatives of the path lengths
at these discontinuities to the surface normal. Based on this
theory, we present an algorithm, called Fermat Flow, to es-
timate the shape of the non-line-of-sight object. Our method
allows, for the ﬁrst time, accurate shape recovery of com-
plex objects, ranging from diffuse to specular, that are hid-
den around the corner as well as hidden behind a diffuser.
Finally, our approach is agnostic to the particular technol-
ogy used for transient imaging. As such, we demonstrate
mm-scale shape recovery from pico-second scale transients
using a SPAD and ultrafast laser, as well as micron-scale
reconstruction from femto-second scale transients using in-
terferometry. We believe our work is a signiﬁcant advance
over the state-of-the-art in non-line-of-sight imaging.

1. Introduction

Most computer vision research assumes that the scene of
interest is directly visible to the camera.
In other words,
the photons from a source that reach a camera are assumed
to have interacted with only the visible scene. However,
some of the source photons are reﬂected by the visible scene
toward parts—say, the back of an object facing a camera,
an object around a corner, or an object viewed through a
diffuser — that are hidden from the direct line of sight of
the camera. In turn, the hidden scene scatters the photons
back toward the visible scene, which then redirects photons
toward the camera. Imaging and understanding the scene
hidden from the camera’s view is of signiﬁcant importance
to many security and safety applications.

Capturing non-line-of-sight (NLOS) photons is chal-

lenging as they are vastly outnumbered by line-of-sight
(LOS) photons. Passive approaches analyze the subtle um-
bra and penumbra of the shadow cast by the hidden scene
to estimate rough motion and structure [6, 2, 38], or use co-
herence properties of light to localize hidden objects [5, 3].
These approaches do not have sufﬁcient information to
compute precise 3D shape of an unknown arbitrary hidden
scene. Extracting additional information about the hidden
scene is possible by using active illumination, including
coherent lighting [42, 21, 4, 22] and steady-state intensity
sources [25, 44, 51, 45]. The majority of approaches for
reconstructing hidden shape information employ fast modu-
lated light sources together with time-resolved sensors (e.g.,
continuous-wave ToF [15, 20], ultrafast photodiodes [24],
streak cameras [49, 48, 13], and single-photon avalanche
photodetectors (SPADs) [11, 32]). These sensors record
not only the number of incident photons (intensity) but also
their arrival times, at a range of temporal resolutions (milli-
to femto-seconds) [49, 12, 31, 32, 11, 18]. Such measure-
ments are called transients and the approach is called tran-
sient NLOS imaging.

By measuring transients at various locations of a known
visible scene, most active techniques perform a volumet-
ric 3D reconstruction by attempting to invert the time-
resolved radiometric image formation process. Examples
include elliptic backprojection [48, 7, 1, 26, 36], regular-
ized linear system approaches [13, 15, 14, 20], the light-
cone transform [33], and analysis-by-synthesis using ren-
dering [35, 47]. These methods have two fundamental dis-
advantages: (1) they rely on radiometric information and
existing SPADs produce poor intensity estimates due to ef-
fects such as pile-up and after-pulsing [16], as well as due
to extreme sensitivity to photon noise and ambient lighting;
and (2) to simplify the inverse problem, all existing recon-
struction techniques rely on an assumption of Lambertian
reﬂectance for the NLOS object.

In this paper, we overcome the above limitations by de-
veloping techniques that use only geometric, rather than in-
tensity, constraints derived from transient measurements of
an NLOS scene. For this, we present a new theory of NLOS
photons that follow speciﬁc geometric paths, called Fermat

16800

Figure 1: Non-line-of-sight imaging. We consider the problem of reconstructing surfaces that are: (a) outside the ﬁeld of
view of sensor, or (b) occluded from it by a diffuser. We develop an algorithm that can use transient imaging measurements to
accurately reconstruct the shape of the non-line-of-sight surface. The ﬁgure shows example reconstructions of a US quarter
from measurements captured by a femtosecond-scale transient imaging system.
In (c), we compare our reconstructions
against groundtruth, obtained using a direct depth scan of the object with the same transient imaging system.

paths between the LOS and NLOS scene. Based on Fer-
mat’s principle [43], we observe that these paths follow ei-
ther the law of specular reﬂection or reﬂect at speciﬁc points
at the object’s boundary. We then prove that Fermat paths
correspond to discontinuities in the transient measurements.
The temporal locations of the discontinuities are a function
of only the shape of the NLOS object and not its reﬂectance
(BRDF). We additionally show that the shape of the tran-
sient around the discontinuity is related to the curvature of
the hidden surface. This theory generalizes previous work
on the paths of ﬁrst-returning photons [46], which are a spe-
cial case of Fermat paths.

We use the above theory to derive an algorithm, called
Fermat ﬂow, for accurate NLOS shape reconstruction. We
show that the spatial derivative of the Fermat pathlength
provides a simple constraint that uniquely determines both
the depth and normal of a hidden scene point. This deriva-
tive is estimated numerically by ﬁtting a smooth pathlength
function to a sparser set of measurements. We then apply a
ﬁnal reﬁnement step that computes a smooth mesh by com-
bining both the depth and normal information [23, 9]. While
most previous approaches reconstruct an albedo volume of
the NLOS object, our approach is one of the few that recon-
struct its surface. Compared to alternative surface recon-
struction algorithms based on analysis-by-synthesis from
intensity measurements [47], our approach uses only geo-
metric constraints, which makes it BRDF-invariant and ro-
bust to imperfections in intensity measurements.

Our theory is agnostic to the speciﬁc transient imag-
ing technology used. We validate our theory and demon-
strate results at both pico-second and femto-second tempo-
ral scales, using a pulsed laser and SPAD for the former and
interferometry for the latter. Hence, for the ﬁrst time, we
are able to compute millimeter-scale and micrometer-scale
NLOS shapes of curved objects with BRDFs ranging from
purely diffuse to purely specular. In addition, our theory ap-

plies to both reﬂective NLOS (looking around the corner)
and transmissive NLOS (seeing through a diffuser) scenar-
ios. Figure 1 shows the estimated micrometer-scale relief
of a coin seen around the corner as well as through thick
paper (diffuser). The obtained height proﬁles compare well
with the reconstruction of the coin when imaged in the line
of sight. This result demonstrates the signiﬁcant theoreti-
cal and practical contribution of this work to active NLOS
imaging, pushing the boundary of what is possible.

2. Fermat Paths in NLOS Transients

Problem setup. We consider a transient imaging sys-
tem [19], comprising a light source and detector, located at
points s, d ∈ R3, respectively. Our theory is agnostic to the
speciﬁc transient imaging technology used, and in Section 4
we describe implementations, one based on a pulsed laser
and a picosecond detector, and another based on interfer-
ometry. The visible scene V ⊂ R3 is the union of surfaces
contained within the common line of sight of the source and
detector. In addition to V, we assume that there exist sur-
faces outside their line of sight; this could be because either
these surfaces are outside the ﬁeld of view, or they are in-
side it but occluded by another surface. We are only inter-
ested in such surfaces that can indirectly receive light from
the light source by means of a single reﬂection or transmis-
sion through the visible scene, and can indirectly send light
to the detector in a likewise manner. We call the union of
such surfaces the non-line-of-sight (NLOS) scene X . Some
situations where these conditions apply, and which will be
relevant to our experiments, are shown in Figure 1.

We assume that the light source and detector are illumi-
nating and imaging the same visible point v ∈ V, which can
be any point in the visible scene. This corresponds to the
confocal scanning scheme, proposed by O’Toole et al. [33].
We emphasize that this assumption is only to simplify ex-
position: All of our theory generalizes to the non-confocal

6801

(b) looking through a diffuser(a) looking around the cornerreconstructed depth mapsource and detectoroccluderhidden objectvisible surfacereconstructed depth mapsource and detectorthick diffuserhidden object(c) comparison with line-of-sight scanningreconstructed depth maphorizontal locationdepthheight profiles from three reconstructions(a)(b)(c)0500 μmcase, as we brieﬂy discuss in various places throughout the
paper, and detail in the supplement. In particular, in Sec-
tion 4, we show results from non-confocal experiments.

The detector records a transient I (t; v), which equals
the irradiance from photons with time of ﬂight t. We as-
sume that all recorded photons follow paths of the form
s → v → x → v → d, where x ∈ X . This three-
bounce assumption is commonplace in NLOS imaging ap-
plications, for two reasons: First, NLOS transient imaging
systems typically have time-gating mechanisms that can be
used to remove direct photons that only interact with the
visible scene. Second, photons with more than one interac-
tions with the NLOS scene X have greatly reduced signal-
to-noise ratio, and in practice are difﬁcult to detect [7, 35].
Finally, we assume that we have calibrated the distance
τV (v) , ks − vk + kd − vk from the source to the visible
point, and from there to the detector. Then, we can use
the pathlength traveled in X , τ , ct − τV (v) where c is
the speed of light, to uniquely reparameterize transients as
I (τ ; v). Under these assumptions, we can write [10, 37]:

I (τ ; v) =ZX

f (x; v) δ (τ − τ (x; v)) dA (p, q)

(1)

where τ (x; v) , 2 · kx − vk, (p, q) ∈ [0, 1]2 is a pa-
rameterization of the NLOS surface X , A (p, q) is the cor-
responding area measure, and the throughput f absorbs
inverse-square fall-off, shading, reﬂectance, and visibility.

2.1. Fermat paths

We assume that the NLOS scene X is formed as the
union of smooth surfaces, and ∂X ⊂ X is the set of points
on the NLOS surface where a surface normal is not deﬁned.
We will be referring to ∂X as the boundary of X for sim-
plicity, but note that, in addition to boundary points, it in-
cludes points at discontinuous intersections of the smooth
surfaces that make up X . Then, we will be focusing on spe-
ciﬁc distinguished points x ∈ X as follows.

Deﬁnition 1. For any visible point v:

• The specular set S (v) ⊂ X consists of all points x ∈
X \ ∂X such that the vector v − x is orthogonal to the
tangent plane TxX of X at x.

• The boundary set B (v) ⊂ ∂X consists of all points
x ∈ ∇X such that the vector v − x is orthogonal to
the tangent vector ˆt (x) of ∂X at x.

• The Fermat set F (v) ⊂ X is the union of these two

sets, F (v) , S (v) ∪ B (v).

Deﬁnition 1 implies that, at points x ∈ S (v), the vector
v − x is also parallel to the surface normal ˆn (x). Equiv-
alently, the path p (x; v) , v → x → v corresponds to a

specular reﬂection at x, explaining the name specular set.
The name Fermat set is due to the following classical propo-
sition of geometric optics [17, 8, 29, 43].

Proposition 2. Let (p, q) ∈ [0, 1]2 be a parameterization of
the NLOS surface X . Then, for any visible point v,

S (v) =(cid:8)x ∈ X : ∇(p,q)τ (x (p, q) ; v) = 0(cid:9) .

Let r ∈ [0, 1] be a parameterization of the NLOS surface
boundary ∂X . Then, for any visible point v,

(2)

B (v) = {x ∈ ∂X : ∂τ (x (r) ; v) /∂r = 0} .

(3)

For completeness, we provide a proof in the supplement.
Proposition 2 is known as Fermat’s principle, and charac-
terizes paths of stationary length with respect to their local
variations. We note that, even though Fermat’s principle is
often described as the “shortest path principle”, it allows for
longest or saddle-point light paths, as we demonstrate later
in this section. Depending on X , F (v) will have at least
one, and potentially multiple, points, as shown in Figure 2.
We will associate each point x ∈ F (v) with the sphere
Sph (τ (x; v) /2; v) of center v and radius τ (x; v) /2. We
call this the tangent sphere, because Proposition 2 implies
that, for x ∈ S (v) or x ∈ B (v), the Sph (τ (x; v) /2; v)
is tangent to X or ∂X , respectively, at x [29, 43].
Relationship to ﬁrst-returning photons. Fermat paths are
a superset of the paths of the ﬁrst-returning photons de-
scribed by Tsai et al. [46]. In particular, the pathlength of
the ﬁrst-returning photon is the global minimum of τ (x; v).
Then, Proposition 2 implies that x ∈ F (v). Observations
2 and 3 of Tsai et al. [46], which make an assumption of
local smoothness, correspond to the case where addition-
ally x ∈ S (v): Observation 3 describes the specular path
p (x; v), and Observation 2 describes the tangent sphere.

2.2. Fermat pathlengths as transient discontinuities

Except when the BRDF of the X surface is perfectly
specular, transients I (τ ; v) will include contributions from
photons that follow both Fermat and non-Fermat paths
p (x; v). Without prior knowledge of the scene, it would
seem impossible to identify parts of the transient due to Fer-
mat paths. However, we make the following observation.

Proposition 3. Assume that the BRDF of the X surface is
non-zero in the specular direction. Then, for all x ∈ F (v),
the transient I (τ ; v) will have a discontinuity at pathlength
τ (x; v). If x ∈ S (v), then I (τ ; v) will additionally have
a vertical asymptote at τ (x; v).

Proof sketch. We sketch a proof for the specular case, and
provide the full proof in the supplement. Let Sph (ρ; v) be
the sphere of center v and radius ρ. Let the curve C (ρ; v)
be the intersection of Sph (ρ; v) with X , parameterized by

6802

NLOS
surface

X

x

xF ,1

xF ,3

Sph (τF ,3; v)

xF ,2

Sph (τF ,2; v)

τF ,1

τF ,2

τF ,3

)
v

;
τ
(

I

t
n
e
i
s
n
a
r
t

v

visible surface V

)
v

;

x
(

τ

h
t
g
n
e
l
h
t
a
p

τF ,3

τF ,2

τF ,1

pathlength τ

NLOS surface point x

Figure 2: Theory of Fermat paths. We illuminate and
image an NLOS surface X from a point v on a visible
surface V. (We show the camera and light sources in Fig-
ure 1.) Among all points x ∈ X , some points on the sur-
face (xF ,2,xF ,3) and boundary (xF ,1) will create paths that
satisfy Fermat’s principle, corresponding to local minima
(xF ,1,xF ,2) or maxima (xF ,3) of the pathlength function
τ (x; v) (bottom right). The paths for the non-boundary
points (xF ,2,xF ,3) will additionally be specular. We can
identify the lengths of these Fermat paths from the fact that
the transient I (τ ; v) (bottom left) will be discontinuous at
the corresponding pathlengths (τF ,1,τF ,2,τF ,3).

r ∈ [0, 1]. Then, we can use (r, ρ) ∈ [0, 1] × [0, ∞) to
reparameterize X , and rewrite the integral of Equation (1):

isolated points, and therefore the tangency property of Def-
inition 1 and the tangent sphere are not meaningful.
BRDF invariance. Proposition 3 implies that the path-
lengths where the transient I (τ ; v) is discontinuous are
determined completely by the function τ (x; v).
In turn,
τ (x; v) depends only on the geometry of v and X . There-
fore, the discontinuity pathlengths are independent of the
BRDF of the NLOS surface X . The BRDF is included in
the throughput term f in Equation (4), and thus only affects
the intensity of the transient at the discontinuity pathlength.
Figure 3 demonstrates this reﬂectance invariance property.
Identifying type of stationarity. Proposition 3 allows us
to identify the lengths of all Fermat paths that contribute to
a transient I (τ ; v), as the pathlengths where I (τ ; v) is dis-
continuous. From Proposition 2, each of these pathlengths
is a stationary point of the function τ (x; v). When the
BRDF of X is not perfectly specular, we can additionally
identify the type of stationarity from the shape of the tran-
sient at a neighborhood of the discontinuity. We use Fig-
ure 2 for intuition, and refer to the supplement for details.

Speciﬁcally, let τF be a pathlength where the transient
is discontinuous. If τF is a local maximum, the disconti-
nuity in the transient I (τ ; v) occurs at the limit from the
left, τ → τ −
F , and the transient decreases to the right of τF
(Figure 2, τF ,3). Conversely, when τF is a local minimum,
the discontinuity occurs at the limit from the right, τ → τ +
F
(Figure 2, τF ,1,τF ,2). Finally, when τF is a saddle point, the
discontinuity and intensity rise are two-sided. An example
of this is shown in Figure 3 (paraboloid case).

Identifying the stationarity type of specular discontinu-

ities provides us with curvature information about X .

Proposition 4. Let a transient I (τ ; v) have a specular dis-
continuity at τS , corresponding to a point xS ∈ S (v). If
κmin, κmax are the principal curvatures of X at xS , then:

−1

dA (r, ρ) , (4)

• If τS is a local minimum of τ (x; v), 2/τS < κmin.

• If τS is a local maximum of τ (x; v), κmax < 2/τS .

I (τ ; v) =

ZX

f (x; v) δ (τ − τ (x; v))(cid:12)(cid:12)(cid:12)

J (r,ρ)

(p,q) (x)(cid:12)(cid:12)(cid:12)

where J (r,ρ)
(p,q) (x) is the Jacobian of the transformation
(p, q) 7→ (r, ρ). We now consider a point xS ∈ S (v). Rec-
ognizing that ρ (xS ) = τ (xS ; v) /2, we have from Equa-
tion (2) that ∇(p,q)ρ (xS ) = 0. Consequently,

(cid:12)(cid:12)(cid:12)

J (r,ρ)

(p,q) (xS )(cid:12)(cid:12)(cid:12)

=

∂ρ (xS )

∂r (xS )

∂p

∂q

−

∂ρ (xS )

∂r (xS )

∂q

∂p

= 0.

(5)
Then, from Equation (4), at τ = τ (xS ; v), the transient
converges to inﬁnity, resulting in a discontinuity.

Figure 2 visualizes

this proposition for a two-
dimensional Lambertian scene X , and a visible point v such
that S (v) = {xF ,2, xF ,3}, B (v) = {xF ,1}. We note that,
in two dimensions, the boundary ∂X is not a curve but just

• If τS is a saddle point of τ (x; v), κmin ≤ 2/τS ≤ κmax.

We provide the proof in the supplement, but we can use
Figure 2 to provide intuition: The pathlength τF ,2 of point
xF ,2 is a local minimum. All X points in the neighbor-
hood of xF ,2 are at a distance from v greater than τF ,2,
and therefore outside the tangent sphere Sph (τF ,2/2; v).
This implies that the (minimal, in 3D) principal radius of
curvature is greater than τF ,2/2. And conversely for the
pathlength τF ,3 of point xF ,3, which is a local maximum.
We note that a sufﬁcient condition for X to produce only
locally-minimum specular pathlengths is that X is convex.
However, this is not a necessary condition: As explained in
Proposition 4, it is possible for X to contain concavities and
still produce only locally-minimum specular pathlengths.

6803

E (τF (vs, vd) ; vs, vd)

Sph (τF (v) ; v)

xF

X

∇vs τF (vs, vd)

∇v τF (v)

2

V

vs

v

vd

Figure 4: The Fermat ﬂow equation. We visualize both
the confocal (black lines) and non-confocal (green lines)
cases. In the confocal case, we consider the Fermat path
connecting the visible point v with an NLOS point xF . The
spatial gradient ∇vτF (v) /2 of the length of this path is a
unit vector parallel to the vector xF − v. If the Fermat path
is also specular, then ∇vτF (v) /2 will additionally be the
opposite of the NLOS surface normal at xF . In the non-
confocal case, we can compute the gradient with respect to
either of the two visible points, vs and vd, and it will be
parallel to the vector xF − vs or xF − vd, respectively.

paraboloid a saddle point, and the plane a local minimum.

We then cover each object with aluminum foil, to create
a rough specular BRDF, and repeat our measurements. We
notice that the measured transients (Figure 3, purple) are
discontinuous at the same locations as the diffuse transients,
in agreement with our discussion of BRDF invariance.

These measurements additionally help evaluate the ro-
bustness of our theoretical predictions in the presence of
the Poisson noise and temporal jitter inherent in SPAD mea-
suremens [16]: Even though the discontinuity shapes devi-
ate from the ideal shapes in the simulated transient of Fig-
ure 2, the theoretically predicted features are still visible.

Figure 3: Experimental demonstration. We measure
transients for three objects in a looking-around-the-corner
conﬁguration: A plane, a paraboloid, and a concave sphere.
We measure each object twice, once with the object cov-
ered with diffuse paint, and a second time with the object
covered with aluminum foil. As predicted by our theory,
the measured transients have discontinuities corresponding
to specular paths of type local minimum, saddle point, and
local maximum, respectively. Additionally, the location of
the discontinuities is not affected by the change in BRDF.

Non-confocal case.
The results of this section have
straightforward generalizations to the case where the source
and detector are pointing at different points vs and vd
on the visible surface V. Propositions 2 and 3 apply ex-
actly, except that τ (x; v) is replaced with τ (x; vs, vd) ,
kx − vsk + kx − vdk. The analogue of the tangent sphere
is the osculating ellipsoid E (τ ; vs, vd), of pathlength τ and
foci vs, vd. Finally, Proposition 4 can be generalized to
analogous relations between the principal curvatures of X
and E (τ ; vs, vd). We provide details in the supplement.

2.3. Experimental demonstration

3. Surface Reconstruction Using Fermat Paths

To demonstrate our theoretical ﬁndings in practice, we
use a picosecond-resolution transient imaging setup (see
Section 4) to capture measurements of a few real-world
objects, in a looking-around-the-corner conﬁguration (Fig-
ure 1(a)). Figure 3 shows the objects: A concave hemi-
sphere, an extruded paraboloid, and a plane. All objects
have size 20 cm × 20 cm and are painted with diffuse paint.
We place each object at a distance 40 cm from the visible
wall, then measure a transient from a visible point such that
there is a specular path corresponding roughly to the cen-
ter of the object. We observe from the measured transients
(Figure 3, orange) that, in agreement with Proposition 4, the
hemisphere produces a local maximum discontinuity, the

Using the results of Section 2, given a transient mea-
surement I (τ ; v), we can identify its discontinuities as
the lengths τF of Fermat paths contributing to the tran-
sient. Each length τF constrains the corresponding point
xF ∈ F (v) to lie on the tangent sphere Sph (τF /2; v) and,
if xF ∈ S (v), also constrains its normal and curvature.
We now develop a procedure for completely determining
the point xF and its normal. Then, given a collection of
Fermat pathlengths, our procedure will produce an oriented
point cloud (locations and normals) for the NLOS surface
X . Figure 5 visualizes our reconstruction procedure.
The Fermat ﬂow equation. We begin by introducing a key
technical result at the heart of our reconstruction procedure.

6804

X

I (τ ; v)

τF ,1 (v)

τF ,2 (v)

τ

vx

vy

v
v

V
(a) scanning

(b) discontinuity detection

(c) gradient estimation by interpolation

(d) point cloud reconstruction

vx

vx

vy

vy

Figure 5: Reconstruction pipeline. (a) We ﬁrst collect transient measurements I (τ, v) at multiple points v on the visible
surface V. (b) For each measured transient, we detect pathlengths where the transient is discontinuous. These correspond
to samples of the multi-valued Fermat pathlength function τF (v). In the example shown, τF (v) has two branches τF ,1 (v)
and τF ,2 (v), shown in blue and red respectively. (c) Within each branch of τF (v), we interpolate to compute the gradient
∇vτF (v). (d) Finally, by applying the Fermat ﬂow equation (7), we reconstruct from each branch a set of points, either on
the boundary (branch τF ,1 (v), blue) or at the interior (branch τF ,2 (v), red) of the NLOS shape.

We ﬁrst deﬁne the Fermat pathlength function τF (v):

τF (v) = {τ : I (τ ; v) is discontinuous} .

(6)

As each transient I (τ ; v) can be discontinuous at more than
one pathlengths, τF (v) is a multi-valued function. We now
prove the following property for this function.

Proposition 5. Consider a branch of the Fermat pathlength
function τF (v) evaluated at v ∈ V. Assume that there is a
unique point xF ∈ F (v) with τ (xF ; v) = τF (v). Then,

∇vτF (v) = −2

xF − v
kxF − vk

.

(7)

We provide the proof in the supplement. It is instructive
to consider the case of the branch of τF (v) corresponding
to the global minimum of τ (x; v). This branch is the path-
length of the ﬁrst-returning photons of Tsai et al. [46], and
is also equal to twice the distance function D (v, X ), where

D (v, X ) , minx∈X kx − vk .

(8)

Then, Equation (7) is equivalent to the well-known eikonal
equation for distance functions [30, 40, 39]. In this con-
text, the uniqueness requirement of Proposition 5 is equiva-
lent to a requirement that the minimizer of Equation (8) be
unique, which is also a requirement for the eikonal equation.
Proposition 5 generalizes the eikonal equation to apply to all
branches of τF (v), corresponding to all stationary points of
τ (x; v) and not only those for ﬁrst-returning photons.

Using τF (v) = 2 kxF − vk, we rewrite Equation (7) as

xF = v − (τF (v) /4)∇vτF (v) .

(9)

In this form, the Fermat ﬂow equation states that an NLOS
point xF ∈ F (v) generating a Fermat path can be uniquely
reconstructed from the corresponding visible point v, the
length τF (v), and the gradient ∇vτF (v). This recon-
struction can be done with a simple geometric operation,

by intersecting the sphere Sph (τF (v) /2; v) with the line
v − λ∇vτF (v) /2.
If the Fermat path is also specular,
xF ∈ S (v), then we can also reconstruct the normal at xF
as ˆn (xF ) = −∇vτF (v) /2. This is shown in Figure 4.
Non-confocal case. We describe here a similar proposition
for the non-confocal case, which we prove in the supple-
ment. In this case, the Fermat pathlength function has two
arguments, τF (vs, vd). Then, as shown in Figure 4,

∇vi τF (vs, vd) = −

xF − vi
kxF − vik

,

(10)

where vi can be either of the two visible points vs and vd.
Gradient estimation. Using Equation (9) requires know-
ing the gradient ∇vτF (v), computed in the local coordinate
frame of the visible surface V at v. We cannot measure this
gradient directly, but we can estimate it through interpola-
tion. For simplicity, we discuss here only the case when the
visible surface V is planar, deferring the general case for the
supplement. When the visible surface V is planar, the local
coordinate system at v can be assumed to be the x − y plane
of the global coordinate system. Given a Fermat pathlength
τF (v) at a point v, we can estimate its partial derivatives
∂τF /∂x and ∂τF /∂y by locally interpolating Fermat path-
lengths from transients measured at nearby points on the
plane. We can then infer the derivative with respect to z by
noting that Equation (7) implies that k∇vτF (v)k = 2,

∇vτF (v) =

.

(11)

∂τF
∂x

,

∂τF
∂y

,s4 −(cid:18) ∂τF
∂x (cid:19)2




−(cid:18) ∂τF

∂y (cid:19)2


(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)v

We note that Equation (11) fails when the uniqueness con-
dition of Proposition 5 is not satisﬁed. In practice, this can
only happen at isolated points v on the visible surface, cor-
responding to non-generic symmetries of the NLOS surface
X . Additionally, we note that the above interpolation pro-
cedure needs to be performed separately for each branch of
the Fermat pathlength function τF (v).

6805

Figure 6: Comparison with groundtruth. We perform
one-dimensional scans of 3D-printed objects, in a looking-
around-the-corner conﬁguration. For each object, we show
a photograph under ambient light (left), and reconstruction
results (red points) superimposed against the groundtruth
mesh used to fabricate the object (middle and right).

Surface ﬁtting. The above procedure produces an oriented
point cloud, of density comparable to the density of mea-
surements on V. We can then use algorithms that take ad-
vantage of normal information to ﬁt a surface representation
(e.g., triangular mesh) to the point cloud with increased ac-
curacy [23]. Given such an initial surface reconstruction,
in the supplement we describe an optimization procedure,
based on the theory of specular path perturbations [9, 17],
that reﬁnes the ﬁtted surface to account for possible errors
due to inaccurate estimation of the gradients ∇vτF (v).

4. Experiments

We discuss results from NLOS reconstruction experi-
ments we have performed to validate and evaluate the Fer-
mat ﬂow algorithm. All experiments are based on measure-
ments captured with two transient imaging setups, one op-
erating at picosecond and the other at femtosecond temporal
scales. We show additional experiments in the supplement.

4.1. Picosecond scale experiments

Imaging system. We use a SPAD-based transient imag-
ing system [11, 33, 31], consisting of a picosecond laser
(NKT SuperK EXW-12), a SPAD detector (MPD module),
and a time-correlated single photon counter (TCSPC, Pico-
Quant PicoHarp). The temporal binning resolution of the
TCSPC unit is 4 ps, for an absolute upper bound in depth
resolution of 1.2 mm. In practice, the resolution is lower,
because of laser and TCSPC jitter. We use galvo mirrors
to independently control viewpoint and illumination direc-
tion, and perform both confocal and non-confocal scanning
in the looking-around-the-corner setting of Figure 1(a).

Figure 7: Comparison of point cloud and surface recon-
structions. We scan a rough specular kettle, shown in the
left under ambient light. We reconstruct an oriented point
cloud, shown in the middle from two views, where points
are colored according to their normal. Finally, we ﬁt a sur-
face to the point cloud, shown to the right under two views.

Comparison with groundtruth. We fabricated small ob-
jects from CAD meshes, providing us with ground-truth
shape for comparison. The objects were painted with matte
white paint to create Lambertian reﬂectance. The objects
are approximately 15 cm in each dimension, and are placed
at a distance 25 cm from a planar visible surface. All ob-
jects are ruled surfaces, to allow reconstruction of their pro-
ﬁle from only one-dimensional scans. We capture measure-
ments under a non-confocal setting, by ﬁxing the point im-
aged by the SPAD and scanning the point illuminated by the
source along multiple horizontal lines on the visible wall.
Along each line, we scan 200 points, at a distance of ap-
proximately 1 mm from each other. Figure 6 shows point
clouds reconstructed from these measurements using the
Fermat ﬂow procedure, superimposed against the meshes
used for fabrication. The reconstructions closely reproduce
the shape of the objects, including their concave and convex
surfaces, and match the groundtruth within 2 mm.

Table-top objects. We scanned a variety of every day ob-
jects (Figures 7-8), with convex and concave geometry of
different BRDFs, including translucent (plastic jug), glossy
(bowl, vase), rough specular (kettle) and smooth specular
(sphere). Most of the objects have a major dimension of
approximately 20 − 30 cm, and are placed at a distance
of 80 cm from the visible wall. We use confocal scan-
ning with a grid of 64 × 64 points distributed in an area
of 80 cm × 80 cm on the visible wall.

Figure 7 visualizes point cloud, normal, and ﬁnal sur-
face reconstruction for one of the objects, an electrical ket-
tle with rough-specular reﬂectance. We observe that our re-
construction procedure produces a point cloud that closely
matches the shape of the object, including accurate normals
on its front surface. We note that we do not reconstruct nor-
mals at the handle of the object: This is expected, because
these parts of the object produce Fermat paths of bound-
ary, rather than specular, type, and such paths do not pro-
vide normal information. The ﬁnal ﬁtted surface further
improves the reconstruction quality. Figure 8 shows recon-

6806

(a) photograph and reconstruction of paraboloid object(b) photograph and reconstruction of sigmoid objectFigure 8: Table-top objects. We scan objects that span a variety of shapes (convex, concave) and reﬂectances (translucent,
glossy, specular). For each object, we show a photograph under ambient light, and two views of its surface reconstruction.

structions for the remaining table-top objects. In all cases,
the reconstruction closely matches the object shape, demon-
strating the ability of our algorithm to handle a variety of
complex geometry and reﬂectance combinations.

4.2. Femtosecond scale experiments

Imaging system. We use a time-domain, full-frame optical
coherent tomography system [12]. We use this system to
perform confocal scans under both the looking-around-the-
corner and looking-through-diffuser settings (Figure 1). We
use spatially and temporally incoherent LED illumination,
which allows us to combine transient imaging with diago-
nal probing [34]. In the context of confocal scanning, this
means that we can simultaneously collect transients I (τ, v)
at all points on the visible surface without scanning, as tran-
sient measurements taken at one point will not be contami-
nated with light emanating from a different point. Our im-
plementation has depth resolution of 10 µm.
Coin reconstructions. We perform experiments in
both the looking-around-the-corner and looking-through-
diffuser settings (Figure 1), where for the diffuser we use
a thin sheet of paper. In both cases, the NLOS object is a
US quarter, with the obverse side facing the visible surface.
We place the coin at a distance of 10 mm from the visible
surface, and collect transient measurements on an area of
about 40 mm × 40 mm, at an 1 MPixel grid of points. For
validation, we additionally use the same setup to directly
scan the coin without occlusion. Figure 1 shows our results.
In both cases, we can reconstruct ﬁne detail on the coin,
sufﬁcient to infer its denomination. The reconstructed de-
tail is also in close agreement with the groundtruth shape
measured with the coin directly in the line-of-sight.

5. Discussion

Reconstruction quality can additionally suffer if we do not
have sufﬁciently dense measurements for estimating Fermat
pathlength gradients through interpolation. Finally, using
only pathlength information provides BRDF invariance, but
it also means that we do not take advantage of information
available in measured intensities about the NLOS scene.

The theory we developed offers new insights into the
NLOS imaging problem, linking it to classical areas such as
specular and differential geometry, and providing ample op-
portunity for transfer of ideas from these areas to the NLOS
imaging setting. By allowing us to treat NLOS reconstruc-
tion from a purely geometric perspective, our theory intro-
duces a new methodology for tackling this problem, dis-
tinct from but complementary to approaches such as (ellip-
tic) backprojection [48, 33] and analysis-by-synthesis [47],
which focus on the radiometric aspects of the problem.

Interestingly, concurrect work [28] has unconvered an in-
triguing link between our and backprojection approaches,
by showing that the latter cannot reconstruct NLOS points
not on Fermat paths, even if those points otherwise con-
tribute to measured transients. Therefore, both approaches
reproduce the same part of the NLOS scene. Further explo-
ration of connections between the geometric and backpro-
jection approaches can help shed light into their fundamen-
tal limits and strengths, potentially by allowing us to de-
rive results applicable to both classes of approaches using
whichever mathematical framework (geometric, radiomet-
ric) is more convenient for analysis.

More broadly, an exciting future direction of research
is combining the two classes of approaches, not only for
NLOS imaging, but also for other related applications,
including acoustic and ultrasound imaging [27], lensless
imaging [50], and seismic imaging [41].

We discuss some limitations of our approach. Our re-
construction procedure does not require radiometric cali-
bration, as it does not use intensity information, instead
relying on estimation of the pathlengths where measured
transients are discontinuous. Consequently, our reconstruc-
tions can be sensitive to inaccurate discontinuity detection.

Acknowledgments. We thank Chia-Yin Tsai for valuable
discussions. This work was supported by the DARPA RE-
VEAL program under contract HR0011-16-C-0025. SX,
ACS, SGN, and IG were additionally supported by NSF Ex-
peditions award CCF-1730147. KNK was supported by the
NSERC RGPIN and RTI programs.

6807

(a) plastic jug(b) glass vase (c) plastic bowl(d) metal sphereReferences

[1] Victor Arellano, Diego Gutierrez, and Adrian Jarabo.
Fast back-projection for non-line of sight reconstruc-
tion. Optics Express, 25(10):11574–11583, 2017. 1

[2] Manel Baradad, Vickie Ye, Adam B Yedidia, Fr´edo
Durand, William T Freeman, Gregory W Wornell, and
Antonio Torralba.
Inferring light ﬁelds from shad-
ows. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition, pages 6267–
6275, 2018. 1

[3] Mufeed Batarseh, Sergey V Sukhov, Zhiqin Shen,
Heath Gemar, Reza Rezvani, and Aristide Dogariu.
Passive sensing around the corner using spatial coher-
ence. Nature communications, 9(1):3629, 2018. 1

[4] Jacopo Bertolotti, Elbert G van Putten, Christian
Blum, Ad Lagendijk, Willem L Vos, and Allard P
Mosk. Non-invasive imaging through opaque scatter-
ing layers. Nature, 491(7423):232, 2012. 1

[5] Jeremy Boger-Lombard and Ori Katz. Non line-
of-sight localization by passive optical time-of-ﬂight.
ArXiv e-prints, Aug. 2018. 1

[6] Katherine L. Bouman, Vickie Ye, Adam B. Yedidia,
Fr´edo Durand, Gregory W Wornell, Antonio Torralba,
and William T Freeman. Turning corners into cam-
eras: Principles and methods. In ICCV, 2017. 1

[7] Mauro Buttafava, Jessica Zeman, Alberto Tosi, Kevin
Eliceiri, and Andreas Velten. Non-line-of-sight imag-
ing using a time-gated single photon avalanche diode.
Optics express, 23(16):20997–21011, 2015. 1, 3

[8] Min Chen and James Arvo. Perturbation methods for
interactive specular reﬂections. IEEE Transactions on
Visualization and Computer Graphics, 6(3):253–264,
2000. 3

[9] Min Chen and James Arvo. Theory and application
of specular path perturbation. ACM Transactions on
Graphics (TOG), 19(4):246–278, 2000. 2, 7

[10] Philip Dutr´e, Kavita Bala, and Philippe Bekaert. Ad-
vanced global illumination. AK Peters, Ltd., 2006. 3

[11] Genevieve Gariepy, Nikola Krstaji´c, Robert Hender-
son, Chunyong Li, Robert R Thomson, Gerald S
Buller, Barmak Heshmat, Ramesh Raskar, Jonathan
Leach, and Daniele Faccio.
Single-photon sensi-
tive light-in-ﬁght imaging. Nature communications,
6:6021, 2015. 1, 7

struction of hidden 3d shapes using diffuse reﬂections.
Optics express, 20(17):19096–19108, 2012. 1

[14] Felix Heide, Matthew O’Toole, Kai Zhang, David Lin-
dell, Steven Diamond, and Gordon Wetzstein. Robust
non-line-of-sight imaging with single photon detec-
tors. arXiv preprint arXiv:1711.07134, 2017. 1

[15] Felix Heide, Lei Xiao, Wolfgang Heidrich, and
Matthias B Hullin. Diffuse mirrors: 3d reconstruc-
tion from diffuse indirect illumination using inexpen-
sive time-of-ﬂight sensors. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recogni-
tion, pages 3222–3229, 2014. 1

[16] Quercus Hernandez, Diego Gutierrez, and Adrian
Jarabo. A computational model of a single-photon
avalanche diode sensor for transient imaging. arXiv
preprint arXiv:1703.02635, 2017. 1, 5

[17] Wenzel Jakob and Steve Marschner. Manifold explo-
ration: A markov chain monte carlo technique for ren-
dering scenes with difﬁcult specular transport. ACM
Transactions on Graphics, 2012. 3, 7

[18] Adrian Jarabo, Julio Marco, Adolfo Mu˜noz, Raul
Buisan, Wojciech Jarosz, and Diego Gutierrez. A
Framework for Transient Rendering. ACM Trans.
Graph., 33(6):177:1–177:10, Nov. 2014. 1

[19] Adrian Jarabo, Belen Masia, Julio Marco, and Diego
Gutierrez. Recent advances in transient imaging: A
computer graphics and vision perspective. Visual In-
formatics, 1(1):65–79, 2017. 2

[20] Achuta Kadambi, Hang Zhao, Boxin Shi, and Ramesh
Raskar. Occluded imaging with time-of-ﬂight sen-
sors. ACM Transactions on Graphics (ToG), 35(2):15,
2016. 1

[21] Ori Katz, Pierre Heidmann, Mathias Fink, and Syl-
vain Gigan. Non-invasive single-shot imaging through
scattering layers and around corners via speckle corre-
lations. Nature photonics, 8(10):784, 2014. 1

[22] Ori Katz, Eran Small, and Yaron Silberberg. Looking
around corners and through thin turbid layers in real
time with scattered incoherent light. Nature photonics,
6(8):549–553, 2012. 1

[23] Michael Kazhdan, Matthew Bolitho, and Hugues
Hoppe. Poisson surface reconstruction. In Proc. Euro-
graphics Symposium on Geometry Processing, pages
61–70, 2006. 2, 7

[12] Ioannis Gkioulekas, Anat Levin, Fr´edo Durand, and
Todd Zickler. Micron-scale light transport decom-
position using interferometry. ACM Transactions on
Graphics, 2015. 1, 8

[24] Ahmed Kirmani, Tyler Hutchison, James Davis, and
Ramesh Raskar. Looking around the corner using
ultrafast transient imaging.
International journal of
computer vision, 95(1):13–28, 2011. 1

[13] Otkrist Gupta, Thomas Willwacher, Andreas Velten,
Ashok Veeraraghavan, and Ramesh Raskar. Recon-

[25] Jonathan Klein, Christoph Peters, Jaime Mart´ın, Mar-
tin Laurenzis, and Matthias B Hullin. Tracking objects

6808

outside the line of sight using 2d intensity images. Sci-
entiﬁc reports, 6, 2016. 1

[26] Marco La Manna, Fiona Kine, Eric Breitbach,
Jonathan Jackson, and Andreas Velten. Error back-
projection algorithms for non-line-of-sight imaging. 1

[27] David Lindell, Gordon Wetzstein,

and Vladlen
Koltun. Acoustic non-line-of-sight imaging. In CVPR,
2019. 8

[28] Xiaochun Liu, Sebastian Bauer, and Andreas Velten.
Analysis of feature visibility in non-line-of-sight mea-
surements. In CVPR, 2019. 8

[29] Don Mitchell and Pat Hanrahan.

Illumination from
curved reﬂectors.
In ACM SIGGRAPH Computer
Graphics, volume 26, pages 283–291. ACM, 1992. 3

[30] Stanley Osher and Ronald Fedkiw. Level set methods
and dynamic implicit surfaces, volume 153. Springer
Science & Business Media, 2006. 6

[31] Matthew O’Toole, Felix Heide, David B Lindell, Kai
Zang, Steven Diamond, and Gordon Wetzstein. Re-
constructing transient images from single-photon sen-
sors. CVPR, 2017. 1, 7

[32] Matthew O’Toole, Felix Heide, Kai Lindell, David
B.and Zang, Steven Diamond, and Gordon Wetzstein.
Reconstructing transient images from single-photon
sensors. In CVPR, 2017. 1

[33] Matthew O’Toole, David B Lindell, and Gordon Wet-
zstein. Confocal non-line-of-sight imaging based on
the light-cone transform. Nature, 555(7696):338,
2018. 1, 2, 7, 8

[34] M. O’Toole, R. Raskar, and K.N. Kutulakos. Primal-
dual coding to probe light transport. ACM Transac-
tions on Graphics, 2012. 8

[35] Adithya Pediredla, Mauro Buttafava, Alberto Tosi,
Oliver Cossairt, and Ashok Veeraraghavan.
Re-
constructing rooms using photon echoes: A plane
based model and reconstruction algorithm for looking
around the corner. ICCP, 2017. 1, 3

[36] Adithya Pediredla, Akshat Dave, and Ashok Veer-
araghavan. Snlos: Non-line-of-sight scanning through
temporal focusing. ICCP, 2019. 1

[37] Adithya Pediredla, Ashok Veeraraghavan, and Ioannis
Gkioulekas. Elliptic path sampling for time-gated ren-
dering. ACM Transactions on Graphics (TOG), 2019.
3

[38] Charles Saunders, John Murray-Bruce, and Vivek K
Goyal. Computational periscopy with an ordinary dig-
ital camera. Nature, 565(7740):472, 2019. 1

[39] James A Sethian. Fast marching methods. SIAM re-

view, 41(2):199–235, 1999. 6

[40] James A Sethian. Level set methods and fast marching
methods: evolving interfaces in computational geom-
etry, ﬂuid mechanics, computer vision, and materials
science, volume 3. Cambridge university press, 1999.
6

[41] James A Sethian and A Mihai Popovici. 3-d traveltime
computation using the fast marching method. Geo-
physics, 64(2):516–523, 1999. 8

[42] Brandon M. Smith, Matthew O’Toole, and Mohit
Gupta. Tracking multiple objects outside the line of
sight using speckle imaging. In CVPR, 2018. 1

[43] Orestes Stavroudis. The optics of rays, wavefronts,

and caustics. Elsevier, 1972. 2, 3

[44] Matthew Tancik, Guy Satat, and Ramesh Raskar.
Flash photography for data-driven hidden scene recov-
ery. arXiv preprint arXiv:1810.11710, 2018. 1

[45] Christos Thrampoulidis, Gal Shulkind, Feihu Xu,
William T Freeman, Jeffrey Shapiro, Antonio Tor-
ralba, Franco Wong, and Gregory Wornell. Exploiting
occlusion in non-line-of-sight active imaging.
IEEE
Transactions on Computational Imaging, 2018. 1

[46] Chia-Yin Tsai, Kiriakos N Kutulakos, Srinivasa G
Narasimhan, and Aswin C Sankaranarayanan. The ge-
ometry of ﬁrst-returning photons for non-line-of-sight
imaging. In CVPR, 2017. 2, 3, 6

[47] Chia-Yin Tsai, Aswin C. Sankaranarayanan, and Ioan-
nis Gkioulekas. Beyond volumetric albedo—a surface
optimization framework for non-line-of-sight imag-
ing. In CVPR, 2019. 1, 2, 8

[48] Andreas Velten, Thomas Willwacher, Otkrist Gupta,
Ashok Veeraraghavan, Moungi G Bawendi, and
Ramesh Raskar. Recovering three-dimensional shape
around a corner using ultrafast time-of-ﬂight imaging.
2012. 1, 8

[49] Andreas Velten, Di Wu, Adrian Jarabo, Belen Ma-
sia, Christopher Barsi, Chinmaya Joshi, Everett Law-
son, Moungi Bawendi, Diego Gutierrez, and Ramesh
Raskar. Femto-photography: Capturing and Visual-
izing the Propagation of Light. ACM Trans. Graph.,
32(4):44:1–44:8, July 2013. 1

[50] Di Wu, Gordon Wetzstein, Christopher Barsi, Thomas
Willwacher, Qionghai Dai, and Ramesh Raskar. Ultra-
fast lensless computational imaging through 5d fre-
quency analysis of time-resolved light transport. Inter-
national journal of computer vision, 110(2):128–140,
2014. 8

[51] Feihu Xu, Gal Shulkind, Christos Thrampoulidis, Jef-
frey H Shapiro, Antonio Torralba, Franco NC Wong,
and Gregory W Wornell. Revealing hidden scenes by
photon-efﬁcient occlusion-based opportunistic active
imaging. Optics express, 26(8):9945–9962, 2018. 1

6809

