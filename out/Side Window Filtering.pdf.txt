Side Window Filtering

Hui Yina ∗ Yuanhao Gonga∗ Guoping Qiua,b

a College of Information Engineering and Guangdong Key Lab for Intelligent Information Processing,

Shenzhen University, China b School of Computer Science, The University of Nottingham, UK

yinhui0606@gmail.com gong@szu.edu.cn guoping.qiu@nottingham.ac.uk

Abstract

(a) Step Edge

(b) Ramp Edge

(c) Roof Edge

Local windows are routinely used in computer vision and
almost without exception the center of the window is aligned
with the pixels being processed. We show that this conven-
tional wisdom is not universally applicable. When a pixel
is on an edge, placing the center of the window on the pixel
is one of the fundamental reasons that cause many ﬁltering
algorithms to blur the edges. Based on this insight, we pro-
pose a new Side Window Filtering (SWF) technique which
aligns the window’s side or corner with the pixel being pro-
cessed. The SWF technique is surprisingly simple yet theo-
retically rooted and very effective in practice. We show that
many traditional linear and nonlinear ﬁlters can be easily
implemented under the SWF framework. Extensive analysis
and experiments show that implementing the SWF princi-
ple can signiﬁcantly improve their edge preserving capa-
bilities and achieve state of the art performances in appli-
cations such as image smoothing, denoising, enhancement,
structure-preserving texture-removing, mutual-structure ex-
traction, and HDR tone mapping. In addition to image ﬁl-
tering, we further show that the SWF principle can be ex-
tended to other applications involving the use of a local win-
dow. Using colorization by optimization as an example, we
demonstrate that implementing the SWF principle can ef-
fectively prevent artifacts such as color leakage associated
with the conventional implementation. Given the ubiquity of
window based operations in computer vision, the new SWF
technique is likely to beneﬁt many more applications.

1. Introduction

In the ﬁelds of computational photography and image
processing, many applications involve the concept of image
ﬁltering to denoise [23], deblur [8] and enhance details [9].
For decades, various ﬁlters have been developed, such as
box ﬁlter, Gaussian ﬁlter and median ﬁlter, to name a few.
These ﬁlters are widely used in image deblurring and sharp-

∗authors equally contribute to this paper

Figure 1. Model of ideal edges in 2D piecewise images. The pixel
‘a’∼‘f’ are on edges or near edges. To satisfy the linear assump-
tion, they should be approximated in the side windows which have
the same colors with them, not the local windows centered at them.

ening, edge detection and feature extraction [10].

There are many applications require image ﬁltering that
can preserve edges. Typical examples include tone mapping
of high dynamic range (HDR) images [6], detail enhance-
ment via multi-lighting images [7], and structure-preserving
and texture removing [29][30].

For this reason, many edge-preserving ﬁlters have been
proposed. Basically, these edge-preserving ﬁlters can be di-
vided into two categories. One is global optimization based
algorithms, such as the total variation (TV) algorithm [23],
its iterative shrinkage approach [17], the relative total varia-
tion algorithm [29] and the weighted least squares algorithm
[18]. The other is local optimization based algorithms, such
as bilateral ﬁlter [26], its accelerated versions [5][19][20],
guided ﬁlter [11], its extensions [15][13], rolling guidance
ﬁlter [30], mutual structure joint ﬁltering [24] and curvature
ﬁlter [9]. In general, the local based ﬁlters can be calculated
in real time. This is preferred because many real application
scenarios require real-time processing.

1.1. Filtering Fundamentals

Local based ﬁlters always attempt to estimate an output
of a pixel based on its neighbors. Almost without exception,
the pixel being processed is located at the center of an oper-
ation window and other pixels in the operation window are
its neighbors. Basically, there are two ways to do estima-
tion: linear approximation, such as box ﬁlter and Gaussian

8758

abcdefﬁlter, and non-linear approximation, such as median ﬁlter
[12], bilateral ﬁlter [26] and guided ﬁlter [11].

A common linear approximation based image ﬁltering
operation assumes that the image is piecewise linear and
approximate a pixel as the weighted average of its neighbor
pixels over a local window

I

′

i = X

j∈Ωi

ωijqj

(1)

where Ωi is the local window (support region) centered at
the pixel i, ωij denotes the weight kernel, qi and Ii are the
intensities of the input image q and the output image I at
location i, respectively.

The discrepancy between the ﬁlter output and the origi-
nal image can be formulated as the following cost function

Ei = ||Ii − I

′

i ||2

2 = (Ii − X

j∈Ωi

ωijqj)2

(2)

Different weight kernels will result in different ﬁltering out-
put images and in most cases the task of designing a ﬁltering
algorithm is that of estimating the weights. Often there is
a trade off between manipulating the input image towards
a desired target and keeping it close to the original. It is
worth noting that optimization problem of the form similar
to eq. (2) is found in many applications including coloriza-
tion [14][22] and image segmentation [25][28], where the
weight functions are usually referred to as afﬁnity functions.
Nonlinear approximation ﬁltering such as median ﬁltering
can also be formulated as a similar form of optimization
problem [21].

1.2. Problem and Motivation

In many applications that using the form of ﬁltering al-
(1), it is desired to smooth out genuine
gorithm in eq.
noise and at the same time preserve edges and other sig-
nal details. For analysis convenience, we focus our study
on three types of typical edges [4], step edge, ramp edge
and roof edge, and model them in 2D signal space as shown
in Fig. 1. We use g(x, y) to denote the intensity value at
(x, y). The functions g(x, y) shown in this ﬁgure are con-
tinuous but non-differentiable. Considering the locations
where the intensity changes (an edge), for example, at lo-
cation ‘a’. We use ‘a-’ and ‘a+’ to denote the left limit
(x − ǫ, y) and right limit (x + ǫ, y), respectively, where
ǫ > 0. Clearly, g(x − ǫ, y) 6= g(x + ǫ, y) and (or)
g′(x − ǫ, y) 6= g′(x + ǫ, y) due to the edge jump. There-
fore, the Taylor expansion at these two regions are differ-
ent: g(x − 2ǫ, y) ≈ g(x − ǫ, y) + g′(x − ǫ, y)(−ǫ) and
g(x + 2ǫ, y) ≈ g(x + ǫ, y) + g′(x + ǫ, y)ǫ. Therefore, any
approximation at location ‘a-’ must come from the left re-
gions of ‘a’ while any approximation at location ‘a+’ must
come from the right regions of ‘a’. Similar statements apply
for other edge locations such as ‘b’, ‘c’, and ‘d’ in Fig. 1.

Based on the analysis and eq. (1), if a pixel i is on an
edge, the support region Ωi must be restricted to one side of
the edge, otherwise, it is not possible to use a linear com-
bination of the neighbors to approximate i. In other words,
we cannot place the center of Ωi over i but rather we must
place the side of Ωi over i. Inspired by this discovery, a
new edge-preserving strategy, termed side window ﬁlter-
ing (SWF) technique, is proposed. We consider each target
pixel as a potential edge and generate multiple local win-
dows (named as side windows) around it, each of which
aligns the target pixel with a side or a corner (instead of the
center) of the window. The output of SWF is a linear com-
bination of the neighbors in one of the side windows which
can best approximate the target pixel.

1.3. Our Contributions

The novel contributions of this paper are:
1. Using Taylor expansion, we show that in order to re-
construct an edge pixel using a linear combination of its
neighbors, the neighbor pixels must come from one side of
the edge. Based on this insight, we propose the side win-
dow ﬁltering (SWF) technique as an effective and practical
edge preserving ﬁltering solution.

2. We show how traditional linear ﬁlters such as box
ﬁlter and Gaussian ﬁlter, popular non-linear ﬁlters such as
median ﬁlter, bilateral ﬁlter and guided ﬁlter can easily be
implemented under the SWF framework. Through exten-
sive analysis, we show that implementing these popular ﬁl-
ters based on the new SWF framework can signiﬁcantly im-
prove their edge preserving capabilities.

3. We show that the implementing traditional ﬁlters un-
der the new SWF framework provides state of the art per-
formances in a variety of real world applications includ-
ing image smoothing, denoising, enhancement, structure-
preserving texture-removing, mutual-structure extraction,
and high dynamic range image tone mapping.

4. We show that the new SWF framework can be ex-
tended to other applications involving a local window and
a linear combination of a neighborhood of pixels. Using
colorization by optimization as an example we demonstrate
that implementing the SWF principle can effectively pre-
vent artifacts such as color leakage.

5. The SWF technique is very simple but theoretically
rooted and in practice surprisingly effective. Given the
ubiquity of window based operations, the SWF principle
has the potential of beneﬁting many areas in image process-
ing and computer vision.

2. Side Window Filtering Technique

First of all we deﬁne the side window in a continuous
case. The deﬁnition of a side window is shown in Fig. 2(a),
with parameters θ and r. θ is the angle between the window
and the horizontal line, r is the radius of the window, ρ ∈

8759

(a)

(b)

(c)

(d)

Figure 2. Deﬁnition of side window. r is the radius of the window. (a) The deﬁnition of side window in continuous case. (b) The lef t
(red rectangle) and right (blue rectangle) side windows. (c) The up (red rectangle) and down (blue rectangle) side windows. (d) The
northwest (red rectangle), northeast (blue rectangle), southwest (green rectangle) and southeast (orange rectangle) side windows.

{0, r} and (x, y) is the position of the target pixel i. r is a
user-deﬁned parameter and it will be ﬁxed for all the side
windows. By changing θ and ﬁxing (x, y), we can change
the direction of the window while aligning its side with i.

i , ωR

To simplify the calculation, we only deﬁne eight side
windows in a discrete case, as shown in Fig. 2(b)∼(d).
These eight speciﬁc windows correspond to θ = k × π
2 , k ∈
[0, 3]. By setting ρ = r, we have the down(D) , right(R),
up(U ), lef t(L) side windows, denoted as ωD
i and
ωL
i . They align i with their sides. By setting ρ = 0, we have
the southwest (SW ), southeast (SE), northeast (N E) and
northwest (N W ) side windows, as shown in Fig. 2(d) and
denoted as ωSW
. They align i with
their corners. It is worth pointing out that there is signiﬁcant
ﬂexibility in designing the size, shape and orientation of the
side windows. And the only speciﬁc requirement is that the
pixel under consideration is placed on the side or corner of
the window.

and ωN W

i , ωU

, ωN E

, ωSE

i

i

i

i

Algorithm 1 Calculate the SWF for each pixel
Require: wij is the weight of pixel j, which is in the neigh-
borhood of the target pixel i, based on kernel function
F . S = {L, R, U, D, N W, N E, SW, SE} is the set of
side window index.

Nn Pj∈ωn

1: In = 1
wij, n ∈ S
2: ﬁnd Im, such that Im = argminn∈S ||qi − In||2
2
Ensure: Im

wijqj , Nn = Pj∈ωn

i

i

By applying a ﬁltering kernel F in each side window,
, where θ =

we can obtain eight outputs, denoted as I
k × π

2 , k ∈ [0, 3] and ρ ∈ {0, r}

′θ,ρ
i

I

′θ,ρ,r
i

= F (qi, θ, ρ, r)

(3)

To preserve the edges means that we want to minimize the
distance between the input and the output at an edge, i.e.,
the ﬁlter output should be the same as or as close as possible
to the input at an edge. Therefore, we choose the output of
the side window that has the minimum L2 distance to the

input intensity as the ﬁnal output,

I ′
SW F = argmin

∀I

′ θ,ρ,r
i

||qi − I

′θ,ρ,r
i

||2
2

(4)

where I ′
SW F is the output of SWF. Eq. (4) is referred to as
the SWF technique. Details of the procedure is described in
Algorithm 1.

Table 1. Summary of the output of BOX and S-BOX
Input

S-BOX

BOX

(a)

(d)

(g)

(j)

(m)

(p)

(r+1)u+rv

2r+1

(r+1)u+rv

2r+1

(r+1)u+rv

(r+1)2u+((2r+1)2−(r+1)2)v

2r+1

(2r+1)2

u + r(r+1)△v
2(2r+1)
v − r(r+1)△u

2r+1

u

u

u

u

u
v − r
2

△ u

2.1. Analysis of SWF

In this section, we present a detailed analysis of the edge-
preserving property of SWF technique. For analysis conve-
nience, we use box ﬁlter (BOX) as an example and similar
analysis can be performed on other forms of ﬁlter. This
means that F in eq. (3) is averaging and the resulting ﬁlter
is called side window box ﬁlter (S-BOX).

We compare the edge-preserving property of BOX and
S-BOX ﬁlters. First of all, testing images with typical edges
are generated, as shown in Fig. 3. There are six typical
edges, including vertical edge (a), horizontal edge (d), di-
agonal edge (g), corner (j), ramp edge (m) and roof edge
(p). For the vertical edge, horizontal edge, diagonal edge
and corner, the pixel values for the black part of the edge is
u and the white part of the edge is v. For the ramp edge, the
pixel values are increased from u to v with a step of △ v.
For the roof edge, the top of the roof is v and is decreased
with a step of △ u. Based on these conditions, the outputs
of BOX and S-BOX are deduced and the results are shown

8760

ρ(x,y)θ2r(x,y)θ=3π/2ρ=rθ=π/2ρ=rLR(x,y)θ=πρ=rθ=0ρ=rUD(x,y)θ=0ρ=0θ=π/2ρ=0NWNESWSEθ=3π/2ρ=0θ=πρ=0(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

(m)

(n)

(o)

(p)

(q)

(r)

Figure 3. Comparing BOX and S-BOX on the testing images with different edges. The ﬁrst and forth columns (a), (g), (m), (d), (j) and (p)
are input images with edge or corner. The second and ﬁfth columns are middle line proﬁles for input, BOX ﬁlter and S-BOX ﬁlter. The
third and sixth columns are the zoomed in region at the edge or corner location.

Table 2. Summary of the output of each side window in S-BOX

U

D

NW

Case

(a)

(d)

(g)

(j)

(m)

(p)

L

u

(r+1)u+rv

R

u+rv
r+1

(r+1)u+rv

2r+1

( 3r

2 +1)u+ r

2

v

2r+1

( r
2 +1)u+ 3r

2

(r+1)u+rv

(r+1)u+rv

2r+1

u

v

( 3r

2 +1)u+ r

2

v

2r+1
u+rv
r+1

( r
2 +1)u+ 3r

2

v

2r+1

(r+1)u+rv

2r+1

u

r

2

△ u

v −

2r+1
u+2rv
2r+1

u + r
2

v −

r

2

△ v

△ u

2r+1

(r+1)u+rv

2r+1

2r+1
u+2rv
2r+1

u + r(r+1)△v
2(2r+1)
r(r+1)△u

v −

2r+1

u + r(r+1)△v
2(2r+1)
r(r+1)△u

v −

2r+1

u

u

u

u

u

v − r
2

△ u

NE
u+rv
r+1
u

( r
2 +1)u+ r

2

v

r+1
u+rv
r+1
+ r
2
△ u

r

2

△ v

u

r+1
v −

SW

u

u+rv
r+1

( r
2 +1)u+ r

2

r+1
u+rv
r+1
u

v −

r

2

△ u

SE
u+rv
r+1
u+rv
r+1

v

((r+1)2

−1)v+u

(r+1)2

((r+1)2

−1)v+u

(r+1)2

u

r+1
v −

△ v

+ r
2
△ u

r

2

in Table 1. From Table 1, we can easily see that S-BOX bet-
ter preserves the edges in (a)∼(m) than BOX. It is also easy
2 < r(r+1)
to prove r
2r+1 , so S-BOX can better preserve the roof
edge than BOX, too.

In order to observe the details of the edge-preserving
property of each side window in S-BOX, the output of each
side window is shown in Table 2. The results which pre-
serve the edges are shown in bold. We can make the follow-
ing observations:

• the L, N W, SW side windows can preserve the edges
on the left of the vertical edge. It is easy to deduce that
the R, N E, SE side windows can preserve the edges
on the right of the vertical edge.

• the U, N W, N E side windows can preserve the edges
above the horizontal edge. Again, it is easy to de-
duce that the D, SW, SE side windows can preserve

the edges below the horizontal edge.

• the N W side window can preserve the edges above the
diagonal edge and on the corner. It is easy to deduce
that the N E, SW, SE side windows can preserve the
diagonal edges and corner with other directions.

• the L, N W, SW side windows can preserve the ramp

edge.

• although the side windows can not preserve the roof
edge completely, seven of them have better results than
BOX.

We also show the experimental results in Fig. 3. In the
experiments, we set u = 0, v = 1 and r = 7. One line (or
column or diagonal) of pixels is extracted from each result
and zoomed in. The results are consistent with the theoreti-
cal deduction. Visually, the sharp edges are smoothed away
by BOX while preserved very well by S-BOX.

8761

010020030040050000.20.40.60.81inputBOXS-BOX220240260280-0.0500.050.10.150.20.250.3inputBOXS-BOXBOXinputS-BOX010020030040050000.20.40.60.81inputBOXS-BOX20025030000.10.20.30.4inputBOXS-BOXBOXinputS-BOX010020030040050000.20.40.60.81inputBOXS-BOX220240260280300-0.0500.050.10.150.20.250.3inputBOXS-BOXBOXinputS-BOX010020030040050000.20.40.60.81inputBOXS-BOX200220240260280300-0.0500.050.10.150.20.250.3inputBOXS-BOXBOXinputS-BOX010020030040050000.20.40.60.81inputBOXS-BOX115120125130135140-0.0100.010.020.030.04inputBOXS-BOXBOXinputS-BOX010020030040050000.20.40.60.81inputBOXS-BOX2452502552602650.950.960.970.980.9911.01inputBOXS-BOXBOXinputS-BOX(a) Input

(b) BOX vs. S-BOX

(c) GAU vs. S-GAU

(d) MED vs. S-MED

(e) BIL vs. S-BIL

(f) GUI vs. S-GUI

Figure 4. Image smoothing (r = 7, σ = 4 for GAU and S-GAU, σs = 7, σr = 0.3 for BIL and S-BIL, ǫ = 0.1 for GUI and S-GUI). The
upper left part of each result is from the traditional ﬁlter and the zoomed in patch is with red rectangle. The lower right part of each result
is from the side window version and the zoomed in patch is with green rectangle. The number shown on each image is the SSIM[27] value.

(a) Input

(b) BOX vs. S-BOX

(c) GAU vs. S-GAU

(d) MED vs. S-MED

(e) BIL vs. S-BIL

(f) GUI vs. S-GUI

Figure 5. Image denoising (r = 10, σ = 5 for GAU and S-GAU, σs = 10, σr = 0.3 for BIL and S-BIL, ǫ = 0.1 for GUI and S-GUI,
iteration = 5 ). The left part of each result is from the traditional ﬁlter and the zoomed in patch is with red rectangle. The right part of
each result is from the side window version and the zoomed in patch is with green rectangle. The number shown on each image is PSNR.

3. Popular Filters under the SWF Framework

By changing F to other kernels, one can easily embed
the side window technique into other ﬁlters.
In this sec-
tion, we will discuss how to embed side window technique
into Gaussian ﬁlter, median ﬁlter, bilateral ﬁlter and guided
ﬁlter. To simplify expression, the ﬁlters’ name are abbrevi-
ated by their ﬁrst three letters and their SWF versions are
abbreviated by adding another ‘S-’. For example, the Gaus-
sian ﬁlter and side window Gaussian ﬁlter are abbreviated
as GAU and S-GAU, respectively.

In S-GAU, F is a half of or a quarter of the Gaussian
kernel. Because the kernel of GAU crosses over the poten-
tial edges, it may blur the edges. By contrast, the kernel of
S-GAU alleviates this problem so it can better preserve the
edges.

In S-MED, F is the operation of calculating the median
value. Since the output has the minimal distance from the
input intensity, S-MED can better preserve the edges than
MED. That is, it selects a window under which the median
of the pixels is closest to the input.

In S-BIL, the kernel is calculated based on the geometric
closeness and photometric similarity as in BIL. Since S-BIL
can prevent the diffusion from crossing the edges, it can
improve the edge-preserving property of BIL.

GUI averages the values of the parameters in all the win-

dows that cover the target pixel. Again, this operation may
blur potential edges. To avoid this problem, S-GUI ensures
that the side windows do not cross over the target pixel. It
slides each side window along its side on which the target
pixel is located until the target pixel is outside of the side
window. In this way, 2r + 1 sliding windows are obtained
for the L, R, U, D side window and averaged to obtain the
outputs of these side windows. For the N W, N E, SW, SE
side windows, sliding can only get one output for each. The
ﬁnal output is chosen according to eq. (4).

4. Applications

In this section, the side window technique is applied to
various image processing applications and its performance
is compared with traditional ﬁlters and methods. More re-
sults are presented in the Supplement. The images are best
viewed electronically on a high resolution monitor.

4.1. Image smoothing

Fig. 4 shows the smoothing results of the ﬁlters on an
image [2]. The upper left part of each result is from the tra-
ditional ﬁlter and the zoomed in patch is with red rectangle.
The lower right part of each result is from the side window
version and the zoomed in patch is with green rectangle. As
can be seen, the corresponding side window ﬁlter outper-

8762

(a) Input

(b) BIL

(c) GUI

(a) BIL

(b) GUI

(c) S-BIL

(d) S-GUI

(d) S-BIL

(e) S-GUI

Figure 6. Image enhancement (σs = 7, σr = 0.3 for BIL and S-
BIL, r = 7, ǫ = 0.1 for GUI and S-GUI). The number shown on
each image is the SSIM value.

forms the original ﬁlter in preserving edges. This is more
clearly shown in the zoomed in patches that the side win-
dow ﬁlters can better preserve the tiger’s whiskers. When
comparing the non-linear ﬁlters, this improvement is also
obvious. This means that the side window technique can
also improve the edge-preserving property of non-linear ﬁl-
ters. This shows the potential for the side window technique
to be widely used in more applications.

4.2. Image denoising

Fig. 5 shows the results of iteratively applying differ-
ent ﬁlters to remove noise of a low light image [3]. The
left part of each result is from the traditional ﬁlter and the
zoomed in patch is with red rectangle. The right part of
each result is from the side window version and the zoomed
in patch is with green rectangle. BOX, GAU, MED, BIL
and GUI remove the noises but blur the edges at the same
time. On the other hand, the side window version of these
ﬁlters can preserve edges and remove noises at the same
time. These results further demonstrate the excellent edge
preserving property of the new side window technique.

Figure 7. HDR tone mapping (σs = 5, σr = 0.3 for BIL and
S-BIL, r = 5, ǫ = 0.1 for GUI and S-GUI).

4.3. Image enhancement

Image enhancement is often performed in image pro-

cessing [11][15]. An enhanced image can be obtained by

Enhanced = q + α × (q − I

′

)

(5)

where α is an ampliﬁcation parameter and is ﬁxed to 5 in
all the experiments in this section. An example of image
enhancement result is shown in Fig. 6. From the zoomed
in patches, we can see that the halo artifacts exist along the
edges in the results of the ﬁlters without implementing the
side window technique. However, the artifacts have dis-
appeared in the results of the side window versions of the
ﬁlters. This can once again be attributed to the excellent
edge-preserving property of the side window technique.

4.4. HDR tone mapping

In [5] a technique based on bilateral ﬁlter was proposed
for displaying HDR images, which reduces the dynamic
range while preserving detail. Brieﬂy the operation works
as follows:

I ′ = γ × qb + qd

(6)

qb is the bilateral ﬁlter output, qd is the difference between
the original HDR radiance map and qb, and γ ∈ (0, 1) is the
compression factor which determines the scale of dynamic
range compression. For speciﬁc details please refer to [5]
and their companion website [1].
In this experiment, we
replace BIL and GUI by their side window versions.

8763

(a) Input

(b) RTV

(c) RGF

(d) IWGF

(e) IS-WGF

Figure 8. Structure-preserving and texture-removing on natural image from BSR Dataset (r = 5, ǫ = 0.005, iteration = 10, λ = 100).
The number shown on each image is the SSIM value.

Fig. 7 shows examples of the results. From the zoomed
in patches, we can see that halo artifacts exist in the results
of ﬁlters without side window technique, while they do not
exist in the results of their side window ﬁlters. These results
can once again be attributed to the good edge-preserving
property of SWF.

4.5. Structure-preserving and texture-removing on

natural image

The goal of this application is to extract image structures
and remove the textures [29]. The side window technique
is embedded into the weighted guided ﬁlter (WGF) [15] to
form a new ﬁlter called S-WGF. By combining WGF and S-
WGF in the iteration framework of [30], we propose a new
structure-preserving texture-removing ﬁlter, termed iterated
side window weighted guided ﬁlter (IS-WGF). In this ﬁlter,
an edge-aware weight [15] and a threshold λ is used to eas-
ily distinguish structures from textures. The structures are
preserved by S-WGF and textures are removed by WGF.

IS-WGF is compared with iterated weighted guided ﬁl-
ter (IWGF), relative total variance (RTV) [29] and rolling
guidance ﬁlter (RGF) [30]. IWGF is obtained by combin-
ing WGF with the iterative framework of [30], RTV is the
state of art of this application and RGF is the original algo-
rithm in [30]. They are applied to smooth natural images
with obvious textures and structures, as shown in Fig. 8(a).
It is chosen from the BSR Dataset [16]. The wave in the
sea is viewed as textures and the sailing boat on the sea
is viewed as structures. From the results we can see that
only IS-WGF can preserve the structures while all other ﬁl-
ters fail. This example demonstrates the excellent structure-
preserving property of side window technique.

4.6. Mutual structure extraction

In this section, the S-WGF is applied to the iteration
framework of [24], which was proposed to extract struc-
tures co-existed in a reference image and a target image,
to form a new ﬁlter termed Mutual-struture S-WGF (MS-
WGF). The method in [24] is referred to as MJF. We apply
MJF and MS-WGF to extract the mutual structures of an

RGB image and a depth image. The results are shown in
Fig. 9. The results of MJF is obtained with 20 iterations
(without post processing by median ﬁlter) and the results
of MS-WGF is obtained with 10 iterations. These results
demonstrate that with fewer iterations, MS-WGF performs
as well as MJF. Moreover, the results on the depth image of
MS-WGF is smoother than that of MJF and the non-mutual
structures on the bear’s face are removed more thoroughly
by MS-WGF.

(a) Input

(b) MJF

(c) MS-WGF

Figure 9. Mutual structure extraction on depth and RGB image
pairs (r = 5, ǫ = 0.05, iteration = 10, λ = 1000).

4.7. Colorization

In addition to image ﬁltering, our new side window tech-
nique can also be used to improve other local patch based
algorithms, such as colorization by optimization [14]. The
algorithm works in the Y U V color space. For a given inten-
sity channel Y (i) as input, the algorithm outputs two color
channels U (i) and V (i), where i denotes a particular pixel,
through optimizing the following cost function

8764

J(U ) = X

i

(cid:16)U (i) − X

j∈N (i)

ωijU (j)(cid:17)2

(7)

To implement the above colorization by optimization
method in the SWF framework, we simply change the
neighborhood N (i) to a side window of i (denoted to as
Ns(i)) and keep all other aspects of the algorithm intact.
Instead of a neighborhood centered on i, we choose a suit-
able side window Ns(i) that aligns its side or corner with i.
For each pixel, the best side window is chosen with a box
ﬁltering kernel (eq. 4).

Experiments have been carried out based on the image
data and code provided in the web page of the authors of
[14]. Some results are shown in Fig. 10. From the zoomed
in patches, we can see that color leakage exists in the orig-
inal method. But it is avoided when the original method is
embedded with the side window technique. This is owing
to the edge-preserving property of side window technique
and demonstrating the wider applicability of the new side
window technique.

Table 3. The computational time on images with 1 mega pixels
GUI
0.131
0.431

BOX GAU MED BIL
8.69
0.052
0.215
26.2

Method
Original

0.023
0.23

SWF version

1.16
3.67

5. Complexity Analysis

The order of complexity of side window based ﬁlters is
the same as the original ﬁlters. However, as the SWF im-
plementation needs to perform calculations over multiple
windows, its computational cost is higher. Our experiments
without code optimization are conducted on a computer
with a 3.5GHz Intel core Xeon(R) CPU. For gray-scale im-
ages with 1 mega pixels, the computational time of the ﬁl-
ters are shown in Table 3. The BIL is the original algorithm
in [26] without modiﬁcation for acceleration. With code op-
timization and implementing GPU programming, the com-
putational speed can be signiﬁcantly improved. Our code
will be made available publicly after the paper is published.

(a) Input

(b) method in [14]

(c) ours

6. Conclusion

Window based processing is one of the most common
operations in computer vision. Traditional practices almost
always align the center of the window with the pixel under
processing.
In this paper, we show that this widely used
practice is not always the best solution. We show that in
many applications, the side or the corner of the operation
window instead of the center should be aligned with the
pixel under processing and propose the side window ﬁl-
tering (SWF) technique. We have shown that many pop-
ular linear and non-linear ﬁltering algorithms can be imple-
mented based on this principle and the SWF implementa-
tion of these traditional ﬁlters can signiﬁcantly boost their
edge preserving capabilities. We have further shown that
the SWF principle can be extended to other computer vi-
sion problems that involve a local operation window and
a linear combination of the neighbors in this window such
as colorization by optimization. We have shown that SWF
technique can improve their performances and avoid arti-
facts such as color leakage that is often associated with
such algorithm. Window based operations is extensively
used in many areas of computer vision and machine learn-
ing including convolutional neural networks (CNNs). The
SWF principle, i.e., aligning the edge or corner of the opera-
tion window with the pixel being processed, although seem-
ingly trivial, is actually deeply rooted in the fundamental
assumptions of many algorithms. Our theoretical analysis
and state of the art results for many real world applications
have demonstrated its effectiveness. We believe that there
are many more applications can beneﬁt from implementing
the SWF principle.

8765

(d) Input

(e) method in [14]

(f) ours

Figure 10. Colorization (r = 3). Color leakage existed in the
original method is avoided by implementing the method under the
SWF framework.

References

[1] https://people.csail.mit.edu/fredo/publi/siggraph2002/.
[2] E. Agustsson and R. Timofte. Ntire 2017 challenge on sin-
gle image super-resolution: Dataset and study. In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) Workshops, July 2017.

[3] J. Anaya and A. Barbu. Renoir - a dataset for real low-light
image noise reduction. Journal of Visual Comm. and Image
Rep, 51(2):144–154, 2018.

[4] H. Chidiac and D. Ziou. Classiﬁcation of image edges. Vi-

sion Interface.

[5] F. Durand and J. Dorsey. Fast bilateral ﬁltering for the dis-
play of high-dynamic-range images. ACM Trans. on Graph-
ics, 21(3):257–266, 2002.

[6] Z. Farbman, R. Fattal, D. Lischinshi, and R. Szeliski. Edge-
preserving decompositions for multi-scale tone and detail
manipulation. ACM Trans. on Graphics, 27(3):67:1–67:10,
2008.

[7] R. Fattal, M. Agrawala, and S. Rusinkiewicz. Multiscale
shape and detail enhancement for multi-light image collec-
tion. ACM Trans. on Graphics, 26(3):211–215, 2007.

[8] Y. Gong and I. Sbalzarini. A natural-scene gradient distri-
bution prior and its application in light-microscopy image
processing. IEEE Journal of Selected Topics in Signal Pro-
cessing, 10(1):99–114, 2016.

[9] Y. Gong and I. Sbalzarini. Curvature ﬁlters efﬁciently re-
IEEE Trans. Image Pro-

duce certain variational energies.
cess, 26(4):1786–1798, 2017.

[10] R. Gonzalez and R. Woods. Digital image processing.
[11] K. He, J. Sun, and X. Tang.

Guied image ﬁltering.
IEEE Trans. On Pattern Analysis and Machine Learning,
35(6):1397–1409, 2013.

[12] T. Huang, G. Yang, and G. Tang. A fast two-dimensional
median ﬁltering algorithm. IEEE Transactions on Acoustics,
Speech and Signal Processing.

[13] F. Kou, W. Chen, C. Wen, and Z. Li. Gradient domain guided
image ﬁltering. IEEE Trans. Image Process, 24(11):4528–
4539, 2015.

[14] A. Levin, D. Lischinski, and Y. Weiss. Colorization using op-

timization. ACM Trans on Graphics, 23(3):689–694, 2004.

[15] Z. Li, J. Zheng, Z. Zhu, W. Yao, and S. Wu. Weighted guided
image ﬁltering. IEEE Trans. Image Process, 24(1):120–129,
2015.

[16] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of
human segmentation algorithms and its application to eval-
uating segmentation algorithms and measuring ecological
statistics. Proc. 8th Int’l Conf. Computer Vision, 2.

[17] O. Michailovich. An iterative shrinkage approach to total-
IEEE Trans. Image Process,

variation image restoration.
20(5):1281–1299, 2011.

[18] D. Min, S. Choi, J. Lu, B. Ham, K. Sohn, and M. Do. Fast
global image smoothing based on weighted least squares.
IEEE Trans. Image Process, 23(12):5638–5653, 2014.

[19] S. Paris and F. Durand. A fast approximation of the bilateral

ﬁlter using a signal processing approach. ECCV.

[20] F. Porikli. Constant time o(1) bilateral ﬁltering. CVPR.

[21] G. Qiu. Functional optimization properties of median ﬁlter-

ing. IEEE Signal Processing Letters, 1(4):64–65, 1994.

[22] G. Qiu and J. Guan. Color by linear neighborhood embed-
ding. IEEE International Conference on Image Processing.
[23] L. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation

based noise removal algorithms. Physica D, 60.

[24] X. Shen, C. Zhou, L. Xu, and J. Jia. Mutual-structure for
joint ﬁltering. IEEE International Journal of Computer Vi-
sion, 125.

[25] J. Shi and J. Malik. Normalized cuts and image segmenta-
tion. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 22(8):888–905, 2000.

[26] C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and

color images. ICCV.

[27] Z. Wang, A. Bovik, and H. Sheikh.

ment: from error visibility to structural similarity.
Trans. on Image Processing, 13(4):600–612, 2004.

Image quality assess-
IEEE

[28] Y. Weiss. Segmentation using eigenvectors: A unifying view.

ICCV.

[29] L. Xu, Q. Yan, Y. Xia, and J. Jia. Structure extraction from
texture via relative total variation. ACM Trans. on Graphics,
31(6):139:1–139:10, 2012.

[30] Q. Zhang, X. Shen, L. Xu, and J. Jia. Rolling guidance ﬁlter.

ECCV.

8766

