Which Way Are You Going? Imitative Decision Learning for Path Forecasting in

Dynamic Scenes

Yuke Li

York University, Toronto, Canada

AutoNavi, Alibaba Group, Beijing, China

ykleewh@yorku.ca

Abstract

Possibility 1

Possibility 2

Possibility 3

Path forecasting is a pivotal step toward understanding
dynamic scenes, and it is an emerging topic in the computer
vision ﬁeld. This task is challenging due to the multimodal
nature of the future, namely, there is more than one plausi-
ble prediction given histories. Yet, the state-of-the-art meth-
ods do not seem to be adequately responsive to this innate
variability. Hence, how to better foresee the forthcoming
trajectories in dynamic scenes has to be more thoroughly
pursued. To this end, we propose a novel Imitative Decision
Learning (IDL) approach. It delves deeper into the key that
inherently characterizes the multimodality – the latent deci-
sion. The proposed IDL ﬁrst infers the distribution of such
latent decisions by learning from moving histories. A policy
is then generated by taking the sampled latent decision into
account to predict the future. Different plausible upcoming
paths correspond to each sampled latent decision. This ap-
proach signiﬁcantly differs from the mainstream literature
that relies on a predeﬁned latent variable to extrapolate
diverse predictions. In order to augment the understand-
ing of the latent decision and resultant multimodal future,
we investigate their connection through mutual information
optimization. Moreover, the proposed IDL integrates spa-
tial and temporal dependencies into one single framework,
in contrast to handling them with two-step settings. As a
result, our approach enables simultaneous anticipating the
paths of all pedestrians in the scene. We assess our pro-
posal on the large-scale Stanford Aerial Pedestrian (SAP),
ETH and UCY datasets. The experiments show that IDL in-
troduces considerable marginal improvements with respect
to recent leading studies.

1. Introduction

Path forecasting in dynamic scenes has surged as an in-
triguing topic because of the rising demands of emerging
applications of artiﬁcial intelligence. For instance, robots
and autonomous vehicles are required to react ``smartly´´as

Figure 1. The multimodal nature of future paths in a dynamic
scene: There are multiple plausible forthcoming paths (the dash
red and cyan lines) based on identical historical moving records
(the solid red and cyan lines). In this ﬁgure, we display three pos-
sibilities as an example.

humans to their fast evolving environments. Thus, equip-
ping them with the capability to forecast what will happen
in the near future is imperative.

Forecasting a future path refers to discerning an un-
known upcoming trajectory by accessing records of prior
movements.
It entails effectively and efﬁciently process-
ing the complex spatial dependencies (interactions among
persons) and temporal dependencies (evolving motion pat-
terns). Therefore, path forecasting is regarded as a multi-
faceted and complicated endeavor.

One issue that has been challenging for the task of path
forecasting in dynamic scenes is the multimodal nature of
the future: Given a set of historical observations, there
will be more than one probable future (see Fig.1). Despite
tremendous accomplishments that has been made to foresee
a deterministic future[1, 44, 26, 45, 25], the majority of the
existing studies fail to consider the multiple possibilities of
future.

To date, state-of-the-art research has attempted to alle-
viate the issue of modeling this multimodality based on a
predeﬁned latent variable z ∼ N (0, 1). For instance, So-
cial GAN [11] takes z as a part of the inputs. It encourages
a diverse set of predictions by using a random sampled z
for each forward pass. Lee et al. present the DESIRE [16]
that approximates the distribution of future trajectories to
the distribution of z. Nevertheless, to predeﬁne z on the
basis of N (0, 1) is probably not able to fully assimilate the
various factors affect the human trajectories within the dy-
namic scenes, such as the spatial and temporal dependen-

1294

cies. The multimodal predictions of aforementioned studies
might be compromised due to this point. Hence, the ques-
tion of how to construct a framework that can better foresee
the multimodal future remains an open challenge. Address-
ing this issue, rather than merely evoking a latent variable,
we propose delving deeper into the substantial factor char-
acterizing the multimodal future that has largely been ne-
glected by previous works:

• Latent decision: The latent human decision internally
determines the motion pattern of a person step by step to
carve out the trajectory.

Our key insight is that the trajectory of a person is the
outcome of his/her decisions, which are made upon all the
related elements in dynamic scenes (e.g. the spatiotempo-
ral dependencies). Exploring the latent decision leads to a
richer understanding concerning the multimodality of future
paths at a certain semantic level: The different plausible fu-
ture moving course essentially accounts for each decision.
Fig.1 presents an example to support our claim – a pedes-
trian may make different decisions and choose one route
among all the possibilities. Thus, we propose investigat-
ing and mimicking the underlying human decision-making
process to foresee the probable upcoming paths in dynamic
scenes. Toward this end, we present a novel approach to the
path forecasting problem, namely Imitative Decision Learn-
ing (IDL) based on the perspective of Generative Adversar-
ial Imitation Learning (GAIL) [13]. Speciﬁcally, we ﬁrst
infer the distribution that corresponds to the latent decisions
from historical observations, which consist of abundant in-
formation of how human decisions were made in dynamic
scenes. The policy generating process then takes the sam-
pled latent decision into consideration to perform forecast-
ing. The connection of the latent decision to generated pol-
icy is augmented with the aid of optimizing their mutual in-
formation [5, 7]. Consequently, this optimization will yield
informative feedback that highlights the intrinsic impact of
the latent decision on the multimodal future paths. It is also
noteworthy that the latent decision is learned in an unsuper-
vised manner without any annotations.

Additionally, another common denominator of ap-
proaches with a predeﬁned latent variable [11, 16] is that
spatial and temporal dependencies are independently han-
dled. These approaches assign a Long-short Term Memory
(LSTM) to each person to obtain temporal information, and
subsequently assign a social pooling term for spatial infor-
mation. These methods overlook the fact that spatial and
temporal information generally co-occur and affect each
other. For example, in a dynamic scene, one person chang-
ing the direction of moving might cause another person fol-
lowing him/her to change direction or slow down to avoid
collision. Therefore, these two parts are better jointly tied
into a single model. In this study, our work enables pro-
cessing the spatiotemporal dependencies at one shot. This

setting also offers the capability of forecasting the paths of
all people in dynamic scenes simultaneously.

In summary, the contributions of our work are:

1. We introduce a novel Imitative Decision Learning to
the task of path forecasting in dynamic scenes. The
proposed IDL delves deeper into the latent human de-
cision to cover the space of diverse plausible future
paths.

2. Our IDL can accommodate spatio-temporal dependen-
cies in a single pass. Further, it allows to simultane-
ously predict the future trajectories for all persons in
dynamic scenes.

3. We evaluate the proposed model on challenging large-
scale video datasets, and show that signiﬁcant gains
can be attained with respect to trending works.

To the best of our knowledge, our work is the ﬁrst study to
imitate the underlying human decision-making process to
uncover multimodality in the context of anticipating future
paths in dynamic scenes.

The remainder of this paper is organized as follows:
First, relevant works are discussed in Section 2. Section 3
details the framework of the proposed IDL. Section 4 con-
ducts the experimental ﬁndings and discussions. Finally, we
conclude in Section 5.

2. Related Work

The relevant literature has accumulated some efforts to
overcome the challenges of path forecasting. The pioneer-
ing work [15] exploited the semantics of a single-person
scenario in order to build a trajectory forecasting model.
This work inspired some early studies that tried to solve the
problem of path forecasting with scene-dependent motion
patterns and handcrafted features, such as [2, 42, 47, 3, 35].
However, this raises a question about the applicability of
these algorithms to different scenes.

Some studies focus on building a generalized predic-
tive network for dynamic scenes motivated by data driven
deep neural networks [8]. For instance, Behavior CNN
[46] and FaF CNN [26] developed 3D Convolutional Neural
Network (CNN) [14] based approaches for path predicting.
Alahi et al. [1] proposed modeling the individual motion
dynamic by assigning one LSTM [38] per pedestrian. Fur-
thermore, a social pooling layer was adopted for processing
spatial dependencies. The similar ideas are considered by
the authors of [39, 45] with more sophisticated spatial in-
formation handling layers. Li. et al.
[18, 19] attempted
to processing the spatiotemporal information at the same
time. The works of [22, 40, 48, 27] built networks upon
ResNet [12, 50] and LSTM to predict highway trafﬁc ﬂow
for preventing potential accidents. The methods presented
in [28, 34] learned a reward correlated to the scene layout
to ﬁnd the best strategy for future trajectory constructions.

295

Nevertheless, a shared deﬁciency of these studies is that
they are only able to predict a deterministic future path. In
other words, the multimodal nature has not been taken into
their considerations.

Recent generative models [9, 37] achieve cutting-edge
performances on the task of synthesizing diverse images
[29, 43, 6, 41, 20].
Inspired by these models, several
recent approaches mitigated the issue of capturing multi-
ple possibilities by harnessing a predeﬁned latent variable
z ∼ N (0, 1), then incorporating it with generative net-
works. Gupta et al. [11] developed an approach to simu-
late multiple possible predictions based on perceiving the z
along with past moving records. The authors of [16] con-
sidered deriving the distribution of the future path that is an
approximation of N (0, 1). A major shortcoming of the re-
search mentioned earlier is that z is predeﬁned by N (0, 1)
in the absence of proper reasoning and justiﬁcation. There-
fore, the prior works might inadequately fully digest the
context of dynamic scenes and might fail to model the in-
herent multimodality of future.

Moreover, previous research involving z separately pro-
cessed the spatial and temporal information. Their out-
comes might be affected by not considering that these two
components are dependent on each other. Thus, it is better
to handle the spatiotemporal dependencies together.

In this study, we propose a novel IDL framework for path
forecasting in dynamic scenes, which explores the latent de-
cision to anticipate future paths. We would like to stress
that our work signiﬁcantly differs from the existing studies
on path forecasting with following facts: (1) With respect to
[11, 16], explicitly exploring the latent decision enables our
approach better capturing mutimodality, rather than utiliz-
ing a predeﬁned latent variable. (2) Unlike previous studies,
our IDL accommodates the spatial and temporal factors in
a single pass. We learn a single architecture for all persons
in a scene instead of assigning one model per person.

3. Methodology

We carry out the path forecasting concern by mimicking
the underlying human decision-making process. Subsection
3.1 introduces the problem formulation. We elaborate our
framework outlining and formally deriving our objective in
subsection 3.2. Subsection 3.3 details the implementation.

3.1. Problem Formulation

We map the labeled coordinates into a set of motion fea-
tures Xt ((t ∈ [t1, tk])) and GT t′ ((t′ ∈ [tk+1, tk+k′ ])). Xt
and GT t′ refer to the moving histories and the ground truth
future, respectively. These motion features encapsulate all
individual motion patterns through displacement informa-
tion 1. Our proposed IDL proceeds by recovering a policy π

1Please refer to the supplementary material for a detailed description of

the motion feature construction.

from Xt ((t ∈ [t1, tk])) to generate Xt′ ((t′ ∈ [tk+1, tk+k′ ]).
We produce future multimodal paths via incorporating the
latent decision S in the process of recovering policy π.

Formally, we consider IDL by extending GAIL [13].
Borrowing the notations from GAIL, our states and actions
correspond to Xt and Xt′ , respectively. The numerous la-
beled ground truth GT t′ are treated as the demonstration
from experts. The latent decision S ∼ p(S|Xt) is unknown
and needs to be inferred. p(S|Xt) denotes the distribution
from which S is sampled. In the context of GAIL, the gen-
erator can be viewed as policy. Instead of solely obtaining
a policy/generator π from the states Xt, we propose to also
learn from S for modeling the multimodality aspect. IDL
quantiﬁes the impact of S on predictions through optimiz-
ing the mutual information between π and S without super-
vision.

3.2. Imitative Decision Learning

As mentioned previously, our work focuses on under-
standing and imitating the underlying human decision-
making process to anticipate future paths in dynamic
scenes. Fundamentally, our IDL can be viewed as jointly
training (1) an inference sub-network L that extrapolates the
latent decision, (2) a policy/generator π that recovers a pol-
icy to generate upcoming paths, (3) a statistics sub-network
Q that discovers the impact of latent decision on predic-
tions, and (4) a discriminator D that attempts to differenti-
ate our generated outcomes from the expert demonstrations.
We depict the structure and workﬂow of our proposed IDL
framework in Figure 2. In what follows, we provide detailed
descriptions of each part.

Latent Decision Inference: We invoke the point that the
latent decision is the key behind the multimodal nature of
the future.
In order to grasp this point, we propose to
ﬁrst uncover the distribution of the latent decisions through
learning from prior moving histories. It is owing to that the
moving histories have a wealth of records on how human
decisions were made under a highly complex dynamic sce-
nario. In practice, we parameterize the distribution of latent
decisions by means of the inference sub-network L.

The existence of spatiotemporal dependencies suggests
the fact that a person cannot decide his/her behavior without
considering his/her neighbors in dynamic scenes. Hence,
it is necessary to learn that a distribution can represent all
individuals in the scene. To achieve this goal, we ﬁrst in-
put the motion features Xt into a pre-trained fully convolu-
tional sub-module [24, 49] to extract a higher-level repre-
sentation of Xt at time instance t (t ∈ [t1, tk]). A set of
higher-level representations from t1 to tk are then fed into
a temporal convolutional sub-module [33, 17] to produce a
two-unit vector. We subsequently append a deconvolutional
[30, 23] sub-module and a softmax layer on each unit of
this two-unit vector. The ﬁnal outcomes are treated as the

296

Figure 2. The detailed schematic diagram of our proposed IDL for forecasting future paths. The red arrows indicate the direction of
information ﬂow between each module. The black arrows suggest the direction of information ﬂow inside a module. The historical
trajectories are ﬁrstly input into the inference sub-network to infer the distribution of latent decisions. The temporal convolutional sub-
module receives the output from the pre-trained convolutional sub-module and produces a two-unit vector. A pre-trained deconvolutional
sub-module and a softmax layer read each unit to form the mean and derivation of a Gaussian distribution of latent decisions. Meanwhile,
the encoder of our policy/generator π processes the historical trajectories by a ConvGRU layer. An element-wise addition product on the
encoded hidden states henc
((t ∈ [t1, tk])) and sampled latent decision S initializes the decoder. The ﬁnal predictions are generated from
tk
the decoded hidden states hdec
(t′ ∈ [tk+1, tk+k′ ) through a deconvolutional layer. The statistics sub-network reads prediction and latent
decision to measure the signiﬁcance of S on multimodal predictions. The discriminator distinguishes the predictions from the ground truth
future paths (expert demonstrations).

t′

mean µXt and variance σXt of a conditional Gaussian dis-
tribution from which the latent decision S samples. It can
be formulated as:

µXt , σXt = Sof tmax(L(Xt), t ∈ [t1, tk])

(1)

S ∼ p(S|Xt) = N (µXt , σXt )

(2)
During our experiments, we sample the latent decision
S via the reparametrization trick. The process of inference
offers the capability of attaining a profound comprehension
of how human decisions handle the relevant factors, such as
spatiotemporal information.

Policy/Generator:
Given the sequential characteris-
tics of human decision-making process, we leverage an
encoder-decoder structure based upon Convolutional Gated
Recurrent Units (ConvGRU) [4] to implement our pol-
icy/generator π. ConvGRU is able to capture temporal in-
formation along with spatial context.

The deﬁnition of the encoding is as follows:

henc
t = Enc(Conv(Xt), henc

t−1), t ∈ [t1, tk]
where Enc is the encoder sub-network and henc
denotes
the hidden states at time instance t (t ∈ [t1, tk]). Conv
pertains to a single convolutional layer that serves to remove
the sparsity, which Xt might present.

(3)

t

tk

Simply passing henc

to the decoder sub-network does
not take into account the latent decision. This fails to ex-
pose the innate multimodality to predictions. To tackle this
issue, we propose incorporating the henc
tk with the latent de-
cision S, which has a vital impact on policy/generator π
for multimodal path forecasting. More speciﬁcally, the de-
coder reads the element-wise addition product henc
tk ⊕ S for
initialization. Accordingly, each sample of the latent deci-
sion S eventually poses a different plausible prediction. We
formulate the decoding process as:

t′ = Dec(hdec
hdec

t′−1), t′ ∈ [tk+1, tk+k′ ]

(4)
where Dec stands for decoder and t′ (t′ ∈ [tk+1, tk+k′ ) is
the future time step. The hidden state hdec
at time instance
t′ is only determined upon the previous hidden state hdec
t′−1 .
In order to obtain Xt′ , we append a single deconvolutional
layer with a stride of 2. It serves to transform hdec
into the
same size as the inputs:

t′

t′

Xt′ = Deconv(hdec

The hidden states hdec

t′ ), t′ ∈ [tk+1, tk+k′ ]
and pre-speciﬁed logarithmic
standard deviations are set to form a Gaussian for the Prox-
imal Policy Optimization (PPO) [36]. The objective of up-
dating our policy/generator π will be described later.

(5)

t′

297

Mutual Information Optimization: In this section, we ex-
plicitly delve into the essence that binds latent decision S to
the policy/generator π to gain a clearer insight into the cor-
relation between S and the multimodal future.

We proceed by optimizing the mutual information be-
tween S and π to establish their connection. As a result, we
are able to quantitatively measure the signiﬁcance of latent
decision on predictions. The mutual information I(S, π) is
termed as:

I(S, π) = H(S) − H(S|π)

(6)
where H(·) denotes the Shannon entropy. A larger value of
I(S, π) refers to a larger inﬂuence of the latent decision.
Optimizing Eq.6 thereby incentivizes S and consolidates
its impact on the predictions. Moreover, such optimization
strengthens our semantic understanding of the impact of la-
tent decision on multimodal future paths. With the assis-
tance of the Mutual Information Neural Estimator [5], opti-
mizing I(S, π) is equivalent to maximizing its lower bound
LI . Toward this end, we introduce a statistics sub-network
Q to approximate LI :

I(S, π) ≥ LI = EXt′ ∼π,S∼p(S|Xt)Q(Xt′ , S)
Xt′ ∼π, ˆS∼p(S|Xt)(eQ(Xt′ , ˆS))

− logE

(7)

where S and ˆS are i.i.d. samples from p(S|Xt). Xt′ is
the corresponding prediction of the sampled latent decision
S. We display the structure of statistics sub-network Q
in Fig.2. The ﬁnal result of LI is obtained from a fully
connected layer by reading the concatenation of the rep-
resentations of predictions Xt′ and the representations of
S. They are outputs from the temporal convolutional sub-
module and pre-trained fully convolutonal sub-module, re-
spectively.

Discriminator and Objective: We advocate applying
GAIL [13, 21] to train our framework. Thus our IDL re-
tains the efﬁciency of gradient-based learning while formu-
lating path forecasting as an occupancy measure matching
problem. We propose using a discriminator D to distin-
guish [Xt, Xt′ ] from [Xt, GT t′ ] to guide π.
[Xt, Xt′ ] and
[Xt, GT t′ ] pertain to the combination of the past records
and the predictions/ground truth, respectively. As a result,
the discriminator can only be fooled if Xt′ is consistent with
Xt. The objective of discriminator is as follows:

LD =D([Xt, Xt′ ]) − D([Xt, GT t′ ])

+ λ(k ▽D(ǫGT t′ + (1 − ǫ)Xt′ ) k2 −1)2

(8)

(k ▽D(ǫGT t′ + (1 − ǫ)Xt′ ) k2 −1)2 is the gradient penalty
term following Wasserstein GAN with Gradient Penalty
(WGAN-GP) [10]. λ > 0 is a coefﬁcient, and ǫ ∼ U [0, 1]
is a random parameter. The discriminator D consists of a
single ConvGRU layer. We top four stacked convolutional
layers upon the ConvGRU layer to obtain a score that re-
ﬂects either [Xt, Xt′ ] or [Xt, GT t′ ].

The policy/generator π receives the gradient from D

through PPO [36] by maximizing the following objective:

Lπ = D([Xt, Xt′ ]) + ηLI

(9)

where η is the parameter of LI .

Algorithm 1 Imitative Decision Learning
Input:

1. Historical records for i-th sequence X i
2. Ground truth future for i-th sequence GT i
[t1, tk+k′ ]);
3. The initial parameters of inference sub-network, pol-
icy/generator, statistics sub-network and discriminator.

t (t ∈ [t1, tk]);
t′ (t′ ∈

Output: Learned policy/generator π

for i = 0,1,2... do

1. Sample and ﬁx S i ∼ N (µX i

t

, σX i

t

) (Eq.2) for each

rollout.

2. Generate future paths X i
3. Gradient descent on D to minimize D([X i

t′ (t′ ∈ [t1, tk+k′ ]) (Eq.5).
t′ ]) −
t′ ) k2

t , X i
t′ + (1 − ǫ)X i

t′ ]) + λ(k ▽D(ǫGT i

t , GT i

D([X i
−1)2

4. Sample and ﬁx ˆS i ∼ N (µX i

) independent of
S i for each rollout. Updating Q and L by maximiz-
ing E

t′ , ˆS i))

, σX i

Xt′ ,si (Q(X i
5. Maximize D([X i

t′ , si)) − logE
t , X i

t′ ]) + ηLI with PPO [36] to up-

t′ , ˆS i (eQ(X i

X i

t

t

date policy/generator π.

end for

3.3. Implementations

Training Strategy: Among the variants of GAN [9],
WGAN-GP [10] stands out due to its ability to overcome
the weaknesses of mode collapse and unstable convergence.
Hence, we form the objective of our proposed IDL by fol-
lowing WGAN-GP. η in Eq.9 λ in Eq.8 are empirically set
as 0.1 and 10, respectively. We summarize the training strat-
egy of our proposed IDL in Algorithm 1. The backpropa-
gation through time and RMSProp [8] is adopted to opti-
mize D with the learning rate initialized at 5 × 10−5, and at
3 × 10−5 for updating L and Q, respectively. To accelerate
training, we initialize our policy/generator π from behavior
cloning as [13, 21] suggest.

Network Conﬁgurations: An inference sub-network L, a
statistics sub-network Q, a policy/generator π and a dis-
criminator D form our proposed IDL approach. Please refer
to the supplementary material for the details.

Our implementation is based on the PyTorch library [31].
The experiments were carried out on two Nvidia GeForce
GTX 1080 Ti, supplied with 22 GB of memory in total.

298

Figure 3. The stochasticity of results from different methods on SAP dataset. Each line presents the result with best ADE (top) and best
FDE (bottom). The numbers on X-axis indicate the number of predictions, and the numbers on Y-axis denote the scores.

G.T.

Example 1

Example 2

Example 3

Example 4

Example 5

Figure 4. Qualitative comparisons on SAP dataset. The top left shows the observed records and the matching ground truth (G.T.). In
order to have a clear visualization for better understanding the multimodality, we separately illustrate several trajectories and the diverse
predicted paths apart from others from example 1 to example 5.

4. Experimental Analysis

4.1. Datasets and Experimental Settings

Three large-scale benchmark datasets are exploited to
validate the performance of the proposed IDL on the task
of path forecasting in dynamic scenes. Namely Stanford
Aerial Pedestrian (SAP) dataset [35], ETH dataset and UCY
dataset [32] are selected. The SAP dataset comprises long
video sequences for eight scenes in total. It labels complete
trajectories of different categorized moving objects from the
time they enter the scene to the exit time, for instance the
pedestrians, bicyclists and vehicles. The SAP dataset makes
a reasonable foundation for realistically evaluating our ex-
perimental results as it manifests a highly dynamic scenario.
The ETH dataset contains two scenes with 750 different
pedestrians and is split into two sub-datasets (ETH and Ho-
tel). The UCY dataset contains three sub-scenes with 786
people: UCY, ZARA-01 and ZARA-02. Both the ETH and
the UCY datasets are uniformly annotated at a 0.4 second

rate. The spatial coordinates of the annotations provided by
all datasets are embedded to a dimension of 256 × 256 to
feed into our network.

To ensure a fair comparison on the SAP dataset, we fol-
low the experimental settings opted in DESIRE [16]. The
entire SAP dataset is divided into 16,000 short video clips
across scenes for our experiments. We train and test by ob-
serving past k = 60 frames (2 seconds), and forecasting
subsequent k′ = 120 frames (4 seconds). The evaluation
criterion follows a randomized 5-fold cross-validation strat-
egy on nonoverlapping videos clips. In the second part of
our experiments on the ETH and UCY dataset, following
[11], we extend the value of k to 8 time steps and k′ to
12 time steps. This is equivalent to observing 3.2 seconds
and predicting next 4.8 seconds. We utilize the leave-one-
out cross-validation to evaluate our performance, which is
training on 4 sub-datasets and testing on the remaining one
as [1, 11].

As per comparing approaches, we assess the perfor-

299

mance of our IDL versus the two most recent state-of-the-
art studies of the path forecasting task. Speciﬁcally, we
select DESIRE [16], which performs the best on the SAP
dataset, and Social GAN [11], which achieves cutting-edge
results on the ETH and UCY datasets. The classic Social
LSTM [1] is employed for comparisons as well. We also
study the effectiveness of each part of our IDL through anal-
yses against the following baselines:

1. IDL-NL: In order to highlight the merit of our latent
decision inference, we use a predeﬁned S ∼ N (0, 1)
rather than inducing the distribution from histories.
The rest of the framework remains unchanged.

2. IDL-NQ: We evaluate the necessity of mutual infor-
mation optimization by comparing with IDL-NQ. This
baseline drops the statistics sub-network from the IDL
framework.

3. IDL-NL2: To test the impact of the latent decision on
the forecasting of future paths, we construct the IDL-
NL2 baseline by discarding both the inference sub-
network and statistics sub-network.

4. IDL-IN: We term our last baseline as IDL-IN to vali-
date the effectiveness of joint processing spatiotempo-
ral dependencies. This baseline replaces the ConvGRU
with vanilla GRU, and replaces the convolutional lay-
ers with fully connected layers in our IDL.

4.2. Quantitative Evaluation

We carry out the experiments by drawing samples of
the latent decision S 50 times for each sequence of the
SAP dataset, and 20 times for each sequence of the ETH
and UCY datasets.
In other words, we generate 50 pre-
dictions/rollouts on each sequence of the SAP dataset, and
20 predictions/rollouts for each sequence of the ETH and
UCY datasets. In our quantitative evaluation, we aim to de-
termine whether the extensive range of possible predictions
produced by our proposed IDL includes the true future. We
judge our experiments with the best Average Displacement
Error (best ADE) and the best Final Displacement Error
(best FDE) of the various approaches. Lower values suggest
better results for both measurements. These two metrics are
reasonable since they address to measure if the ground truth
is approximated within a diverse set of multiple predictions.
Fig.3 suggests that the probability of forecasting the true fu-
ture ascends by creating more plausible upcoming futures,
as it is likely to obtain a prediction that is closer to ground
truth.

Table 1 summarizes the quantitative results of the best
ADE and best FDE following [11, 16]. Our proposed IDL
manifests the best performance against other approaches
often by a considerable margin for both criteria. For in-
stance, the reported best ADE and best FDE rate of IDL
amount to 2.25 and 3.82 on SAP dataset. These scores out-
perform Social GAN [11] (by 1.32 and 2.03, respectively),

Best ADE / FDE on SAP dataset

ADE

3.57

3.11

4.49

3.08

3.04

2.76

2.25

FDE

5.85

5.33

6.14

5.36

5.27

4.90

3.82

Social GAN[11]

DESIRE[16]

IDL-IN

IDL-NQ

IDL-NL2

IDL-NL

IDL (Ours)

Best ADE / FDE on ETH and UCY datasets

ETH

HOTEL

UNIV

ZARA1

ZARA2

ADE/FDE ADE/FDE ADE/FDE ADE/FDE ADE/FDE

Social LSTM[1]

1.09/2.35 0.79/1.76 0.67/1.40 0.47/1.00 0.56/1.17

Social GAN[11]

0.87/1.62 0.67/1.37 0.76/1.52 0.35/0.68 0.42/0.84

IDL-IN

IDL-NQ

IDL-NL2

IDL-NL

1.24/2.61 1.06/2.04 0.92/1.87 0.64/1.16 0.77/1.39

0.83/1.57 0.66/1.25 0.74/1.50 0.33/0.67 0.41/0.82

0.81/1.59 0.65/1.22 0.74/1.48 0.31/0.64 0.39/0.80

0.75/1.51 0.60/1.06 0.69/1.42 0.28/0.61 0.35/0.73

IDL (Ours)

0.59/1.30 0.46/0.83 0.51/1.27 0.22/0.49 0.23/0.55

Table 1. The quantitative comparisons.

DESIRE [16] (by 0.86 and 1.51, respectively), IDL-IN (by
2.24 and 2.32, respectively), IDL-NQ (by 0.83 and 1.54, re-
spectively), IDL-NL2 (by 0.79 and 1.45) and IDL-NL (by
0.51 and 1.08, respectively). The signiﬁcant superiorities
of our proposed IDL compared with other methods on the
ETH and UCY datasets speak to its advantages.

In order to analyze the beneﬁts of IDL in detail, we fur-
ther conduct ablation studies from the following two as-
pects:

Latent Decision Exploration: The proposed inference
sub-network investigates the latent decision from observed
records. We report that the results reﬂect the beneﬁt of in-
ferring the distribution of the latent decision in Table 1. Our
proposed IDL incurs remarkable advantages, by far, ver-
sus IDL-NL, which achieves the second best performance
across the datasets. The IDL drastically advances the state-
of-the-art methods Social GAN [11] and DESIRE [16] as
well. These outcomes tip the balance steeply toward delv-
ing deeper into the latent decision in terms of forecasting
future paths and away from the use of a predeﬁned latent
variable.

During our experiments, we ﬁnd that IDL-NQ tends to
generate predictions that are insensitive to the latent deci-
sion. Furthermore, these predictions are close to determin-
istic IDL-NL2 (refer to Fig.3). This result overwhelmingly
demonstrates the value of considering the mutual informa-
tion optimization for capturing multimodality.

The scores attained by our IDL outdo those of IDL-NL2
on all datasets. This ﬁnding provides the evidence that ex-
plicitly modeling the latent decision enables a better under-
standing of the multimodal nature. In fact, even the IDL-NL
baseline yields better results than the IDL-NL2. Regarding

300

G.T.

Example 1

Example 2

Example 3

Example 4

Example 5

Figure 5. The visual results on ETH dataset. The top left depicts the entire trajectories combining the historical observations and ground
truth future (G.T.) in a dynamic scene. For clearer visualizations, we isolate each input and corresponding multimodal predictions produced
by our IDL and deterministic IDL-NL2 for comparison in each example.

Social LSTM [1], the second worst results are obtained on
the ETH and UCY datasets due to lack of considering the
multimodality.

Spatiotemporal Dependencies Processing: In this sec-
tion, we verify the effectiveness of jointly processing spa-
tiotemporal dependencies. A signiﬁcant overall poor per-
formance of the methods with two-step settings, i.e., Social
GAN [11], DESIRE [16] and Social LSTM [1], compared
to our IDL can be observed. This ﬁnding meets our expecta-
tions that combining the spatial and temporal dependencies
into one single framework is a better strategy. Additionally,
we assign one IDL-IN framework per person as [11, 16, 1].
However, failing to consider the spatial dependencies hin-
ders IDL-IN achieving satisfactory results.

4.3. Qualitative Evaluation

Since neither of the best ADE/FDE perfectly captures the
perceptual ﬁdelity of the multimodal nature of future paths,
we make additional qualitative evaluations.

Fig.4 and Fig.5 illustrate examples of path forecasting
of our proposed IDL on the SAP and ETH datasets. We
highlight the prediction that obtains the best ADE scores
and two randomly selected results. It is worth noting that
IDL simultaneously forecasts the future paths of all mov-
ing objects.In order to better understand the various possi-
ble future paths, we also visualize the deterministic output
from IDL-NL2 baseline and ground truth. It is evident that
our IDL generates diverse forthcoming paths. Such diver-
sity can be traced back to different latent decisions. For
instance, in example 1 of Fig.4, we observe that the pre-
dictions of ``random 1´´and ``random 2´´exhibit two differ-
ent types of future possibilities (going straight and turning
right, respectively). Meanwhile, IDL also successfully fore-

sees the true future path of turning left, as the result of ``best
ADE´´indicates. Conversely, the IDL-NL2 produces a de-
terministic path with a large discrepancy to ground truth due
to disregard the inherent multimodality of future paths.

5. Conclusion

In this paper, we propose a novel Imitative Decision
Learning approach for multimodal path forecasting in dy-
namic scenes. Our IDL delves deeper into the latent de-
cision that shapes the multimodality to anticipate multiple
plausible outcomes. Moreover, Our approach enables the
processing of the spatiotemporal information in one uniﬁed
framework. We extensively assess the performance of the
proposed IDL on two large-scale datasets in a path fore-
casting challenge. We demonstrate that IDL is capable of
producing diverse future paths as shown in our visual exam-
ples. Additionally, our IDL outperforms the recent promi-
nent studies by quantitative justiﬁcations

We believe that our IDL can beneﬁt future studies of real-
world applications by imitating human decision-making
process. For instance, one interesting direction would be
to extend our framework to enable a self-navigating robot
or an autonomous vehicle choosing an optimal path in dy-
namic scenes after foreseeing multiple possibilities.

6. Acknowledgement

The author was with York University, Canada. This
work was funded by VISTA and Canada First Research Ex-
cellence Fund (CFREF). The author sincerely appreciates
the consistent help and thought-provoking discussions from
Prof. James Elder. The author is grateful to the insightful
suggestions from Dr. Ling Wang and Dr. Henrique Morim-
itsu as well.

301

References

[1] Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan,
Alexandre Robicquet, Li Fei-Fei, and Silvio Savarese. So-
cial lstm: Human trajectory prediction in crowded spaces.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pages 961–971, 2016. 1,
2, 6, 7, 8

[2] Alexandre Alahi, Vignesh Ramanathan, and Li Fei-Fei.
In Proceed-
Socially-aware large-scale crowd forecasting.
ings of the IEEE Conference on Computer Vision and Pattern
Recognition(CVPR), pages 2203–2210, 2014. 2

[3] Lamberto Ballan, Francesco Castaldo, Alexandre Alahi,
Francesco Palmieri, and Silvio Savarese. Knowledge Trans-
fer for Scene-speciﬁc Motion Prediction.
In European
Conference on Computer Vision (ECCV), pages 697–713.
Springer, 2016. 2

[4] Nicolas Ballas, Li Yao, Chris Pal, and Aaron Courville.
Delving deeper into convolutional networks for learning
video representations. In International Conference on Learn-
ing Representations (ICLR), 2016. 4

[5] Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajesh-
war, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and
Devon Hjelm. Mutual Information Neural Estimation.
In
Proceedings of the 35th International Conference on Ma-
chine Learning(ICML), volume 80, pages 531–540, 10–15
Jul 2018. 2, 5

[6] Liqun Chen, Shuyang Dai, Yunchen Pu, Erjin Zhou, Chun-
yuan Li, Qinliang Su, Changyou Chen, and Lawrence Carin.
Symmetric variational autoencoder and connections to ad-
versarial learning. In International Conference on Artiﬁcial
Intelligence and Statistics, pages 661–669, 2018. 3

[7] Tian Qi Chen, Xuechen Li, Roger Grosse, and David Duve-
naud.
Isolating Sources of Disentanglement in Variational
Autoencoders. In Advances in Neural Information Process-
ing Systems (NIPS), 2018. 2

[8] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep

Learning. MIT Press, 2016. 2, 5

[9] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets. In Advances in
Neural Information Processing Systems (NIPS), pages 2672–
2680, 2014. 3, 5

[10] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent
Improved Training of
Dumoulin, and Aaron Courville.
Wasserstein GANs. In Advances in Neural Information Pro-
cessing Systems (NIPS), 2017. 5

[11] Agrim Gupta, Justin Johnson, Li Fei-Fei, Silvio Savarese,
and Alexandre Alahi. Social GAN: Socially Acceptable
Trajectories With Generative Adversarial Networks. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), June 2018. 1, 2, 3, 6, 7, 8

[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition(CVPR), pages 770–778, 2016. 2

[13] Jonathan Ho and Stefano Ermon. Generative adversarial im-
itation learning. In Advances in Neural Information Process-
ing Systems, pages 4565–4573, 2016. 2, 3, 5

[14] Shuiwang Ji, Wei Xu, Ming Yang, and Kai Yu. 3D convolu-
tional neural networks for human action recognition. IEEE
transactions on pattern analysis and machine intelligence,
(1):221–231, 2013. 2

[15] Kris M Kitani, Brian D Ziebart, James Andrew Bagnell, and
Martial Hebert. Activity forecasting. In European Confer-
ence on Computer Vision (ECCV), pages 201–214. Springer,
2012. 2

[16] Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B
Choy, Philip HS Torr, and Manmohan Chandraker. DESIRE:
Distant Future Prediction in Dynamic Scenes With Interact-
ing Agents. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition, pages 336–345, 2017.
1, 2, 3, 6, 7, 8

[17] Peng Lei and Sinisa Todorovic. Temporal Deformable Resid-
In Pro-
ual Networks for Action Segmentation in Videos.
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 6742–6751, 2018. 3

[18] Yuke Li. Pedestrian Path Forecasting in Crowd: A Deep
Spatio-Temporal Perspective.
In Proceedings of the 2017
ACM on Multimedia Conference, MM ’17, pages 235–243,
New York, NY, USA, 2017. ACM. 2

[19] Yuke. Li. A Deep Spatiotemporal Perspective for Under-
standing Crowd Behavior. IEEE Transactions on Multime-
dia, 20(12):3289–3297, Dec 2018. 2

[20] Yuke Li. Video Forecasting with Forward-Backward-Net:
Delving Deeper into Spatiotemporal Consistency.
In 2018
ACM Multimedia Conference on Multimedia Conference,
pages 211–219. ACM, 2018. 3

[21] Yunzhu Li, Jiaming Song, and Stefano Ermon. Infogail: In-
terpretable imitation learning from visual demonstrations. In
Advances in Neural Information Processing Systems, pages
3812–3822, 2017. 5

[22] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffu-
sion Convolutional Recurrent Neural Network: Data-Driven
Trafﬁc Forecasting. In International Conference on Learning
Representations (ICLR), 2018. 2

[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia.
Path aggregation network for instance segmentation. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 8759–8768, 2018. 3

[24] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition, pages 3431–3440, 2015. 3

[25] Pauline Luc, Camille Couprie, Yann LeCun, and Jakob Ver-
beek. Predicting Future Instance Segmentation by Forecast-
ing Convolutional Features. In The European Conference on
Computer Vision (ECCV), September 2018. 1

[26] Wenjie Luo, Bin Yang, and Raquel Urtasun. Fast and Furi-
ous: Real Time End-to-End 3D Detection, Tracking and Mo-
tion Forecasting With a Single Convolutional Net. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pages 3569–3577, 2018. 1, 2

302

[27] Zhongjian Lv, Jiajie Xu, Kai Zheng, Hongzhi Yin, Peng-
peng Zhao, and Xiaofang Zhou. LC-RNN: A Deep Learning
Model for Trafﬁc Speed Prediction.
In Proceedings of the
Twenty-Seventh International Joint Conference on Artiﬁcial
Intelligence (IJCAI), pages 3470–3476, 7 2018. 2

[28] Wei-Chiu Ma, De-An Huang, Namhoon Lee, and Kris M Ki-
tani. Forecasting interactive dynamics of pedestrians with
ﬁctitious play.
In Computer Vision and Pattern Recogni-
tion (CVPR), 2017 IEEE Conference on, pages 4636–4644.
IEEE, 2017. 2

[29] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.
Which Training Methods for GANs do actually Converge?
In International Conference on Machine Learning, pages
3478–3487, 2018. 3

[30] Hyeonwoo Noh, Seunghoon Hong, and Bohyung Han.
Learning deconvolution network for semantic segmentation.
In Proceedings of the IEEE international conference on com-
puter vision, pages 1520–1528, 2015. 3

[31] Adam Paszke, Sam Gross, Soumith Chintala, Gregory
Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Al-
ban Desmaison, Luca Antiga, and Adam Lerer. Automatic
differentiation in pytorch. 2017. 5

[32] S Pellegrini, A Ess, K Schindler, and L van Gool. You’ll
never walk alone: Modeling social behavior for multi-target
tracking.
In 2009 IEEE 12th International Conference on
Computer Vision (ICCV), 2009. 6

[33] Colin Lea Michael D Flynn Ren´e and Vidal Austin Reiter
Gregory D Hager. Temporal convolutional networks for ac-
tion segmentation and detection. In IEEE International Con-
ference on Computer Vision (ICCV), 2017. 3

[34] Nicholas Rhinehart and Kris M Kitani. First-Person Activity
Forecasting With Online Inverse Reinforcement Learning. In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 3696–3705, 2017. 2

[35] Alexandre Robicquet, Amir Sadeghian, Alexandre Alahi,
and Silvio Savarese. Learning social etiquette: Human tra-
jectory understanding in crowded scenes. In European con-
ference on computer vision, pages 549–565. Springer, 2016.
2, 6

[36] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Rad-
ford, and Oleg Klimov. Proximal policy optimization algo-
rithms. arXiv preprint arXiv:1707.06347, 2017. 4, 5

[37] Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning
structured output representation using deep conditional gen-
erative models. In Advances in Neural Information Process-
ing Systems, pages 3483–3491, 2015. 3

[38] Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudi-
nov. Unsupervised Learning of Video Representations using
LSTMs. In Proceedings of the 32nd International Confer-
ence on Machine Learning (ICML), pages 843–852, 2015.
2

[39] Shan Su, Jung Pyo Hong, Jianbo Shi, and Hyun Soo Park.
Predicting behaviors of basketball players from ﬁrst person
videos. In IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), volume 2, pages 1501–1510, 2017. 2

[40] Tomoyuki Suzuki, Hirokatsu Kataoka, Yoshimitsu Aoki, and
Yutaka Satoh. Anticipating Trafﬁc Accidents With Adaptive

Loss and Large-Scale Incident DB. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), June
2018. 2

[41] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bern-
In Interna-

hard Schoelkopf. Wasserstein Auto-Encoders.
tional Conference on Learning Representations, 2018. 3

[42] Jacob Walker, Abhinav Gupta, and Martial Hebert. Patch to
the future: Unsupervised visual prediction.
In 2014 IEEE
Conference on Computer Vision and Pattern Recognition,
pages 3302–3309. IEEE, 2014. 2

[43] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao,
Jan Kautz, and Bryan Catanzaro. High-resolution image syn-
thesis and semantic manipulation with conditional gans. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), volume 1, page 5, 2018. 3

[44] Jingwei Xu, Bingbing Ni, Zefan Li, Shuo Cheng, and Xi-
aokang Yang. Structure Preserving Video Prediction. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), June 2018. 1

[45] Yanyu Xu, Zhixin Piao, and Shenghua Gao. Encoding
Crowd Interaction With Deep Neural Network for Pedestrian
Trajectory Prediction. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), June 2018. 1, 2

[46] Shuai Yi, Hongsheng Li, and Xiaogang Wang. Pedestrian
Behavior Understanding and Prediction with Deep Neural
Networks.
In European Conference on Computer Vision
(ECCV), pages 263–279. Springer, 2016. 2

[47] YoungJoon Yoo, Kimin Yun, Sangdoo Yun, JongHee Hong,
Hawook Jeong, and Jin Young Choi. Visual Path Prediction
in Complex Scenes With Crowded Moving Objects. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), June 2016. 2

[48] Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-Temporal
Graph Convolutional Networks: A Deep Learning Frame-
work for Trafﬁc Forecasting. In Proceedings of the Twenty-
Seventh International Joint Conference on Artiﬁcial Intelli-
gence (IJCAI), pages 3634–3640, 2018. 2

[49] Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang,
Xiaogang Wang, Ambrish Tyagi, and Amit Agrawal. Con-
text encoding for semantic segmentation.
In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), 2018. 3

[50] Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng
Zhong, and Yun Fu.
Image Super-Resolution Using Very
Deep Residual Channel Attention Networks. In Proceedings
of the European Conference on Computer Vision (ECCV),
pages 286–301, 2018. 2

303

