Enhancing TripleGAN for Semi-Supervised Conditional Instance

Synthesis and Classiﬁcation

Si Wu12 Guangchang Deng1
Jichang Li1 Rui Li2 Zhiwen Yu1 Hau-San Wong2
1School of Computer Science and Engineering, South China University of Technology

2Department of Computer Science, City University of Hong Kong

cswusi@scut.edu.cn, csgc@mail.scut.edu.cn, cslijichang@mail.scut.edu.cn

ruili52-c@my.cityu.edu.hk, zhwyu@scut.edu.cn, cshswong@cityu.edu.hk

Abstract

Learning class-conditional data distributions is cru-
cial for Generative Adversarial Networks (GAN) in semi-
supervised learning. To improve both instance synthesis
and classiﬁcation in this setting, we propose an enhanced
TripleGAN (EnhancedTGAN) model in this work. We fol-
low the adversarial training scheme of the original Triple-
GAN, but completely re-design the training targets of the
generator and classiﬁer. Speciﬁcally, we adopt feature-
semantics matching to enhance the generator in learning
class-conditional distributions from both the aspects of s-
tatistics in the latent space and semantics consistency with
respect to the generator and classiﬁer. Since a limited
amount of labeled data is not sufﬁcient to determine satis-
factory decision boundaries, we include two classiﬁers, and
incorporate collaborative learning into our model to pro-
vide better guidance for generator training. The synthesized
high-ﬁdelity data can in turn be used for improving classiﬁ-
er training. In the experiments, the superior performance of
our approach on multiple benchmark datasets demonstrates
the effectiveness of the mutual reinforcement between the
generator and classiﬁers in facilitating semi-supervised in-
stance synthesis and classiﬁcation.

1. Introduction

Signiﬁcant advances in deep learning techniques have re-
sulted in its wide adoption in a broad set of applications,
most notably in computer vision [14] [31] [34] and natu-
ral language processing [42]. However, in view of the need
to collect a massive amount of labeled data for most fully-
supervised deep learning models, semi-supervised learning
represents an effective approach to avoid the need for ex-
tensive manual annotations. This is due to the capability of
semi-supervised learning to capture the characteristics of a
dataset through a small number of labeled instances, togeth-

(a) TripleGAN∗

(b) EnhancedTGAN

Figure 1. The embedding of the unlabeled training data and syn-
thesized data on CIFAR-10 with 4000 labels. The features of the
last hidden layer of the classiﬁer network are projected to 3D using
PCA. The unlabeled samples are marked gray, and different colors
denote different classes of synthesized samples. We implement
TripleGAN [17] in our conﬁguration environment as the baseline
which is referred to as TripleGAN∗. One can observe that the pro-
posed EnhancedTGAN performs better than TripleGAN∗ in learn-
ing class-conditional distribution, since the synthesized data can
match the unlabeled data in sub-ﬁgure (b).

er with a large set of unlabeled instance. A number of pre-
vious methods have been developed to learn discriminative
representations, explore the underlying manifold structures,
and infer the labels of the unlabeled data, such as [41] [12]
[18] [1] [39]. However, the quality of the unlabeled data
will have a signiﬁcant effect on the performance of semi-
supervised learning, and incorporation of low-quality data
in the training process could lead to ambiguous or even in-
correct decisions.

Recent applications of generative adversarial network
(GAN) [8] [29] [43] [21] [22] to semi-supervised learn-
ing have shown promise, due to the capability of GAN to
synthesize high-quality samples by learning the probability
distribution of a data set. To perform semi-supervised data
synthesis, Odena [27] modiﬁed the discriminator network to
classify the synthesized data to the K + 1-th class, while in
[35] the predicted class probability distribution for the syn-

110091

Figure 2. Illustration of the structure of the proposed EnhancedTGAN model for semi-supervised conditional instance synthesis and clas-
siﬁcation.

thesized data is forced to be uniform. To avoid the case in
which the discriminator also needs to predict the class label
for real data, Li et al. [17] proposed the TripleGAN model,
in which a classiﬁer was incorporated into the adversarial
training process. However, a limited number of labeled in-
stances are not sufﬁcient for learning the class-conditional
probability distribution of the categories. In this case, there
may exist a domain shift in which the divergence between
the real and synthesized data distributions is signiﬁcant. In
particular, the domain discrepancy may be signiﬁcant in the
early phase of the training process, and the generator and
classiﬁer may negatively affect each other. As a result, it
is important, for the purpose of facilitating semi-supervised
synthesis and classiﬁcation, to effectively match the statis-
tics of real and synthesized data, and this work presents a
feature-semantics matching approach to achieve this objec-
tive as shown in Figure 1.

In this work, we propose an enhanced TripleGAN (En-
hancedTGAN) model for improving semi-supervised con-
ditional instance synthesis and classiﬁcation. We follow the
adversarial training scheme of the TripleGAN model in gen-
eral, but re-design the overall loss functions of the generator
and classiﬁers. Our feature-semantics matching approach is
able to reduce the risk of mode collapse and improve the
synthesis of the instances of each class. Speciﬁcally, we
adopt class-wise mean feature matching to regularize the
generator, such that the class-conditional distribution of the
synthesized data can match with that of the real data for
each class in the latent space learnt by a classiﬁer, instead
of the discriminator. In addition, we further include a se-
mantic matching term to ensure the semantics consistency
of the synthesized data between the generator and the classi-
ﬁer, which is a prerequisite for improving classiﬁer training.
On the other hand, a better classiﬁcation model can provide
more accurate categorical information on a large number of
unlabeled instances, which leads to better guidance for the

generator. For this purpose, we include two classiﬁers in
our model which operate in a collaborative learning fash-
ion. The classiﬁers can learn from each other by penalizing
the divergence between the predicted class probability dis-
tributions, and the consensus predictions on the unlabeled
data are more accurate than individual predictions in most
cases. As a result, the generator and the classiﬁers can mu-
tually reinforce each other. The structure of our model is
illustrated in Figure 2. Our experiments verify the effec-
tiveness and superiority of the proposed model. The main
contributions of this work are summarized as follows:

• We propose a feature-semantics matching approach
through which the generator can more effectively learn
the class-conditional data distributions.

• In addition to the synthesized high-ﬁdelity instances
for training data augmentation, collaborative learning
between the classiﬁers can also lead to more accurate
classiﬁcation on the unlabeled data, which in turn pro-
vides better guidance for the generator.

• The proposed enhanced TripleGAN model improves
the state-of-the-art results in both semi-supervised in-
stance synthesis and classiﬁcation on multiple widely
used benchmarks.

2. Related Work

Recently, various strategies have been applied to im-
prove semi-supervised deep learning. Unsupervised learn-
ing can be used as an auxiliary task for exploring the struc-
ture of a dataset, and thus the generalization capability of
the classiﬁcation model can be improved. To formulate the
unsupervised learning loss function for unlabeled samples,
Rasmus et al. [30] proposed the Γ-model, in which a consis-
tency regularization term was adopted to penalize the incon-
sistent predictions of the Ladder network [37] in inputs with

210092

and without noise. Similar to the Γ-model, Laine and Aila
[15] proposed the Π-model, which regularized the model
outputs of the training samples under different dropout and
augmentation conditions. To provide more stable training
targets for the unsupervised loss, Laine and Aila further pro-
posed the Temporal-Ensembling model. In this model, self-
ensembling of the network was applied to complement su-
pervision. The ensemble of predictions at different epochs
are expected to be more accurate, and can thus be used as
the training targets for unlabeled samples.
In contrast to
the exponential moving average of the network predictions
on each sample, Tarvainen and Valpola [36] proposed the
Mean-Teacher model to average the network weights, and
the resulting model can be considered as a teacher to pro-
vide the training targets for the unlabeled samples. Based
on the assumption that similar samples should be located
in the same cluster in the latent space, Luo et al. [19] pro-
posed the Smooth Neighbors on Teacher Graphs (SNTG)
method to build a graph based on the predictions of a teach-
er network for measuring the similarity between unlabeled
data points. To ensure smoothness on the data manifold, the
contrastive loss was used to ensure that neighbors had con-
sistent predictions, while non-neighbors were pushed away
from each other. In addition, it is common to incorporate the
locally-Lipschitz condition through penalizing inconsisten-
t predictions of unlabeled samples with different perturba-
tions. Miyato et al. [24] [23] proposed the Virtual Adversar-
ial Training (VAT) based regularization method to improve
the local smoothness of the predicted class probability dis-
tribution by applying perturbation in the adversarial direc-
tion with respect to the classiﬁcation model. VAT can be in-
corporated into existing semi-supervised learning networks,
and yields impressive results. On the other hand, Park et al.
[28] developed the Virtual Adversarial Dropout (VAdD) ap-
proach to reconﬁgure the neural network and minimize the
divergence between the obtained network and the original
network for increasing the sparsity of the overall network.

Deep generative models have been recently applied to
semi-supervised learning.
In [10], Kingma et al. adopt-
ed the Variational Auto-Encoder (VAE) model [11] to treat
class label as an additional latent variable in the process
of learning the generative model. In [27], Odena modiﬁed
the discriminator network to simultaneously distinguish re-
al samples from synthesized samples and predict the cor-
responding class labels. Springenberg [35] proposed the
Categorical Generative Adversarial Network (CatGAN) to
make the discriminator assign high-conﬁdence class labels
for the real samples, while forcing the predicted class prob-
ability distributions on the synthesized samples to be uni-
form. Salimans et al. [32] proposed a variety of training
techniques to improve the GAN training procedure, which
lead to improvement in semi-supervised learning and sam-
ple synthesis. Furthermore, Wei et al. [38] improved the

Wasserstein GAN [2] by including a consistency term with
respect to the discriminator responses for enforcing Lips-
chitz continuity. To prevent the discriminator from playing
two roles of identifying synthesized samples and predict-
ing class labels for real samples in a minimax game, Li et
al. [17] incorporated a classiﬁer as an additional player into
the game, and proposed the Triple Generative Adversarial
Net (TripleGAN). Dumoulin et al. [5] proposed the Adver-
sarially Learned Inference (ALI) model, in which a genera-
tion network learnt the mapping from the latent space to the
data space, while an inference network learnt the inverse
mapping. These two networks were jointly optimized with
a discriminative network in an adversarial process. To learn
the joint distribution between samples and labels, Gan et al.
[7] proposed the Triangle Generative Adversarial Network
(TriangleGAN), in which two generators were adopted to
learn the conditional distributions between samples and la-
bels, and two discriminators were used to identify the types
of fake pairs between real (fake) samples and fake (real) la-
bels. Instead of matching the real and fake data distribution-
s, Dai et al. [4] proposed a complementary generator which
was trained by minimizing the KL divergence between the
distributions, such that the generated samples were located
in the low-density region in the latent space, and the diver-
sity of the training data was increased.

TripleGAN is the most related work to our proposed
approach. However there are signiﬁcant differences be-
tween them. Although we follow the adversarial train-
ing scheme of TripleGAN in general, we completely re-
design the overall loss function of the generator by includ-
ing feature-semantics matching for effective and efﬁcient
learning of the class-conditional data distributions. In addi-
tion, we include two classiﬁers which collaboratively learn
from each other to provide more accurate categorical in-
formation for the generator. As a result, the generator and
classiﬁer mutually reinforce each other to facilitate semi-
supervised instance synthesis and classiﬁcation.

3. Method

Inspired by the method in [6], the maximum mean dis-
crepancy measure was used for training GANs. Feature
matching has shown effectiveness in addressing the insta-
bility problem in GAN. The objective function deﬁned be-
low can be applied to force the generator G to synthesize
data that matches the statistics of the real data [32] [3]:

(cid:13)(cid:13)Ex∼pdata fD(x) − Ez∼pz fD(G(z))(cid:13)(cid:13),

(1)

where pdata denotes the distribution of real data x, pz de-
notes the distribution of random vector z, e.g., U [0, 1], G(z)
denotes a synthesized sample from z, and fD(·) denotes the
features associated with the hidden layer of the discrimina-
tor D. The center of synthesized data points is forced to

310093

match that of real data points in the latent space learnt by
the discriminator. However, there are two main issues when
applying the above formulation to our task. On one hand,
the categories of the instances are not taken into account
during the process of matching the marginal distributions.
On the other hand, in addition to class-conditional instance
synthesis, another objective is to perform accurate classiﬁ-
cation on the unlabeled data, while feature matching in the
space learnt by the discriminator cannot directly improve
classiﬁcation. In this section, we introduce the EnhancedT-
GAN model to improve both semi-supervised conditional
instance synthesis and classiﬁcation.

3.1. Feature Semantics Matching

In our setting, only a small portion of the training sam-
ples are labeled. Let x ∼ pu denote unlabeled samples,
and (x, y) ∼ pl denote the labeled data pair, where y de-
notes the label of sample x. Our EnhancedTGAN consists
of the following four modules: the generator G, discrim-
inator D, and classiﬁers C1 and C2. We slightly modify
the adversarial training scheme of the TripleGAN model.
Speciﬁcally, the generator G synthesizes new instances by
sampling pairs of random vector and class label (z, ˜y) from
a pre-speciﬁed distribution pg. The two classiﬁers C1 and
C2 collaboratively learn from each other, and produce the
consensus prediction ¯y of the input data.

To improve class-conditional instance synthesis, we opti-
mize the generator by including the class-wise mean feature
matching term deﬁned as follows:

ℓf eaM at(θG) = Xk (cid:13)(cid:13)(cid:13)

E(x,y)∼pl(cid:2)1(y, k)fC1 (x)(cid:3)

− E(z,˜y)∼pg(cid:2)1(˜y, k)fC1 (G(z, ˜y))(cid:3)(cid:13)(cid:13)(cid:13)

where k denotes the class index, fC1 (·) denotes the features
on the hidden layer of the classiﬁer C1, and the function
1(·, ·) returns 1 if the inputs are equal and 0 otherwise. S-
ince the number of labeled instances is small, we can use
moving historical averages to obtain more stable means for
them. The main advantage of ℓf eaM at is to avoid the mod-
e collapse problem where the generator always outputs the
same point. Another advantage is to increase the separabili-
ty of different classes of synthesized data. In order to utilize
the synthesized samples for training the classiﬁers, their se-
mantics from the perspectives of the classiﬁer and generator
should be consistent. To enforce this consistency, we adop-
t a semantics matching term to regularize the generator as
follows:

ℓsemM at(θG) = E(z,˜y)∼pg(cid:2) − ˜y log ¯pC(G(z, ˜y))(cid:3),

where

¯pC(x) = avg-pool(cid:0)pC1 (x), pC2 (x)(cid:1),

(3)

(4)

and pC1 (·) (pC2 (·)) denotes the predicted class probability
distribution by classiﬁer C1 (C2). The average pooling of
the classiﬁer predictions can be expected to be more accu-
rate in most cases. After including the adversarial training
term with the discriminator, the optimization of the genera-
tor can be formulated as follows:

min

G

1
2

E(z,˜y)∼pg(cid:2) log(1 − D(G(z, ˜y), ˜y))(cid:3)

+ ηℓf eaM at + νℓsemM at,

(5)

where the weighting factors η and ν are used for controlling
the relative importance of the corresponding terms.

3.2. Collaborative Learning of Classiﬁers

Different from the TripleGAN model, we include two
classiﬁers in our model, due to the reason that they can
provide the training targets of the unlabeled instances for
each other via collaborative learning. Existing works have
demonstrated that collaborative learning is capable of facil-
itating semi-supervised classiﬁcation.

Similar to the given labeled instances, the synthesized
instances can also be utilized because of the known labels.
The classiﬁer can be enhanced by including the instances
from the generator. The loss measure for supervised learn-
ing is the cross entropy between the given labels and the pre-
dicted distribution. Furthermore, the model can also learn
from the unlabeled samples by minimizing the conditional
entropy with respect to the posterior probability distribu-
tion. Therefore, we deﬁne the term for classiﬁcation evalu-
ation as follows:

(2)

,

ℓclassif y(θC1 ) =E(x,y)∼pl(cid:2) − y log pC1 (x)(cid:3)

+ E(z,˜y)∼pg(cid:2) − ˜y log pC1 (G(z, ˜y))(cid:3)
+ Ex∼pu(cid:2) − pC1 (x) log pC1 (x)(cid:3).

(6)

The classiﬁers tend to be conﬁdent on the unlabeled sam-
ples. To stabilize the estimation of the conditional entropy,
a smoothness regularization term ℓsmoReg is deﬁned as fol-
lows:

ℓsmoReg(θC1 ) = Ex∼pu (cid:20) max

kγk≤ξ

KL(cid:0)pC1 (x)kpC1 (x + γ)(cid:1)(cid:21) ,

(7)

where the constant ξ is used to control the intensity of
the adversarial perturbation γ, and KL(·k·) denotes the
Kullback-Leibler (KL) divergence. Similar to [24], the per-
turbation is generated in the direction most sensitive to the
classiﬁer prediction, and the KL divergence is used to mea-
sure the prediction difference with respect to the classiﬁer
for cases with and without perturbation. As a result, the
output of the classiﬁer will become smooth in the neighbor-
hood of unlabeled samples.

410094

5:

6:

7:

8:

9:

Algorithm 1 The proposed EnhancedTGAN model for semi-supervised conditional instance synthesis and classiﬁcation.

1: Input: Labeled data Xl and unlabeled data Xu.
2: Initialize: Generator G, discriminator D, classiﬁers C1 and C2, learning rate ζG, ζD and ζC , and batch size bl, bu and bg for labeled,

unlabeled and synthesized samples, respectively.

3: for n = 1 to N do
4:

Sample labeled instances {(x, y)} of size bl from Xl, unlabeled instances {x} of size bu from Xu, and random vectors {(z, ˜y)} of
size bg from the uniform distribution.
for each mini-batch B do

Evaluate classiﬁer predictions pθC1
Compute the consensus results ¯pC and the corresponding one-hot label ¯y for x.
Update the discriminator D by using Adam [9]

for x, x and G(z, ˜y).

and pθC2

θD ← Adam(cid:18)∇θD(cid:18) X(x,y)

log D(x, y) +

1

2 X(z,˜y)

Update the classiﬁers C1 and C2 by using Adam

log(1 − D(G(z, ˜y), ˜y)) +

1

2 X(x,¯y)

log(1 − D(x, ¯y))(cid:19), θD, ζD(cid:19).

θC1 ← Adam(cid:18)∇θC1(cid:18) 1
θC2 ← Adam(cid:18)∇θC2(cid:18) 1

2 X(x,¯y)
2 X(x,¯y)

¯pC (x) log(1 − D(x, ¯y)) + ℓclassif y + λℓsmoReg + µℓconReg(cid:19), θC1 , ζC(cid:19),
¯pC (x) log(1 − D(x, ¯y)) + ℓclassif y + λℓsmoReg + µℓconReg(cid:19), θC2 , ζC(cid:19).

10:

Update the generator G by using Adam

θG ← Adam(cid:18)∇θG(cid:18) 1

2 X(z,˜y)

log(1 − D(G(z, ˜y), ˜y)) + ηℓf eaM at + νℓsemM at(cid:19), θG, ζG(cid:19).

end for

11:
12: end for
13: Return θG, θD, θC1 and θC2 .

To encourage the classiﬁers to learn from each other,
we further deﬁne a consistency regularization term ℓconReg
by adopting the Jensen-Shannon (JS) divergence [33] DJ S
to measure the similarity between the posterior probability
distributions of the two classiﬁers as follows:

ℓconReg(θC1 , θC2 ) = Ex∼pu(cid:2)DJ S(cid:0)pC1 (x), pC2 (x)(cid:1)(cid:3)
+ E(z,˜y)∼pg(cid:2)DJ S(cid:0)pC1 (G(z, ˜y)), pC2 (G(z, ˜y))(cid:1)(cid:3).

(8)

formulation can be expressed as follows:

min
C1,C2

Ex∼pu(cid:2)¯pC(x) log(1 − D(x, ¯y))(cid:3)

1
2
+ ℓclassif y(θC1 ) + λℓsmoReg(θC1 )
+ ℓclassif y(θC2 ) + λℓsmoReg(θC2 )
+ µℓconReg(θC1 , θC2 ),

(10)

where λ and µ are the weighting factors for achieving a bal-
ance among the terms.

As a symmetrized and smoothed version of the KL diver-
gence, DJ S is deﬁned by

3.3. Adversarial Training

DJ S(cid:0)pC1 (x), pC2 (x)(cid:1) =

1
2

KL(cid:0)pC1 (x)k¯pC(x)(cid:1)

+

1
2

KL(cid:0)pC2 (x)k¯pC(x)(cid:1),

(9)

Since we follow the adversarial training scheme of the
TripleGAN model in general, the discriminator D learns
to distinguish the labeled data pair (x, y) from the synthe-
sized data pair (G(z), ˜y) and predicted data pair (x, ¯y). The
corresponding optimization formulation is presented as fol-
lows:

In addition, DJ S(pC1 (G(z, ˜y)), pC2 (G(z, ˜y))) has a similar
deﬁnition. Based on the deﬁnitions in Eq.(4) and Eqs.(8-9),
minimizing ℓconReg leads to the classiﬁers producing pre-
dictions consistent with the consensus result ¯pC .

The classiﬁers attempt to produce the predicted data pair
(x, ¯y) for fooling the discriminator, where ¯y denotes the
one-hot label determined by ¯pC(x). We need an adversari-
al training term for optimizing the classiﬁers, and the ﬁnal

max

D

E(x,y)∼pl(cid:2) log D(x, y)(cid:3)

+

+

1
2
1
2

E(z,˜y)∼pg(cid:2) log(1 − D(G(z, ˜y), ˜y))(cid:3)
Ex∼pu(cid:2) log(1 − D(x, ¯y))(cid:3).

(11)

The discriminator competes with the generator and classi-
ﬁers in the minimax game. The generator attempts to syn-

510095

(a) TripleGAN∗

(b) EnhancedTGAN

Figure 3. Results on a toy examples for the baseline model and the
proposed model. Different colors denote different types of data
points: dark (labeled), cyan (unlabeled), and red/green (synthe-
sized). The solid lines denote the resulting decision boundaries.

thesize high-ﬁdelity instances, and the classiﬁers try to pro-
duce more accurate predictions on the unlabeled instances.
When training the four modules jointly, collaborative learn-
ing between classiﬁers is able to provide more accurate
categorical information of unlabeled data, which is crucial
for the generator to learn the class-conditional distribution
of the real data. More synthesized instances with high-
ﬁdelity can in turn be leveraged to improve classiﬁer train-
ing, which lead to better decision boundaries and more ac-
curate guidance to the generator. Therefore, the proposed
EnhancedTGAN model is able to improve both instance
synthesis and classiﬁcation in the semi-supervised setting.
The details of the corresponding optimization process are
summarized in Algorithm 1.

4. Experiments

In this section, we verify the effectiveness of the pro-
posed EnhancedTGAN model in semi-supervised instance
synthesis and classiﬁcation on both synthetic and real ob-
ject recognition datasets. For a fair comparison with our
baseline model TripleGAN [17], we implement this model
in our conﬁguration environment using the same setting as
our EnhancedTGAN, and the resulting model is referred to
as TripleGAN∗. We also compare EnhancedTGAN with the
state-of-the-art semi-supervised learning methods on multi-
ple widely used benchmarks, including MNIST [16], SVH-
N [25] and CIFAR-10 [13]. Furthermore, we test the pro-
posed model on FaceScrub [26] to investigate the quality
of the synthesized human face images.
In all the experi-
ments, we perform labeled instance sampling 10 times, and
report the mean and standard deviation of the test error rates
for the classiﬁcation task. In the class-conditional instance
synthesis task, we present the synthesized images in a way
that each group contains one image for each class and all of
them share the same random vector.

4.1. Synthetic dataset

To show the effectiveness of our proposed feature-
semantics matching approach, we compare TripleGAN∗

and EnhancedTGAN in terms of their capability to learn
the class-conditional data distributions of a toy example.
We adopt the ‘two moons’ synthetic dataset as shown in
Figure 3, in which there are two classes, and each of them
consists of 10 labeled data points and 1000 unlabeled da-
ta points. The generator, discriminator and classiﬁers are
multi-layer perceptrons with 2-3 hidden layers. The two
competing models share the same settings, but the proposed
model has one more classiﬁer than TripleGAN∗. We train
each model until it converges. The synthesized data points
of TripleGAN∗ and EnhancedTGAN are shown in Figure
3(a) and (b), respectively. We use different colors (red and
green) to denote the two classes of the synthesized data
points. We can observe that the data points synthesized by
TripleGAN∗ only lie in a portion of the real data distribu-
tion, and our EnhancedTGAN correctly learns the real data
distributions. In addition, the decision boundary of the pro-
posed model aligns better than that of the baseline.

4.2. Benchmark datasets

We further compare EnhancedTGAN with state-or-the-
art semi-supervised deep learning models on the MNIST,
SVHN and CIFAR-10 benchmarks, which are widely used
for evaluation of classiﬁcation and synthesis. According to
the common setting, we perform experiments for the cases
in which there are 100, 1000 and 4000 randomly selected
labeled instances for MNIST, SVHN and CIFAR-10, re-
spectively. The network architecture of the classiﬁers in
EnhancedTGAN is the same as that in the main competing
methods, such as TripleGAN and CT-GAN. The classiﬁca-
tion results are presented in Table 1. The error rates of the
competing methods are taken from the existing literature,
except TripleGAN∗. TripleGAN∗ is a strong baseline, and
outperforms the original TripleGAN. In all the cases, the
proposed EnhancedTGAN achieves more accurate classiﬁ-
cation results than TripleGAN∗. For CIFAR-10 with 4000
labels, EnhancedTGAN surpasses TripleGAN∗ by a large
margin, and signiﬁcantly reduces the test error rate from
14.65% to 9.42%. Compared with other competing meth-
ods, the proposed EnhancedTGAN produces more accu-
rate or comparable classiﬁcation results in all cases. Figure
4 shows the synthesized samples by our EnhancedTGAN
model for the three datasets. We also visualize the t-SNE
embedding [20] of the features associated with the last hid-
den layer of the classiﬁer network in TripleGAN∗ and our
EnhancedTGAN model on CIFAR-10 with 4000 labels. As
shown in Figure 5, EnhancedTGAN performs better than
TripleGAN∗ in learning the class-conditional data distribu-
tions, since we can observe that the samples are strongly
clustered, and the distribution of the synthesized data can
match the distribution of the unlabeled data very well.

610096

Table 1. Comparison between our model and the competing methods on semi-supervised classiﬁcation on the benchmark datasets.

Method

LadderNetwork[30]
SPCTN[40]
Π-model[15]
Temporal-Ensembling[15]
Mean-Teacher[36]
VAT[24]
VAdD[28]
VAdD+VAT[28]
SNTG+Π-model[19]
SNTG+VAT[19]

CatGAN[35]
Improved GAN[32]
ALI[5]
TripleGAN[17]
GoodBadGAN[4]
CT-GAN[38]

TripleGAN∗
EnhancedTGAN

Test error rate (%) with # labels

MNIST

SVHN

CIFAR-10

All labels

1000 labels

All labels

4000 labels

All labels

0.57±0.02

-
-
-
-
-
-
-
-
-

-
-
-
-
-
-

0.31±0.04
0.27±0.03

-

7.37±0.30
4.82±0.17
4.42±0.16
3.95±0.19
3.74±0.09
4.16±0.08
3.55±0.05
3.82±0.25
3.83±0.22

-

8.11±1.30
7.42±0.65
5.77±0.17
4.25±0.03

-

4.53±0.22
2.97±0.09

-
-

2.50±0.07
2.74±0.06
2.50±0.05
2.69±0.04
2.31±0.01
2.23±0.03
2.42±0.05

-

-
-
-
-
-
-

2.94±0.15
2.23±0.01

20.40±0.47
14.17±0.27
12.36±0.31
12.16±0.24
12.31±0.28
11.96±0.10
11.68±0.19
10.07±0.11
11.00±0.13
9.89±0.34

19.58±0.58
18.63±2.32
17.99±1.62
16.99±0.36
14.41±0.03
9.98±0.21

14.65±0.38
9.42±0.22

-
-

6.06±0.11
5.60±0.10
5.94±0.15
5.65±0.17
5.27±0.10
4.40±0.12
5.19±0.14

-

-
-
-
-
-
-

6.64±0.13
4.80±0.07

100 labels

1.06±0.37
1.00±0.11
0.89±0.15

-
-
-
-
-

0.66±0.07

-

1.39±0.28
0.93±0.07

-

0.91±0.58
0.80±0.10
0.89±0.13

0.81±0.08
0.42±0.03

(a) MNIST

(b) SVHN

(c) CIFAR-10

Figure 4. Synthesized instances produced by the proposed EnhancedTGAN model for semi-supervised class-conditional object image
synthesis on MNIST with 100 labels, SVHN with 1000 labels and CIFAR-10 with 4000 labels. Each row has the same class label, and
each column is synthesized from the same random vector.

Table 2. Ablation study of the proposed model on CIFAR-10 with 4000
labels for investigating the inﬂuence of synthesized data, and consistency
and smoothness regularization in semi-supervised classiﬁcation.

Test error rate (%) with # labels

synthesized data can better match the statistics of the real
data. The semantics matching term can further improve the
training of the generator.

Method

w/o GAN
w/o ℓconReg
w/o ℓsmoReg

EnhancedTGAN

4000 labels

11.92±0.19
11.47±0.13
12.03±0.29

9.42±0.22

4.3. Ablation study

We remove the feature-semantics matching terms from
the overall loss function of the generator on CIFAR-10 with
4000 labels, and show the classiﬁcation accuracy on the
synthesized data during training in Figure 6. We can ob-
serve that the class-wise mean feature matching term is able
to boost the classiﬁcation accuracy, which indicates that the

To investigate the effectiveness of our proposed improve-
ment strategies in semi-supervised classiﬁcation, we per-
form an ablation study to compare the resulting models
when removing the corresponding modules on CIFAR-10
with 4000 labels as shown in Table 2. We ﬁrst remove the
generator and the discriminator to evaluate the classiﬁers
with collaborative learning, and the test error rate rises to
11.92%, which indicates that the synthesized instances are
useful for improving classiﬁer training. In addition, we re-
move the consistency and smoothness regularization terms
from the overall loss function of the classiﬁers to investigate
the inﬂuence of collaborative learning and the local Lips-
chitz condition, and a signiﬁcant performance drop can be
observed in both cases. We consider that both synthesized
data and regularization are important for improving semi-

710097

(a) TripleGAN∗

(b) EnhancedTGAN

Figure 5. The t-SNE embedding of unlabeled training data and
synthesized data on CIFAR-10 with 4000 labels. The unlabeled
samples are marked gray, and different classes of synthesized sam-
ples are marked different colors.

Figure 6. Classiﬁcation accuracy on synthesized data when remov-
ing the feature-semantics matching terms from the overall loss
function of the generator on CIFAR-10 with 4000 labels.

supervised classiﬁcation.

4.4. Face synthesis

To further investigate the capability of the proposed
EnhancedTGAN model
in performing difﬁcult semi-
supervised instance synthesis, we conduct an experiment on
the FaceScrub dataset. Since the classes in this dataset con-
tain different numbers of human face images, we select the
100 largest classes in our experiment, and only 20 images
sampled randomly in each class are labeled. All the im-
ages are resized to 64 × 64, and thus we slightly modify
the network architectures used previously for this experi-
ment without signiﬁcantly increasing the number of model
parameters. The synthesized human face images are shown
in Figure 7. For TripleGAN∗, we observe that the variation
within a class is relatively small, and the structures of the
human faces are lost in some images. On the other hand,
the synthesized images of our EnhancedTGAN look realis-
tic and preserve human identities. The corresponding clas-
siﬁcation results of TripleGAN∗ and EnhancedTGAN are
shown in Table 3.

(a) TripleGAN∗

(b) EnhancedTGAN

Figure 7. Synthesized instances produced by the TripleGAN∗ and
EnhancedTGAN models for semi-supervised class-conditional hu-
man face image synthesis on FaceScrub with 2000 labels. Each
row has the same class label, and each column is synthesized from
the same random vector.

Table 3. Comparison between the baseline model and the proposed model
on semi-supervised classiﬁcation on FaceScrub-100.

Test error rate (%) with # labels

Method

2000 labels

All labels

TripleGAN∗
EnhancedTGAN

18.23±0.56
16.08±0.24

5.43±0.41
4.29±0.20

5. Conclusion

In this paper, we propose an enhanced TripleGAN mod-
el for improving both semi-supervised conditional instance
synthesis and classiﬁcation. Toward this end, we adop-
t feature-semantics matching to force the generator to ef-
fectively learn the class-conditional data distributions, such
that the synthesized instances with high-ﬁdelity can be used
for training better classiﬁers. On the other hand, we col-
laboratively train two classiﬁers, which can provide more
accurate guidance for the generator. The experiment results
demonstrate that the proposed model outperforms the origi-
nal TripleGAN and achieves new state-of-the-art results on
multiple benchmark datasets.

Acknowledgments

This work was supported in part by the National Natu-
ral Science Foundation of China (Project No. 61502173,
U1611461, 61722205, 61751205, 61572199), in part by
the Research Grants Council of the Hong Kong Special
Administration Region (Project No. CityU 11300715),
in part by City University of Hong Kong (Project No.
7005055), in part by the Natural Science Foundation of
Guangdong Province (Project No. 2016A030310422), in
part by Key R&D Program of Guangdong Province (Project
No. 2018B010107002), and in part by the Fundamental
Research Funds for the Central Universities (Project No.
2018ZD33).

810098

References

[1] M. Abbasnejad, A. Dick, and A. Hengel. Inﬁnite variation-
al autoencoder for semi-supervised learning. In Proc. IEEE
Conference on Computer Vision and Pattern Recognition,
pages 781 – 790, 2017.

[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein genera-
tive adversarial networks. In Proc. International Conference
on Machine Learning, pages 214 – 223, 2017.

[3] J. Bao, D. Chen, F. Wen, H. Li, and G. Hua. CVAE-
GAN: ﬁne-grained image generation through asymmetric
training. In Proc. International Conference on Computer Vi-
sion, pages 2745 – 2754, 2017.

[4] Z. Dai, Z. Yang, F. Yang, W. Cohen, and R. Salakhutdinov.
Good semi-supervised learning that requires a bad GAN. In
Proc. Advances in Neural Information Processing Systems,
pages 6513 – 6523, 2017.

[5] V. Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A.
Lamb, M. Arjovsky, and A. Courville. Adversarially learned
inference.
In Proc. International Conference on Learning
Representation, 2017.

[6] G. Dziugaite, D. Roy, and Z. Ghahramani. Training gener-
ative neural networks via maximum mean discrepancy opti-
mization. In Proc. Conference on Uncertainty in Artiﬁcial
Intelligence, pages 258–267, 2015.

[7] Z. Gan, L. Chen, W. Wang, Y. Pu, Y. Zhang, H. Liu, C. Li,
and L. Carin. Triangle generative adversarial networks. In
Proc. Advances in Neural Information Processing Systems,
2017.

[8] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D.
Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Gener-
ative adversarial nets. In Proc. Advances in Neural Informa-
tion Processing Systems, pages 2672 – 2680, 2014.

[9] D. Kingma and J. Ba. Adam: a method for stochastic op-
timization. In Proc. International Conference on Learning
Representations, 2015.

[10] D. Kingma, S. Mohamed, D. Rezende, and M. Welling.
Semi-supervised learning with deep generative models.
In
Proc. Neural Information Processing Systmes, pages 3581 –
3589, 2017.

[11] D. Kingma and M. Welling. Auto-encoding variational
Bayes. In Proc. International Conference on Learning Rep-
resentation, 2014.

[12] T. Kipf and M. Welling. Semi-supervised classiﬁcation with
graph convolutional networks. In Proc. International Con-
ference on Learning Representation, 2017.

[13] A. Krizhevsky and G. Hinton. Learning multiple layers of

features from tiny images. In Technical Report, 2009.

[14] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Proc. Neural Information Processing Systmes, pages 1106 –
1114, 2014.

[15] S. Laine and T. Aila.

supervised learning.
Learning Representations, 2017.

Temporal ensembling for semi-
In Proc. International Conference on

[16] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-
based learning applied to document recognition. Proceed-
ings of the IEEE, 86(11):2278 – 2324, 1998.

[17] C. Li, K. Xu, J. Zhu, and B. Zhang. Triple generative ad-
versarial nets. In Proc. Advances in Neural Information Pro-
cessing Systems, pages 1195 – 1204, 2017.

[18] C. Li, J. Zhu, and B. Zhang. Max-margin deep generative
models for (semi-)supervised learning.
IEEE Transactions
on Pattern Analysis and Machine Intelligence, 40(11):2762
– 2775, 2018.

[19] Y. Luo, J. Zhu, M. Li, Y. Ren, and B. Zhang. Smooth neigh-
bors on teacher graphs for semi-supervised learning. In Proc.
IEEE Conference on Computer Vision and Pattern Recogni-
tion, 2018.

[20] L. Maaten and G. Hinton. Visualizing data using t-sne. Jour-
nal of Machine Learning Research, 9(11):2579 – 2605, 2008.
[21] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida. Spectral
normalization for generative adversarial networks. In Proc.
International Conference on Learning Representation, 2018.
[22] T. Miyato and M. Koyama. cGANs with projection discrim-
inator. In Proc. International Conference on Learning Rep-
resentation, 2018.

[23] T. Miyato, S. Maeda, S. Ishii, and M. Koyama. Virtual
adversarial training: a regularization method for supervised
and semi-supervised learning. IEEE Transactions on Pattern
Analysis and Machine Intelligence (Early Access), 2018.

[24] T. Miyato, S. Maeda, M. Koyama, K. Nakae, and S. Ishii.
Distributional smoothing with virtual adversarial training. In
Proc. International Conference on Learning Representation-
s, 2016.

[25] Y. Netzer, T. Wang, A. Goates, A. Bissacco, B. Wu, and A.
Ng. Reading digits in natural images with unsupervised fea-
ture learning.
In Proc. NIPS Workshop on Deep Learning
and Unsupervised Feature Learning, 2011.

[26] H. Ng and S. Winkler. A data-driven approach to cleaning
In Proc. International Conference on

large face datasets.
Image Processing, pages 343 – 347, 2014.

[27] A. Odena. Semi-supervised learning with generative adver-
sarial networks. In Proc. International Conference on Learn-
ing Representation, 2016.

[28] S. Park, J. Park, S. Shin, and I. Moon. Adversarial dropout
for supervised and semi-supervised learning. In Proc. AAAI
Conference on Artiﬁcial Intelligence, 2018.

[29] A. Radford, L. Metz, and S. Chintala. Unsupervised repre-
sentation learning with deep convolutional generative adver-
sarial networks. In Proc. International Conference on Learn-
ing Representation, 2016.

[30] A. Rasmus, M. Berglund, M. Honkala, H. Valpola, and T.
Raiko. Semi-supervised learning with ladder networks. In
Proc. Neural Information Processing Systmes, pages 3546 –
3554, 2015.

[31] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: To-
wards real-time object detection with region proposal net-
works. In Proc. Advances in Neural Information Processing
Systems, 2015.

[32] T. Salimans, I. Goodfellow, W. Zaremba, and V. Cheung. Im-
proved techniques for training GANs. In Proc. Neural Infor-
mation Processing Systmes, pages 2234 – 2242, 2016.

[33] H. Schutze and C. Manning. Fundations of statistical nutural

language processing. MIT Press, Cambridge, Mass, 1999.

910099

[34] E. Shelhamer, J. Long, and T. Darrell. Fully convolutional
networks for semantic segmentation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 39(4):640 – 651,
2017.

[35] J. Springenberg. Unsupervised and semi-supervised learning
with categorical generative adversarial networks. In Proc. In-
ternational Conference on Learning Representations, 2016.
[36] A. Tarvainen and H. Valpola. Mean teachers are better role
models: weight-averaged consistency targets improve semi-
supervised deep learning results. In Proc. Advances in Neu-
ral Information Processing Systems, 2017.

[37] H. Valpola. From neural PCA to deep unsupervised learning.
In Proc. Advances in Independent Component Analysis and
Learning Machines, arXiv:1411.7783, 2015.

[38] X. Wei, B. Gong, Z. Liu, W. Lu, and L. Wang. Improving
the improved training of Wasserstein GANs: a consistency
term and its dual effect. In Proc. International Conference
on Learning Representations, 2018.

[39] H. Wu and S. Prasad. Semi-supervised deep learning using
pseudo labels for hyperspectral image classiﬁcation. IEEE
Transactions on Image Processing, 27(3):1259 – 1270, 2018.
[40] S. Wu, Q. Ji, S. Wang, H. Wong, Z. Yu, and Y. Xu. Semi-
supervised image classiﬁcation with self-paced cross-task
networks.
IEEE Transactions on Multimedia, 20(4):851–
865, 2018.

[41] Z. Yang, W. Cohen, and R. Salakhutdinov. Revisiting semi-
supervised learning with graph embeddings. In Proc. Inter-
national Conference on Machine Learning, 2016.

[42] T. Young, D. Hazarika, S. Poria, and E. Cambria. Recent
trends in deep learning based natural language processing.
IEEE Computational Intelligence Magazine, 13(3):55 – 75,
2018.

[43] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena. Self-
attention generative adversarial networks. In arXiv preprint
arXiv:1705.05512, 2018.

1010100

