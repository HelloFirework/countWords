FOCNet: A Fractional Optimal Control Network for Image Denoising

Xixi Jia1,2, Sanyang Liu1, Xiangchu Feng1 and Lei Zhang∗2,3

1School of Mathematics and Statistics, Xidian University, Xi’an, China

2Dept. of Computing, The Hong Kong Polytechnic University, Hong Kong, China

3DAMO Academy, Alibaba Group

hsijiaxidian@gmail.com, liusanyang@126.com, xcfeng@mail.xidian.edu.cn,

cslzhang@comp.polyu.edu.hk

Abstract

Deep convolutional neural networks (DCNN) have been
successfully used in many low-level vision problems such as
image denoising. Recent studies on the mathematical foun-
dation of DCNN has revealed that the forward propagation
of DCNN corresponds to a dynamic system, which can be
described by an ordinary differential equation (ODE) and
solved by the optimal control method. However, most of
these methods employ integer-order differential equation,
which has local connectivity in time space and cannot de-
scribe the long-term memory of the system. Inspired by the
fact that the fractional-order differential equation has long-
term memory, in this paper we develop an advanced im-
age denoising network, namely FOCNet, by solving a frac-
tional optimal control (FOC) problem. Speciﬁcally, the net-
work structure is designed based on the discretization of
a fractional-order differential equation, which enjoys long-
term memory in both forward and backward passes. Be-
sides, multi-scale feature interactions are introduced into
the FOCNet to strengthen the control of the dynamic sys-
tem. Extensive experiments demonstrate the leading perfor-
mance of the proposed FOCNet on image denoising. Code
will be made available.

1. Introduction

Image denoising aims to estimate the underlying clean
image from its noisy observation. As an indispensable step
in many digital imaging and computer vision systems, im-
age denoising has been investigated for decades, while it
is still an active research topic. A vast amount of methods

∗Corresponding author. This work is partially supported by Hong Kong
RGC GRF grant (PolyU 152216/18E) and National Natural Science Foun-
dation of China (grant no. 61772389, 61877406, 61871260).

have been developed by using different mathematical tools
and models, including partial differential equations (PDE)
[39, 32], sparse coding [28, 13], low-rank approximation
[16, 22], and others [6, 9, 38]. Most of these methods rely
on very limited human knowledge or assumptions about the
image prior, limiting their capability in recovering complex
image structures.

In recent years, deep convolutional neural networks
(DCNN) have achieved a great success in many low-level
vision problems, including image denoising.
In particu-
lar, Zhang et al. [45] proposed an effective image denois-
ing network called DnCNN by integrating batch normal-
ization into the residual learning framework, which outper-
forms traditional denoising algorithms by a noticeable mar-
gin. By adding symmetric skip connections, Mao et al. [29]
constructed an improved encoder-decoder network for im-
age denoising. Bae et al. [4] suggested to learn CNN on
the wavelets sub-bands for image denoising. Based on the
wavelet decomposition, Liu et al. [26] put forward a multi-
level wavelet based denoising DCNN. Tai et al. [42] con-
structed a densely connected denoising network to enable
memory of the network. Zhang et al. [46] introduced a fast
and ﬂexible network (FFDNet) which can process images
with nonuniform noise corruption. To exploit the nonlocal
property of the image features in DCNN, Pl¨otz et al. [35]
presented an N3Net by employing the k-nearest neighbor
matching in the denoising network.

Although various DCNN methods have been proposed
for image denoising, the network design is mostly empiri-
cal without clear mathematical bases. Recently, some stud-
ies [34, 44, 27, 40, 17, 25] on the mathematical founda-
tion of DCNN have revealed that the forward propagation
of DCNN corresponds to a dynamic system, which can be
characterized by an ODE and solved by optimal control
methods [44, 25]. For example, Pineda [34] studied the

6054

neural network from a viewpoint of dynamic systems, and
formulated the forward propagation of neural networks as
the discretization of a special ODE.

In [25], Li et al. studied the Residual Network (ResNet)
[18] via optimal control and showed that the ResNet can be
solved by Pontryagin’s maximum principle. Lu et al. [27]
found that the forward propagation of ResNet is the Euler
discretization of an ODE. They further concluded that many
state-of-the-art network structures can be considered as dif-
ferent discretizations of ODEs, such as FractalNet [24],
PolyNet [47] and RevNet [15]. More recently, Ruthotto et
al. [40] investigated the relation between DCNN and partial
differential equation (PDE), and indicated that the forward
process of DCNN resembles the diffusion equation. The
PDE/diffusion models on one hand provide an alternative
perspective to understand DCNN; on the other hand, they
help to explain the success of DCNN for image denoising,
since PDE/diffusion models have long been effective math-
ematical tools for developing image denoising algorithms
[39, 32, 21].

The differential equations that indwell in the existing
DCNNs are integer-order differential equations (IODE),
which can only allow short-term feature interactions due to
their short-term memory. In practice, the evolution of a sys-
tem often depends on not only its current state but also its
historical states [10, 3]. In optimal control, the long-term
memory provides important information for robust control
of linear and nonlinear systems [33]. Long-term memory is
also beneﬁcial for vision problems such as image denois-
ing [42], since it can preserve better mid/high-frequency
information. Therefore, it is not enough to employ only
IODE for designing advanced denoising DCNN. Although
some DCNNs have been designed to address the long-term
memory problem, such as DenseNet [19] and MemNet [42],
there still lacks solid theoretical analysis on how the mem-
ory is exploited.

It has been found that in a majority of systems such as
biological systems, electromagnetic ﬁelds and Hamiltonian
systems, the long-term memory holds in a certain mode
which can be characterized by the power-law [11]. It has
also been found that the corresponding memory systems
could be described by the fractional-order differential equa-
tions (FODE) [10]. The FODE was developed to mitigate
the limitations of IODE [5, 31, 36] not only in the memory
but also in many other aspects such as the stability of the
system. It has been shown that FODE can more accurately
describe a lot of dynamic systems than IODE [7].

In this paper, by solving a Fractional Optimal Control
(FOC) problem, we naturally design an advanced image de-
noising network, namely FOCNet. The forward propaga-
tion of FOCNet is constructed by an explicit discretization
of a FODE with control variables. The advantages of the
FODE induced FOCNet over the IODE induced networks

are twofold: 1) The fractional-order FODE can describe the
power-law memory mode which has been veriﬁed in many
practical systems to persist memory; 2) The FOCNet has
long-term memory not only in the forward process but also
in the backward passes. Instead of characterizing the FODE
based FOCNet on only one speciﬁc image scale, we further
introduce a multi-scale strategy to strengthen the denoising
network. Speciﬁcally, in the multi-scale model, different
scale features propagate forward according to their corre-
sponding FODE, and at the same time multi-scale feature
interactions are allowed by a scale transform operator.

To sum up, the contributions of this work are:

• A novel denoising network – FOCNet – is presented by
solving a FOC problem using FODE. FOCNet theoret-
ically enjoys the advantages such as long-term mem-
ory and better stability.

• A multi-scale implementation of FODE is elaborated
such that ﬁne scale and coarse scale features in FOC-
Net can be simultaneously utilized to strengthen the
denoising system.

Extensive experiments on image denoising are con-
ducted to validate the effectiveness of FOCNet. The results
show that FOCNet achieves leading denoising performance
in both visual quality and quantitative measures.

2. Related work

In this section we brieﬂy describe some ingredients of
DCNN and optimal control relevant to our work. First, we
outline the forward framework of DCNN, and its applica-
tion to image denoising. Then we present the optimal con-
trol problem and its connection to DCNN.

2.1. The propagation of DCNN

The DCNN learns a highly nonlinear mapping from a
large amount of labeled data by stacking multiple simple
nonlinear units. Mathematically, the plain DCNN can be
formulated as the following evolution process

ut+1 = f (ut, θt)

t = 1 · · · T,

(1)

where ut ∈ Rd is the input of the t-th layer of the network,
ut+1 ∈ Rd is the output of the t-th layer and θt ∈ Rm
is the parameters of the convolution kernel. The nonlinear
unit is often modeled as f (ut, θt) = σ(θt ∗ ut) 1, where
σ : Rd → Rd denotes the nonlinear activation function. Af-
ter T layers evolution, a loss function is used to measure the
distance between the output and the label. The optimal net-
work parameters are obtained by minimizing the loss func-
tion and the regularization function of the parameters as

min
{θt}T

t=1XT

t=1

R(θt) + L(Φ(uT ), x),

(2)

1For simplicity, the bias term is omited.

6055

where Φ : Rd → Rn transforms the ﬁnal layer features to
the output, L : Rn → R is the loss function, R : Rm → R is
the regularization function on the parameter θt and x ∈ Rn
is the label.

The residual network [18] improves the plain network by

adding a skip connection as

ut+1 = ut + f (ut, θt)

t = 1 · · · T.

(3)

Surprisingly, such a minor change has achieved remarkable
success in a lot of computer vision and image processing
applications [18].

The DCNN can be directly used for image denoising by
setting the input as the transformation of the noisy image
u0 = Ψ(y), and label x be the corresponding clean image.
For denoising, the loss function is often set to the l2 loss as
L(uT , x) = 1
2. Due to the powerful learning
ability, DCNN has been attracting considerable attention in
image denoising [45, 42, 35] as we have introduced in Sec-
tion 1.

2 kΦ(uT ) − xk2

2.2. The optimal control problem

The continuous counterpart of deep neural network is
optimal control which has been well studied for hundreds
of years with solid mathematical theories [14]. Denote by
u0 ∈ Rd the initial condition of a dynamic system, the con-
trol of the system can be described by the following ordi-
nary differential equation (ODE)

(cid:26) ˙u(t) = f (u(t), θ(t)),

u(0) = u0, t ∈ [0, T ],

(4)

where θ(t) : [0, T ] → Θ ⊂ Rd is the control parameter
function also called a control [14]. The trajectory u(t) is
regarded as the corresponding response of the system.

PAYOFFS. The overall task of optimal control is to de-
termine what is the best control θ(t) for the system in Eq.
(4). For this reason, a payoff functional should be speci-
ﬁed such that the optimal control maximizes the payoff [14].
The payoff functional can be deﬁned as [25]

P [θ(·)] := Z T

0

H(u(t), θ(t))dt + G(Φ(u(T )))

(5)

where H(·) is the running payoff and G(·) is the terminal
payoff.

Eq. (5) plays the same role as the regularization function
and the loss in Eq. (2), and the residual network in Eq. (3) is
exactly the explicit Euler forward discretization of Eq. (4)
[27]. From the differential equation (4), one can see that the
nonlinear function f (u(t), θ(t)) is designed to depict the
time derivative of the feature trajectory u(t) at time t. The
optimal control viewpoint opens a new way to study deep
neural networks in continuous functional space by leverag-
ing the rich results from differential equations and varia-
tional calculus [41, 25].

3. Proposed method

In Eq. (4), the integer-order differential equation (IODE)
is used to depict the dynamic system, and based on which
the network is constructed [27]. However, the IODE system
has short-term memory, i.e., the evolution of the feature tra-
jectory depends only on the current state without consider-
ing the history of its development.

t
h
g
i
e
W
 
y
r
o
m
e
M

1

0

5

Time

10

i

 

t
h
g
e
W
y
r
o
m
e
M

0.03

0.02

0.01

0

5

Time

10

Figure 1. Memory mode. The left subﬁgure illustrates the short-
term memory of IODE, and the right subﬁgure illustrates the
power-law memory (long-term memory) of FODE.

Power-law memory. As previously discussed, the long-
term memory is the key to the success of a lot of dynamic
systems.
In general, memory obeys the power-law prop-
erty, in which the weight of the previous state at time ti
in deﬁning the present stage at time t is proportional to
(t − ti)β−1 [11], where 1 > β > 0. Recent studies in [12]
have shown that the power-law memory system can be de-
scribed by a fractional-order differential equation (FODE),
where the fractional-order derivative D β
u(t) of a function
u(t) is deﬁned by 2

Deﬁnition 1 [31](Gr¨unwald-Letnikov)

D β

u(t) = lim
h→0

1
hβ

[ t
h ]

Xk=0

(−1)k(cid:18)β

k(cid:19)u(t − kh)

(6)

where β is the order of the derivative (0 < β < 1), [·] means
the interger part and h is the step size.

To show how the memory mode of FODE is different
from that of IODE, an illustration is given in Figure 1, and
where the vertical-axis is the memory weight of the pre-
vious state ti in deﬁning the present stage at time t, the
horizontal-axis is the time that has been past. One can see
that when time evolves, the memory on the previous states
disappear in IODE, while it lasts in FODE. To take full ad-
vantage of the FODE in memory persistent, we propose to
construct an image denoising network from the fractional
optimal control (FOC) viewpoint.

2Note that there are several deﬁnitions of the fractional-order deriva-

tive. Here we adopt the widely used Gr¨unwald-Letnikov’s deﬁnition.

6056

Layers

Current 

state

Scales

(a)

Current 

state

Layers

(b)

Figure 2. Comparison between the single scale memory system
and multi-scale memory system. The blue dot represents the cur-
rent state, the black arrow lines represent the connections of dif-
ferent layers in one scale, and the red arrow lines represent the
cross-scale feature interactions.

3.1. Fractional optimal control view of image de 

noising

We consider the fractional-order system in [36], and as-
sume that u is not only continuous in time but also continu-
ous in space as a functional u(t, s) to depict the image fea-
ture trajectory, where s ∈ Ω is the two dimensional spatial
position. Thus the control problem can be mathematically
described as

1

min
θ(t)

2 ZΩ
s.t.(cid:26) D β

(Φ(u (T, s)) − x (s))2 ds

t u(t, s) = f (u(t, s), θ(t))
u(0, s) = Ψ(y(s)), t ∈ [0, T ],

(7)

where y(s) is the input noisy image, x(s) is the ground
truth clean image and D β
t u(t, s) is the β-th order derivative
of u(t, s) w.r.t. time t. Φ and Ψ are linear transformations,
e.g., convolution. The problem (7) aims to ﬁnd the optimal
control θ(t) such that the objective loss is minimized. The
state equation in problem (7) characterizes the whole evo-
lution process of the denoising system given the noisy input
u(0, s).

3.2. Multi scale memory systems

The continuous model (7) is independent of the actual
image resolution.
In practice, different resolutions of an
image represent different scales of features. Enabling the
long-term memory on different scale features can naturally
strengthen the representation power of the system. There-
fore, to make the best use of our memory system, we pro-
pose a multi-scale model by applying the FODE in Eq. (7)
to multi-scale image features, which can be described as
follows

D β
D β

t u(t, s, l1) = f (u(t, s, l1), g(u(t, s, l1+1)), θ1(t))
t u(t, s, l2) = f (u(t, s, l2), g(u(t, s, l2±1)), θ2(t))

· · ·

t u(t, s, lk) = f (u(t, s, lk), g(u(t, s, lk−1)), θk(t))

D β
u(0, s, l1) = Ψy(s), u(0, s, li) = T↓u(1, s, li−1)
1 ≤ li ≤ k, 0 ≤ t ≤ T,




where D β
t u(t, s, li) represents the fractional order deriva-
tives in Eq. (7) at scale li. l1 is the original scale space and
lk is the down-sampled k-th scale space. In Eq. (8), adja-
cent scale interactions are allowed by a scale switch func-
tion which is deﬁned by g(x) = wT (x), where w ∈ {0, 1}
is a binary variable and T (·) is the pooling or unpooling op-
eration 3. The average pooling is adopted in this paper such
that high scale features represent mostly the low frequency
information (coarse features).

The multi-scale memory system increases the expres-
sivity of current state features by memorizing the previous
state features and different scale features, as shown in Fig-
ure 2. Consider only the current state (blue dot), Figure 2
(a) is the single scale memory system, in which the current
state is explicitly connected to the previous layers. Figure
2 (b) is the multi-scale memory system, in which the cur-
rent state is not only explicitly connnected to the previous
layers (black arrow lines) but also implicitly connect to the
features of all the scales (red arrow lines), thus the features
of the current state can be more expressive.

3.3. Architecture of FOCNet

The architecture of our FOCNet is based on the dis-
cretization of the foregoing continuous FOC model in Eq.
(8). In discretization, we set h in Eq. (6) to be 1. Based on
the multi-scale dynamic system deﬁned in Eq. (8), we could
build our network whose architecture is shown in Figure. 3.
The image features evolve in different scales according to
FODE in Eq. (8).

In each scale, the network connects the long-term fea-
tures according to the speciﬁc deﬁnition of the fractional-
order derivative. Moreover, different scale features are in-
teracted via a scale transform (pooling/unpooling) operator
together with a learned scale transform switch function g in
Eq. (8), which determines whether cross-scale feature inter-
actions are allowed or not by taking a binary value {0, 1}.
Mathematically, the evolution process of our image denois-
ing network can be expressed as

ll
t+1 =

u

t

Xk=0

ll
wku

k + σ(cid:16)θt ∗(cid:16)u

ll±1
ll
t + g(u
t

)(cid:17)(cid:17)

(9)

β

where u
The weight wk is set according to Eq.

ll
t+1 is the output of the t-th layer in scale ll.
(6) as wk =

(−1)t−k+2(cid:0)
β, wk−1 = (1 − 1+β
unit σ(·) consists of “Convolution + BN + Relu”. u
ll+1
notes that either upper scale features u
t

t−k+1(cid:1), which can be calculated by wt =
t−k+2 )wk, k = 1, · · · t. The nonlinear
de-

or lower scale

ll±1
t

features u

ll−1
t

are used 4.

3Pooling is denoted by T↓ and unpooling is denoted by T↑.
4Note that cross-scale feature interactions are not necessary for every

(8)

layer in each scale, the speciﬁc connections are shown in Figure 3.

6057

Scale-1

Scale-2

Scale-3

Average 
Pooling

Unpooling

+

Scale Switch

Scale-4

Feature 
Space

Memory Line

Conv+BN+Relu

Weighted Sum

Figure 3. Architecture of the FOCNet. The memory lines are constructed according to the Gr¨unwald-Letnikov’s deﬁnition of the fractional-
order derivative in Eq. (6). The block “Conv+BN+Relu” corresponds to Eq. (9). The scale switch function is deﬁned in Eq. (8).

i, x

Let {(y

i=1 be a training set, where y

i is the input
i)}N
i is the ground truth image label (clean
noisy image and x
i
T (Θ) the ﬁnal output of our network
image). Denote by u
and Θ represents the parameters of the network, then ac-
cording to Eq. (7), the loss functional in our FOCNet is

i
L (u
T (Θ)) =

1
2N

N

Xi=1

kΦ(u

i
T (Θ)) − x

ik2
F

(10)

The optimal parameter set Θ∗ is obtained by minimizing the
i
loss function L (u
T (Θ)) using the ADAM algorithm [23].

3.4. Property of the long term memory

By exploiting the optimal conditions of the control prob-
lem (7), we show that our FOCNet has the long-term mem-
ory not only in the forward but also in the backward prop-
agation. To begin with, we deﬁne the Hamiltonian H :
Rd × Rd × Θ → R of the control problem

H(u(t), p(t), θ(t)) := p(t) · f (u(t), θ(t)).

(11)

According to the Pontryagin’s maximum principle, the opti-
mal conditions of the minimization problem (7) can be char-
acterized by the following lemma.

Lemma 1 (Pontryagin’s maximum principle) [2] Let
( ˆu(t), ˆθ(t)) be the optimal control process for (7). Then
there exists an absolutely continuous co-state process ˆp(t) :
[0, T ] → Rd such that the Hamilton’s equation

D β

t ˆu(t) = ∇pH( ˆu(t), ˆp(t), ˆθ(t)),

D β

t ˆp(t) = −∇uH( ˆu(t), ˆp(t), ˆθ(t)),

(12)

(13)

with initial conditions

ˆu(0) = Φ(y), ˆp(T ) = −∇L ( ˆu(T ))

are satisﬁed. Moreover, for each t ∈ [0, T ], we have the
Hamiltonian maximization condition

H( ˆu(t), ˆp(t), ˆθ(t)) ≥ H( ˆu(t), ˆp(t), θ(t)).

(14)

for all θ(t).

According to the analysis in [25] and the mechanism of
backward propagation (BP), one can easily verify that the
discretization of Eq. (12) and Eq. (13) correspond to the
forward propagation (FP) and BP of the FOCNet, respec-
tively. Thus, the forward and backward of FOCNet corre-
spond to a speciﬁc FODE which has the long-term memory.

3.5. Discussions

We construct a FOCNet by solving a multi-scale
fractional-order optimal control problem to address the
long-term memory in denoising DCNN. Some denoising
DCNN have also been constructed to deal with the long-
term memory and multi-scale interactions but from totally
different angles.

Relation to MemNets. The MemNet [42] was proposed
to address the long-term memory by concatenating the out-
put of previous layers to generate large size features, then
the large size features are contracted to a small one by learn-
ing a contraction ﬁlter with a huge amount of parameters.
In addition, the mechanism for characterizing the long-term
memory using concatenation is not theoretically solid. In
contrast, our FOCNet can characterize well the power-law
memory principle. Moreover, it does not need to learn the
huge amount of contraction ﬁlters to combine the image fea-
tures.

Relation to Unet. The Unet consists of a contraction and
an expansion subnets. In the contraction stage, the image
features are successively convolved and down-sampled to

6058

generate multi-scale image features. In the expansion stage,
the image features are convolved and up-sampled succes-
sively to generate the ﬁnal output. In our proposed method,
image features propagate in multiple scales, and the Unet
can be considered as a special case of FOCNet in which the
forward process evolves only one step for each scale. Be-
sides, a scale transform switch is designed in our FOCNet
so that the across-scale feature interactions can be adaptive,
which is not available in Unet. In brief, our proposed net-
work structure is more ﬂexible and general than the Unet
architecture [37].

4. Experiments

4.1. Experimental setting

Dataset generation. Before training the FOCNet model,
we need to prepare a training dataset with image pairs
{yi, xi}N
i=1. Here yi is generated by adding AWGN with
speciﬁc noise levels to the latent clean image xi, i.e., yi =
xi + n. Following [26], we consider three noise levels, i.e.,
σ = 15, 25, 50. We collect clean images from two datasets,
including 200 images from Berkeley Segmentation Dataset
[30] and 500 images from DIV2K [1] to generate the train-
ing data. We randomly crop N = 64 × 2000 image patches
of size 80 × 80 from the collected images for training.

Network training. The residual mapping strategy pre-
sented in [45] is employed in our FOCNet. To learn the
optimal parameters, the ADAM optimizer [23] is used to
minimize the loss function. The default setting of the hyper-
parameters of ADAM is adopted. The network parameters
are initialized by random values as in DnCNN [23] and the
mini-batch size is 64. We set the scale number as 4, the
ﬁrst scale has 4 convoution layers, the second and the third
scale have 11 convolution layers and the fourth scale has
7 convolution layers. For all the 4 scales, we set the fea-
ture channel as 128 and the size of the convolution ﬁlters as
3 × 3 × 128 × 128.

We use the MatConvNet package [43] with cuDNN 8.0
to train FOCNet. All the experiments are conducted in the
Matlab (R2017a) environment running on a PC with In-
ter(R) Xeon(R) E5-2620 CPU 2.10GHz and an Nvidia TI-
TAN Xp GPU. We learn for each noise level a FOCNet
model. The learning algorithm converges very fast within
40 epoch, thus we train 35 epoch for our FOCNet, the learn-
ing rate is decayed exponentially from 10−3 to 10−4 in the
35 epochs. It takes about two days to train a FOCNet.

4.2. Ablation study

The setting of β. The setting of parameter β in Eq. (6)
is important to our FOCNet. When β is an integer num-
ber, Eq. (6) reduces to an integer-order derivative. To ﬁg-
ure out how the parameter β inﬂuences the denoising re-
sults, we conduct experiments with different β values as:

Table 1. Comparison of the denoising results with different β. The
PSNR values are the average results on Set12 with noise level 50.

β

0.1

0.2

0.5

0.7

1.0

2.0

PSNR

27.37

27.42

27.30

27.25

27.12

27.15

Table 2. Comparison of the denoising results (dB) with different
scales. The noise level is set as σ = 50.

Dataset
Set12
BSD68
Urban100

one scale

two scales

three scales

four scales

ﬁve scales

27.42
26.32
26.80

27.49
26.38
27.02

27.58
26.45
27.21

27.68
26.48
27.40

27.69
26.50
27.40

FOCNet

27.7

27.6

27.5

27.4

27.3

R
N
S
P

FFDNet

N3Net

MemNet

RED

27.2

27.1

DnCNN
10-2

Computational time (seconds)

100

Figure 4. Comparison of computational time and PSNR values.

β = 0.1, 0.2, 0.5, 0.7, 1.0 and 2.0 for single scale FOC-
Net. We test FOCNet on the dataset Set12 for noise level
σ = 50. The results (average PSNR) are shown in Table
1. One can see that the FOCNet achieves the highest PSNR
when β = 0.2 and gets inferior PSNR value for β = 1, 2,
which indicates that the long-term memory is useful to im-
age denoising.

The setting of scale. We would also like to show the ef-
fectiveness of the multi-scale strategy in FOCNet for image
denoising. We test FOCNet from 1 to 5 scales, and the aver-
age PSNR values on three datasets are shown in Table 2. We
see that with the increase of the number of scales, the PSNR
values increase as well. However, when the scale number is
up to 4, further increase of the scale only gives negligible
improvement. To balance the efﬁciency and effectiveness,
we set the scale number to be 4.

4.3. Denoising results

We evaluate the denoising performance of FOCNet on
three widely used test sets, i.e., Set12 [45], BSD68 [30] and
Urban100 [20]. The experimental results of the FOCNet are
compared with the following state-of-the-art and represen-
tative denoising methods: BM3D [9], WNNM [16], TNRD
[8], DnCNN [45], FFDNet [46], RED [29], MemNet [42]
and N3Net [35]. Among the compared methods, except for
BM3D, WNNM and TNRD, all the remaining methods are
based on DCNN. Similar to FOCNet, the MemNet exploits
the long-term memory as well.

Table 3 exhibits the average PSNR results of the compet-
ing methods on the three datasets and Table 4 lists the PSNR
values of the competing methods for each image in Set12.
The best results are highlighted in red. It can be seen from
Table 3 and Table 4 that the PSNR results of FOCNet have
remarkable improvements over the competing methods not

6059

(a) Original Image

(b) Noisy Image

(c) WNNM [16] (25.44)

(d) TNRD [8] (25.42)

(e) DnCNN [45] (25.70)

(f) FFDNet [46] (25.77)

(g) RED [29] (25.80)

(h) MemNet [42] (25.76)

(i) N3Net [35] (26.00)

(j) FOCNet (26.19)

Figure 5. Visual quality comparison. The referenced region (red rectangle) is zoom in at the bottom left green rectangle for better compar-
ison. The PSNR value of each recovered result is given in the parentheses.

Table 3. Average PSNR values for noise level 15, 25 and 50 on Set12, BSD68 and Urban100. The best results are highlighted in red. The
symbol “-” denotes that the results are not provided by the corresponding authors.

Dataset

Set12

BSD68

Urban100

σ
15
25
50
15
25
50
15
25
50

BM3D [9] WNNM [16]

TNRD [8]

DnCNN [45]

FFDNet [46]

RED [29] MemNet [42] N3Net [35]

FOCNet

32.37
29.97
26.72
31.08
28.57
25.60
32.34
29.70
25.94

32.70
30.28
27.05
31.37
28.83
25.87
32.97
30.39
26.83

32.50
30.05
26.82
31.42
28.92
25.97
31.98
29.29
25.71

32.86
30.44
27.18
31.73
29.23
26.23
32.67
29.97
26.28

32.75
30.43
27.32
31.63
29.19
26.29
32.42
29.92
26.52

-
-

-
-

27.34

27.38

-
-

-
-

26.35

26.35

-
-

-
-

26.48

26.64

-

30.50
27.43

-

29.30
26.39

-

30.19
26.82

33.07
30.73
27.68
31.83
29.38
26.50
33.15
30.64
27.40

only on average but also for each test image. Speciﬁcally,
FOCNet improves the traditional methods such as BM3D
and WNNM by 0.5 ∼ 0.9 dB on Set12 with noise level
σ = 50, and compared with DnCNN, the improvement is
still up to 0.3 ∼ 0.5dB. On the Urban100 dataset, the dif-
ferences between FOCNet and the compared methods be-
come more distinct. FOCNet also outperforms the memory
persistent network MemNet by a large margin in all the test
sets. We also compare FOCNet with the nonlocal based
denoising network N3Net, and the results veriﬁed the su-
periority of FOCNet over N3Net, despite that there are no
time consuming nonlocal operations in FOCNet.

Visual quality comparisons are given in Fig. 5 and Fig.
6, in which the clean images are corrupted by Gaussian
noise with noise level σ = 50. In Fig. 5, we can see that
FOCNet is able to recovery the ﬁne details of the corrupted
image, such as the region in the red rectangle, which is
zoomed-in at the bottom left of the image marked by green
rectangle. In contrast, the competing methods over-smooth
In Fig. 6, the recovered result
the details of the image.
provided by FOCNet is more faithful to the clean image

than all the competing methods. As shown in the zoomed-
in part (the windows of the building and the wall), FOCNet
can accurately estimate the clean image with clear struc-
tures, while the results of competing methods either over-
smooth or blur much the structures. All these facts indicate
that FOCNet is superior to the existing methods not only in
quantitative results but also in perceptual quality.

In addition to the denoising performance, we also com-
pare the run time together with the corresponding PSNR
value of the competing methods in Figure 4. Only the CNN
based methods are considered in this comparison. The com-
putational time of FOCNet is much less than RED [29],
MemNet [42] and N3Net [35]. In comparison to DnCNN
[45] and FFDNet [46], FOCNet is a little slower but it deliv-
ers much more satisfactory results in terms of PSNR. Over-
all, FOCNet is not only efﬁcient but also effective.

5. Conclusion

In this paper, we used the fractional optimal control
(FOC) theory to model the deep convolution neural net-

6060

(a) Original Image

(b) Noisy Image

(c) WNNM [16] (25.40)

(d) TNRD [8] (25.06)

(e) DnCNN [45] (25.56)

(f) FFDNet [46] (25.75)

(g) RED [29] (25.78)

(h) MemNet [42] (25.82)

(i) N3Net [35] (25.91)

(j) FOCNet (26.14)

Figure 6. Visual quality comparison. Two reference regions (marked in red) are zoomed in at the bottom of each subimage (marked in
green). The PSNR value of each recovered result is given in the parentheses.

Table 4. The PSNR results of different methods on Set12 dataset with noise level 15, 25 and 50. The best results are highlighted in red.

Images

C.man

House

Peppers

Starﬁsh Monarch

Airplane

Parrot

Lena

Barbara

Boat

Man

Couple

Noise Level
BM3D [9]

WNNM [16]

TNRD [8]

DnCNN [45]
FFDNet [46]

FOCNet

Noise Level
BM3D [9]

WNNM [16]

TNRD [8]

DnCNN [45]
FFDNet [46]
N3Net [35]

FOCNet

Noise Level
BM3D [9]

WNNM [16]

TNRD [8]

DnCNN [45]
FFDNet [46]

RED [29]

MemNet [42]
N3Net [35]

FOCNet

31.91
32.17
32.19
32.61
32.42
32.71

29.45
29.64
29.72
30.18
30.06
30.08
30.35

26.13
26.45
26.62
27.03
27.03
27.02
27.23
27.14
27.36

34.93
35.13
34.53
34.97
35.01
35.44

32.85
33.22
32.53
33.06
33.27
33.25
33.63

29.69
30.33
29.48
30.00
30.43
30.46
30.70
30.50
30.91

32.69
32.99
33.04
33.30
33.10
33.41

30.16
30.42
30.57
30.87
30.79
30.90
31.00

26.68
26.95
27.10
27.32
27.43
27.22
27.51
27.58
27.57

31.14
31.82
31.75
32.20
32.02
32.40

28.56
29.03
29.02
29.41
29.33
29.55
29.75

25.04
25.44
25.42
25.70
25.77
25.80
25.76
26.00
26.19

31.85
32.71
32.56
33.09
32.77
33.29

29.25
29.84
29.85
30.28
30.14
30.45
30.49

25.82
26.32
26.31
26.78
26.88
26.99
27.19
27.03
27.10

σ = 15

31.07
31.39
31.46
31.70
31.58
31.82

σ = 25

28.42
28.69
28.88
29.13
29.05
29.02
29.26

σ = 50

25.10
25.42
25.59
25.87
25.90
25.94
25.96
25.75
26.06

31.37
31.62
31.63
31.83
31.77
31.98

28.93
29.15
29.18
29.43
29.43
29.45
29.58

25.90
26.14
26.16
26.48
26.58
26.45
26.49
26.50
26.75

34.26
34.27
34.24
34.62
34.63
34.85

32.07
32.24
32.00
32.44
32.59
32.59
32.83

29.05
29.25
28.93
29.39
29.68
29.58
29.63
29.67
29.98

33.10
33.60
32.13
32.64
32.50
33.09

30.71
31.24
29.41
30.00
29.98
30.22
30.74

27.22
27.79
25.70
26.22
26.48
26.65
26.67
27.01
27.60

32.13
32.27
32.14
32.42
32.35
32.62

29.90
30.03
29.91
30.21
30.23
30.26
30.46

26.78
26.97
26.94
27.20
27.32
27.32
27.29
27.32
27.53

31.92
32.11
32.23
32.46
32.40
32.56

29.61
29.76
29.87
30.10
30.10
30.12
30.22

26.81
26.94
26.98
27.24
27.30
27.20
27.24
27.33
27.42

32.10
32.17
32.11
32.47
32.45
32.64

29.71
29.82
29.71
30.12
30.18
30.12
30.40

26.46
26.64
26.50
26.90
27.07
27.08
27.14
27.04
27.39

work. With the aid of fractional-order derivative, a FOCNet
was elaborated to mitigate the short-term memory of the ex-
isting integer-order derivative based network. The FOCNet
obeys the power-law memory mode which has veriﬁed to be
effective in a lot of dynamic systems. According to the op-
timal condition given by Pontryagin’s maximum principle,
we showed that the FOCNet has long-term memory not only
in the forward process but also in the backward process. In

addition, a multi-scale strategy was adopted to strengthen
the network by promoting cross-scale feature interactions.
Experimental results on image denoising veriﬁed that FOC-
Net achieves the leading PSNR results while having a rea-
sonable runing speed.

6061

References

[1] E. Agustsson and R. Timofte. Ntire 2017 challenge on sin-
gle image super-resolution: Dataset and study. In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR) Workshops, volume 3, page 2, 2017. 6

[2] H. M. Ali, F. L. Pereira, and S. M. Gama. A new approach to
the pontryagin maximum principle for nonlinear fractional
optimal control problems. Mathematical Methods in the Ap-
plied Sciences, 39(13):3640–3649, 2016. 5

[3] J. R. Anderson. Learning and memory: An integrated ap-

proach. John Wiley & Sons Inc, 2000. 2

[4] W. Bae, J. J. Yoo, and J. C. Ye. Beyond deep residual learn-
ing for image restoration: Persistent homology-guided man-
ifold simpliﬁcation. In CVPR Workshops, pages 1141–1149,
2017. 1

[5] J. Bai and X.-C. Feng. Fractional-order anisotropic diffusion
for image denoising. IEEE transactions on image process-
ing, 16(10):2492–2502, 2007. 2

[6] A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
for image denoising. In Computer Vision and Pattern Recog-
nition, 2005. CVPR 2005. IEEE Computer Society Confer-
ence on, volume 2, pages 60–65. IEEE, 2005. 1

[7] R. Caponetto. Fractional order systems: modeling and con-

trol applications, volume 72. World Scientiﬁc, 2010. 2

[8] Y. Chen and T. Pock. Trainable nonlinear reaction diffusion:
A ﬂexible framework for fast and effective image restora-
tion.
IEEE transactions on pattern analysis and machine
intelligence, 39(6):1256–1272, 2017. 6, 7, 8

[9] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Image
denoising by sparse 3-d transform-domain collaborative ﬁl-
tering. IEEE Transactions on image processing, 16(8):2080–
2095, 2007. 1, 6, 7, 8

[10] M. Edelman. Fractional dynamical systems. arXiv preprint

arXiv:1401.0048, 2013. 2

[11] M. Edelman. Fractional maps as maps with power-law mem-
ory. In Nonlinear dynamics and complexity, pages 79–120.
Springer, 2014. 2, 3

[12] M. Edelman. Universality in systems with power-law mem-
ory and fractional dynamics.
In Chaotic, Fractional, and
Complex Dynamics: New Insights and Perspectives, pages
147–171. Springer, 2018. 3

[13] M. Elad and M. Aharon.

Image denoising via sparse and
redundant representations over learned dictionaries.
IEEE
Transactions on Image processing, 15(12):3736–3745, 2006.
1

[14] L. C. Evans. An introduction to mathematical optimal con-
trol theory. Lecture Notes, University of California, Depart-
ment of Mathematics, Berkeley, 2005. 3

[15] A. N. Gomez, M. Ren, R. Urtasun, and R. B. Grosse. The re-
versible residual network: Backpropagation without storing
activations. In Advances in Neural Information Processing
Systems, pages 2214–2224, 2017. 2

[16] S. Gu, L. Zhang, W. Zuo, and X. Feng. Weighted nuclear
norm minimization with application to image denoising. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 2862–2869, 2014. 1, 6, 7,
8

[17] E. Haber and L. Ruthotto. Stable architectures for deep neu-

ral networks. Inverse Problems, 34(1), 2018. 1

[18] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn-
ing for image recognition. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition, pages
770–778, 2016. 2, 3

[19] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Wein-
berger. Densely connected convolutional networks. In 2017
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), pages 2261–2269. IEEE, 2017. 2

[20] J.-B. Huang, A. Singh, and N. Ahuja. Single image super-
resolution from transformed self-exemplars. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 5197–5206, 2015. 6

[21] A. Jain and J. Jain. Partial differential equations and ﬁ-
Im-
IEEE Transactions on Automatic Control,

nite difference methods in image processing–part ii:
age restoration.
23(5):817–834, 1978. 2

[22] X. Jia, X. Feng, and W. Wang. Adaptive regularizer learn-
ing for low rank approximation with application to image
denoising. In Image Processing (ICIP), 2016 IEEE Interna-
tional Conference on, pages 3096–3100. IEEE, 2016. 1

[23] D. P. Kingma and J. L. Ba. Adam: Amethod for stochastic

optimization. 5, 6

[24] G. Larsson, M. Maire, and G. Shakhnarovich. Fractalnet:
Ultra-deep neural networks without residuals. arXiv preprint
arXiv:1605.07648, 2016. 2

[25] Q. Li, L. Chen, C. Tai, and E. Weinan. Maximum principle
based algorithms for deep learning. The Journal of Machine
Learning Research, 18(1):5998–6026, 2017. 1, 2, 3, 5

[26] P. Liu, H. Zhang, K. Zhang, L. Lin, and W. Zuo. Multi-level
In Proceedings of the
wavelet-cnn for image restoration.
IEEE Conference on Computer Vision and Pattern Recog-
nition Workshops, pages 773–782, 2018. 1, 6

[27] Y. Lu, A. Zhong, Q. Li, and B. Dong. Beyond ﬁnite layer
neural networks: Bridging deep architectures and numeri-
cal differential equations. arXiv preprint arXiv:1710.10121,
2017. 1, 2, 3

[28] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman.
Non-local sparse models for image restoration. In Computer
Vision, 2009 IEEE 12th International Conference on, pages
2272–2279. IEEE, 2009. 1

[29] X. Mao, C. Shen, and Y.-B. Yang.

Image restoration us-
ing very deep convolutional encoder-decoder networks with
symmetric skip connections.
In Advances in neural infor-
mation processing systems, pages 2802–2810, 2016. 1, 6, 7,
8

[30] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of
human segmented natural images and its application to eval-
uating segmentation algorithms and measuring ecological
statistics. In Computer Vision, 2001. ICCV 2001. Proceed-
ings. Eighth IEEE International Conference on, volume 2,
pages 416–423. IEEE, 2001. 6

[31] C. A. Monje, Y. Chen, B. M. Vinagre, D. Xue, and V. Feliu-
Batlle. Fractional-order systems and controls: fundamentals
and applications. Springer Science & Business Media, 2010.
2, 3

6062

[32] P. Perona and J. Malik. Scale-space and edge detection using
anisotropic diffusion. IEEE Transactions on pattern analysis
and machine intelligence, 12(7):629–639, 1990. 1, 2

[33] I. Petr´aˇs. Fractional-order nonlinear systems: modeling,
analysis and simulation. Springer Science & Business Me-
dia, 2011. 2

[34] F. J. Pineda. Dynamics and architecture for neural computa-

tion. Journal of Complexity, 4(3):216–245, 1988. 1

[35] T. Pl¨otz and S. Roth. Neural nearest neighbors networks. In
Advances in Neural Information Processing Systems (NIPS),
2018. 1, 3, 6, 7, 8

[36] I. Podlubny.

Fractional-order systems and pi/sup/spl
IEEE Transactions on

lambda//d/sup/spl mu//-controllers.
automatic control, 44(1):208–214, 1999. 2, 4

[37] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convo-
lutional networks for biomedical image segmentation.
In
International Conference on Medical image computing and
computer-assisted intervention, pages 234–241. Springer,
2015. 6

[38] S. Roth and M. J. Black. Fields of experts.

International

Journal of Computer Vision, 82(2):205–229, 2009. 1

[39] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total varia-
tion based noise removal algorithms. Physica D: nonlinear
phenomena, 60(1-4):259–268, 1992. 1, 2

[40] L. Ruthotto and E. Haber. Deep neural networks mo-
arXiv preprint

tivated by partial differential equations.
arXiv:1804.04272, 2018. 1, 2

[41] O. Scherzer, M. Grasmair, H. Grossauer, M. Haltmeier, and
F. Lenzen. Variational methods in imaging. Springer, 2009.
3

[42] Y. Tai, J. Yang, X. Liu, and C. Xu. Memnet: A persistent
memory network for image restoration. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 4539–4547, 2017. 1, 2, 3, 5, 6, 7, 8

[43] A. Vedaldi and K. Lenc. Matconvnet: Convolutional neural
networks for matlab. In Proceedings of the 23rd ACM inter-
national conference on Multimedia, pages 689–692. ACM,
2015. 6

[44] E. Weinan. A proposal on machine learning via dynami-
cal systems. Communications in Mathematics and Statistics,
5(1):1–11, 2017. 1

[45] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
yond a gaussian denoiser: Residual learning of deep cnn for
image denoising. IEEE Transactions on Image Processing,
26(7):3142–3155, 2017. 1, 3, 6, 7, 8

[46] K. Zhang, W. Zuo, and L. Zhang. Ffdnet: Toward a fast
and ﬂexible solution for cnn based image denoising. IEEE
Transactions on Image Processing, 27(9):4608–4622, 2018.
1, 6, 7, 8

[47] X. Zhang, Z. Li, C. C. Loy, and D. Lin. Polynet: A pursuit
of structural diversity in very deep networks. In Computer
Vision and Pattern Recognition (CVPR), 2017 IEEE Confer-
ence on, pages 3900–3908. IEEE, 2017. 2

6063

