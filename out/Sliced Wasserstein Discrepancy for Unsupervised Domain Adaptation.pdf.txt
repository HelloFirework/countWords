Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation

Chen-Yu Lee

Tanmay Batra

Mohammad Haris Baig

Daniel Ulbricht

Apple Inc

Abstract

In this work, we connect two distinct concepts for un-
supervised domain adaptation: feature distribution align-
ment between domains by utilizing the task-speciﬁc decision
boundary [57] and the Wasserstein metric [72]. Our pro-
posed sliced Wasserstein discrepancy (SWD) is designed to
capture the natural notion of dissimilarity between the out-
puts of task-speciﬁc classiﬁers. It provides a geometrically
meaningful guidance to detect target samples that are far
from the support of the source and enables efﬁcient distri-
bution alignment in an end-to-end trainable fashion. In the
experiments, we validate the effectiveness and genericness
of our method on digit and sign recognition, image classiﬁ-
cation, semantic segmentation, and object detection.

1. Introduction

Deep convolutional neural networks [30] is a milestone
technique in the development of modern machine percep-
tion systems solving various tasks such as classiﬁcation,
semantic segmentation, object detection, etc. However, in
spite of the exceptional learning capacity and the improved
generalizability, deep learning models still suffer from the
challenge of domain shift – a shift in the relationship be-
tween data collected in two different domains [3, 2] (e.g.
synthetic and real). Models trained on data collected in
one domain can perform poorly on other domains. Domain
shift can exist in multiple forms: covariate shift (distribu-
tion shift in attributes), prior probability shift (shift in la-
bels), and concept shift (shift in the relationship between
attributes and labels) [61, 66, 44].

In this paper, we focus on the covariate shift problem
for the case where we have access to labeled data from one
domain (source) and unlabeled data from another domain
(target). This setup is commonly called unsupervised do-
main adaptation. Most of the work done in this ﬁeld has fo-
cused on establishing a direct alignment between the feature
distribution of source and target domains. Such alignment
involves minimizing some distance measure of the feature
distribution learned by the models [56, 17, 38]. More so-
phisticated methods use adversarial training [19] to fur-

ther improve the quality of alignment between distributions
by adapting representations at feature-level [24, 18], pixel-
level [36, 70, 5], or output-level [69] across domains.

A recent advance that moves beyond the direction of
plain distribution matching was presented by Saito et
al. in [57]. They propose a within-network adversarial
learning-based method containing a feature generator and
two (task-speciﬁc) classiﬁers, which uses the task-speciﬁc
decision boundary for aligning source and target samples.
Their method deﬁnes a new standard in developing generic
domain adaptation frameworks. However, the system does
have some limitations. For instance, their discrepancy loss
(L1 in this case) is only helpful when the two output proba-
bility measures from the classiﬁers overlap.

Inspired by the framework in [57], we focus our ef-
forts on improving the discrepancy measure which plays
a central role in such within-network adversarial learning-
based approach. Our method aims to minimize the cost of
moving the marginal distributions between the task-speciﬁc
classiﬁers by utilizing the Wasserstein metric [43, 27, 1],
which provides a more meaningful notion of dissimilarity
for probability distributions. We make several key contri-
butions in this work: (1) a novel and principled method
for aligning feature distributions between domains via op-
timal transport theory (i.e.,Wasserstein distance) and the
task-speciﬁc decision boundary. (2) enable efﬁcient end-to-
end training using sliced Wasserstein discrepancy (a vari-
ational formulation of Wasserstein metric). (3) effectively
harness the geometry of the underlying manifold created by
optimizing the sliced Wasserstein discrepancy in an adver-
sarial manner. (4) the method advances the state-of-the-art
across several tasks and can be readily applied to any do-
main adaptation problem such as image classiﬁcation, se-
mantic segmentation, and object detection.

2. Related Work

A rich body of approaches to unsupervised domain adap-
tation aim to reduce the gap between the source and tar-
get domains by learning domain-invariant feature represen-
tations, through various statistical moment matching tech-
niques. Some methods utilize maximum mean discrepancy
(MMD) [38, 39] to match the hidden representations of cer-

110285

tain layers in a deep neural network. Other approaches
uses Central moment discrepancy (CMD) method [75] to
explicitly match each order and each hidden coordinate of
higher order moments. Adaptive batch normalization (Ad-
aBN) [33] has also been proposed to modulate the statis-
tics in all batch normalization layers across the network be-
tween domains.

Another family of strategies tackles the domain adapta-
tion problem by leveraging the adversarial learning behav-
ior of GANs [19]. Such technique was ﬁrst used at feature-
level where a domain discriminator is trained to correctly
classify the domain of each input feature and the feature
generator is trained to deceive the domain discriminator so
that the resulting feature distribution is made domain in-
variant [71, 24, 18]. Later the technique was applied at
pixel-level to perform distribution alignment in raw input
space, translating source domain to the “style” of target do-
main and obtaining models trained on transformed source
data [36, 70, 5, 62, 23, 59, 45]. Recently the technique was
used at output-level by assuming that the output space con-
tains similar spatial structure for some speciﬁc tasks such as
semantic segmentation. The method in [69] thereby aligns
pixel-level ground truth through adversarial learning in the
output space. Other hybrid approaches have also been pro-
posed in [60, 25].

In contrast, Saito et al. in [57] proposed to align distri-
butions by explicitly utilizing task-speciﬁc classiﬁers as a
discriminator. The framework maximizes the discrepancy
between two classiﬁers’ output to detect target samples that
are outside the support of the source and then minimizes the
discrepancy to generate feature representations that are in-
side the support of the source with respect to the decision
boundary.
Instead of aligning manifold in feature, input,
or output space by heuristic assumptions, this approach fo-
cuses on directly reshaping the target data regions that in-
deed need to be reshaped.

Wasserstein metric, the natural geometry for probability
measures induced by the optimal transport theory, has been
investigated in several ﬁelds such as image retrieval [55],
color-based style transfer [51], and image warping [21].
The Wasserstein distance has also recently raised interest
in stabilizing generative modeling [1, 14, 73], learning in-
trospective neural networks [32], and obtaining Gaussian
mixture models [29] thanks to its geometrically meaningful
distance measure even when the supports of the distribu-
tions do not overlap.

As for domain adaptation, Courty et al. in [10] ﬁrst learn
a transportation plan matching source and target samples
with class regularity. JDOT method [9] learns to map input
space from source to target by jointly considering the class
regularity and feature distribution. DeepJDOT method [12]
further improves upon JDOT by jointly matching feature
and label space distributions with more discriminative fea-

ture representations in a deep neural network layer. How-
ever, the fact that these approaches explicitly enforce an
one-to-one mapping between source samples and target
samples in label space could largely restrict the practical
usages when balanced source-target pairs are unavailable.
It is also unclear how to extend these approaches to more
generic tasks when one data sample has structured output
space such as pixel-wise semantic segmentation.

In this work, we propose a principled framework to
marry the two powerful concepts: distribution alignment
by task-speciﬁc decision boundary [57] and the Wasserstein
distance [72]. The Wasserstein metric serves as a reliable
discrepancy measure between the task-speciﬁc classiﬁers,
which directly measures the support of target samples from
source samples instead of producing explicit one-to-one
mapping in label space. A variational version of the Wasser-
stein discrepancy further provides straightforward and geo-
matrically meaningful gradients to jointly train the feature
generator and classiﬁers in the framework efﬁciently.

3. Method

We ﬁrst introduce unsupervised domain adaptation set-
ting in Section 3.1. Second, we brieﬂy review the concept
of optimal transport in Section 3.2. Finally, we detail how
to train the proposed method with the sliced Wasserstein
discrepancy in Section 3.3.

3.1. Framework Setup

Given input data xs and the corresponding ground truth
ys drawn from the source set {Xs, Ys}, and input data xt
drawn from the target set Xt, the goal of unsupervised do-
main adaptation is to establish knowledge transfer from the
labeled source set to the unlabeled target set as mentioned
in [47]. When the two data distributions Xs and Xt are
close enough, one can simply focus on minimizing an em-
pirical risk of the joint probability distribution P(Xs, Ys).
However, when that the two distributions are substantially
different, optimizing a model solely over the source infor-
mation results in poor generalizability.

Following the Maximum Classiﬁer Discrepancy (MCD)
framework [57], we train a feature generator network G and
the classiﬁer networks C1 and C2, which take feature re-
sponses generated from G and produce the corresponding
logits p1(y|x), p2(y|x) respectively (as shown in Figure 1).
The optimization procedure consists of three steps:
(1) train both generator G and classiﬁers (C1, C2) on the
source domain {Xs, Ys} to classify or regress the source
samples correctly,

min

G,C1,C2

Ls(Xs, Ys),

(1)

where Ls can be any loss functions of interest such as cross
entropy loss or mean squared error loss.

10286

Input

G

C
1

C
2

Linear 
Projection 

Task-Specific 
Sliced Wasserstein Discrepancy

Figure 1: An illustration of the proposed sliced Wasserstein discrepancy (SWD) computation. The SWD is designed to capture the
dissimilarity of probability measures p1 and p2 in Rd between the task-speciﬁc classiﬁers C1 and C2, which take input from feature
generator G. The SWD enables end-to-end training directly through a variational formulation of Wasserstein metric using radial projections
on the uniform measures on the unit sphere S d−1, providing a geometrically meaningful guidance to detect target samples that are far from
the support of the source. Please refer to Section 3.3 for details.

(2) freeze the parameters of the generator G and update the
classiﬁers (C1, C2) to maximize the discrepancy between
the outputs of the two classiﬁers on the target set Xt, identi-
fying the target samples that are outside the support of task-
speciﬁc decision boundaries,

min
C1,C2

Ls(Xs, Ys) − LDIS(Xt)

(2)

where LDIS(Xt) is the discrepancy loss (L1 in [57]).
Ls(Xs, Ys) is also added to this step to retain information
from the source domain, and
(3) freeze the parameters of the two classiﬁers and update
the generator G to minimize the discrepancy between the
outputs of the two classiﬁers on the target set Xt,

min

G

LDIS(Xt)

(3)

This step brings the target feature manifold closer to the
source.

3.2. Optimal Transport and Wasserstein Distance

The effectiveness of domain adaptation in the aforemen-
tioned MCD framework depends entirely on the reliability
of the discrepancy loss. Learning without the discrepancy
loss, essentially dropping step 2 and step 3 in the training
procedure, is simply supervised learning on the source do-
main.

The Wasserstein distance has recently received great at-
tention in designing loss functions for its superiority over
other probability measures [73, 41]. In comparison to other
popular probability measures such as total variation dis-
tance, Kullback-Leibler divergence, and Jensen-Shannon
divergence that compare point-wise histogram embeddings
alone, Wasserstein distance takes into account the proper-
ties of the underlying geometry of probability space and it is
even able to compare distribution measures that do not share
support [1]. Motivated by the advantages of the Wasserstein
distance, we now describe how we leverage this metric for
measuring the discrepancy in our method.

Let Ω be a probability space and µ, ν be two probability
measures in P(Ω), the Monge problem [43] seeks a trans-
port map T : Ω → Ω that minimizes the cost

T#µ=νZΩ

inf

c(z, T (z))dµ(z),

(4)

where T#µ = ν denotes a one-to-one push-forward from
µ toward ν ∀ Borel subset A ⊂ Ω and c : Ω × Ω → R+
is a geodesic metric that can be either linear or quadratic.
However, the solution T ∗ may not always exist due to the
assumption of no splitting of the probability measures, for
example when pushing a Dirac measure toward a non-Dirac
measure.

Kantorovitch [27] proposed a relaxed version of Eq 4,
which seeks a transportation plan of a joint probability dis-
tribution γ ∈ P(Ω × Ω) such that

γ∈Π(µ,ν)ZΩ×Ω

inf

c(z1, z2)dγ(z1, z2),

(5)

where Π(µ, ν) = {γ ∈ P(Ω × Ω)|π1#γ = µ, π2#γ = ν}
and π1 and π2 denote the two marginal projections of Ω × Ω
∗ are called optimal transport plans or
to Ω. The solutions γ
optimal couplings [72].

For q ≥ 1, the q-Wasserstein distance between µ and ν

in P(Ω) is deﬁned as

Wq(µ, ν) = (cid:18) inf

γ∈Π(µ,ν)ZΩ×Ω

c(z1, z2)qdγ(z1, z2)(cid:19)1/q

,

(6)

which is the minimum cost induced by the optimal trans-
In our method, we use the 1-Wasserstein
portation plan.
distance, also called the earth mover’s distance (EMD).

3.3. Learning with Sliced Wasserstein Discrepancy

In this work, we propose to apply 1-Wasserstein dis-
tance to the domain adaptation framework described in
Section 3.1. We utilize the geometrically meaningful 1-
Wasserstein distance as the discrepancy measure in step 2

10287

Algorithm 1 Sliced Wasserstein Discrepancy for Unsupervised Domain
Adaptation

Require: Labeled source set {Xs, Ys}, unlabeled target set Xt, number
of random projections M , and randomly initialized feature generator G
and classiﬁers C1, C2.
while G, C1, and C2 have not converged do

Step 1: Train G, C1, and C2 on labeled source set:

min

G,C1,C2

Ls(Xs, Ys)

Step 2: Train C1 and C2 to maximize sliced Wasserstein discrepancy

on unlabeled target set:
Obtain classiﬁers’ output p1 and p2 on target samples
Sample {θ1, ..., θM } from Sd−1 in Rd
Sort Rθm p1 such that Rθm p1(j) ≤ Rθm p1(j+1)
Sort Rθm p2 such that Rθm p2(j) ≤ Rθm p2(j+1)

min
C1,C2

Ls(Xs, Ys) − LDIS(Xt)

where LDIS(Xt) = P
m

P
j

c(Rθm p1(j), Rθm p2(j))

Step 3: Train G to minimize the same sliced Wasserstein discrepancy

on unlabeled target set:
min

G

LDIS(Xt)

end while

and step 3 in the aforementioned framework. In practice, we
consider the discrete version of classiﬁers’ logits p1(y|x)
and p2(y|x). Computing W1(p1, p2) requires obtaining the
∗ by solving a linear program-
optimal transport coupling γ
ming problem [27], which is not efﬁcient. Although var-
ious optimization approaches have been proposed in the
past [11, 16], it is unclear how we can directly optimize
W1(p1, p2) in an end-to-end trainable fashion efﬁciently.

To take advantage of the best of both worlds – to align
distributions of source and target by utilizing the task-
speciﬁc decision boundaries and to incorporate the Wasser-
stein discrepancy, which has well-behaved energy land-
scape for stochastic gradient descent training, we propose to
integrate W1(p1, p2) into our framework by using the sliced
Wasserstein discrepancy, a 1-D variational formulation of
the 1-Wasserstein distance between the outputs p1 and p2
of the classiﬁers along the radial projections.

Motivated by [52] which deﬁnes a sliced barycenter of
discrete measures, we deﬁne the sliced 1-Wasserstein dis-
crepancy (SWD) as

SWD(µ, ν) = ZS d−1

W1(Rθµ, Rθν)dθ,

(7)

where Rθ denotes a one-dimensional linear projection op-
eration on the probability measure µ or ν, and θ is a uniform

measure on the unit sphere S d−1 in Rd such thatRS d−1 dθ =

1.
In this manner, computing the sliced Wasserstein dis-
crepancy is equivalent to solving several one-dimensional
optimal transport problems which have closed-form solu-
tions [52].

Speciﬁcally, let α and β be the permutations that or-
der the N one-dimensional linear projections of N sam-
ples such that ∀ 0 ≤ i < N − 1, Rθµα(i) ≤ Rθµα(i+1)

and Rθν β(i) ≤ Rθν β(i+1), then the optimal coupling γ
that minimizes such one-dimensional Wasserstein distance
is simply assign Rθµα(i) to Rθν β(i) using a sorting algo-
rithm. For discrete probability measures, our SWD can be
written as:

∗

SWD(µ, ν) =

M

N

Xm=1

Xi=1

c(Rθm µα(i), Rθm νβ(i))

(8)

for M randomly sampled θ and quadratic loss for c unless
otherwise mentioned. Our proposed SWD is essentially a
variational version of original Wasserstein distance but at
a fraction of its computational cost [4]. More importantly,
the SWD is differentiable due to the close-form characteris-
tic, so we can focus on using optimal transport as a reliable
ﬁdelity measure to guide the optimization of feature gener-
ator and classiﬁers. We summarize our framework in Algo-
rithm 1 and illustrate the SWD computation in Figure 1.

4. Experiments

In principle, our method can be applied to any domain
adaptation tasks and does not require any similarity assump-
tions in input or output space. We perform extensive evalu-
ation of the proposed method on digit and sign recognition,
image classiﬁcation, semantic segmentation, and object de-
tection tasks.

4.1. Digit and Sign Recognition

In this experiment, we evaluate our method using ﬁve
standard benchmark datasets: Street View House Numbers
(SVHN) [46], MNIST [31], USPS [26], Synthetic Trafﬁc
Signs (SYNSIG) [42], and German Trafﬁc Sign Recogni-
tion Benchmark (GTSRB) [65] datasets. For each domain
shift pair, we use the exact CNN architecture provided by
Saito et al. [57]. We use Adam [28] solver with mini-
batch size of 128 in all experiments. Gradient reversal layer
(GRL) [17] is used for training the networks so we do not
need to control the update frequency between the genera-
tor and classiﬁers. The hyper-parameter particular to our
method is the number of radial projections M . We varied
the value of M in our experiment and detailed the sensitiv-
ity to the hyper-parameter in Figure 2(a) and 2(b).

SVHN → MNIST We ﬁrst examine the adaptation from
real-world house numbers obtained from Google Street
View images [46] to handwritten digits [31]. The two
domains demonstrate distinct distributions because images
from SVHN dataset contain cluttered background from
streets and cropped digits near the image boundaries. We
use the standard training set as training samples, and testing
set as test samples both for source and target domains. The
feature generator contains three 5×5 conv layers with stride
two 3×3 max pooling placed after the ﬁrst two conv layers.
For classiﬁers, we use 3-layered fully-connected networks.

10288

(a) SVHN to MNIST

(b) SYNSIG to GTSRB

(c) Source only

(d) SWD adapted (ours)

Figure 2: The effect of number of radial projections M to accuracy on (a) SVHN to MNIST adaptation, and (b) SYNSIG to GTSRB
adaptation. M = 128 is sufﬁcient for stable optimization and good accuracies. T-SNE [40] visualization of features obtained from SVHN
to MNIST experiment by (c) source domain only, and (d) SWD adaptation. Blue and red points denote the source and target samples,
respectively. Our method generates much more discriminative feature representation compared to source only setting.

SYNSIG → GTSRB In this setting, we evaluate the adap-
tation ability from synthetic images SYNSIG to real images
GTSRB. We randomly selected 31367 samples for target
training and evaluated the accuracy on the rest. The feature
generator contains three 5×5 conv layers with stride two
2×2 max pooling placed after each conv layer. For classi-
ﬁers, we use 2-layered fully-connected networks. The per-
formance is evaluated for 43 common classes between the
two domains.

MNIST ↔ USPS For the two-way domain shift experiment
we also follow the protocols provided by [57] that we use
the standard training set as training samples, and testing set
as test samples both for source and target domains. The
feature generator contains two 5×5 conv layers with stride
two 2×2 max pooling placed after the each conv layer. For
classiﬁers, we use 3-layered fully-connected networks.

Results Table 1 lists the accuracies for the target samples
by four different domain shifts. We observed that our SWD
method outperforms competing approaches in all settings.
The proposed method also outperforms the direct compara-
ble method MCD [57] by a large margin – absolute accu-
racy improvement of 2.8% on average across the four set-
tings. Figure 2(a) and 2(b) show the ablation study on the
sensitivity to the number of radial projections M . In our ex-
periment we empirically found that M = 128 works well in
all cases. We also visualized learned features in Figure 2(c)
and 2(d). Our method generates much more discriminative
feature representation compared to source only setting.

It is interesting to see that the task-speciﬁc discrepancy-
aware methods such as MCD [57], DeepJDOT [12], and the
proposed SWD are the current leading approaches for the
tasks being addressed here. This demonstrates the impor-
tance of utilizing the task-speciﬁc decision boundaries (dis-
crepancy) to guide the process of transfer learning instead
of simply matching the distributions between the source and
target domains in pixel, feature, or output space in most of
the other distribution matching approaches. In particular,

SVHN

SYNSIG

MNIST

Method

↓

↓

MNIST

GTSRB

Source only
MMD [38]
DANN [17]
DSN [6]
ADDA [70]
CoGAN [36]
PixelDA [5]
ASSC [20]
UNIT [35]
CyCADA [23]
I2I Adapt [45]
GenToAdapt [59]
MCD [57]
DeepJDOT [12]

67.1
71.1
71.1
82.7

76.0 ± 1.8

-
-

85.1
91.1
88.7
93.1

-
-
-

95.7 ± 1.5

82.8 ± 1.3

90.5

90.4 ± 0.4

92.1

92.4 ± 0.9
96.2 ± 0.4

96.7

-
-
-
-

94.4 ± 0.3

↓

USPS

79.4
81.1
85.1

-
-
-

95.9

-

96.0

USPS

↓

MNIST

63.4

-

73.0 ± 0.2

-

90.1 ± 0.8
89.1 ± 0.8

-
-

93.6

95.6 ± 0.2

96.5 ± 0.1

95.1

92.2

95.3 ± 0.7
96.5 ± 0.3

90.8 ± 1.3
94.1 ± 0.3

-

95.7

96.4

SWD (ours)

98.9 ± 0.1

98.6 ± 0.3

98.1 ± 0.1

97.1 ± 0.1

Table 1: Results of unsupervised domain adaptation across digit
and trafﬁc sign datasets. We repeat each experiment 5 times and
report the mean and the standard deviation of the accuracy. Our
method signiﬁcantly outperforms the direct comparable method
MCD [57] and other methods as well.

the adversarial training based methods require a separate
generator and multiple discriminators that are oftentimes
larger than the main task network itself. For example, the
method in [23] uses a 10-layer generator, a 6-layer image
level discriminator, and a 3-layer feature level discriminator
while the main task network is a 4-layer network. Besides,
the auxiliary discriminators are discarded after the training
is completed.

Furthermore, the main distinction between the proposed
method and the DeepJDOT [12] approach is that the Deep-
JDOT requires a multi-staged training process – it trains a
CNN and solves a linear programming task iteratively. The
DeepJDOT also assumes the true optimal transport cou-
pling between every pair of samples in a mini-batch con-
verges when propagating pseudo labels from the source do-
main to target domain, which is often not the case in prac-

10289

1248163264128256512Number of radial projections (M)8486889092949698100Acc (%)1248163264128256512Number of radial projections (M)8486889092949698100Acc (%)Method

plane

bcycl

bus

car

horse

knife mcycl

person

plant

sktbrd

train

truck mean

Source only
MMD [38]
DANN [17]
MCD [57]

55.1
87.1
81.9
87.0

53.3
63.0
77.7
60.9

61.9
76.5
82.8
83.7

59.1
42.0
44.3
64.0

80.6
90.3
81.2
88.9

SWD (ours)

90.8

82.5

81.7

70.5

91.7

17.9
42.9
29.5
79.6

69.5

79.7
85.9
65.1
84.7

86.3

31.2
53.1
28.6
76.9

77.5

81.0
49.7
51.9
88.6

87.4

26.5
36.3
54.6
40.3

63.6

73.5
85.8
82.8
83.0

8.5
20.7
7.8
25.8

85.6

29.2

52.4
61.1
57.4
71.9

76.4

Table 2: Results of unsupervised domain adaptation on VisDA 2017 [49] image classiﬁcation track. Accuracies are obtained by ﬁne-tuning
ResNet-101 model pre-trained on ImageNet. This task evaluates the adaptation capability from synthetic CAD model images to real-world
MSCOCO images. Our method outperforms the direct comparable method MCD [57] and other methods as well.

tice. This emphasizes the importance of choosing a geo-
metrically meaningful discrepancy measure that makes no
assumptions on the optimal transport coupling in the label
space and is end-to-end trainable, optimizing over one dis-
crepancy loss instead of solving multiple losses indepen-
dently.

We note that the method in [63] obtained 99.4% on
SVHN to MNIST adaptation task with various engineering
efforts such as using instance normalization, adding Gaus-
sian noise, and leveraging a much deeper 18-layer network.
This clustering assumption-based approach achieves per-
formance on-par with ours, and we leave this architectural
search for future exploration.

4.2. VisDA Image Classiﬁcation

Next, we evaluate the proposed method on image classi-
ﬁcation task. We use the VisDA dataset [49], which is de-
signed to assess the domain adaptation capability from syn-
thetic to real images across 12 object classes. The source
domain contains 152,397 synthetic images generated by
rendering 3D CAD models from different angles and un-
der different lighting conditions. For target domain we use
the validation set collected from MSCOCO [34] and it con-
sists of 55,388 real images. Following the protocol in [57],
we evaluate our method by ﬁne-tuning ImageNet [13] pre-
trained ResNet-101 [22] model. The ResNet model except
the last fully-connected layer was used as our feature gener-
ator and randomly initialized three-layered fully-connected
networks were used as our classiﬁers. We used Adam solver
with mini-batch size of 32 in the experiment. The num-
ber of radial projections M is set to 128. We apply hori-
zontal ﬂipping of input images during training as the only
data augmentation. Learning rate was set to value of 10−6
throughout the training. GRL [17] is used for training the
network so we do not need to control the update frequency
between the generator and classiﬁers.

Results Table 2 lists the results that are based on the
same evaluation protocol1. We can see that the task-
speciﬁc discrepancy-aware methods MCD [57] and our

1Method in [15] involves various data augmentation including scaling,
cropping, ﬂipping, rotation, brightness and color space perturbation, etc.
The authors reported mean accuracy of 74.2% in the minimal augmenta-
tion setting using a much deeper ResNet-152 backbone.

SWD method perform better than the source only model
in all object classes, while pure distribution matching based
methods perform worse than the source only model in some
categories. Our method also outperforms the direct compa-
rable method MCD [57] by a large margin. We emphasize
that the main difference between MCD and our method is
the choice of discrepancy loss. This validated the effective-
ness of the proposed sliced Wasserstein discrepancy in this
challenging synthetic to real image adaption task.

4.3. Semantic Segmentation

Unlike image classiﬁcation task, obtaining ground truth
label for each pixel in an image requires a lot more amount
of human labor. Here we extend our framework to perform
domain adaptation for the semantic segmentation task.

Datasets In this experiment we used three benchmark
datasets: GTA5 [53], Synthia [54], and Cityscapes [8]. All
three datasets contain dense pixel-level semantic annota-
tions that are compatible with one another. GTA5 contains
24966 vehicle-egocentric images synthesized from a pho-
torealistic open-world computer game Grand Theft Auto
V. Synthia consists of 9400 images generated by render-
ing a virtual city created with the Unity engine. Frames in
Synthia are acquired from multiple camera viewpoints – up
to eight views per location that are not necessary vehicle-
egocentric. Cityscapes has 2975 training images, 500 vali-
dation images, and 1525 test images with dense pixel-level
annotation of urban street scenes in Germany and neigh-
boring countries. During training, the synthetic GTA5 or
Synthia is used as source domain and the real Cityscapes is
used as target domain. We used the standard training split
for training and validation split for evaluation purpose.

Implementation details In an effort to demonstrate the ef-
fectiveness of the proposed method and to decouple the per-
formance gain due to architectural search, we adopted the
commonly used VGG-16 [64] and ResNet-101 [22] models
for our feature generator. For classiﬁers we used the de-
coder in PSPNet [77] for its simplicity of implementation.
Based on this straightforward design choice, our segmenta-
tion model achieves mean intersection-over-union (mIoU)
of 60.5% for VGG-16 backbone and 64.1% for ResNet-101
backbone when trained on the Cityscapes training set and

10290

Method

Source only (VGG16)
FCN Wld [24]
MCD [57]
CDA [76]
AdaSegNet [69]
CyCADA [23]
CBST [78]
DCAN [74]
SWD (ours)

Source only (ResNet101)
AdaSegNet [69]
SWD (ours)

d
a
o
r

25.9
70.4
86.4
74.9
87.3
85.2
90.4
82.3
91.0

75.8
86.5
92.0

k
w
d
s

10.9
32.4
8.5
22.0
29.8
37.2
50.8
26.7
35.7

16.8
36.0
46.4

g
n
d
l
b

50.5
62.1
76.1
71.7
78.6
76.5
72.0
77.4
78.0

77.2
79.9
82.4

l
l
a
w

3.3
14.9
18.6
6.0
21.1
21.8
18.3
23.7
21.6

12.5
23.4
24.8

e
c
n
e
f

12.2
5.4
9.7
11.9
18.2
15.0
9.5
20.5
21.7

21.0
23.3
24.0

e
l
o
p

25.4
10.9
14.9
8.4
22.5
23.8
27.2
20.4
31.8

25.5
23.9
35.1

t
h
g
i
l

28.6
14.2
7.8
16.3
21.5
22.9
28.6
30.3
30.2

30.1
35.2
33.4

n
g
i
s

13.0
2.7
0.6
11.1
11.0
21.5
14.1
15.9
25.2

20.1
14.8
34.2

n
t
t
g
v

78.3
79.2
82.8
75.7
79.7
80.5
82.4
80.9
80.2

81.3
83.4
83.6

n
r
r
t

y
k
s

7.3
21.3
32.7
13.3
29.6
31.3
25.1
25.4
23.9

24.6
33.3
30.4

63.9
64.6
71.4
66.5
71.3
60.7
70.8
69.5
74.1

70.3
75.6
80.9

n
o
s
r
e
p

52.1
44.1
25.2
38.0
46.8
50.5
42.6
52.6
53.1

53.8
58.5
56.9

r
e
d
i
r

7.9
4.2
1.1
9.3
6.5
9.0
14.5
11.1
15.8

26.4
27.6
21.9

r
a
c

66.3
70.4
76.3
55.2
80.1
76.9
76.9
79.6
79.3

49.9
73.7
82.0

k
c
u
r
t

5.2
8.0
16.1
18.8
23.0
17.1
5.9
24.9
22.1

17.2
32.5
24.4

s
u
b

7.8
7.3
17.1
18.9
26.9
28.2
12.5
21.2
26.5

25.9
35.4
28.7

n
i
a
r
t

0.9
0.0
1.4
0.0
0.0
4.5
1.2
1.30
1.5

6.5
3.9
6.1

l
c
y
c
m

13.7
3.5
0.2
16.8
10.6
9.8
14.0
17.0
17.2

25.3
30.1
25.0

l
c
y
c
b

0.7
0.0
0.0
14.6
0.3
0.0
28.6
6.70
30.4

36.0
28.1
33.6

U
o
I
m

24.9
27.1
28.8
28.9
35.0
35.4
36.1
36.2
39.9

36.6
42.4
44.5

Table 3: Adaptation results from GTA5 to Cityscapes. We compare our results with other state-of-the-art approaches that are based on the
standard VGG-16 or ResNet-101 backbone.

Method

Source only (VGG16)
FCN Wld [24]
Cross-city [7]
CBST [78]
AdaSegNet [69]
SWD (ours)

Source only (ResNet101)
AdaSegNet [69]
SWD (ours)

d
a
o
r

6.4
11.5
62.7
69.6
78.9
83.3

55.6
79.2
82.4

k
w
d
s

17.7
19.6
25.6
28.7
29.2
35.4

23.8
37.2
33.2

g
n
d
l
b

29.7
30.8
78.3
69.5
75.5
82.1

74.6
78.8
82.5

t
h
g
i
l

0.0
0.1
1.2
11.9
0.1
12.2

6.1
9.9
22.6

n
g
i
s

7.2
11.7
5.4
13.6
4.8
12.6

12.1
10.5
19.7

n
t
t
g
v

30.3
42.3
81.3
82.0
72.6
83.8

74.8
78.2
83.7

y
k
s

66.8
68.7
81.0
81.9
76.7
76.5

79.0
80.5
78.8

n
o
s
r
e
p

51.1
51.2
37.4
49.1
43.4
47.4

55.3
53.5
44.0

r
e
d
i
r

1.5
3.8
6.4
14.5
8.8
12.0

19.1
19.6
17.9

r
a
c

s
u
b

47.3
54.0
63.5
66.0
71.1
71.5

39.6
67.0
75.4

3.9
3.2
16.1
6.6
16.0
17.9

23.3
29.5
30.2

l
c
y
c
m

0.1
0.2
1.2
3.7
3.6
1.6

13.7
21.6
14.4

l
c
y
c
b

0.0
0.6
4.6
32.4
8.4
29.7

25.0
31.3
39.9

U
o
I
m

20.2
22.9
35.7
36.1
37.6
43.5

38.6
45.9
48.1

Table 4: Adaptation results from Synthia to Cityscapes. We compare our results with other state-of-the-art approaches that are based on
the standard VGG-16 or ResNet-101 backbone.

evaluated on the Cityscapes validation set for 19 compatible
classes, which match the same oracle performance reported
in the recent literature [69, 74].

We used Momentum SGD solver with a ﬁxed momen-
tum of 0.9 and weight decay of 0.0001 in all experiments.
Learning rate was set to value of 0.0001 for GTA5 to
Cityscapes setting and 0.001 for Synthia to Cityscapes set-
ting. During training, we randomly sampled a single image
from both source and target domains for each mini-batch
optimization. All images are resized to 1024×512 resolu-
tion. No data augmentation is used (such as ﬂipping, crop-
ping, scaling, and multi-scale ensemble) to minimize the
performance gain due to the engineering efforts and to en-
sure the reproducibility. Since the sliced Wasserstein dis-
crepancy is computed at every pixel of an image in a mini-
batch fashion, we empirically found that the number of ra-
dial projections M = 8 is sufﬁcient to produce good results.

Results We use the evaluation protocol released along
with VisDA challenge [49] to calculate the PASCAL VOC
intersection-over-union (IoU). We show quantitative and
qualitative results of adapting GTA5 to Cityscapes in Ta-
ble 3 and Figure 3, respectively. We can see clear improve-
ment from models trained on source domain only to models
trained with the proposed SWD method for both VGG-16
and ResNet-101 backbones. Also, our method consistently
outperforms other recent approaches that utilize generative

adversarial networks [69, 23] and the style transfer based
technique [74].

Table 4 shows the results of adapting Synthia to
Cityscapes. The domain shift is even more signiﬁcant be-
tween these two datasets because images from Synthia are
not only generated by a rendering engine but also con-
tain multiple viewpoints that are not necessary vehicle-
egocentric. Our method shows consistent improvement
over other approaches and generalizes well with such dra-
matic viewpoint shift.

Note that most of the competing approaches are specif-
ically designed only for semantic segmentation tasks and
they often require the assumption of input space similar-
ity, output space similarity, or geometric constrains. For
instance, the method in [78] incorporated spatial priors by
assuming sky is likely to appear at the top and road is likely
to appear at the bottom of an image, etc. The frequen-
cies of ground truth labels per pixel are computed from
GTA5 dataset and are then multiplied with the softmax out-
put of the segmentation network. However, it is unclear
how to generalize this prior when large viewpoint differ-
ences present between the source and target domains, such
as adaptation from Synthia to Cityscapes. Our method does
not require any prior assumptions of the characteristics of
the task of interest and nevertheless achieves better perfor-
mance.

10291

Figure 3: Qualitative semantic segmentation results on adaptation from GTA5 to Cityscapes. From left to right: input, source only model,
our method, and ground truth. Our method produces cleaner predictions and less confusion between challenging classes such as road, car,
sidewalk, and vegetation.

Method

plane bcycl bus

car horse knife mcycl person plant

sktbrd train truck mAP

Source only
MCD [57]
SWD (ours)

0.5
11.8
11.9

0.4
1.3
2.0

9.4
9.4
10.3 3.3
15.5 5.4

7.2
10.2
13.1

0.1
0.1
0.1

1.3
8.0
4.7

4.6
2.4
9.8

0.5
0.6
0.9

0.3
1.5
1.0

1.5
5.8
6.2

0.9
1.1
0.7

3.0
4.7
5.9

Table 5: Results of unsupervised domain adaptation on VisDA 2018 [50] object detection track. This task evaluates the adaptation capability
from synthetic CAD model images to real-world MSCOCO images (COCO17-val). We report mean average precision (mAP) at 0.5 IoU
using SSD with Inception-V2 backbone. Our method outperforms the direct comparable method MCD [57] by 25% relatively.

4.4. Object Detection

To demonstrate if our method generalizes to other tasks
as well, we extend it to object detection task. We use the
recent released VisDA 2018 dataset [50], which contains
source images generated by rendering 3D CAD models and
target images collected from MSCOCO [34]. This dataset
is especially challenging due to uncalibrated object scales
and positions between the synthetic and real images.

We use a standard off-the-shelf Single Shot Detector
(SSD) [37] with Inception-V2 [68] backbone without any
architectural modiﬁcations or heuristic assumptions. The
model predicts class labels, locations and size shifts for a
total of 1.9k possible anchor boxes. The feature generator
in this case is the backbone network pre-trained on Ima-
geNet and the classiﬁers comprise of all the additional lay-
ers which are present after the backbone network. We em-
ploy the proposed sliced Wasserstein discrepancy to both
classiﬁcation and bounding box regression outputs to the
existing loss functions in SSD. No other modiﬁcations are
made to the network. We also implement MCD [57] method
with the exact network architecture for baseline compar-
ison. All networks are optimized with Momentum SGD
solver with a ﬁxed momentum of 0.9, mini-batch size of 16,
and weight decay of 0.0001. Learning rate is set to value
of 0.0001. The number of radial projections M is set to

128. We apply random cropping and ﬂipping to all network
training.

Results We report mean average precision (mAP) at 0.5 IoU
in Table 5. These results show that even with large domain
shift in image realism, object scales, and relative object po-
sitions, our method is able to improve the performance by a
large margin compared to models trained on source image
only. Our method also outperforms the direct comparable
method MCD [57] by a signiﬁcant 25% relatively.

5. Conclusion

In this paper, we have developed a new unsupervised
domain adaptation approach, which aligns distributions by
measuring sliced Wasserstein discrepancy between task-
speciﬁc classiﬁers. The connection to Wasserstein metric
paves the way to make better use of its geometrically mean-
ingful embeddings in an efﬁcient fashion, which in the past
has primarily been restricted to obtaining one-to-one map-
ping in label space. Our method is generic and achieves
superior results across digit and sign recognition, image
classiﬁcation, semantic segmentation, and object detection
tasks. Future work includes extension of our approach to
domain randomization [67], open set adaptation [58], and
zero-shot domain adaptation [48].

10292

References

[1] Martin Arjovsky, Soumith Chintala, and L´eon Bottou.
Wasserstein generative adversarial networks. In ICML, 2017.
1, 2, 3

[2] Shai Ben-David,

John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.
A theory of learning from different domains. Machine learn-
ing, 2010. 1

[3] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando
Pereira. Analysis of representations for domain adaptation.
In NIPS, 2007. 1

[4] Nicolas Bonneel, Julien Rabin, Gabriel Peyr´e, and Hanspeter
Pﬁster. Sliced and radon wasserstein barycenters of mea-
sures. JMIV, 2015. 4

[5] Konstantinos Bousmalis, Nathan Silberman, David Dohan,
Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-
level domain adaptation with generative adversarial net-
works. In CVPR, 2017. 1, 2, 5

[6] Konstantinos Bousmalis, George Trigeorgis, Nathan Silber-
man, Dilip Krishnan, and Dumitru Erhan. Domain separa-
tion networks. In NIPS, 2016. 5

[7] Yi-Hsin Chen, Wei-Yu Chen, Yu-Ting Chen, Bo-Cheng Tsai,
Yu-Chiang Frank Wang, and Min Sun. No more discrimi-
nation: Cross city adaptation of road scene segmenters. In
ICCV, 2017. 7

[8] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
Franke, Stefan Roth, and Bernt Schiele. The cityscapes
dataset for semantic urban scene understanding. In CVPR,
2016. 6

[9] Nicolas Courty, R´emi Flamary, Amaury Habrard, and Alain
Joint distribution optimal transportation

Rakotomamonjy.
for domain adaptation. In NIPS, 2017. 2

[10] Nicolas Courty, R´emi Flamary, Devis Tuia, and Alain
Rakotomamonjy. Optimal transport for domain adaptation.
TPAMI, 2016. 2

[11] Marco Cuturi. Sinkhorn distances: Lightspeed computation

of optimal transport. In NIPS, 2013. 4

[12] Bharath Bhushan Damodaran, Benjamin Kellenberger, R´emi
Flamary, Devis Tuia, and Nicolas Courty. Deepjdot: Deep
joint distribution optimal transport for unsupervised domain
adaptation. In ECCV, 2018. 2, 5

[13] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In CVPR, 2009. 6

[14] Ishan Deshpande, Ziyu Zhang, and Alexander Schwing.
Generative modeling using the sliced wasserstein distance.
In CVPR, 2018. 2

[15] Geoffrey French, Michal Mackiewicz,

and Mark
Self-ensembling for visual domain adaptation.

Fisher.
arXiv:1706.05208, 2017. 6

[16] Charlie Frogner, Chiyuan Zhang, Hossein Mobahi, Mauricio
Araya, and Tomaso A Poggio. Learning with a wasserstein
loss. In NIPS, 2015. 4

[18] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-
cal Germain, Hugo Larochelle, Franc¸ois Laviolette, Mario
Marchand, and Victor Lempitsky. Domain-adversarial train-
ing of neural networks. JMLR, 2016. 1, 2

[19] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
1, 2

[20] Philip Haeusser, Thomas Frerix, Alexander Mordvintsev,
In

and Daniel Cremers. Associative domain adaptation.
ICCV, 2017. 5

[21] Steven Haker, Lei Zhu, Allen Tannenbaum, and Sigurd An-
genent. Optimal mass transport for registration and warping.
IJCV, 2004. 2

[22] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
In CVPR,

Deep residual learning for image recognition.
2016. 6

[23] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
Phillip Isola, Kate Saenko, Alexei A Efros, and Trevor Dar-
rell. Cycada: Cycle-consistent adversarial domain adapta-
tion. In ICML, 2018. 2, 5, 7

[24] Judy Hoffman, Dequan Wang, Fisher Yu, and Trevor Darrell.
Fcns in the wild: Pixel-level adversarial and constraint-based
adaptation. arXiv:1612.02649, 2016. 1, 2, 7

[25] Haoshuo Huang, Qixing Huang, and Philipp Krahenbuhl.
In

Domain transfer through deep activation matching.
ECCV, 2018. 2

[26] Jonathan J. Hull. A database for handwritten text recognition

research. TPAMI, 1994. 4

[27] Leonid Kantorovitch. On the translocation of masses. Man-

agement Science, 1958. 1, 3, 4

[28] Diederik P Kingma and Jimmy Ba. Adam: A method for

stochastic optimization. arXiv:1412.6980, 2014. 4

[29] Soheil Kolouri, Gustavo K Rohde, and Heiko Hoffmann.
Sliced wasserstein distance for learning gaussian mixture
models. In CVPR, 2018. 2

[30] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classiﬁcation with deep convolutional neural net-
works. In NIPS, 2012. 1

[31] Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick
Haffner. Gradient-based learning applied to document recog-
nition. Proceedings of the IEEE, 1998. 4

[32] Kwonjoon Lee, Weijian Xu, Fan Fan, and Zhuowen Tu.
Wasserstein introspective neural networks. In CVPR, 2018.
2

[33] Yanghao Li, Naiyan Wang, Jianping Shi, Xiaodi Hou, and
Jiaying Liu. Adaptive batch normalization for practical do-
main adaptation. Pattern Recognition, 2018. 2

[34] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll´ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context.
In
ECCV, 2014. 6, 8

[35] Ming-Yu Liu, Thomas Breuel, and Jan Kautz. Unsupervised

image-to-image translation networks. In NIPS, 2017. 5

[17] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain

[36] Ming-Yu Liu and Oncel Tuzel. Coupled generative adversar-

adaptation by backpropagation. In ICML, 2014. 1, 4, 5, 6

ial networks. In NIPS, 2016. 1, 2, 5

10293

[37] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian
Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C
Berg. Ssd: Single shot multibox detector. In ECCV, 2016. 8

[55] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. A met-
ric for distributions with applications to image databases. In
ICCV, 1998. 2

[38] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I
Jordan. Learning transferable features with deep adaptation
networks. In ICML, 2015. 1, 5, 6

[39] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I
Jordan. Unsupervised domain adaptation with residual trans-
fer networks. In NIPS, 2016. 1

[40] Laurens van der Maaten and Geoffrey Hinton. Visualizing

data using t-sne. JMLR, 2008. 5

[41] Liang Mi, Wen Zhang, Xianfeng Gu, and Yalin Wang. Vari-

ational wasserstein clustering. In ECCV, 2018. 3

[42] Boris Moiseev, Artem Konev, Alexander Chigorin, and An-
ton Konushin. Evaluation of trafﬁc sign recognition methods
trained on synthetically generated data. In ACIVS. Springer,
2013. 4

[43] Gaspard Monge. M´emoire sur la th´eorie des d´eblais et des
remblais. Histoire de l’Acad´emie Royale des Sciences de
Paris, 1781. 1, 3

[44] Jose G Moreno-Torres, Troy Raeder, Roc´ıO Alaiz-
Rodr´ıGuez, Nitesh V Chawla, and Francisco Herrera. A uni-
fying view on dataset shift in classiﬁcation. Pattern Recog-
nition, 2012. 1

[45] Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ra-
mamoorthi, and Kyungnam Kim. Image to image translation
for domain adaptation. In CVPR, 2018. 2, 5

[46] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-
sacco, Bo Wu, and Andrew Y Ng. Reading digits in natural
images with unsupervised feature learning. In NIPS work-
shop, 2011. 4

[47] Sinno Jialin Pan, Qiang Yang, et al. A survey on transfer
learning. IEEE Transactions on knowledge and data engi-
neering, 2010. 2

[48] Kuan-Chuan Peng, Ziyan Wu, and Jan Ernst. Zero-shot deep

domain adaptation. In ECCV, 2018. 8

[49] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman,
Dequan Wang, and Kate Saenko. Visda: The visual domain
adaptation challenge. arXiv:1710.06924, 2017. 6, 7

[50] Xingchao Peng, Ben Usman, Kuniaki Saito, Neela Kaushik,
Judy Hoffman, and Kate Saenko.
Syn2real: A new
benchmark for synthetic-to-real visual domain adaptation.
arXiv:1806.09755, 2018. 8

[51] Francois Pitie, Anil C Kokaram, and Rozenn Dahyot. N-
dimensional probablility density function transfer and its ap-
plication to colour transfer. In ICCV, 2005. 2

[52] Julien Rabin, Gabriel Peyr´e, Julie Delon, and Marc Bernot.
Wasserstein barycenter and its application to texture mixing.
In SSVM, 2011. 4

[53] Stephan R Richter, Vibhav Vineet, Stefan Roth, and Vladlen
Koltun. Playing for data: Ground truth from computer
games. In ECCV, 2016. 6

[54] German Ros, Laura Sellart, Joanna Materzynska, David
Vazquez, and Antonio M Lopez. The synthia dataset: A large
collection of synthetic images for semantic segmentation of
urban scenes. In CVPR, 2016. 6

[56] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
Adapting visual category models to new domains. In ECCV,
2010. 1

[57] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat-
suya Harada. Maximum classiﬁer discrepancy for unsuper-
vised domain adaptation. In CVPR, 2018. 1, 2, 3, 4, 5, 6, 7,
8

[58] Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and
Tatsuya Harada. Open set domain adaptation by backpropa-
gation. In ECCV, 2018. 8

[59] Swami Sankaranarayanan, Yogesh Balaji, Carlos D Castillo,
and Rama Chellappa. Generate to adapt: Aligning domains
using generative adversarial networks. In CVPR, 2018. 2, 5
[60] Swami Sankaranarayanan, Yogesh Balaji, Arpit Jain, Ser
Nam Lim, and Rama Chellappa. Learning from synthetic
data: Addressing domain shift for semantic segmentation. In
CVPR, 2018. 2

[61] Hidetoshi Shimodaira.

Improving predictive inference un-
der covariate shift by weighting the log-likelihood function.
Journal of statistical planning and inference, 2000. 1

[62] Ashish Shrivastava, Tomas Pﬁster, Oncel Tuzel, Joshua
Susskind, Wenda Wang, and Russell Webb.
Learning
from simulated and unsupervised images through adversarial
training. In CVPR, 2017. 2

[63] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon.
In

A dirt-t approach to unsupervised domain adaptation.
ICLR, 2018. 6

[64] Karen Simonyan and Andrew Zisserman. Very deep convo-
lutional networks for large-scale image recognition. In ICLR,
2015. 6

[65] Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and
Christian Igel. The german trafﬁc sign recognition bench-
mark: a multi-class classiﬁcation competition.
In IJCNN,
2011. 4

[66] Amos Storkey. When training and test sets are different:
characterizing learning transfer. Dataset shift in machine
learning, 2009. 1

[67] Martin Sundermeyer, Zoltan-Csaba Marton, Maximilian
Durner, Manuel Brucker, and Rudolph Triebel. Implicit 3d
orientation learning for 6d object detection from rgb images.
In ECCV, 2018. 8

[68] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
Shlens, and Zbigniew Wojna. Rethinking the inception ar-
chitecture for computer vision. In CVPR, 2016. 8

[69] Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Ki-
hyuk Sohn, Ming-Hsuan Yang, and Manmohan Chandraker.
Learning to adapt structured output space for semantic seg-
mentation. In CVPR, 2018. 1, 2, 7

[70] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
In CVPR,

Adversarial discriminative domain adaptation.
2017. 1, 2, 5

[71] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and
Trevor Darrell. Deep domain confusion: Maximizing for
domain invariance. arXiv:1412.3474, 2014. 2

10294

[72] Cedric Villani. Optimal transport, old and new. Springer-

Verlag, 2009. 1, 2, 3

[73] Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya,
In

and Luc Van Gool. Wasserstein divergence for gans.
ECCV, 2018. 2, 3

[74] Zuxuan Wu, Xintong Han, Yen-Liang Lin, Mustafa Gkhan
Uzunbas, Tom Goldstein, Ser Nam Lim, and Larry S Davis.
Dcan: Dual channel-wise alignment networks for unsuper-
vised scene adaptation. In ECCV, 2018. 7

[75] Werner Zellinger, Thomas Grubinger, Edwin Lughofer,
Thomas Natschl¨ager, and Susanne Saminger-Platz. Central
moment discrepancy (cmd) for domain-invariant representa-
tion learning. In ICLR, 2017. 2

[76] Yang Zhang, Philip David, and Boqing Gong. Curricu-
lum domain adaptation for semantic segmentation of urban
scenes. In ICCV, 2017. 7

[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
In

Wang, and Jiaya Jia. Pyramid scene parsing network.
CVPR, 2017. 6

[78] Yang Zou, Zhiding Yu, BVK Vijaya Kumar, and Jinsong
Wang. Unsupervised domain adaptation for semantic seg-
mentation via class-balanced self-training. In ECCV, 2018.
7

10295

