Divergence Triangle for Joint Training of Generator Model, Energy-based

Model, and Inferential Model

Tian Han1 ∗, Erik Nijkamp1 ∗, Xiaolin Fang2, Mitch Hill1, Song-Chun Zhu1, Ying Nian Wu1

1University of California, Los Angeles 2Zhejiang University

{hantian, enijkamp, mkhil}@ucla.edu, xiaolinfang@zju.edu.cn, {sczhu,ywu}@stat.ucla.edu

Abstract

This paper proposes the divergence triangle as a frame-
work for joint training of a generator model, energy-based
model and inference model. The divergence triangle is
a compact and symmetric (anti-symmetric) objective func-
tion that seamlessly integrates variational learning, adver-
sarial learning, wake-sleep algorithm, and contrastive di-
vergence in a uniﬁed probabilistic formulation. This uni-
ﬁcation makes the processes of sampling, inference, and
energy evaluation readily available without the need for
costly Markov chain Monte Carlo methods. Our experi-
ments demonstrate that the divergence triangle is capable
of learning (1) an energy-based model with well-formed en-
ergy landscape, (2) direct sampling in the form of a gener-
ator network, and (3) feed-forward inference that faithfully
reconstructs observed as well as synthesized data.

1. Introduction

1.1. Integrating Three Models

Deep probabilistic generative models are a powerful
framework for representing complex data distributions.
They have been widely used in unsupervised learning prob-
lems to learn from unlabeled data. The goal of generative
learning is to build rich and ﬂexible models to ﬁt com-
plex, multi-modal data distributions as well as to be able
to generate samples with high realism. The family of gen-
erative models may be roughly divided into two classes:
The ﬁrst class is the energy-based model (a.k.a undirected
graphical model) and the second class is the latent vari-
able model (a.k.a directed graphical model) which usually
includes generator model for the generation and inference
model for inference or reconstruction.

These models have their advantages and limitations. An
energy-based model deﬁnes an explicit likelihood of the ob-
served data up to a normalizing constant. However, sam-

∗Equal contributions.

pling from such a model usually requires expensive Markov
chain Monte Carlo (MCMC). A generator model deﬁnes di-
rect sampling of the data. However, it does not have an ex-
plicit likelihood. The inference of the latent variables also
requires MCMC sampling from the posterior distribution.
The inference model deﬁnes an explicit approximation to
the posterior distribution of the latent variables.

Combining the energy-based model,

the generator
model, and the inference model to get the best of each
model is an attractive goal. On the other hand, challenges
may accumulate when the models are trained together since
different models need to effectively compete or cooperate
together to achieve their highest performances. In this work,
we propose the divergence triangle for joint training of
energy-based model, generator model and inference model.
The learning of three models can then be seamlessly inte-
grated in a principled probabilistic framework. The energy-
based model is learned based on the samples supplied by the
generator model. With the help of the inference model, the
generator model is trained by both the observed data and the
energy-based model. The inference model is learned from
both the real data ﬁtted by the generator model as well as
the synthesized data generated by the generator model.

Our experiments demonstrate that the divergence trian-
gle is capable of learning an energy-based model with a
well-behaved energy landscape, a generator model with
highly realistic samples, and an inference model with faith-
ful reconstruction ability.

1.2. Prior Art

The maximum likelihood learning of the energy-based
model requires expectation with respect
to the current
model, while the maximum likelihood learning of the gen-
erator model requires expectation with respect to the pos-
terior distribution of the latent variables. Both expec-
tations can be approximated by MCMC, such as Gibbs
sampling [11], Langevin dynamics, or Hamiltonian Monte
Carlo (HMC) [34]. [31, 48] used Langevin dynamics for
learning the energy-based models, and [13] used Langevin
dynamics for learning the generator model. In both cases,

18670

MCMC sampling introduces an inner loop in the training
procedure, posing a computational expense.

generator model can learn from the MCMC revisions of its
initial samples.

An early version of the energy-based model

is the
FRAME (Filters, Random ﬁeld, And Maximum Entropy)
model [53, 45]. [52] used gradient-based method such as
Langevin dynamics to sample from the model. [51] called
[31, 48]
the energy-based models as descriptive models.
generalized the model to deep variants.

Contrastive divergence (CD) [15] initializes ﬁnite step
MCMC from the observed data to reduce the computational
cost of sampling when learning an energy-based model
[28]. The resulting learning algorithm follows the gradi-
ent of the difference between two Kullback-Leibler diver-
gences, thus the name contrastive divergence. In this pa-
per, we shall use the term “contrastive divergence” in a
more general sense than [15]. Persistent contrastive diver-
gence [42] initializes MCMC sampling from the samples of
the previous learning iteration.

Generalizing [43], [21] developed an introspective learn-
ing method where the energy function is discriminatively
learned, and the energy-based model is both a generative
model and a discriminative model.

For learning the generator model, the variational auto-
encoder (VAE) [25, 38, 33] approximates the posterior dis-
tribution of the latent variables by an explicit inference
model. In VAE, the inference model is learned jointly with
the generator model from the observed data. A precursor
of VAE is the wake-sleep algorithm [17], where the infer-
ence model is learned from the dream data generated by the
generator model in the sleep phase.

The generator model can also be learned jointly with
a discriminator model, as in the generative adversar-
ial networks (GAN) [12], as well as deep convolutional
GAN (DCGAN) [37], energy-based GAN (EB-GAN) [50],
Wasserstein GAN (WGAN) [2]. GAN does not involve an
inference model.

The generator model can also be learned jointly with an
energy-based model [23, 6]. We can interpret the learning
scheme as an adversarial version of contrastive divergence.
In GAN, the discriminator model eventually becomes con-
fused between real and fake images, while in the joint learn-
ing of the generator model and the energy-based model, the
learned energy-based model becomes a well-deﬁned prob-
ability distribution on the observed data. The joint learning
bears some similarity to WGAN, but unlike WGAN, the
learning framework involves two complementary probabil-
ity distributions.

The cooperative learning method of [47] bridges the
gap between the energy-based model and generator model
by initializing ﬁnite-step MCMC sampling of the energy-
based model from images synthesized by the generator
model. Such ﬁnite-step MCMC produces revised samples
that closer to the modes of the energy-based model, and the

Adversarially learned inference (ALI) [10, 9] combines
the learning of the generator model and inference model
in an adversarial framework. ALI can be improved by
adding conditional entropy regularization, resulting in the
ALICE [29] model. The recently proposed method [4]
shares the same spirit. They lack an energy-based model
on observed data.

1.3. Our Contributions

Our proposed formulation, which we call the divergence
triangle, re-interprets and integrates the following elements
in unsupervised generative learning: (1) maximum likeli-
hood learning, (2) variational learning, (3) adversarial learn-
ing, (4) contrastive divergence, (5) wake-sleep algorithm.
The learning is seamlessly integrated into a probabilistic
framework based on KL divergence.

2. Learning Deep Probabilistic Models

In this section, we shall review the two probabilistic
models, namely the generator model and the energy-based
model, both of which are parametrized by convolutional
neural networks [27, 26]. Then, we shall present the max-
imum likelihood learning algorithms for training these two
models, respectively. Our presentation of the two maximum
likelihood learning algorithms is unconventional. We seek
to derive both algorithms based on the Kullback-Leibler di-
vergence using the same scheme. This will set the stage for
the divergence triangle.

2.1. Generator Model and Energy based Model

The generator model [12, 37, 25, 38, 33] is a generaliza-

tion of the factor analysis model [39],

z ∼ N(0, Id), x = gθ(z) + ǫ,

(1)

where gθ is a top-down mapping parametrized by a deep
network with parameters θ. It maps the d-dimensional latent
vector z to the D-dimensional signal x. ǫ ∼ N(0, σ2ID)
and is independent of z. In general, the model is deﬁned by
the prior distribution p(z) and the conditional distribution
pθ(x|z). The complete-data model pθ(z, x) = p(z)pθ(x|z).

The observed-data model is pθ(x) = R pθ(z, x)dz. The

posterior distribution is pθ(z|x) = pθ(z, x)/pθ(x). See the
diagram (a) below.

Top-down mapping

Bottom-up mapping

hidden vector z

energy −fα(x)

⇓

signal x ≈ gθ(z)

⇑

signal x

(a) Generator model

(b) Energy-based model

A complementary model is the energy-based model [35,
5, 31, 48], where −fα(x) deﬁnes the energy of x, and a

8671

low energy x is assigned a high probability. Speciﬁcally,
we have the following probability model

πα(x) =

1

Z(α)

exp [fα(x)] ,

(2)

where fα(x) is parametrized by a bottom-up deep network
with parameters α, and Z(α) is the normalizing constant. If
fα(x) is linear in α, the model becomes the familiar expo-
nential family model in statistics or the Gibbs distribution in
statistical physics. We may consider πα an evaluator, where
fα assigns the value to x, and πα evaluates x by a normal-
ized probability distribution. See the diagram (b) above.

The energy-based model πα deﬁnes explicit

log-
likelihood via fα(x), even though Z(α) is intractable.
However, it is difﬁcult to sample from πα. The genera-
tor model pθ can generate x directly by ﬁrst generating
z ∼ p(z), and then transforming z to x by gθ(z). But it
does not deﬁne an explicit log-likelihood of x.

In the context of inverse reinforcement learning [54, 1]
or inverse optimal control, x is action and −fα(x) deﬁnes
the cost function or fα(x) deﬁnes the value function or the
objective function.

2.2. Maximum Likelihood Learning

Let qdata(x) be the true distribution that generates the
training data. Both the generator pθ and the energy-based
model πα can be learned by maximum likelihood. For large
sample, the maximum likelihood amounts to minimizing
the Kullback-Leibler divergence KL(qdatakpθ) over θ, and
minimizing KL(qdatakπα) over α, respectively. The expec-
tation Eqdata can be approximated by sample average.

2.2.1 EM-type Learning of Generator Model

To learn the generator model pθ, we seek to minimize
KL(qdata(x)kpθ(x)) over θ. Suppose in an iterative algo-
rithm, the current θ is θt. We can ﬁx θt at any place we
want, and vary θ around θt.

majorizes (upper bounds) K, and they touch each other at
θt, so that S(θt) = K(θt) and S′(θt) = K ′(θt). The reason
is that ˜K(θt) = 0 and ˜K ′(θt) = 0. See Figure 1.

Figure 1. The surrogate S majorizes (upper bounds) K, and they
touch each other at θt with the same tangent.

qdata(x)pθt (z|x) gives us the complete data. Each step
of EM ﬁts the complete-data model pθ(z, x) by minimizing
the surrogate S(θ),

θt+1 = arg min

θ

KL(qdata(x)pθt (z|x)kpθ(z, x)),

(5)

which amounts to maximizing the complete-data log-
likelihood. By minimizing S, we will reduce S(θ) relative
to θt, and we will reduce K(θ) even more, relative to θt,
because of the majorization picture.

We can also use gradient descent to update θ. Because

S′(θt) = K ′(θt), and we can place θt anywhere, we have

−

∂
∂θ

KL(qdata(x)kpθ(x))

= Eqdata(x)pθ(z|x)(cid:20) ∂

∂θ

log pθ(z, x)(cid:21) .

(6)

To implement the above updates, we need to compute
the expectation with respect to the posterior distribution
pθ(z|x).
It can be approximated by MCMC such as
Langevin dynamics or HMC [34]. Both require gradient
computations that can be efﬁciently accomplished by back-
propagation. We have learned the generator using such
learning method [13].

We can write

2.2.2 Self-critic Learning of Energy-based Model

KL(qdata(x)pθt (z|x)kpθ(z, x)) =
KL(qdata(x)kpθ(x)) + KL(pθt (z|x)kpθ(z|x)). (3)

In the EM algorithm [7], the left hand side is the surrogate
objective function. This surrogate function is more tractable
than the true objective function KL(qdata(x)kpθ(x)) be-
cause qdata(x)pθt (z|x) is a distribution of the complete
data, and pθ(z, x) is the complete-data model.

We can write (3) as

S(θ) = K(θ) + ˜K(θ).

(4)

The geometric picture is that the surrogate objective func-
tion S(θ) is above the true objective function K(θ), i.e., S

To learn the energy-based model πα, we seek to minimize
KL(qdata(x)kπα(x)) over α. Suppose in an iterative algo-
rithm, the current α is αt. We can ﬁx αt at any place we
want, and vary α around αt.

Consider the following contrastive divergence

KL(qdata(x)kπα(x)) − KL(παt (x)kπα(x)).

(7)

We can use the above as surrogate function, which is more
tractable than the true objective function, since the log Z(α)
term is canceled out. Speciﬁcally, we can write (7) as

S(α) = K(α) − ˜K(α)

(8)

= −(Eqdata [fα(x)] − Eπαt

[fα(x)]) + const.(9)

8672

The geometric picture is that the surrogate function S(α)
is below the true objective function K(α), i.e., S minorizes
(lower bounds) K, and they touch each other at αt, so that
S(αt) = K(αt), and S′(αt) = K ′(αt). The reason is that
˜K(αt) = 0 and ˜K ′(αt) = 0. See Figure 2.

Figure 2. The surrogate S minorizes (lower bounds) K, and they
touch each other at αt with the same tangent.

Because S minorizes K, we do not have a EM-like up-
date. However, we can still use gradient descent to update
α, where the derivative is

K ′(αt) = S′(αt) = −(Eqdata [f ′

αt (x)] − Eπαt

[f ′

αt (x)]), (10)

where

f ′
αt (x) =

∂
∂α

.

(11)

fα(x)(cid:12)(cid:12)(cid:12)αt

Since we can place αt anywhere, we have

−

∂
∂α

KL(qdata(x)kπα(x))

= Eqdata (cid:20) ∂

∂α

fα(x)(cid:21) − Eπα (cid:20) ∂

∂α

fα(x)(cid:21) . (12)

To implement the above update, we need to compute the
expectation with respect to the current model παt . It can
be approximated by MCMC such as Langevin dynamics or
HMC that samples from παt . It can be efﬁciently imple-
mented by gradient computation via back-propagation. We
have trained the energy-based model using such learning
method [31, 48].

The above learning algorithm has an adversarial inter-
pretation. Updating αt to αt+1 by following the gradient
of S(α) = KL(qdata(x)kπα(x)) − KL(παt (x)kπα(x)) =
−(Eqdata [fα(x)] − Eπαt
[fα(x)]) + const, we seek to de-
crease the ﬁrst KL-divergence, while we will increase the
second KL-divergence, or we seek to shift the value func-
tion fα(x) toward the observed data and away from the syn-
thesized data generated from the current model. That is, the
model πα criticizes its current version παt , i.e., the model
is its own adversary or its own critic.

2.2.3 Similarity and Difference

In both models, at θt or αt, we have S = K, S′ = K ′,
because ˜K = 0 and ˜K ′ = 0.

The difference is that in the generator model, S = K +

˜K, whereas in energy-based model, S = K − ˜K.

In the generator model, if we replace the intractable

pθt (z|x) by the inference model qφ(z|x), we get VAE.

In energy-based model, if we replace the intractable
παt (x) by the generator pθ(x), we get adversarial con-
trastive divergence (ACD). The negative sign in front of ˜K
is the root of the adversarial learning.

3. Divergence Triangle: Integrating Adversar-

ial and Variational Learning

In this section, we shall ﬁrst present the divergence
triangle, emphasizing its compact symmetric and anti-
symmetric form. Then, we shall show that it is an re-
interpretation and integration of existing methods, in par-
ticular, VAE [25, 38, 33] and ACD [23, 6].

3.1. Loss Function

observe

training

Suppose

examples
we
{x(i) ∼ qdata(x)}n
i=1 where qdata(x) is the unknown
data distribution. πα(x) ∝ exp[fα(x)] with energy func-
tion −fα denotes the energy-based model with parameters
α. The generator model p(z)pθ(x|z) has parameters θ and
latent vector z. It is trivial to sample the latent distribution
p(z) and the generative process is deﬁned as z ∼ p(z),
x ∼ pθ(x|z).

The maximum likelihood learning algorithms for both
the generator and energy-based model require MCMC sam-
pling. We modify the maximum likelihood KL-divergences
by proposing a divergence triangle criterion, so that the two
models can be learned jointly without MCMC. In addition
to the generator pθ and energy-based model πα, we also in-
clude an inference model qφ(z|x) in the learning scheme.
Such an inference model is a key component in the vari-
ational auto-encoder [25, 38, 33]. The inference model
qφ(z|x) with parameters φ maps from the data space to la-
tent space. In the context of EM, qφ(z|x) can be considered
an imputor that imputes the missing data z to get the com-
plete data (z, x).

The three models above deﬁne joint distributions over z
and x from different perspectives. The two marginals, i.e.,
empirical data distribution qdata(x) and latent prior distri-
bution p(z), are known to us. The goal is to harmonize the
three joint distributions so that the competition and cooper-
ation between different loss terms improves learning.

The divergence triangle involves the following three joint

distributions on (z, x):

1. Q-distribution: Q(z, x) = qdata(x)qφ(z|x).

2. P -distribution: P (z, x) = p(z)pθ(x|z).

3. Π-distribution: Π(z, x) = πα(x)qφ(z|x).

We propose to learn the three models pθ, πα, qφ by the

8673

Recall S = K + ˜K in (4), if we replace the intractable
pθt (z|x) in (4) by the explicit qφ(z|x), we get (14), so that
we avoid MCMC for sampling pθt (z|x).

We may interpret VAE as alternating projection between
If qφ(z|x) =
Q and P . See Figure 4 for illustration.
pθ(z|x), the algorithm reduces to the EM algorithm. The
wake-sleep algorithm [17] is similar to VAE, except that it
updates φ by minφ KL(P kQ) instead of minφ KL(QkP ),
so that the wake-sleep algorithm does not have a single ob-
jective function.

The VAE minθ minφ KL(QkP ) deﬁnes a cooperative
game, with the dynamics that qφ and pθ run toward each
other.

Figure 3. Divergence triangle is based on the Kullback-Leibler di-
vergences between three joint distributions of (z, x). The blue
arrow indicates the “running toward” behavior and the red arrow
indicates the “running away” behavior.

following divergence triangle loss functional D

max

α

min

θ

min

φ

D(α, θ, φ),

D = KL(QkP ) + KL(P kΠ) − KL(QkΠ). (13)

3.2.2 Adversarial Learning

See Figure 3 for illustration. The divergence triangle
is based on the three KL-divergences between the three
joint distributions on (z, x). It has a symmetric and anti-
symmetric form, where the anti-symmetry is due to the neg-
ative sign in front of the last KL-divergence and the maxi-
mization over α. The divergence triangle leads to the fol-
lowing dynamics between the three models: (1) Q and P
(2) P seeks to get close
seek to get close to each other.
to Π. (3) π seeks to get close to qdata, but it seeks to get
away from P , as indicated by the red arrow. Note that
KL(QkΠ) = KL(qdatakπα), because qφ(z|x) is canceled
out. The effect of (2) and (3) is that π gets close to qdata,
while inducing P to get close to qdata as well, or in other
words, P chases πα toward qdata.

3.2. Unpacking the Loss Function

The divergence triangle integrates variational and adver-
sarial learning methods, which are modiﬁcations of maxi-
mum likelihood.

3.2.1 Variational Learning

Figure 4. Variational auto-encoder (VAE) as joint minimization
by alternating projection. Left: Interaction between the models.
Right: Alternating projection. The two models run toward each
other.

First, minθ minφ KL(QkP ) captures the variational

auto-encoder (VAE).

KL(QkP ) = KL(qdata(x)kpθ(x))

+ KL(qφ(z|x)kpθ(z|x)),

(14)

Figure 5. Adversarial contrastive divergence (ACD). Left: Inter-
action between the models. Red arrow indicates a chasing game,
where the generator model chases the energy-based model, which
runs toward the data distribution. Right: Contrastive divergence.

Next, consider the learning of the energy-based model
model [23, 6]. Recall S = K − ˜K in (8), if we replace the
intractable παt (x) in (8) by pθ(x), we get

min

α

max

θ

[KL(qdata(x)kπα(x)) − KL(pθ(x)kπα(x))], (15)

or equivalently

max

α

min

θ

[KL(pθ(x)kπα(x)) − KL(qdata(x)kπα(x))], (16)

so that we avoid MCMC for sampling παt (x), and the gra-
dient for updating α becomes

∂
∂α

[Eqdata (fα(x)) − Epθ (fα(x))].

(17)

Because of the negative sign in front of the second KL-
divergence in (15), we need maxθ in (15) or minθ in (16),
so that the learning becomes adversarial. See Figure 5 for
illustration. Inspired by [16], we call (15) the adversarial
contrastive divergence (ACD). It underlies [23, 6].

The adversarial form (15) or (16) deﬁnes a chasing game
with the following dynamics: the generator pθ chases the
energy-based model πα in minθ KL(pθkπα), the energy-
based model πα seeks to get closer to qdata and get away
from pθ. The red arrow in Figure 5 illustrates this chas-
ing game. The result is that πα lures pθ toward qdata.

8674

3.3. Training Algorithm

The three models are parameterized by convolutional
neural networks. Algorithm 1 outlines joint learning under
the divergence triangle. In practice we use stochastic gradi-
ent descent and the expectations are replaced by the sample
averages.

Algorithm 1 Joint Training for Divergence Triangle Model
Require:

training images {x(i)}n
number of learning iterations T ,
α, θ, φ ← initialized network parameters.

i=1,

Ensure:

estimated parameters {α, θ, φ},
generated samples {˜x(i)}˜n

i=1.

1: Let t ← 0.
2: repeat

3:

4:

5:

6:

7:

8:

9:

i=1.

i=1.

{z(i) ∼ p(z)} ˜M
{˜x(i) ∼ pθ(x|z(i))} ˜M
{x(i) ∼ qdata(x)}M
i=1.
{˜z(i) ∼ qφ(z|x(i))}M
i=1.
α-step: Given {˜x(i)} ˜M
i=1 and {x(i)}M
∂
∂α D with learning rate ηα.
update α ← α + ηα
φ-step: Given {(z(i), ˜x(i))} ˜M
update φ ← φ − ηφ
θ-step: Given {(z(i), ˜x(i))} ˜M
update θ ← θ − ηθ
(optional: multiple-step update).
Let t ← t + 1.

∂
∂φ D, with learning rate ηφ.

∂
∂θ D, with learning rate ηθ

i=1,

i=1 and {(˜z(i), x(i))}M

i=1,

i=1 and {(˜z(i), x(i))}M

i=1,

10:
11: until t = T

4. Experiments

The images are resized and scaled to [−1, 1]. The
network parameters are initialized with zero-mean Gaus-
sian with standard deviation 0.02 and optimized using
Adam [24]. Network weights are decayed with rate 0.0005,
and batch normalization [20] is used. The code is available
at https://github.com/enijkamp/triangle.

4.1. Image Generation

4.1.1 Object Generation

For object categories, we test our model on two
commonly-used datasets of natural images: CIFAR-10 and
CelebA [30]. For CelebA face dataset, we randomly se-
lect 9,000 images for training and another 1,000 images for
testing in reconstruction task. The face images are resized
to 64 × 64 and CIFAR-10 images remain 32 × 32. The qual-
itative results of generated samples for objects are shown in
Figure 6. We further evaluate our model using quantitative

Figure 6. Generated samples. Left: generated samples on CIFAR-
10 dataset. Right: generated samples on CelebA dataset.

Figure 7. Generated samples. Left: 32 × 32 ImageNet. Right:
64 × 64 LSUN (bedroom).

In the idealized case, pθ always catches up with πα, then
πα will converge to the maximum likelihood estimate
minα KL(qdatakπα), and pθ converges to πα.

The updating of α by (17) bears similarity to Wasser-
stein GAN (WGAN) [2], but unlike WGAN, fα deﬁnes a
probability distribution πα, and the learning of θ is based
on minθ KL(pθ(x)kπα(x)), which is a variational approx-
imation to πα. This variational approximation only re-
quires knowing fα(x), without knowing Z(α). How-
ever, unlike qφ(z|x), pθ(x) is still intractable, in particu-
lar, its entropy does not have a closed form. Thus, we can
again use variational approximation, by changing the prob-
lem to minθ minφKL(p(z)pθ(x|z)kπα(x)qφ(z|x)),
i.e.,
minθ minφ KL(P kΠ), which is analytically tractable and
which underlies [6]. In fact,

KL(P kΠ) = KL(pθ(x)kπα(x)) + KL(pθ(z|x)kqφ(z|x)). (18)

we

Thus,
maxα minθ minφ[KL(P kΠ) − KL(QkΠ)],
again KL(QkΠ) = KL(qdatakπα).

modify

can

(16)

into
because

Fitting the above together, we have the divergence tri-
angle (13), which has a compact symmetric and anti-
symmetric form.

8675

Figure 8. Generated samples with 1, 024 × 1, 024 resolution drawn from gθ(z) with 512-dimensional latent vector for CelebA-HQ.

Figure 9. High-resolution synthesis from the generator model gθ(z) with linear interpolation in latent space for CelebA-HQ.

Model

CIFAR-10 (IS)
CelebA (FID)

VAE [25] DCGAN [37] WGAN [2] CoopNet [46] CEGAN [6] ALI [10] ALICE [29] Ours
7.23
31.92

4.08
99.09

6.16
38.39

5.76
36.36

6.55
56.57

7.07
41.89

5.93
60.29

6.02
46.14

Table 1. Sample quality evaluation. Row 1: inception scores for CIFAR-10. Row 2: FID scores for CelebA.

Model

CIFAR-10

CelebA

WS [17] VAE [25] ALI [10] ALICE [29] Ours
0.028
0.030

0.037
0.039

0.034
0.046

0.058
0.152

0.311
0.519

Table 2. Test reconstruction evaluation. Row 1: MSE for CIFAR-
10 test set. Row 2: MSE for 1,000 hold out set from CelebA.

evaluations which are based on the Inception Score (IS) [41]
for CIFAR-10 and Frechet Inception Distance (FID) [32]
for CelebA faces. We generate 50,000 random samples
for the computation of the inception score and 10,000 ran-
dom samples for the computation of the FID score. Table 1
shows the IS and FID scores of our model compared with
VAE [25], DCGAN [37], WGAN [2], CoopNet [47], CE-
GAN [6], ALI [10], ALICE [29].

For the Inception Score on CIFAR-10, we borrowed the
scores from relevant papers, and for FID score on 9,000
CelebA faces, we re-implemented or used available code
with network structures similar to our model. The diver-
gence triangle achieves competitive performance compared
to recent baseline models.

4.1.2 Large-scale Dataset

We also train our model on large scale datasets includ-
ing down-sampled 32 × 32 version of ImageNet [36, 40]
(roughly 1 million images) and Large-scale Scene Under-
stand (LSUN) dataset [49]. For the LSUN dataset, we con-
sider the bedroom, tower and Church ourdoor categories
which contains roughly 3 million, 0.7 million and 0.1 mil-

lion images and were re-sized to 64 × 64. The network
structures are similar with the ones used in object genera-
tion with twice the number of channels and batch normal-
ization is used in all three models. Generated samples are
shown on Figure 7.

4.1.3 High-resolution Synthesis

In this section, we recruit a layer-wise training scheme to
learn models on CelebA-HQ [22] with resolutions of up to
1, 024 × 1, 024 pixels. Layer-wise training dates back to
initializing deep neural networks by Restricted Boltzmann
Machines to overcome optimization hurdles [18, 3]. The
technique has been resurrected in progressive GANs [22],
albeit the order of layer transitions is reversed such that top
layers are trained ﬁrst. This resembles a Laplacian Pyra-
mid [8] in which images are generated in a coarse-to-ﬁne
fashion.

As in [22], the training starts with down-sampled images
with a spatial resolution of 4×4 while progressively increas-
ing the size of the images and number of layers. All three
models are grown in synchrony where 1 × 1 convolutions
project between RGB and feature. In contrast to [22], we
do not require mini-batch discrimination to increase vari-
ation of gθ(·) nor gradient penalty to preserve 1-Lipschitz
continuity of fα(·).

Figure 8 depicts high-ﬁdelity synthesis in a resolution of
1, 024 × 1, 024 pixels sampled from the generator model
gθ(z) on CelebA-HQ. Figure 9 illustrates linear interpola-
tion in latent space.

8676

Figure 10. Test image reconstruction. Top: CIFAR-10. Bottom:
CelebA. Left: test images. Right: reconstructed images.

4.2. Test Image Reconstruction

In this experiment, we evaluate the reconstruction ability
of our model for a hold-out testing image dataset. This is a
strong indicator for the accuracy of our inference model.
Speciﬁcally, if our divergence triangle model D is well-
learned, then the inference model should match the true pos-
terior of generator model, i.e., qφ(z|x) ≈ pθ(z|x). There-
fore, given test signal xte, its reconstruction ˜xte should
pθ−→ ˜xte ≈ xte. Fig-
be close to xte, i.e., xte
ure 10 shows the testing images and their reconstructions
on CIFAR-10 and CelebA.

qφ−→ zte

For CIFAR-10 we use the 10,000 pre-deﬁned test im-
ages, while for CelebA we use 1,000 hold-out images that
are unseen in training. The reconstruction quality is quan-
titatively measured by per-pixel mean square error (MSE).
Table 2 shows the per-pixel MSE of our model compared to
WS [17], VAE [25], ALI [10], ALICE [29].

4.3. Energy Landscape Mapping

In the following experiment, we evaluate the learned
energy-based model by mapping the macroscopic structure
of the energy landscape. A well-formed energy function
partitions the image space into meaningful Hopﬁeld basins
of attraction [19]. In order to learn such energy-function,
in Algorithm 1, we perform multiple θ-steps such that the
samples {˜xi} ˜M
i=1 are sufﬁciently “close” to the local min-
ima of −fα(x). Following [14], we map the structure of
the energy function −fα. First, we identify energy minima.
Then, we sort the minima from lowest energy to highest

Figure 11. Disconnectivity-graph depicting the basin structure of
the energy function for Fashion-MNIST. Each column represents
basins members ordered by energy. Circle size indicates the total
number of basin members. Vertical lines encode minima depth
in terms of energy and horizontal lines depict the lowest known
barrier at which two basins merge.

energy and sequentially group images if the energy barrier
between two minima satisﬁes some threshold. This process
is continued until all minima have been clustered. Figure 11
depicts a mapping of −fα in the form of a disconnectivity-
graph [44] and suggests that the learned energy function not
only encodes meaningful images as minima, but also forms
meaningful macroscopic structure.

5. Conclusion

We propose a novel probabilistic framework, namely
the divergence triangle, for joint learning of the energy-
based model, the generator model, and the inference model.
The divergence triangle forms a compact learning func-
tional for three models and naturally uniﬁes aspects of
maximum likelihood estimation [13, 47], variational auto-
encoder [25, 38, 33], adversarial learning [23, 6], con-
trastive divergence [15], and the wake-sleep algorithm [17].

Acknowledgment

The work is supported by DARPA XAI project N66001-
17-2-4029; ARO project W911NF1810296; and ONR
MURI project N00014-16-1-2007; and Extreme Science
and Engineering Discovery Environment (XSEDE) grant
ASC170063. We thank Dr. Tianfu Wu, Shuai Zhu and Bo
Pang for helpful discussions.

8677

0510152025Minima index98765EnergyReferences

[1] P. Abbeel and A. Y. Ng. Apprenticeship learning via inverse
reinforcement learning.
In Proceedings of the twenty-ﬁrst
international conference on Machine learning, page 1, 2004.
3

[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gen-
erative adversarial networks. In International Conference on
Machine Learning, pages 214–223, 2017. 2, 6, 7

[3] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle.
Greedy layer-wise training of deep networks. In Advances
in neural information processing systems, pages 153–160,
2007. 7

[4] L. Chen, S. Dai, Y. Pu, E. Zhou, C. Li, Q. Su, C. Chen, and
L. Carin. Symmetric variational autoencoder and connec-
tions to adversarial learning. In International Conference on
Artiﬁcial Intelligence and Statistics, pages 661–669, 2018. 2

[5] J. Dai, Y. Lu, and Y.-N. Wu. Generative modeling of convo-
lutional neural networks. arXiv preprint arXiv:1412.6296,
2014. 2

[6] Z. Dai, A. Almahairi, P. Bachman, E. Hovy,

and
A. Courville. Calibrating energy-based generative adversar-
ial networks. arXiv preprint arXiv:1702.01691, 2017. 2, 4,
5, 6, 7, 8

[7] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum
likelihood from incomplete data via the em algorithm. Jour-
nal of the royal statistical society. Series B (methodological),
pages 1–38, 1977. 3

[8] E. L. Denton, S. Chintala, R. Fergus, et al. Deep genera-
tive image models using a laplacian pyramid of adversarial
networks. In NIPS, pages 1486–1494, 2015. 7

[9] J. Donahue, P. Kr¨ahenb¨uhl, and T. Darrell. Adversarial fea-

ture learning. arXiv preprint arXiv:1605.09782, 2016. 2

[10] V. Dumoulin,

I. Belghazi, B. Poole, O. Mastropietro,
A. Lamb, M. Arjovsky, and A. Courville. Adversarially
learned inference. arXiv preprint arXiv:1606.00704, 2016.
2, 7, 8

[11] S. Geman and D. Geman. Stochastic relaxation, gibbs dis-
tributions, and the bayesian restoration of images.
IEEE
Transactions on pattern analysis and machine intelligence,
(6):721–741, 1984. 1

[12] I. Goodfellow,

J. Pouget-Abadie, M. Mirza, B. Xu,
D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Gen-
erative adversarial nets. In Advances in neural information
processing systems, pages 2672–2680, 2014. 2

[13] T. Han, Y. Lu, S.-C. Zhu, and Y. N. Wu. Alternating back-
In AAAI, volume 3,

propagation for generator network.
page 13, 2017. 1, 3, 8

[14] M. Hill, E. Nijkamp, and S.-C. Zhu. Building a telescope
to look into high-dimensional image spaces. arXiv preprint
arXiv:1803.01043, 2018. 8

[15] G. Hinton. Training products of experts by minimizing con-
trastive divergence. Neural Computation, pages 1771–1800,
2002. 2, 8

[17] G. E. Hinton, P. Dayan, B. J. Frey, and R. M. Neal. The”
wake-sleep” algorithm for unsupervised neural networks.
Science, 268(5214):1158–1161, 1995. 2, 5, 7, 8

[18] G. E. Hinton and R. R. Salakhutdinov.

dimensionality of data with neural networks.
313(5786):504–507, 2006. 7

Reducing the
science,

[19] J. J. Hopﬁeld. Neural networks and physical systems with
emergent collective computational abilities. Proceedings of
the National Academy of Sciences, 79(8):2554–2558, 1982.
8

[20] S. Ioffe and C. Szegedy. Batch normalization: Accelerating
deep network training by reducing internal covariate shift.
arXiv preprint arXiv:1502.03167, 2015. 6

[21] L. Jin, J. Lazarow, and Z. Tu. Introspective learning for dis-
criminative classiﬁcation. In Advances in Neural Informa-
tion Processing Systems, 2017. 2

[22] T. Karras, T. Aila, S. Laine, and J. Lehtinen. Progressive
growing of gans for improved quality, stability, and variation.
arXiv preprint arXiv:1710.10196, 2017. 7

[23] T. Kim and Y. Bengio. Deep directed generative models
with energy-based probability estimation. arXiv preprint
arXiv:1606.03439, 2016. 2, 4, 5, 8

[24] D. Kingma and J. Ba. Adam: A method for stochastic opti-

mization. arXiv preprint arXiv:1412.6980, 2014. 6

[25] D. P. Kingma and M. Welling. Auto-encoding variational

bayes. arXiv preprint arXiv:1312.6114, 2013. 2, 4, 7, 8

[26] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

classiﬁcation with deep convolutional neural networks.
NIPS, pages 1097–1105, 2012. 2

Imagenet
In

[27] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-
based learning applied to document recognition. Proceed-
ings of the IEEE, 86(11):2278–2324, 1998. 2

[28] Y. LeCun, S. Chopra, R. Hadsell, M. Ranzato, and F. Huang.
A tutorial on energy-based learning. Predicting structured
data, 1(0), 2006. 2

[29] C. Li, H. Liu, C. Chen, Y. Pu, L. Chen, R. Henao, and
L. Carin. Alice: Towards understanding adversarial learn-
ing for joint distribution matching. In Advances in Neural
Information Processing Systems, pages 5495–5503, 2017. 2,
7, 8

[30] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face
attributes in the wild. In Proceedings of International Con-
ference on Computer Vision (ICCV), 2015. 6

[31] Y. Lu, S.-C. Zhu, and Y. N. Wu. Learning FRAME models
using CNN ﬁlters. In Thirtieth AAAI Conference on Artiﬁcial
Intelligence, 2016. 1, 2, 4

[32] M. Lucic, K. Kurach, M. Michalski, S. Gelly, and O. Bous-
quet. Are gans created equal? a large-scale study. arXiv
preprint arXiv:1711.10337, 2017. 7

[33] A. Mnih and K. Gregor. Neural variational inference and
learning in belief networks. In International Conference on
Machine Learning, pages 1791–1799, 2014. 2, 4, 8

[34] R. M. Neal. Mcmc using hamiltonian dynamics. Handbook

of Markov Chain Monte Carlo, 2, 2011. 1, 3

[16] G. E. Hinton. Training products of experts by minimizing
contrastive divergence. Neural Computation, 14(8):1771–
1800, 2002. 5

[35] J. Ngiam, Z. Chen, P. W. Koh, and A. Y. Ng. Learning
In International Conference on Ma-

deep energy models.
chine Learning, pages 1105–1112, 2011. 2

8678

[36] A. v. d. Oord, N. Kalchbrenner, and K. Kavukcuoglu. Pixel
recurrent neural networks. arXiv preprint arXiv:1601.06759,
2016. 7

[53] S.-C. Zhu, Y. N. Wu, and D. Mumford. Minimax entropy
principle and its application to texture modeling. Neural
Computation, 9(8):1627–1660, 1997. 2

[54] B. D. Ziebart, A. L. Maas, J. A. Bagnell, and A. K. Dey.

Maximum entropy inverse reinforcement learning. 2008. 3

[37] A. Radford, L. Metz, and S. Chintala. Unsupervised repre-
sentation learning with deep convolutional generative adver-
sarial networks. arXiv preprint arXiv:1511.06434, 2015. 2,
7

[38] D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic
backpropagation and approximate inference in deep genera-
tive models. In International Conference on Machine Learn-
ing, pages 1278–1286, 2014. 2, 4, 8

[39] D. B. Rubin and D. T. Thayer. Em algorithms for ml factor

analysis. Psychometrika, 47(1):69–76, 1982. 2

[40] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
et al.
Imagenet large scale visual recognition challenge.
International Journal of Computer Vision, 115(3):211–252,
2015. 7

[41] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Rad-
ford, and X. Chen. Improved techniques for training gans. In
Advances in Neural Information Processing Systems, pages
2234–2242, 2016. 7

[42] T. Tieleman. Training restricted boltzmann machines us-
ing approximations to the likelihood gradient. ICML, pages
1064–1071, 2008. 2

[43] Z. Tu. Learning generative models via discriminative ap-
proaches. In 2007 IEEE Conference on Computer Vision and
Pattern Recognition, pages 1–8, 2007. 2

[44] D. J. Wales, M. A. Miller, and T. R. Walsh. Archetypal en-

ergy landscapes. Nature, 394(6695):758, 1998. 8

[45] Y. N. Wu, S. C. Zhu, and X. Liu. Equivalence of julesz en-
sembles and frame models. International Journal of Com-
puter Vision, 38(3):247–265, 2000. 2

[46] J. Xie, Y. Lu, R. Gao, S.-C. Zhu, and Y. N. Wu. Cooperative
training of descriptor and generator networks. arXiv preprint
arXiv:1609.09408, 2016. 7

[47] J. Xie, Y. Lu, R. Gao, S.-C. Zhu, and Y. N. Wu. Cooperative
training of descriptor and generator networks. IEEE transac-
tions on pattern analysis and machine intelligence (PAMI),
2018. 2, 7, 8

[48] J. Xie, Y. Lu, S.-C. Zhu, and Y. N. Wu. A theory of genera-
tive convnet. In International Conference on Machine Learn-
ing, pages 2635–2644, 2016. 1, 2, 4

[49] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and
J. Xiao. Lsun: Construction of a large-scale image dataset
using deep learning with humans in the loop. arXiv preprint
arXiv:1506.03365, 2015. 7

[50] J. Zhao, M. Mathieu, and Y. LeCun. Energy-based genera-
tive adversarial network. arXiv preprint arXiv:1609.03126,
2016. 2

[51] S.-C. Zhu. Statistical modeling and conceptualization of vi-
IEEE Transactions on Pattern Analysis and

sual patterns.
Machine Intelligence, 25(6):691–712, 2003. 2

[52] S.-C. Zhu and D. Mumford. Grade: Gibbs reaction and dif-
fusion equations. In International Conference on Computer
Vision, pages 847–854, 1998. 2

8679

