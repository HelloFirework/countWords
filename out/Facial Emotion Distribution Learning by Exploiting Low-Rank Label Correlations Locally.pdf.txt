Facial Emotion Distribution Learning

by Exploiting Low-Rank Label Correlations Locally

Xiuyi Jia1,2, Xiang Zheng1, Weiwei Li3, Changqing Zhang4, Zechao Li1 ∗

1School of Computer Science and Engineering, Nanjing University of Science and Technology,

2State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China

3College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, China

4College of Intelligence and Computing, Tianjin University, Tianjin, China

Nanjing, China

Abstract

Emotion recognition from facial expressions is an inter-
esting and challenging problem and has attracted much at-
tention in recent years. Substantial previous research has
only been able to address the ambiguity of “what describes
the expression”, which assumes that each facial expression
is associated with one or more predeﬁned affective labels
while ignoring the fact that multiple emotions always have
different intensities in a single picture. Therefore, to de-
pict facial expressions more accurately, this paper adopts
a label distribution learning approach for emotion recogni-
tion that can address the ambiguity of “how to describe the
expression” and proposes an emotion distribution learning
method that exploits label correlations locally. Moreover,
a local low-rank structure is employed to capture the local
label correlations implicitly. Experiments on benchmark fa-
cial expression datasets demonstrate that our method can
better address the emotion distribution recognition problem
than state-of-the-art methods.

1. Introduction

As one of the most natural, powerful and immediate
means for human beings to express their emotions and in-
tentions, facial expression recognition techniques have al-
ready been adopted in numerous multimedia systems. Due
to its wide range of application, such as human-computer
interaction [21] and data-driven animation [19], automatic

∗Corresponding author: Zechao Li (zechao.li@njust.edu.cn). This
work is jointly supported by National Natural Science Foundation of
China (Grant No. 61773208), the Natural Science Foundation of Jiangsu
Province (Grant No. BK20170809) and the China Postdoctoral Science
Foundation (Grant No. 2018M632304).

facial expression recognition has attracted signiﬁcant atten-
tion in recent years. Recent facial expression recognition
methods usually focus on extracting useful features and
applying efﬁcient classiﬁers such as neural-network-based
methods [14], support vector machine (SVM) [13] and hid-
den Markov models (HMM) [27].

Although promising recognition results have been
achieved, there still exist a common issue in previous fa-
cial expression recognition methods:
the assumption that
each facial image is associated with only one of the prede-
ﬁned affective labels tends to be an over-simpliﬁcation. In
real-world applications, a facial expression always contains
blended emotions. For example, when one receives a let-
ter from a friend whom he has not seen for a long time, he
would be happy and surprised simultaneously. According
to Plutchik’s wheel of emotion theory [22], only a few emo-
tions are basic emotions, and each facial expression usually
expresses a mixture of basic emotions with different intensi-
ties. Therefore, to depict facial expressions more accurately,
multi-label learning is utilized for facial expression recogni-
tion, and each picture is associated with multiple predeﬁned
emotions. For example, the GLMM (Group Lasso Regu-
larized Maximum Margin) method was proposed to solve
the facial expression recognition problem in the multi-label
scenario [32]. However, there remain some cases that are
not suitable to be solved by multi-label learning. Specially,
in some cases, we need to know not only which emotions
are associated with a facial expression but also the extent to
which each emotion describes the expression. To solve such
problems, label distribution learning (LDL) [6] is utilized to
address facial expression recognition problems.

To the best of our knowledge, only one study [36] has
been conducted on facial expression recognition by using
LDL. Speciﬁcally, in this work, LDL was applied for facial

9841

(a)

(b)

(c)

Figure 1: Illustration of non-global label correlations. ANG
and DIS have a correlation in (a) and (b), but the correlation
is not shared in (c).

expression recognition to improve the accuracy of facial ex-
pression recognition, and the label correlations are consid-
ered by seeking the Pearson’s correlation coefﬁcients [36].
Although their work attempted to exploit label correlations,
it exploited label correlations in a global manne under the
assumption that the correlations are shared by all instances.
However, in real-world applications, label correlations are
usually local, where a label correlation may be shared by
only a subset of instances rather than all instances. For
example, Fig. 1 gives three pictures from the s-JAFFE
database with 6 basic emotions (happiness, sadness, sur-
prise, anger, disgust and fear), and we consider the corre-
lation between anger (ANG) and disgust (DIS). In Fig. 1a
and Fig. 1b, ANG and DIS have similar description degrees
in their respective images; thus, we consider that ANG and
DIS have a correlation. However, in Fig. 1c, the description
degree of DIS is signiﬁcantly higher than ANG. Therefore,
we deem that the correlation between ANG and DIS is not
shared in Fig. 1c.

In this paper, we will solve the facial expression recog-
nition problem by exploiting the emotion correlations at a
local level, which has never been considered in previous
LDL algorithms. Considering the complexity of emotion
correlations, we adopt a low-rank structure to capture the
local emotion correlations. Unlike previous works, we as-
sume that the label space is the local low-rank structure
shown in Fig. 2b rather than the global low-rank structure
shown in Fig. 2a. As shown in Fig. 2b, it is not a low-rank
structure at the global level but it can be divided into three
blocks of low-rank structure. Based on this assumption, we
propose an Emotion Distribution Learning method by ex-
ploiting Low-Rank label correlations Locally (EDL-LRL).
Furthermore, we develop an alternating direction method
of multipliers (ADMM) to optimize the objective function.
Experiments on two widely used facial expression datasets
show that our proposed method exhibits a promising per-
formance when considering low-rank label correlations lo-

(a) global

(b) local

Figure 2: A simple illustration of global and local label
correlations. Each row denotes the label distribution of
an instance, each column denotes an emotion and differ-
ent colours denote different description degrees. The struc-
ture with same colour in each column constructs a low-rank
structure that can capture the linear label correlation. (a) is
the global low-rank structure and (b) is the local low-rank
structure that can be divided into three blocks of low-rank
structure.

cally.

The main contributions of this study can be summarized
as follows: 1) different from the existing work that exploits
the global label correlations, we consider the label correla-
tions at a local leval; 2) unlike the existing work that cal-
culate the pairwise label correlations explicitly, we employ
a local low-rank structure to exploit the label correlations
implicitly, which can capture the complex label correlations
better. The remained of the paper is organized as follows.
First, we brieﬂy introduce facial expression recognition and
label distribution learning. Second, we present the details
of the proposed EDL-LRL algorithm. Finally, the experi-
mental results are reported, followed by the conclusion.

2. Related Works

2.1. Facial Expression Recognition

Facial expressions are the facial changes in response to a
person’s internal emotional states, intentions, or social com-
munications. Many studies have paid signiﬁcant attention
to facial expression recognition. Some approaches focused
on feature extraction for the facial expression recognition
problem, e.g., the shapes and locations of facial compo-
nents are extracted to represent the face geometry [20]; ac-
tion unit detection is presented by classifying features cal-
culated from tracked ﬁducial facial points [26]. Moreover,
other facial expression recognition research focused on ap-
plying different classiﬁers such as kNN [34], SVM [23] and
Artiﬁcial Neural Networks(ANNs) [18]. Besides, emotions
of facial expression were transmitted by some richer repre-
sentations [2, 16] in recent years.

Although facial expression recognition methods have
been designed from various perspectives, the goal of these
works is to predict the most descriptive emotion from the

9842

predeﬁned affective labels. However, choosing only one
emotion to represent the whole facial expression is inac-
curate and insufﬁcient because a facial expression usually
contains a mixture of basic emotions with different intensi-
ties.

2.2. Label Distribution Learning

In recent years,

learning with ambiguity has been
a popular topic in machine learning area.
There are
three paradigms for solving label ambiguity at present,
namely, single-label learning (SLL), multi-label learning
(MLL) [25] and LDL. MLL has been successfully applied
to facial expression recognition area [31]. Nevertheless,
MLL cannot describe the extent of each label, in which it
is unlikely that multiple affective labels have the same de-
scription degrees to the image. Thus, this paper describes
a facial expression via an emotion distribution and employs
LDL for prediction. LDL is a further extension of MLL,
and LDL outputs a label distribution rather than a label set
like MLL.

A number of algorithms, which can be divided into three
groups, have been proposed for LDL. One group is based
on the problem transformation (PT) strategy, which trans-
forms an LDL problem into an SLL problem and changes
the training examples to weighted single-label examples
such as PT-SVM [9] and PT-Bayes [7]. The second group
is based on the algorithm adaptation (AA). Certain algo-
rithms, such as kNN and BP, are adapted to form the AA-
kNN [8] and AA-BP [10], respectively. The ﬁnal group
consists of those based on the specialized algorithm (SA)
that match the LDL problem directly such as SA-IIS [6]
and SA-BFGS [6]. The related research has demonstrated
that the third strategy is more effective than the other two
strategies [6]. Therefore, this paper designs the emotion
distribution learning algorithm based on the SA strategy as
well.

To improve the performance of LDL, some algorithms
attemp to exploit label correlations in different ways. In de-
tail, the correlations were captured based on the Plutchik’s
wheel of emotions [35];
the label correlations were ex-
ploited by seeking the Pearson’s correlation coefﬁcients be-
tween two labels [36]; global label correlations were ex-
ploited for incomplete label distribution learning [28]; ad-
ditional features were used to encode the inﬂuence of local
sample correlations [33]; and a distance-mapping function
was employed to encode the global label correlations [12].
However, these approaches exploited label correlations at a
global level, and we explained that it is more reasonable to
use the label correlations locally in the introduction.

3. Emotion Distribution Learning

3.1. Formalization

i , d2

We will give a more formal deﬁnition of emotion
Let X = Rq denote the q-
distribution learning.
dimensional image space of facial expressions, and let Y =
{y1, y2, · · · , yL} denote the L predeﬁned affective labels.
Each label represents one of the basic emotions. Given
a training set S = {(x1, D1), (x2, D2), · · · , (xn, Dn)},
where Di = {d1
i , · · · , dL
i } is the emotion distribution
with xi, we assign a value dj
i called the description degree
to facial expression xi for a particular emotion yj , where
xi ∈ X and yj ∈ Y. Note that dj
i is not the probability that
yj correctly labels xi but rather is the proportion that yj
accounts for in a full description of xi. All emotions with
non-zero dj
i -s are the correct emotions to describe the fa-
i = 1, which means that
all emotions in the set can fully describe the facial expres-
sion. The goal of emotion distribution learning is to learn a
mapping function f : X → D that can predict the emotion
distribution for unseen facial expression.

cial expression and satisfyPL

j=1 dj

Suppose that p(y|x; θ) is the output model learnt from S,
where θ is the parameter matrix. The goal of emotion distri-
bution learning is to ﬁnd an appropriate θ that can generate
a distribution p(y|xi; θ) similar to Di given a facial expres-
sion xi. Moreover, as for the form of p(y|xi; θ), we as-
sume it to be a maximum entropy model similar to previous
work [6] as follows:

p(yl|xi; θ) =

1
Zi

exp(Xk

θl,kxk

i ),

(1)

where xk

and Zi =Pl exp(Pk θl,kxk

i is the k-th feature of xi, θl,k is an element in θ,
i ) is a normalization term used
to satisfy the requirement that the sum of all emotion de-
scription degrees of an instance equals 1. In addition, we
optimize θ by minimizing the following objective function,
which incorporates global discrimination ﬁtting and the in-
ﬂuence of local label correlations:

min

θ

V (θ, S) + λ1Ω(θ, S) + λ2Υ(θ, S),

(2)

where V is the loss function deﬁned on the training data,
Ω is a regularizer to control the complexity of the output
model, Υ is a regularizer to enforce the characteristic of
local label correlations, and λ1 and λ2 are two parameters
to balance the three terms.

With the previous discussion, the purpose of emotion
distribution learning is to make the predicted distribution
and the true distribution as similar as possible; therefore,
we choose a loss function that can measure the similarity of
two distributions. Various functions were analyzed to mea-
sure the similarity between two distributions such as the

9843

Euclidean distance, Kullback-Leibler divergence and Jef-
fery divergence [4]. Here, for easy computation, we use the
square of the Euclidean distance as the loss function deﬁned
by

DJ (Qa||Qb) =Xj

(Qj

a − Qj

b)2,

(3)

a and Qj

where Qj
b are the j-th element of the two distribu-
tions Qa and Qb, respectively. Speciﬁcally, in this paper,
the expression for V based on the Euclidean distance is de-
ﬁned as follows:

V (θ, S) =

1
2

kD − ¯Dk2
F ,

(4)

where k · k2
F denotes the Frobenius norm of a matrix, D and
¯D denote the predicted distribution and the true distribution
of the training set, respectively. For the second term of Eq.
(2), we simply implement it as follows:

Ω(θ, S) = kθk2
F .

(5)

The third term of Eq. (2) is employed to enforce the lo-
cal low-rank structure of the predicted distribution, which
implicitly exploits the label correlations locally. We as-
sume that the training data can be divided into m clus-
ters {G1, G2, · · · , Gm} and that each cluster is a low-rank
structure. This partitioning can be implemented by cluster-
ing or some domain knowledge, such as gene pathways [24]
and networks [5] in bioinformatics applications. For easy
implementation, we use K-means as the clustering method.
Notice that we cluster the training data in the label space
rather than in the feature space because instances with sim-
ilar label distributions usually share similar label correla-
tions, and the cluster is more likely to be a low-rank struc-
ture. Unfortunately, the rank of a matrix is difﬁcult to op-
timize; therefore, the trace norm k · ktr is utilized in this
paper as a convex approximation of the rank of a matrix.
The trace norm k · ktr is deﬁned as the sum of singular val-

ues, i.e., k · ktr = Pi σi(·), where σi is the i-th singular

value of the matrix. Thus, the ﬁnal term of Eq. (2) based on
local low-rank label correlations is derived as follows:

Υ(θ, S) =

m

Xi=1

kD(i)ktr,

(6)

where D(i) denotes the predicted distribution of the i-th
cluster Gi. By substituting Eqs. (4), (5) and (6) into Eq.
(2), the optimization problem is obtained as follows:

min

θ

1
2

kD − ¯Dk2

F + λ1kθk2

F + λ2

kD(i)ktr.

(7)

m

Xi=1

3.2. Optimizing using ADMM

ADMM (Alternating Direction Method of Multipli-
ers) [3] is a simple but powerful algorithm that is well suited

min
θ,Z,Λ

1
2

m

+

Xi=1

m

m

Xi=1
Xi=1

ρ(i)
2

(7).

It takes the form of a decomposition-
to solve Eq.
coordination procedure, in which the solutions to small lo-
cal subproblems are coordinated to ﬁnd a solution to a large
global problem. For easy optimization in the following, we
transform Eq. (7) into the form:

min
θ,Z

1
2

kD − ¯Dk2

F + λ1kθk2

F + λ2

s.t. D(i) − Z (i) = 0.

m

Xi=1

kZ (i)ktr

(8)

The augmented Lagrange function of Eq. (8) is given by

kD − ¯Dk2

F + λ1kθk2

F + λ2

kZ (i)ktr

< Λ(i), D(i) − Z (i) > +

kD(i) − Z (i)k2
F ,

of

{ρ(1), ρ(2), · · · , ρ(m)};

called the penalty parameters,

(9)
where Λ is a list of Lagrange multipliers, consist-
ing of {Λ(1), Λ(2), · · · , Λ(m)}; ρ is a list of posi-
tive numbers,
con-
sisting
of
{Z (1), Z (2), · · · , Z (m)}; and < ·, · > is the Frobe-
nius dot-product, i.e., for two matrices X, Y ∈ Rm×n,
j=1 XijYij . Now, the
above optimization problem can be solved by alternating
minimization, i.e., update each variable (θ, Z and Λ) with
the others ﬁxed in iteration t:

< X, Y >= tr(X T Y ) = Pm

i=1Pn

Z consists

θt+1 = arg min

θ

1
2

kD − ¯Dk2

F + λ1kθk2

F

+

+

m

m

Xi=1
Xi=1

< Λ(i)t, D(i) − Z (i)t >

(10)

ρ(i)
2

kD(i) − Z (i)tk2
F ,

Z t+1 = arg min
Z

λ2

kZ (i)ktr

m

Xi=1

+

+

m

m

Xi=1
Xi=1

< Λ(i)t, D(i)t+1 − Z (i) >

(11)

ρ(i)
2

kD(i)t+1 − Z (i)k2
F ,

Λ(i)t+1 = Λ(i)t + ρ(i)(D(i)t+1 − Z (i)t+1).

(12)

Eq. (10) can be effectively solved by the limited-memory
quasi-Newton method (L-BFGS) [30]. The basic idea is
to avoid explicit calculation of the inverse Hessian matrix
used in the Newton method. In addition, L-BFGS approx-
imates the inverse Hessian matrix with an iteratively up-
dated matrix instead of storing the full matrix. Let Eq. (10)

9844

be T (θ), we follow the idea of an effective quasi-Newton
method BFGS. Consider the second order Taylor series of
T ′(θ) = −T (θ) at the current estimate of the parameter
vector θ(l):

T ′(θ(l+1)) ≈ T ′(θ(l)) + ∇T ′(θ(l+1))T ∆ +

∆T H(θ(l))∆,
(13)
where ∆ = θ(l+1) − θ(l) is the update step, ∇T (θ(l)) and
H(θ(l)) are the gradient and Hessian matrix of T ′(θ(l+1))
at θ(l), respectively. The minimizer of Eq. (13) is

1
2

∆(l) = −H −1(θ(l))∇T ′(θ(l)).

(14)

The line search Newton method uses ∆(l) as the search di-
rection p(l) = ∆(l) and updates model parameters by

θ(l+1) = θ(l) + α(l)p(l),

(15)

where the step length α(l) is obtained from a line search
procedure to satisfy the strong Wolfe conditions [17]:

T ′(θ(l) + α(l)p(l)) 6 T ′(θ(l)) + c1α(l)∇T ′(θ(l))T p(l),

|∇T ′(θ(l) + α(l)p(l))| 6 c2|∇T ′(θ(l))T p(l)|,

(16)

(17)

where 0 < c1 < c2 < 1. The idea of L-BFGS is to avoid
explicit calculation of H −1(θ(l)) by approximating it with
an iteratively updated matrix B, i.e.

B(l+1) = (I − ρ(l)s(l)(u(l))T )B(l)(I − ρ(l)u(l)(s(l))T )

+ ρ(l)s(l)(s(l))T ,

(18)
where s(l) = θ(l+1) − θ(l), u(l) = ∇T ′(θ(l+1)) − ∇T ′(θ(l))
and ρ(l) = 1

s(l)u(l) .

As for the optimization of Eq. (10), the computation of
L-BFGS is mainly related to the ﬁrst-order gradient, which
can be obtained by

n

∇θl,k =

(p(yl|xi; θ) − dl

i)p′(yl|xi; θ) + 2λ1θl,k

m

+

Xi=1
Xi=1 Xxj ∈Gi
Xi=1 Xxj ∈Gi

+

m

Λ(i)
j,l p′(yl|xj; θ)

ρ(i)(p(yl|xj; θ) − Z (i)l

j

)p′(yl|xj; θ),

j,l is an element of Λ(i), Z (i)l

j

where Λ(i)
and p′(yl|xi; θ) = xk

i (p(yl|xi; θ) − p2(yl|xi; θ)).

To solve Eq. (11), it can be decomposed into m opti-

mization problems, where the i-th problem is:

(19)
is an element of Z (i)

λ2kZ (i)ktr+ < Λ(i)t, D(i)t+1 − Z (i) >

min
Z(i)

+

ρ(i)
2

kD(i)t+1 − Z (i)k2
F .

Algorithm 1: The EDL-LRL algorithm

Input: training set S = {X, D}, parameters λ1, λ2

and m.

Output: the label distribution Dt.

1 cluster training set S with K-means;
2 initialize Λ, Z, ρ and θ;
3 t = 1;
4 repeat

5

6

7

8

solve θt+1 by Eq. (10);
solve Z t+1 by Eq. (11);
update Λt+1 by Eq. (12);
t = t + 1;

9 until stopping criterion is satisﬁed;
10 return the label distribution Dt according to Eq. (1).

Then, Eq. (20) can be further rewritten as follows:

min
Z(i)

λ2
ρ(i) kZ (i)ktr +

1
2

kZ (i) − (D(i) +

Λ(i)
ρi )k2
F ,

(21)

which has closed-form solutions. Eq. (21) can be solved by
the following Lemma 1:

Lemma 1 For matrix Y ∈ Rn×d and µ > 0, the problem
as follows has the only one analysis solution,

arg min

M ∈Rn×d

µkM ktr +

1
2

kM − Y k2
F .

This solution can be described by singular value threshold-
ing operator,

SV Tµ(Y ) = U diag[(σ − µ)+]V T

(σ − µ)+ =( σ − µ σ > µ

otherwise,

0

U ∈ Rn×r, V ∈ Rd×r and σ = {σ1, σ2, · · · , σr} ∈ Rr×1
can be achieved by singular decomposition of matrix Y ,
Y = U ΣV T and Σ = diag(σ).

The overall procedure of our proposed algorithm is pre-
sented in Algorithm 1. Moreover, the ADMM method in
our algorithm will converge at O(1/T ) rate to the optimum
solution according to [11], where T is the number of iter-
ation steps. Although it can be slower to converge to high
accuracy than other optimization methods, a modest accu-
racy is sufﬁcient to attain satisfactory performance [3].

4. Experiments

4.1. Datasets

(20)

Various datasets are widely used in the facial expression
recognition area. However, most of them are only suitable

9845

Dateset
s-JAFFE

SBU 3DFE

Examples Features Lables

213
2500

243
243

6
6

Table 1: The characteristics of two datasets.

for single-emotion or multi-emotion problems rather than
the emotion distribution problem. While our proposed ap-
proach prefers to the distribution datasets with annotations
of different voters, the majority voting scheme is widely
adopted as the ground truth in this area. Unfortunately, there
are few facial expression datasets provide the detailed votes
from all the workers. Therefore, to evaluate the effective-
ness of our proposed algorithm, we performed extensive
experiments on two facial expression datasets, s-JAFFE
and SBU 3DFE, which are extended from JAFFE [15] and
BU 3DFE [29], respectively. The characteristics of the two
datasets are summarized in Table 1.

The s-JAFFE dataset contains 213 grayscale images of
10 Japanese female models. Each image is scored by 60
people on the 6 basic emotions (i.e., happiness, sadness,
surprise, fear, anger and disgust) with a ﬁve-level scale (1
represents the lowest emotion intensity, while 5 represents
the highest emotion intensity). The average score (after nor-
malization) of each emotion is used to represent the emo-
tion distribution. The second dataset, named SBU 3DFE,
contains 2500 images, and the emotion distribution of each
image is obtained by the same method as s-JAFFE. Besides,
a 243-dimensional feature vector is extracted from each im-
age in s-JAFFE and SBU 3DFE by Local Binary Patterns
(LBP) method [1].

4.2. Evaluation Measures

Different from [36], a different set of measures are used
in our paper, because our used measures are more represen-
tative that are validated in [6]. In detail, six measures, in-
cluding distance-based measures and similarity-based mea-
sures [6], are chosen as the evaluation measures for the LDL
algorithms in this paper. The names and formulas are pre-
sented in Table 2, where D = {d1, d2, · · · , dL} denote the
predicted label distribution and ¯D = { ¯d1, ¯d2, · · · , ¯dL} de-
note the real label distribution. For the ﬁrst four distance
measures, “↓” indicates “the smaller, the better”, and “↑”
indicates “the larger, the better” for the last two similarity
measures.

4.3. Experimental Setting

To verify the performance of the proposed EDL-LRL
method, we take PT-SVM [9], PT-Bayes [7], AA-kNN [8],
AA-BP [10], SA-IIS [6], SA-BFGS [6], EDL [36], LDL-
SCL [33] and LDLLC [12] in our comparison. The param-
eter settings of those algorithms are as follows. PT-SVM

Name

Chebyshev↓

Clark↓

Canberra ↓

Kullback-Leibler(K-L)↓

Cosine↑

Intersection↑

e
c
n
a
t
s
i
D

y
t
i
r
a
l
i

m
S

i

Formula

j=1

j=1

Dis1( ¯D, D) = maxj | ¯dj − dj |
( ¯dj −dj )2
( ¯dj +dj )2
| ¯dj −dj |
¯dj +dj
¯dj
¯dj ln
dj
¯dj dj
jrPL

Dis2( ¯D, D) = rPL
Dis3( ¯D, D) = PL
Dis4( ¯D, D) = PL
PL
rPL
Sim2( ¯D, D) = PL

j=1 min( ¯dj , dj )

j=1
¯d2

Sim1( ¯D, D) =

j=1

j=1

j=1

d2
j

Table 2: Evaluation measures for LDL algorithms.

is implemented as the “C-SVC” type in LIBSVM using the
RBF kernel with the parameters C = 1.0 and Gamma =
0.01. For PT-Bayes, maximum likelihood estimation is em-
ployed to estimate the Gaussian class-conditional probabil-
ity density functions. The number of neighbors k in AA-
kNN is set to 5 and the number of hidden-layer neurons for
AA-BP is set to 60. The parameters in SA-BFGS are set to:
c1 = 10−4 and c2 = 0.9. The parameters η, ε, ξ1 and ξ2
in EDL are set as 5, 0.25, 0.0001, 0.001, respectively. For
LDL-SCL, λ1, λ2 and λ3 are set to 0.001. For LDLLC, the
parameters are set to: λ1 = 0.1 and λ2 = 0.01. In addition,
for EDL-LRL, the regularization parameters λ1 and λ2 are
set as 10−3 and 10−2, respectively. The number of clusters
obtained by K-means is set to 5, i.e., m = 5, and we will
investigate the inﬂuence of m in the following.

4.4. Results and Discussion

For each dataset, the ﬁve-fold cross validation is em-
ployed in this paper. In detail, the instances in each dataset
are randomly divided into 5 parts, one part for testing and
the remainder for training. Note that the EDL results com-
pared in our experiments are different with those reported
in [36], because they used 90% instances as the training
set whereas we use 80% instances, since a small test set
is difﬁcult to reﬂect the difference between different algo-
rithms (For s-JAFFE, 10% instances has only 21 instances).
We apply each method 10 times on each dataset, and the
experimental results are presented in the form of “mean±
std”. The experimental results are reported in Table 3. The
best performance on each measure is marked in bold, and
the two-tailed t-test with 5% signiﬁcance level is performed
to see whether the differences between our method (EDL-
LRL) and the other methods are statistically signiﬁcant. The
results of the t-test are presented immediately after the per-
formance of each method, where • (◦) indicates signiﬁcance
difference.

As illustrated in Table 3, our proposed EDL-LRL
method outperforms all other methods (PT-SVM [9], PT-
Bayes [7], AA-kNN [8], AA-BP [10], SA-IIS [6], SA-

9846

data

s-JAFFE

SBU 3DFE

algorithm
EDL-LRL
PT-SVM
PT-Bayes
AA-kNN
AA-BP
SA-IIS

SA-BFGS

EDL

LDL-SCL
LDLLC

EDL-LRL
PT-SVM
PT-Bayes
AA-kNN
AA-BP
SA-IIS

SA-BFGS

EDL

LDL-SCL
LDLLC

Chebyshev↓
0.0806±0.006
0.1238±0.027•
0.1204±0.030•
0.1009±0.015•
0.1447±0.015•
0.1202±0.048•
0.1007±0.029•
0.1211±0.008•
0.0890±0.007•
0.1194±0.010•
0.0951±0.002
0.1439±0.006•
0.1451±0.005•
0.1300±0.004•
0.1475±0.004•
0.1405±0.005•
0.1291±0.009•
0.1377±0.002•
0.1106±0.002•
0.1356±0.003•

Clark↓

0.3008±0.016
0.4353±0.045•
0.4287±0.053•
0.3562±0.036•
0.5330±0.062•
0.4651±0.050•
0.3847±0.094•
0.4311±0.022•
0.3304±0.021•
0.4207±0.016•
0.3556±0.006
0.4305±0.012•
0.4292±0.013•
0.4105±0.005•
0.4925±0.031•
0.4270±0.016•
0.3984±0.016•
0.4099±0.003•
0.3749±0.003•
0.4328±0.007•

Canberra↓

0.6134±0.034
0.9039±0.099•
0.8972±0.138•
0.7283±0.102•
1.0995±0.109•
0.9349±0.125•
0.7825±0.195•
0.9050±0.054•
0.6808±0.047•
0.8775±0.043•
0.7463±0.013
0.9321±0.027•
0.9413±0.031•
0.8532±0.015
1.0345±0.063•
0.9241±0.038•
0.8596±0.046•
0.8970±0.007•
0.7517±0.007
0.9290±0.015•

K-L↓

0.0361±0.004
0.0745±0.024•
0.0764±0.031•
0.0527±0.018•
0.1180±0.027•
0.0775±0.036•
0.0568±0.024•
0.0745±0.008•
0.0443±0.006•
0.0713±0.008•
0.0694±0.002
0.0926±0.008•
0.0904±0.005•
0.0845±0.007•
0.1205±0.042•
0.0852±0.007•
0.0758±0.008•
0.0844±0.001•
0.0574±0.001◦
0.0857±0.003•

Cosine↑

0.9660±0.004
0.9290±0.023•
0.9287±0.027•
0.9484±0.020•
0.8959±0.021•
0.9286±0.036•
0.9452±0.025•
0.9297±0.007•
0.9583±0.006•
0.9324±0.008•
0.9626±0.002
0.9113±0.007•
0.9126±0.004•
0.9176±0.005•
0.8952±0.011•
0.9166±0.005•
0.9255±0.007•
0.9185±0.001•
0.9435±0.001•
0.9165±0.002•

Intersection↑
0.8970±0.006
0.8453±0.021•
0.8470±0.029•
0.8739±0.018•
0.8132±0.017•
0.8442±0.031•
0.8673±0.032•
0.8458±0.010•
0.8851±0.009•
0.8503±0.009•
0.8686±0.002
0.8324±0.005•
0.8314±0.005•
0.8453±0.003•
0.8158±0.008•
0.8341±0.006•
0.8454±0.008•
0.8397±0.001•
0.8656±0.001•
0.8330±0.003•

Table 3: Comparison results (mean±std.) of LDL methods on real-world datasets. The best performance on each measure is
marked in bold. • (◦) indicates that EDL-LRL is signiﬁcantly better (worse) than the corresponding method on the criterion
based on two-tailed t-test with 5% signiﬁcance level. ↑ (↓) indicates the larger (smaller), the better.

(a) Shebyshev

(b) Clark

(c) Canberra

(d) K-L

(e) Cosine

(f) Intersection

Figure 3: Comparison of eight methods under varying the training data sizes on s-JAFFE.

BFGS [6], EDL [36], LDL-SCL [33] and LDLLC [12])
on all criteria except for K-L, and EDL-LRL has the top
2 performances on K-L. Besides, the specialized LDL algo-
rithms generally perform better than those algorithms ob-
tained from PT and AA in most cases. The reason is that the
specialized LDL algorithms are designed to directly mini-
mize the similarity between the predicted label distribution
and the true label distribution. Furthermore, it is worth men-
tioning that the EDL-LRL method is superior to the EDL

and LDLLC methods, which exploit label correlations in a
global manner. This indicates that exploiting label correla-
tions locally is more reasonable.

In addition, to demonstrate the robustness of our pro-
posed method, we studied the performance of emotion dis-
tribution prediction under varying training data sizes. In the
experiment, 10% − 90% of the data are used as the training
set. A desired number of instances are sampled randomly
ten times, and the resulting average Chebyshev, Clark, Can-

9847

(a) Shebyshev

(b) Clark

(c) Canberra

(d) K-L

(e) Cosine

(f) Intersection

Figure 4: Inﬂuence of m with 6 measures on dataset s-JAFFE.

berra, K-L, Cosine and Intersection are recorded. We re-
port the experimental results on the s-JAFFE dataset with
6 evaluation measures, which are shown in Fig. 3. For the
simplicity of illustration and the poor performances of PT-
SVM and AA-BP, the results of these algorithms are not
reported in Fig. 3. It can be observed that the performance
of our EDL-LRL method improves as the training data size
increases. Furthermore, EDL-LRL achieves the best perfor-
mance when the training data size is greater than 40%, and
it is in the top 3 performances when the training data size is
less than 40% because the local label correlations cannot be
effectively exploited when the training set is insufﬁcient.

4.5. Inﬂuence of the Number of Clusters

To investigate the inﬂuence of the number of clusters m,
we run EDL-LRL with m varying from 1 to 9, and ﬁve-fold
cross validation is employed in each experiment. Besides,
we only show the results with six measures on the s-JAFFE
dataset because the results have the similar trend on the
SBU 3DFE. As seen in Fig. 4, the performance improves
as m increases and tends to be stable after m becomes suf-
ﬁciently large.

4.6. Convergence

An ADMM based optimization method is used to solve
the objective function of our algorithm. To investigate the
convergence of the ADMM method to solve the EDL-LRL
model, we plot the value of the objective function (i.e., Eq.
(8)) on the two datasets in Fig. 5. As can be observed, the
objective function value decreases with respect to the num-
ber of iterations, and the value approaches a ﬁxed value after

(a) s-JAFFE

(b) SBU 3DFE

Figure 5: Convergence of EDL-LRL on s-JAFFE and
SBU 3DFE.

a few iterations.

5. Conclusion

To depict facial expressions more accurately, this pa-
per introduces a challenging learning scenario wherein fa-
cial expression recognition is modeled as an emotion dis-
tribution learning problem and proposes the EDL-LRL al-
gorithm. Moreover, we exploit the label correlations at a
local level since different facial expressions may share dif-
ferent label correlations in real-world applications, and a
local low-rank assumption is employed to capture the local
label correlations. A series of experiments demonstrate that
EDL-LRL is superior to some state-of-the-art label distri-
bution learning methods.

References

[1] T. Ahonen, A. Hadid, and M. Pietikainen. Face description
with local binary patterns: Application to face recognition.

9848

IEEE Trans. Pattern Anal. Mach. Intell., 28(12):2037–2041,
2006.

[17] Jorge Nocedal and Stephen J. Wright. Numerical Optimiza-

tion. Springer Science & Business Media, 2006.

[2] Carlos F. Benitezquiroz, Ramprakash Srinivasan,

and
Aleix M Martinez.
Facial color is an efﬁcient mecha-
nism to visually transmit emotion. Proceedings of the Na-
tional Academy of Sciences of the United States of America,
115(14):3581–3586, 2018.

[3] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and
Jonathan Eckstein. Distributed optimization and statistical
learning via the alternating direction method of multipli-
ers. Foundations & Trends in Machine Learning, 3(1):1–122,
2011.

[4] Sung Hyuk Cha.

Comprehensive survey on dis-
tance/similarity measures between probability density func-
tions.
International Journal of Mathematical Models &
Methods in Applied Sciences, 1(4):300–307, 2007.

[5] Hanyu Chuang, Eunjung Lee, Yutsueng Liu, Doheon Lee,
and Trey Ideker. Network-based classiﬁcation of breast can-
cer metastasis. Molecular Systems Biology, 3(1):140–149,
2007.

[6] Xin Geng. Label distribution learning. IEEE Transactions
on Knowledge & Data Engineering, 28(7):1734–1748, 2016.
In
IEEE International Conference on Data Mining Workshops,
pages 377–383, 2013.

[7] Xin Geng and Rongzi Ji. Label distribution learning.

[8] Xin Geng, Kate Smith-Miles, and Zhihua Zhou. Facial age
estimation by learning from label distributions. In AAAI Con-
ference on Artiﬁcial Intelligence, pages 451–456, 2010.

[9] Xin Geng, Qin Wang, and Yu Xia. Facial age estimation by
adaptive label distribution learning.
In IEEE International
Conference on Pattern Recognition, pages 4465–4470, 2014.
[10] Xin Geng, Chao Yin, and Zhihua Zhou. Facial age estima-
tion by learning from label distributions. IEEE Transactions
on Pattern Analysis & Machine Intelligence, 35(10):2401–
2412, 2013.

[11] Bingsheng He and Xiaoming Yuan. On the O(1/n) con-
vergence rate of the douglas-rachford alternating direction
method. SIAM Journal on Numerical Analysis, 50(2):700–
709, 2012.

[12] Xiuyi Jia, Weiwei Li, Junyu Liu, and Yu Zhang. Label
In
distribution learning by exploiting label correlations.
AAAI Conference on Artiﬁcial Intelligence, pages 3310–
3317, 2018.

[13] Irene Kotsia and Ioannis Pitas. Facial expression recogni-
tion in image sequences using geometric deformation fea-
tures and support vector machines.
IEEE Transactions on
Image Processing, 16(1):172–187, 2006.

[14] Ping Liu, Shizhong Han, Zibo Meng, and Yan Tong. Facial
expression recognition via a boosted deep belief network. In
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 1805–1812, 2014.

[15] M Lyons, S Akamatsu, M Kamachi, and J Gyoba. Coding
facial expressions with gabor wavelets.
In IEEE Interna-
tional Conference on Automatic Face and Gesture Recogni-
tion, pages 200–205, 2002.

[16] Aleix M Martinez. Visual perception of facial expressions of

emotion. Current Opinion in Psychology, 17:27–33, 2017.

[18] Ebenezer Owusu, Yongzhao Zhan, and Qirong Mao. A
neural-adaboost based facial expression recognition system.
Expert Systems with Applications, 41(7):3383–3390, 2014.

[19] Maja Pantic and Leon J M Rothkrantz. Automatic analysis
of facial expressions: the state of the art. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 22(12):1424–
1445, 2000.

[20] M. Pantic and L. J. M Rothkrantz. Expert system for auto-
matic analysis of facial expressions. Image & Vision Com-
puting, 18(11):881–905, 2000.

[21] Maja Pantic and Leon J M Rothkrantz. Toward an affect-
sensitive multimodal human-computer interaction. Proceed-
ings of the IEEE, 91(9):1370–1390, 2003.

[22] Robert Plutchik. Chapter 1 - A General Psychoevolutionary

Theory of Emotion. Elsevier Inc., 1980.

[23] Caifeng Song, Weifeng Liu, and Yanjiang Wang. Facial ex-
pression recognition based on hessian regularized support
vector machine.
In International Conference on Internet
Multimedia Computing and Service, pages 264–267, 2013.

[24] Aravind Subramanian, Pablo Tamayo, Vamsi K Mootha,
Sayan Mukherjee, Benjamin L Ebert, Michael A Gillette,
Amanda G Paulovich, Scott L Pomeroy, Todd R Golub,
Eric S Lander, et al. Gene set enrichment analysis: A
knowledge-based approach for interpreting genome-wide ex-
pression proﬁles. Proceedings of the National Academy of
Sciences of the United States of America, 102(43):15545–
15550, 2005.

[25] Grigorios Tsoumakas, Ioannis Katakis, and David Taniar.
Multi-label classiﬁcation: An overview. International Jour-
nal of Data Warehousing & Mining, 3(3):1–13, 2007.

[26] M. Valstar, I. Patras, and M. Pantic. Facial action unit detec-
tion using probabilistic actively learned support vector ma-
chines on tracked facial point data. In IEEE Conference on
Computer Vision and Pattern Recognition Workshop, pages
76–84, 2005.

[27] Te Hsun Wang and Jenn Jier James Lien. Facial expres-
sion recognition system based on rigid and non-rigid mo-
tion separation and 3D pose estimation. Pattern Recognition,
42(5):962–977, 2009.

[28] Miao Xu and Zhihua Zhou.

Incomplete label distribution
learning. In International Joint Conference on Artiﬁcial In-
telligence, pages 3175–3181, 2017.

[29] Lijun Yin, Xiaozhou Wei, Yi Sun, Jun Wang, and Matthew J
Rosato. A 3D facial expression database for facial behav-
ior research. In International Conference on Automatic Face
and Gesture Recognition, pages 211–216, 2006.

[30] Yaxiang Yuan. A modiﬁed BFGS algorithm for uncon-
strained optimization. IMA Journal of Numerical Analysis,
11(3):325–332, 1991.

[31] Kaili Zhao, Wensheng Chu, Fernando De la Torre, Jef-
frey F. Cohn, and Honggang Zhang. Joint patch and multi-
label learning for facial action unit and holistic expres-
sion recognition. IEEE Transactions on Image Processing,
25(8):3931–3946, 2016.

9849

[32] Kaili Zhao, Honggang Zhang, Mingzhi Dong, Jun Guo,
Yonggang Qi, and Yizhe Song. A multi-label classiﬁcation
approach for facial expression recognition. In Visual Com-
munications and Image Processing, pages 1–6, 2014.

[33] Xiang Zheng, Xiuyi Jia, and Weiwei Li. Label distribu-
tion learning by exploiting sample correlations locally.
In
AAAI Conference on Artiﬁcial Intelligence, pages 4556–
4563, 2018.

[34] Ruicong Zhi and Qiuqi Ruan. Facial expression recognition
based on two-dimensional discriminant locality preserving
projections. Neurocomputing, 71(79):1730–1734, 2008.

[35] Deyu Zhou, Xuan Zhang, Yin Zhou, Quan Zhao, and Xin
Geng. Emotion distribution learning from texts. In Confer-
ence on Empirical Methods in Natural Language Processing,
pages 638–647, 2016.

[36] Ying Zhou, Hui Xue, and Xin Geng. Emotion distribution
recognition from facial expressions. In ACM International
Conference on Multimedia, pages 1247–1250, 2015.

9850

