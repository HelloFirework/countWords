Spectral Reconstruction from Dispersive Blur: A Novel Light Efﬁcient Spectral

Imager

Yuanyuan Zhao∗

,

1 Xuemei Hu∗

,

1 Hui Guo1 Zhan Ma1 Tao Yue1

,

2 Xun Cao1

1Nanjing University, Nanjing, China

2NJU institute of sensing and imaging engineering, Nanjing, China

{yuan square, guo hui}@smail.nju.edu.cn

{xuemeihu,

mazhan,

yuetao,

caoxun}@nju.edu.cn

Abstract

Developing high light efﬁciency imaging techniques to
retrieve high dimensional optical signal is a long-term
goal in computational photography. Multispectral imaging,
which captures images of different wavelengths and boost-
ing the abilities for revealing scene properties, has devel-
oped rapidly in the last few decades. From scanning method
to snapshot imaging, the limit of light collection efﬁciency
is kept being pushed which enables wider applications es-
pecially under the light-starved scenes.
In this work, we
propose a novel multispectral imaging technique, that could
capture the multispectral images with a high light efﬁciency.
Through investigating the dispersive blur caused by spec-
tral dispersers and introducing the difference of blur (DoB)
constraints, we propose a basic theory for capturing mul-
tispectral information from a single dispersive-blurred im-
age and an additional spectrum of an arbitrary point in the
scene. Based on the theory, we design a prototype system
and develop an optimization algorithm to realize snapshot
multispectral imaging. The effectiveness of the proposed
method is veriﬁed on both the synthetic data and real cap-
tured images.

1. Introduction

The spectrum of light contains rich information of the
scene, and is of great signiﬁcance for many applications,
e.g., medical diagnostics [3], object distinguishment [8],
face recognition [26], etc. The core technique for captur-
ing the spectrum of light is snapshot multispectral imaging,
i.e., taking images or videos of different wavelength band
over the visible wavelength range in a single snapshot.

Existing snapshot multispectral imaging techniques can
be mainly categorized into ﬁve main categories:
tomog-
raphy methods [9], remapping methods [7, 13, 16], coded
aperture methods [11, 17, 23, 28, 30], spectral ﬁlter based

∗Both authors contributed equally to this work.

Figure 1. Overview of our imaging method. (a) Prototype system:
incoming light is splitted into two light paths: a sharp gray im-
age is captured from one light path for the location information of
edges. A dispersive-blurred and margin-masked image is captured
on the other path for the DoB constraints and the additional spec-
trum of the edge point. (b) DoB constraints along each edge: the
derivative of the dispersive blur along each edge equals the differ-
ence of the spectrum of the adjacent areas. (c) DoB constraints
over all edges constitute a graph, based on which we reconstruct
the hyperspectral images.

methods [5, 21, 22, 25] and RGB camera based meth-
ods [1, 2, 4, 10, 33]. The total light throughput of these
multispectral imaging techniques is sacriﬁced either in the
spatial or the spectral dimension, which greatly reduce the
signal-to-noise-ratio (SNR) of measurements and prevent
the high-quality multispectral reconstruction [24]. Thus,
improving the light throughput is one of the key concern in
spectrometer design, especially for the video-rate spectral
imagers where the exposure time is strictly limited.

In this paper, we propose a novel snapshot multispec-
tral imaging technique with high light throughput. Based
on the difference of blur (DoB) constraints [12] (i.e., the
derivative of the dispersive blur along the dispersive direc-
tion over each edge is exactly the difference of spectrum
of the adjacent area, as shown in Fig. 1(b)), we theoret-

112202

RelayLensPrismImagingLensObjectEdgeMaskImagingLensSensor#1Sharp GrayImageDispersiveImageSensor#2xyIxdI/dxxIII0s2s60000-ss31x2x6x2x6II(c)(b)(a)ically prove that we can recover the multispectral images
from a single dispersive-blurred image plus an additional
spectrum of a single point in the scene. Speciﬁcally, the
multispectral image reconstruction problem can be mod-
elled as a N -linear equation system, and through introduc-
ing a graph model, we theoretically prove that DoB con-
straints provide only N − 1 independent constraints and
the spectrum of an additional point is required for multi-
spectral recovery. We propose to introduce the edge mask
to get an additional spectrum of the edge point and realize
the full rank retrieval of multispectral images. Based on
the theory we proved, we design a snapshot multispectral
imaging technique (Fig. 1(a)) that could capture all the re-
quired information. The imager is composed of two light
paths: the dispersive-blurred path is for capturing the above
mentioned full rank multispectral information and the gray-
camera path is for locating the sharp edge. An optimiza-
tion algorithm is proposed to reconstruct the multispectral
information from the captured two images. Since the light
throughput loss introduced around the edge is ignorable, our
methods could achieve snapshot multispectral imaging with
a high light efﬁciency.

High throughput imaging could directly improve the
SNR of the measurements, and improve the following hy-
perspectral recovery, which is especially important in the
light-starved applications such as multispectral ﬂuorescence
microscopic imaging [20], high speed multispectral imag-
ing [31] and plenoptic light imaging techniques [32, 34],
etc. Besides, other than the spectral domain imaging, the
theory and imaging method we proposed for extracting the
information from dispersion could be applied to the other
domain, such as time domain, and enables high-throughput
snapshot ultrafast imaging [14].

In particular, we make the following contributions:
• We prove theoretically that we can recover the multi-
spectral images from a single dispersive-blurred image
plus the spectrum of an additional point in the scene
based on the graph theory.

• We develop a pixel-wise spectral reconstruction algo-

rithm based on the proposed theory.

• We build a prototype imaging system to verify this ap-
proach and demonstrate the feasibility and effective-
ness with both synthetic and experimental data.

2. Related Work

Traditional multispectral

imaging are implemented
through scanning either along the spatial dimension [6, 27]
or along the spectral dimension [15]. These scanning meth-
ods are slow and the optical throughput is quite low, which
is not applicable for realtime multispectral imaging espe-
cially under light-starved conditions [14, 20, 31]. Snap-
shot spectrometer collect the three dimensional multispec-
tral image in a single exposure period, with a much higher

optical throughput than scanning based methods [18]. Re-
searches in this ﬁeld has been evolving rapidly in the last
few decades, which can be mainly categorized into ﬁve
main methods.
Computed Tomography Methods. Descour and Dere-
niak [9] proposed the Computed Tomography Imaging
Spectrometer (CTIS) and reconstruct the multispectral im-
ages from a set of dispersive projections. Assuming the
number of projection is Np, the spatial resolution captured
is reduced to 1/Np of the sensor pixel number N and so as
the optical throughput. Instead of capturing multiple pro-
jections in different directions, we proposed to capture the
multispectral images with only one dispersive projection,
thus with a much higher light efﬁciency.
Remaping Methods. Remapping methods are proposed
to remap the 3D multispectral volume to 2D spatial detec-
tion [7, 13, 16]. The spatial information is directly sacri-
ﬁced in exchange of spectral resolution, i.e., assuming that
the spectral resolution is Nλ, the total optical throughput
of the multispectral imaging is reduced to 1/Nλ. While
in our method, the spectral information all over the image
are dispersively blurred and integrated together, no spatial
information are directly sacriﬁced and we experimentally
demonstrate that our method could preserve most of the
space information with the proposed algorithm.
Coded Aperture Methods. To overcome the spatial-
spectral resolution trade-offs, methods combing compres-
sive sensing and the statistical priors of natural multispectral
images are proposed [11, 17, 23, 28, 30] , through introduc-
ing random-amplitude aperture to codes both the spatial and
the spectral dimension. These coded aperture based meth-
ods enable multispectral imaging with high spatial resolu-
tion, while the loss of optical throughput introduce by the
random coded aperture is 50% percent and the optical sys-
tem of these methods require complex calibration while our
method only requires simple calibration between the disper-
sive light path and the sharp gray light path.
Spectral Filter Based Methods. To capture the multispec-
tral images with a compact imaging system, a set of spectral
ﬁlter array (SFA) based methods with modulations either in
the primal domain [5, 22, 25] or in the Fourier domain [21]
are investigated. Beneﬁting from the computational recon-
struction, these methods use wide-band spectral ﬁlters and
thus can achieve even more than 50% light throughput. But
generally the manufacturing of SFAs is difﬁcult and thus
limits their widely application in practice.
RGB Camera based Methods. Recently, RGB imaging
sensors are explored to recover the multispectral images [1,
2, 4, 10, 33]. While these methods can realize multispectral
with RGB cameras, the RGB Bayer ﬁlter blocks a large part
of the light and is light inefﬁcient.

In all, we propose a novel multispectral imaging methods
in this paper, which only requires to capture a single disper-

12203

sive blurred image and a sharp gray image. Our imaging
system is easy to calibrate, of low cost and light efﬁcient.
With our snapshot spectral imaging technique, we could
capture high SNR measurements of multispectral data and
we demonstrate that our method could achieve state-of-the-
art snapshot multispectral imaging.

3. Theory

In this part, we will introduce the proposed theory for
multispectral imaging and recovery. Our theoretical infer-
ence is based on two assumptions: 1) The image can be
explicitly segmented into a series of regions, and the spec-
tra are uniform up to a scale factor in each region. 2) All
the maximum distance between each pair of adjacent edges
along the dispersive direction are larger than the size of dis-
persion. We need to note that the ﬁrst assumption are only
invalid in the scene where there are specularities or complex
illumination, which is not the research focus of this paper.
As for the second assumption, in most cases, the edges of
the narrow region are not exactly parallel, the information
is mixed inconsistently, where heterogeneous information
contained in the edges along the narrow regions can still
guarantee the high ﬁdelity spectral recovery, as will be fur-
ther demonstrated in the experimental part.

To simplify the derivation, we consider the case with-
out shading effect ﬁrst and discuss the effect introduced by
shading later. Without shading, natural images consisted of
a set of surfaces with uniﬁed spectral reﬂectance are consid-
ered ﬁrst. We will show that DoB constraints can provide
most of the spectral information for recovering the entire
multispectral image, except a single additional spectrum of
an arbitrary point is required.

3.1. DoB Constraints

In 1989, Funt and Ho [12] have pioneeringly proposed to
estimate the difference of spectra from image edges. To fa-
cilitate further inference, we ﬁrst brieﬂy introduce this DoB
constraints. According to the principle of dispersion, the
spectrum of a single point will spread spatially when pass-
ing the dispersive elements, generating a spectral dispersion
band s, which maps the spectrum into spatial domain. Con-
sidering an edge between two regions (i, j) with two dif-
ferent spectral dispersion band (si, sj ), the DoB constraints
can be represented as:

∇θb = δij ∗ (si − sj),

(1)

where δij is the impulse function, indicating the edge loca-
tion between regions i and j, ∗ denotes spatial convolution,
∇θb represent the derivative of the image intensity b at the
edge along the projection angle θ. Thus, if we know the
position δij of the edge, we can derive the difference of the
spectra si and sj from the derivative of the dispersive blur.

GC of  v
GC of  v
GC of  v
GC of  v
GC of  v
GC of  v

1
2
3
4
5
6

RC of  v
RC of  v
RC of  v
RC of  v
RC of  v
RC of  v

1
2
3
4
5
6

0.12

s
e
v
r
u
c
 
l
a
r
t
c
e
p
s
 

d
e
z
i
l
a
m
r
o
N

0.1

0.08

0.06

0.04

0.02

0
400

450

500

550

600

650

700

Wavelength/nm

(a)

(b)

Figure 2. Illustration of the graph model and veriﬁcation on syn-
thetically generated image. The ‘mushroom’ multispectral image
in Fig. 1(b) is used to synthesize the sharp gray image and the dis-
persive image, which is dispersively blurred on x− direction. (a)
The corresponding graph model. (b) The reconstructed spectral
curves (RC) as well as the ground truth spectral curves (GC) of
the surface pieces indexed in (a).

For a dispersive blurred image, we could deﬁne an edge
matrix A and DoB matrix B to represent the DoB con-
straints. Mathematically, we use each row of A and B to
denote a DoB constraint of an edge. All the DoB constraints
of the entire dispersive blurred image can be formulated by

AS = B,

(2)

where S = [s1, s2, . . . , sN ]T denote the spectra of regions
1, 2, . . . , N in the image, each row of A has only two non-
zero elements 1 and −1 which indicates the corresponding
spectra si and sj of the two surfaces beside the edge, each
row of B is the derivative of blur at the edge. We will prove
in the next section that A is of rank N -1, and an additional
spectrum of a single point is required to realize full-rank
recovery of S.

3.2. Graph Theory for Spectrum Reconstruction

To facilitate discussing the rank of A, we build a corre-
sponding graph model G = (V, E), where V is the vertex
set and each vertex denote a single surface. E is the edge
set and each edge denotes the adjacency between the corre-
sponding vertexes. As in Fig. 2, by introducing the graph
model, each row of A corresponds to an edge in E. We use
the undirected graph in this paper without loss of generality
and since each of the surfaces in an image is at least adja-
cent to another surface, the undirected graph G is connected.
Given the customized edge matrix A of a dispersive blurred
image and its corresponding graph model G, we have the
following theorem.

Theorem 1 The rank of the edge matrix A exactly equals
to the edge number of the spanning tree of its corresponding
undirected connected graph G.

Theorem 1 follows from Lemma 1 below which proves the
equivalence of the connected graph G and its spanning tree
G ′ for the spectrum reconstruction problem. According to

12204

2367514the characteristics of trees, a tree G ′ of N vertexes has N −1
edges, and thus its corresponding edge matrix A′ has N − 1
rows. In other words, the rank of A and A′ is smaller than
or equals to N − 1. Meanwhile, according to Lemma 2, the
edge matrix of a tree is of full row rank. Therefore, the rank
of A′ and the rank of A are both N − 1.

Lemma 1 A connected graph G and its spanning tree G ′
have the same spectrum solution space.

Proof sketch of Lemma 1 We separate the lemma into the
forward and backward propositions.
Forward proposition: any feasible solution S of graph
model G is also a solution of G ′. Assume A and B are
the corresponding edge matrix and the DoB matrix of the
graph model G, S is a solution of AX = B. The spanning
tree G ′ of G can be derived by removing the edges which
are parts of cycles while keeping the connection property.
In other words, the edge matrix A′ and the DoB matrix B′
are pruned version of A and B, and the removed rows just
correspond to the removed edges. Therefore, the forward
proposition here is self-evident since the solution space of
G is exactly a subset of the solution space of G ′.
Backward proposition: any feasible solution S′ of graph
model G ′ is also a solution of G. Since a removed edge
e is a part of a certain cycle C in the original graph G, it
means that the rest edges of the cycle C\e form a path con-
necting the vertexes of the end of the removed edge e. As
the direction of the edges denote the direction of difference
operation (from 1 to −1) and once a certain directed con-
straint is known, its reverse version can be easily derived by
changing the sign of the elements of the corresponding row
in B, thus we can form a directed path from one end of the
removed edge e to the other end, and the summation of the
corresponding rows of A has two non-zero elements 1, −1,
which corresponds to the start and end vertexes respectively.
This summed row vector exactly equals the removed edge
e. Consequentially, the removed row of e can be linearly
represented by the rest rows of C\e, so that the solution S′
satisﬁes the constraints C\e in graph G ′ also satisﬁes the
constraint C = (C\e) ∪ e in graph G.

Lemma 2 The edge matrix A of an undirected acyclic
graph G, a.k.a. a tree, is of full row rank.

Proof sketch of Lemma 2 According to Lemma 1, the so-
lution spaces of the given undirected acyclic graph G and
its corresponding complete graph G ∗ (i.e., G ∗ has the same
vertex set with G, and every pair of distinct vertexes in G ∗
is connected by a unique edge) are exactly the same, that is
because G can be regarded as a spanning tree of G ∗. Mean-
while, a chain graph Gc which is the subgraph of G ∗ and
threads all the vertexes of G ∗ is as well a spanning tree of G ∗
and also share the same solution space of G ∗. Therefore, G
and Gc have the same solution space as well. Furthermore,

the edge matrix Ac of the chain graph Gc is an incomplete
Toeplitz matrix which is of full row rank obviously. Since
the chain graph Gc and G have the same solution space, Ac
and A have the same solution space as well and thus both
of them are of full row rank (N − 1).

3.3. Shading effect

Because of the illumination condition and the shape of
the scenes, the light emitted from the different points of a
same surface may have different irradiance. The uniform
assumption ignores this shading effect and thus is incapable
of dealing with the real scenes. In the following, we intro-
duce the shading effect by using the irradiance scale model
to make the proposed method more feasible for practical
applications.

For the points of a certain surface, we assume that the
reﬂectances are of the uniform spectrum up to a scale, which
means that the observed spectrum of a certain pixel p in
surface i is,

so
p = Ipsi,

(3)

where Ip is the illumination intensity integrated over all
wavelength, si is the normalized spectrum of surface i and
so
p is the observed spectrum of pixel p in it, we could get

∇(p,q)

θ

|p∈surf(i),q∈surf(j)b = δij ∗ (Ipsi − Iqsj),

(4)

θ

where (p, q) denote the adjacent pixels in surface i and j.
∇(p,q)
b is the DoB constraint of pixel pair (p, q). For each
adjacent surface pair i and j, there are many DoB con-
straints with different intensity pairs Ip and Iq. A set of
constraints with different intensity elements Ip and Iq in-
stead of 1 and −1 then replace each row of adjacent matrix
A. In most cases, when there are several different weighted
constraints for a single surface pair, the matrix A becomes
full-rank, and the problem is solvable. However, we found
the condition number of A is not always small in practice,
since the shading caused intensity change is insufﬁciently
large to provide an additional well-deﬁned constraint. Thus,
we propose to introduce the spectrum of a single point to re-
duce the ill-posedness in practice.

Note that after introducing the irradiance scale model
in Eq. 4, the number of unknowns increases from N M to
N M + P , where P is the number of pixels. The added
unknowns are the intensities of the sharp gray scale image.
Although the sharp gray image can be retrieved from the
dispersive blurred image by using blind deblurring algo-
rithms, we propose to use the hybrid camera system as in
[7] to directly capture the sharp gray image. Therefore, in
the following experiment, we propose a multispectral imag-
ing technique that could captures the sharp gray image, the
dispersive blurred image and a single spectrum of a certain
point in a snapshot way and verify the proposed theory.

12205

4. Point-wise Reconstruction Algorithm

Based on the proposed theory, we propose a spectral im-
ager as in Fig. 1(a): incoming light is splitted into two light
paths capturing both the dispersive blurred image and the
sharp gray image. To capture the required additional spec-
trum of a single point, we introduce a side block mask in the
dispersive light path to cut off the sides of the virtual image
focused on sensor #1. Thus the spectra of these blocked re-
gions are known (i.e. zero for all spectral channels), and the
full rank information for multispectral image reconstruction
can be captured.

If the segmentation of scenes is given, the spectra of each
surface can be reconstructed by solving Eq. 2. However,
practically, computing exact segmentations is usually difﬁ-
cult for existing segmentation technologies. Therefore, in
this subsection, we develop a pixel-wise reconstruction al-
gorithm with two snapshot inputs, i.e. the dispersive blurred
image and sharp gray image, to make the proposed method
feasible in practice.

4.1. Problem Statement

Fidelity Term. Using the proposed system, we can cap-
ture dispersive blurred and sharp gray image pairs simulta-
neously, and the acquisition process can be denoted by

G = PgS = X

S(x, y, λ)

λ

D = PdS = X

S(x + ∆x(λ), y, λ),

λ

(5)

where G and D are the gray projection and dispersive pro-
jection of the multispectral cube S. Pg and Pd are the pro-
jection matrix. x, y are the spatial coordinates and λ denotes
wavelength. Given this projection model, the basic ﬁdelity
term of our reconstruction problem is derived,

the differences on the edges of all the channels on the DoB
plane. ∇x,yD denotes the difference map of dispersive
blurred image, and thus exactly matches the DoB projec-
tions. This pixel-wise difference projection constraint for-
mulates all the DoB constraints.
Side Block Constraint. We introduce the side block con-
straint to model the the marginal mask:

Eside = ||S ⊙ M||2,

(8)

where M is the side block mask with 1 in the block areas
and 0 in the rest, and ⊙ denotes the pixel-wise product.
Cross-channel & Sparse Regularizer. The proposed
method is essentially beneﬁted from the piece-wise smooth
assumption of natural scenes, and the segmentation is used
to imply this assumption in the inferences in Sec.3. In our
practical implementation, the cross-channel and sparse con-
straints are adopted to replace the explicit segmentation to
reduce the ill-posedness of the problem. The cross-channel
and sparse regularizer can enforce the piece-wise smooth-
ness on spatial domain and similar edge locations on differ-
ent spectral channels [19]. In our scenario, a sharp projec-
tion image is given, which can be used as the reference map
for the cross-channel and sparse constraint,

Ecs = ||∇x,yS||1 + X

||∇x,ySλ(x, y) − ∇x,yG||1, (9)

λ

where || · ||1 is the L-1 norm, and ||∇x,yS||1 is the sparse
term. Pλ ||∇x,ySλ(x, y) − ∇x,yG||1 is the cross-channel
term, and ∇x,ySλ(x, y) is the gradient map of spectral
channel Sλ, ∇x,yG denotes the gradient map of sharp pro-
jection G.
Objective Function. So far, we have all the ﬁdelity and
constraints of our multispectral reconstruction problem, and
the ﬁnal objective function becomes

Ef = ||G − Pg(S)||2 + ||D − Pd(S)||2,

(6)

E = Ef + λDoBEDoB + λsideEside + λcsEcs,

(10)

where Ef denotes the ﬁdelity term of our objective func-
tion, and || · ||2 is the square of L-2 norm, which is usually
applied for reconstruction problem.
DoB Constraint. Instead of segmenting input images into
regions and extracting DoB constraints explicitly, we utilize
the pixel-wise difference projection constraints to model the
DoB constraints here,

EDoB = ||∇x,yD − Pd(∇x,yS)||2,

(7)

where ∇x,y means the difference operation in both row x
and column y directions. ∇x,yS is full of zeros except for
the pixels on the edges, and the non-zero value on the edge
along the spectral dimension is exactly the difference be-
tween the spectra of the adjacent surfaces. The dispersive
projection operation shear the difference cube and project

where λDoB, λside and λcs are the weights of correspond-
ing terms respectively.

4.2. Optimization

To optimize Eq. 10, we ﬁrst introduce an auxiliary vari-

able Qcs here,

E ′ =Ef + λDoBEDoB + λsideEside

+ βcs||∇S − Qcs||2 + λcs||Qcs||1
+ λcs||Qcs − ∇G||1.

(11)

Then Eq. 11 can be solved by iteratively optimizing two
sub-problems.
Q-subproblem. In this subproblem, we just optimize the
Qcs related terms and update the optimal Qcs by ﬁxing S.

12206

The sub-objective function becomes

E(Qcs) =βcs||∇S − Qcs||2 + λcs||Qcs||1

+ λcs||Qcs − ∇G||1.

(12)

Eq. 12 can be optimized in a pixel-wise way, which means
the sub-objective function can be divided into a series
of sub-functions E(Qcs) = P(x,y) E(Qcs(x, y)), which
takes only one single pixel into consideration,

E(Qcs(x, y)) = βcs||∇S(x, y) − Qcs(x, y)||2
+ λcs||Qcs(x, y)||1 + λcs||Qcs(x, y) − ∇G(x, y)||1.

(13)
To minimize Eq. 12 fast, we adopt the 2-D lookup table
method in [36]. Speciﬁcally, the minimum Qcs with differ-
ent ∇S(x, y) and ∇G(x, y) are recorded. In practice, both
∇S(x, y) and ∇G(x, y) are uniformly sampled from -1 to
1 with interval 0.002. For each combination of ∇S(x, y)
and ∇G(x, y), the minimum Qcs are computed numeri-
cally. By generating the 2-D lookup table before hand, we
can solve the Q-subproblem efﬁciently.
S-subproblem. Then, the spectral cube S is updated in S-
subproblem. The terms related to S are

E(S) =Ef + λDoBEDoB + λsideEside

+ βcs||∇S − Qcs||2.

(14)

It is obvious that all the terms in Eq. 14 are quadratic
terms, and thus can be easily solved by gradient based op-
timization algorithm. In our implementation, the Conjugate
Gradient (CG) algorithm is used to optimize Eq. 14.

B
d
/
R
N
S
P

5. Assessment

In this section, the proposed method is veriﬁed on vari-
ous scenes, including both synthetic and real captured data.
Both quantitative and qualitative comparisons with state-of-
the-art multispectral imaging methods are conducted.

5.1. Experiments on Synthetic Data

We test the proposed method on the Columbia Multi-
spectral Image Database (CMID) [35] to verify the effec-
tiveness, build a prototype spectrometer and further demon-
strate our method on real captured data.
Quantitative Comparisons with State-of-the-art Meth-
ods. We ﬁrst test the proposed method on the dataset
and compare the PSNR with state-of-the-art compressive
snapshot multispectral imagers, i.e. SD-CASSI [29], DD-
CASSI [17]. Considering our system actually requires two
kinds of projections, i.e., the sharp gray projection and
the dispersive blurred projection, we also compare the per-
formance with the hybrid version of SD-CASSI and DD-
CASSI, i.e. hybrid SD-CASSI and hybrid DD-CASSI, and
hybrid PMIS [7, 30] for fair comparison. Fig. 3 shows the

Figure 3. Quantitative comparisons with state-of-the-art multi-
spectral imaging methods on hyperspectral dataset [35].

Hybrid-PMIS
SD-CASSI
Hybrid-SD-CASSI
DD-CASSI
Hybrid-DD-CASSI
Ours

32

30

28

26

24

22

20

18

16

14

12

0

0.02

0.04

0.06

0.08

0.1

Standerd Variances of Noises

Figure 4. Comparison on different noise levels with state-of-the-art
multispectral imagers.

Peak Signal to Noise Ratio (PSNR) of the results of pro-
posed method and other state-of-the-art methods. We can
see that the reconstruction quality of proposed method is
comparable or even better than the state-of-the-art spectral
imaging method. Besides, the proposed method performs
slightly worse than other methods on the images containing
invalid cases of our assumptions, like the Balloons scene
which contains severe specular highlight effects. As for the
cases coincided with the assumptions, the proposed method
can achieve better performance, showing the great potential
of proposed method in hyperspectral imaging.
Performance Comparison with Different Noise Levels.
We also apply the proposed method on different noise lev-

12207

so that their results become better or comparable than DD-
CASSI and hybrid-DD-CASSI when noise level is larger.

It is worth noting that the proposed scheme can enhance
the light throughput of the spectral imager, and thus de-
crease the noise level of observed measurements as well.
In other words, under the same illumination condition, the
measurements of our proposed system can achieve higher
SNR than other hybrid state-of-the-art snapshot multispec-
tral imagers. Considering the proposed method achieves
comparable or even better performance in noise tolerance
experiment, as shown in Fig. 4, our method is of great po-
tential in the light-starved applications [20, 32, 34], which
is a common case in most multispectral imaging scenarios.
We present the reconstructed spectral curves of proposed
and state-of-the-art methods on the images from CMID
[35], as shown in Fig. 5. Compared with the other three
spectral imaging methods, the proposed method achieves
much higher accuracy.

5.2. Experiments on Real Captured Data

We build the prototype spectral imager as in Fig. 6, and
reconstruct real captured spectral images with the proposed
algorithm. As for the calibration step, since the prism dis-
perser which leads to nonlinear dispersion is used in our
system, we pre-calibrate the non-linear dispersion, and cor-
rect the reconstructed spectral curves with the calibration
results. The prism can introduce additional anisotropy aber-
rations, which may deteriorate the quality of our imaging
system. This is a common problem of prism-based spec-
trometers, and can be greatly alleviated by adopting Amici
prism (exactly what we use). The reconstruction results are
shown in Fig. 7. The 1st column is the captured dispersive
image and the second column is the captured sharp gray
image. We reconstruct the multispectral images from these
two measurements. Based on the reconstructed multispec-
tral images, we calculate the corresponding RGB images
and compare with the captured RGB images. The results
are shown in the 3th-4th column. As shown, our result re-
sembles the captured RGB images, demonstrating the high
quality of our results. Further, the reconstructed images at
480 nm, 540 nm, 620 nm, 650 nm and the corresponding
detailed region are shown in the 5th-8th column. As shown
in column 7 and 8, our method could recover the spatial
details, further verifying the proposed algorithm on the re-
trieving ability of spatial resolution. The ground truth here
is captured by an RGB camera. Accurately calibrating its
characteristics, e.g., the white balance, the spectral trans-
mission of optical lenses and the spectral response curves
of its RGB sensor, is difﬁcult in practice and the inaccuracy
may cause slight color difference between captured images
and our results. Furthermore, to check the reconstruction
quality directly, we use a single point spectrometer to cap-
ture the ground truth spectra of points in the scene and com-

12208

Figure 5. Spectral reconstruction results comparisons of the pro-
posed and state-of-the-art methods. Curves extracted from three
‘lemon slices ms’, ‘lemons ms’ and
multispectral images (i.e.
‘real and fake strawberries ms’) from CMID [35] are presented.
Three selected points of each image are marked in the RGB im-
ages (top row), and the corresponding spectral curves of the Point
1, 2 and 3 are shown in second to bottom rows respectively.

Figure 6. The prototype spectrometer: front view and side view.

els to test the noise tolerance of our method, and compare
it with other multispectral imaging methods. As shown
in Fig. 4, the degrading trend of the performance of our
method is much slower than that of DD-CASSI based meth-
ods, showing the excellent capablility of noise resistance of
our method. Especially for the hybrid-DD-CASSI method,
which performs comparable with our method on noise free
data, the recovery performance degrades rapidly with the
increase of noise. In contrast, the SD-CASSI and hybrid-
SD-CASSI present good noise tolerance in the experiments,

Sensor #1Imaging LensPrismEdge MaskBeam SplitterRelay LensImaging LensSensor #2pare with our method. The scene illumination is a tungsten
lamp and as compared, our results resemble the captured
spectrum from the single point spectrometer, verifying the
effectiveness of our method.

6. Discussion and Conclusion

In this paper, we propose a novel view of the multi-
spectral imaging problem. By exploring the dispersive blur
between adjacent regions in dispersive blurred images, we
propose to reconstruct the spectral images from the DoB
constraints. A graph model is introduced to describe the lin-
ear equation system consisting of DoB constraints. Based
on the graph model, we prove the most important conclu-
sion of this paper, i.e., the whole spectral image can be re-
constructed from a single dispersive blurred image and the
spectrum of a single point. Based on the theory, we build an
effective spectral imaging method. The proposed method
have the following advantages: (1) Without using modula-

tion, the proposed spectral imaging method is simple, easy
to calibrate and low cost, promising for wider applications.
(2) The light throughput can be ﬂexibly tuned through ad-
justing the splitting ratio of light between the two arms with
different beamsplitters, so that the spectral imager can ap-
proach very high light throughput (70%-80%).

As for future work, there are a few interesting topics
that are worth to explore, such as directly estimating the
edge information from the dispersive blurred image, fur-
ther modeling the specularities and complex illumination
conditions, introducing perpendicular dispersion pairs for
anisotropy reduction.

Acknowledgement.

This work was supported by Grant No.61671236
from National Science Foundation of China, Grant No.
BK20160634 from National Science Foundation for Young
Scholar of Jiangsu Province.

Dispersive

Image

Sharp

Gray Image

Synthetic

RGB Image

Groundtruth
RGB Image

Hyperspectral

Images

Spatial Details

480nm 540nm 

620nm 650nm

Spectral 
Response

Figure 7. Experimental results on real captured data. The synthetic RGB images, spatial details and spectral responses at marked dots are
evaluated.

12209

References

[1] B. Arad and O. Ben-Shahar. Sparse recovery of hyperspec-
tral signal from natural rgb images. In Proc. ECCV, pages
19–34. Springer, 2016. 1, 2

[2] B. Arad and O. Ben-Shahar. Filter selection for hyperspectral

estimation. In Proc. CVPR, pages 21–26, 2017. 1, 2

[3] V. Backman, M. Wallace, L. Perelman, J. Arendt, R. Gur-
jar, M. M¨uller, Q. Zhang, G. Zonios, E. Kline, T. McGilli-
can, et al. Detection of preinvasive cancer cells. Nature,
406(6791):35–36, 2000. 1

[4] S.-H. Baek, I. Kim, D. Gutierrez, and M. H. Kim. Com-
pact single-shot hyperspectral imaging using a prism. ACM
Trans. on Graphics (TOG), 36(6):217, 2017. 1, 2

[5] J. Bao and M. G. Bawendi. A colloidal quantum dot spec-

trometer. Nature, 523(7558):67, 2015. 1, 2

[6] R. W. Basedow, D. C. Carmer, and M. E. Anderson. Hydice
In Proc. SPIE,

system: Implementation and performance.
pages 258–267, 1995. 2

[7] X. Cao, X. Tong, Q. Dai, and S. Lin. High resolution multi-
spectral video capture with a hybrid camera system. In Proc.
CVPR, pages 297–304, 2011. 1, 2, 4, 6

[8] W. Debskia, P. Walczykowskia, A. Klewskia,

and
M. Zyznowskib. Analysis of usage of multispectral video
technique for distinguishing objects in real time. In ISPRS,
2004. 1

[9] M. Descour and E. Dereniak. Computed-tomography imag-
ing spectrometer: experimental calibration and reconstruc-
tion results. Appl. Opt., 34(22):4817–4826, 1995. 1, 2

[10] Y. Fu, T. Zhang, Y. Zheng, D. Zhang, and H. Huang. Joint
camera spectral sensitivity selection and hyperspectral image
recovery. In Proc. ECCV, pages 812–828. Springer, 2018. 1,
2

[11] Y. Fu, Y. Zheng, I. Sato, and Y. Sato. Exploiting spectral-
spatial correlation for coded hyperspectral image restoration.
In Proc. CVPR, pages 3727–3736, 2016. 1, 2

[12] B. Funt and J. Ho. Color from black and white.

IJCV,

3(2):109–117, 1989. 1, 3

[13] L. Gao, R. T. Kester, and T. S. Tkaczyk. Compact image
slicing spectrometer (iss) for hyperspectral ﬂuorescence mi-
croscopy. Opt. Express, 17(15):12293–12308, 2009. 1, 2

[14] L. Gao, J. Liang, C. Li, and L. V. Wang. Single-shot com-
pressed ultrafast photography at one hundred billion frames
per second. Nature, 516(7529):74, 2014. 2

[15] N. Gat. Imaging spectroscopy using tunable ﬁlters: a review.
In Wavelet Applications VII, volume 4056, pages 50–65. In-
ternational Society for Optics and Photonics, 2000. 2

[16] N. Gat, G. Scriven, J. Garman, M. De Li, and J. Zhang. De-
velopment of four-dimensional imaging spectrometers (4d-
is). In Proc. SPIE, pages 63020M–63020M, 2006. 1, 2

[17] M. Gehm, R. John, D. Brady, R. Willett, and T. Schulz.
Single-shot compressive spectral
imaging with a dual-
disperser architecture. Opt. Express, 15(21):14013–14027,
2007. 1, 2, 6

[18] N. A. Hagen, L. S. Gao, T. S. Tkaczyk, and R. T. Kester.
Snapshot advantage: a review of the light collection im-
provement for parallel high-dimensional measurement sys-
tems. Opt. Eng., 51(11):111702, 2012. 2

[19] F. Heide, M. Rouf, M. B. Hullin, B. Labitzke, W. Hei-
drich, and A. Kolb. High-quality computational imaging
through simple lenses. ACM Transactions on Graphics
(TOG), 32(5):149, 2013. 5

[20] W. Jahr, B. Schmid, C. Schmied, F. O. Fahrbach, and
J. Huisken. Hyperspectral light sheet microscopy. Nature
Commu., 6:7990, 2015. 2, 7

[21] J. Jia, K. J. Barnard, and K. Hirakawa. Fourier spectral ﬁl-
ter array for optimal multispectral imaging. IEEE Trans. on
Image Process., 25(4):1530–1543, 2016. 1, 2

[22] P. J. Lapray, X. Wang, J. B. Thomas, and P. Gouton. Mul-
tispectral ﬁlter arrays: Recent advances and practical imple-
mentation. Sensors, 14(11):21626–21659, 2014. 1, 2

[23] X. Lin, Y. Liu, J. Wu, and Q. Dai. Spatial-spectral encoded
compressive hyperspectral imaging. ACM Trans. on Graph.,
33(6):233, 2014. 1, 2

[24] K. Mitra, O. S. Cossairt, and A. Veeraraghavan. A frame-
work for analysis of computational imaging systems: role
of signal prior, sensor noise and multiplexing. IEEE Trans.
Pattern Anal. Mach. Intell., 36(10):1909–1921, 2014. 1

[25] S. Nie, L. Gu, Y. Zheng, A. Lam, N. Ono, and I. Sato.
Deeply learned ﬁlter response functions for hyperspectral re-
construction. In Proc. CVPR, pages 4767–4776, 2018. 1, 2

[26] Z. Pan, G. Healey, M. Prasad, and B. Tromberg. Face recog-
IEEE Trans. Pattern Anal.

nition in hyperspectral images.
Mach. Intell., 25(12):1552–1560, 2003. 1

[27] W. M. Porter and H. T. Enmark. A system overview of the
airborne visible/infrared imaging spectrometer (aviris).
In
31st Ann. Tech. Sym., pages 22–31. International Society for
Optics and Photonics, 1987. 2

[28] A. Wagadarikar, R. John, R. Willett, and D. Brady. Single
disperser design for coded aperture snapshot spectral imag-
ing. App. Opt., 47(10):B44–B51, 2008. 1, 2

[29] A. a. Wagadarikar, N. P. Pitsianis, X. Sun, and D. J. Brady.
Video rate spectral imaging using a coded aperture snapshot
spectral imager. Opt. Express, 17(8):6368–6388, 2009. 6

[30] L. Wang, Z. Xiong, D. Gao, G. Shi, and F. Wu. Dual-camera
design for coded aperture snapshot spectral imaging. Appl.
Opt., 54(4):848–858, Feb 2015. 1, 2, 6

[31] L. Wang, Z. Xiong, D. Gao, G. Shi, W. Zeng, and F. Wu.
High-speed hyperspectral video acquisition with a dual-
camera architecture.
In Proc. CVPR, pages 4942–4950,
2015. 2

[32] J. Wu, B. Xiong, X. Lin, J. He, J. Suo, and Q. Dai. Snapshot
hyperspectral volumetric microscopy. Sci. Rep., 6:24624,
2016. 2, 7

[33] S. Wug Oh, M. S. Brown, M. Pollefeys, and S. Joo Kim.
Do it yourself hyperspectral imaging with everyday digital
cameras. In Proc. CVPR, pages 2461–2469, 2016. 1, 2

[34] Z. Xiong, L. Wang, H. Li, D. Liu, and F. Wu. Snapshot
hyperspectral light ﬁeld imaging. In Proc. CVPR, volume 2,
2017. 2, 7

[35] F. Yasuma, T. Mitsunaga, D. Iso, and S. K. Nayar. Gener-
alized assorted pixel camera: postcapture control of resolu-
tion, dynamic range, and spectrum. IEEE Trans. on Image
Process., 19(9):2241–2253, 2010. 6, 7

12210

[36] T. Yue, J. Suo, J. Wang, X. Cao, and Q. Dai. Blind opti-
cal aberration correction by exploring geometric and visual
priors. In Proc. CVPR, pages 1684–1692, 2015. 6

12211

