Boosting Local Shape Matching for Dense 3D Face Correspondence

Zhenfeng Fan1,2, Xiyuan Hu1,2 ∗

, Chen Chen1,2, and Silong Peng1,2,3

1Institute of Automation, Chinese Academy of Sciences

2University of Chinese Academy of Sciences

3Beijing Visytem Co. Ltd.

{fanzhenfeng2016,xiyuan.hu,chen.chen,silong.peng}@ia.ac.cn

Abstract

Dense 3D face correspondence is a fundamental and
challenging issue in the literature of 3D face analysis. Cor-
respondence between two 3D faces can be viewed as a non-
rigid registration problem that one deforms into the other,
which is commonly guided by a few facial landmarks in
many existing works. However, the current works seldom
consider the problem of incoherent deformation caused by
landmarks. In this paper, we explicitly formulate the defor-
mation as locally rigid motions guided by some seed points,
and the formulated deformation satisﬁes coherent local mo-
tions everywhere on a face. The seed points are initialized
by a few landmarks, and are then augmented to boost shape
matching between the template and the target face step by
step, to ﬁnally achieve dense correspondence. In each step,
we employ a hierarchical scheme for local shape registra-
tion, together with a Gaussian reweighting strategy for ac-
curate matching of local features around the seed points. In
our experiments, we evaluate the proposed method exten-
sively on several datasets, including two publicly available
ones: FRGC v2.0 and BU-3DFE. The experimental results
demonstrate that our method can achieve accurate feature
correspondence, coherent local shape motion, and compact
data representation. These merits actually settle some im-
portant issues for practical applications, such as expres-
sions, noise, and partial data.

1. Introduction

Dense correspondence seeks canonical representations
of data such that both global and local structures of them

∗All correspondences should be forwarded to Xiyuan Hu.

This
work is supported by the National Key R&D Program of Chi-
na (2017YFC0803505),
the Natural Science Foundation of China
(61571438), and the Open Project of National Engineering Laboratory for
Forensic Science (2017NELKFKT02).

can be compared. It can be viewed as a non-rigid registra-
tion problem [55], which is fundamental in the ﬁeld of 3D
face analysis. While landmark correspondence [29, 32] on-
ly matches sparse and anatomically meaningful key-points
for different faces, dense correspondence matches all points
that are sufﬁcient for detailed descriptions of the whole fa-
cial regions. Accurate point-to-point correspondence con-
tributes to many applications of 3D faces [18, 41, 5, 42, 66,
56, 39, 60, 28, 24, 13, 14, 33].

However, dense 3D face correspondence remains a chal-
lenging task, particularly for data with large expressions.
It can be argued that this problem is implicit both mathe-
matically and physically. In the mathematical view, unlike
the rigid case, the non-rigid registration problem belongs
to a much larger class that has no explicit formulation, and
large expressions add another layer of complexity for the
registration considering large deformations. In the physical
view, while locating landmarks on 3D faces can be guid-
ed by the common knowledge of the anatomical structures,
correspondence of points on smooth regions (such as the
check and forehead) has no solid deﬁnition. This also raises
difﬁculties in assessing the correspondence results.

The state-of-the-art literature [2, 35, 46, 28, 37, 63,
62, 65] commonly uses triangle mesh data and template-
warping strategies to establish dense correspondence be-
tween different faces. The mesh connection relationship
(topology) is intrinsically ﬁxed during the correspondence
process, which is beneﬁcial for accurate point-to-point cor-
respondence. We adopt the template-warping strategy in
this work. First an arbitrary but noiseless face is chosen
as the template. After the correspondences of all faces are
completed, we use the average face of all neutral faces as
the template.

A single-template strategy cannot guarantee good result-
s for large expression variations. To address this problem,
some existing works [37, 36, 51] treat the chin as articulate
shape and use blendshapes to model open-mouth motions,

10944

while others [27, 45, 58, 16, 7, 26] use statistical face mod-
els to regularize the correspondence process. These meth-
ods incorporate some prior knowledge of face and show im-
pressive results capable of modeling expressions. However,
this is a chicken-and-egg problem, since the prior knowl-
edge is usually learned from some accurately corresponded
face samples.

This study aims at building dense point-to-point corre-
spondence of 3D faces without a prior model. We pro-
pose an explicit deformation model to minimize the weight-
ed least-square error for the rigid alignment of some seed
points. The seed points are initialized by a few facial land-
marks, and are then augmented gradually to boost local
shape matching to build overall correspondence. Extensive
experiments on several datasets demonstrate that the pro-
posed method can achieve accurate and reliable results.

The main contributions of this work are: 1) we propose
an explicit formulation of the deformation process, and it
guarantees not only exact seed point matching but also co-
herent motions of neighboring points; 2) we construct a
global-to-local hierarchical registration strategy for accu-
rate localization of seed points.

2. Related work

There are numerous rigid/non-rigid registration meth-
ods for 3D shapes in the literature. For a comprehensive
overview one can refer to [55, 57, 40]. In this section, we
only cover the most related works and mainly focus on 3D
faces.

2.1. 2D vs. 3D methods

Most previous methods [42, 28, 2, 27, 37, 51, 45, 7] work
directly on the 3D space of facial shapes, since full infor-
mation of the raw data is kept on this original domain. As
alternatives, some other methods [30, 59, 11, 31, 53, 38]
ﬁnd reasonable mappings from the 3D space to canonical
2D domains. In the seminal work of 3D Morphable Mod-
el (3DMM) [5, 6], Blanz and Vetter propose to map the 3D
face to the 2D cylindrical coordinate, encode both shape and
texture features, and use a regularized optic-ﬂow based al-
gorithm for dense correspondence. Despite the efﬁciency of
the 2D methods by reducing the dimensionality, one poten-
tial pitfall is that some original 3D shape features are lost.
Therefore, we deal with the dense correspondence problem
on 3D in this work.

2.2. Modeling shape motions

Correspondence of two faces can be viewed as a defor-
mation process that one moves to the other either locally
or globally. Patel and Smith [46] use a thin-plate spline
(TPS) warp to build correspondence with the help of some
manual annotations. [43, 42, 45] simply regularize the off-
set of each individual point by enforcing local smoothness

constraint. [44, 64] incorporate functional maps into the
correspondence process, and guarantee smooth local mo-
tion by the low frequency basis of the eigenfunctions of
Laplace-Beltrami operators. To sum up, it is universally ac-
knowledged that the registration process should satisfy co-
herent local motion. Amberg et al. [2] propose an optimal
step non-rigid iterative closest points (NICP) algorithm and
model the shape motion as locally afﬁne transformation.
The NICP is commonly treated as a benchmark method and
has many effective variants [45, 16, 42, 17, 35]. Most re-
cently, it has been used to build some well-known statistical
facial models, such as the Basel face model (BFM) [47, 25]
and the large scale facial model (LSFM) [8, 9].

2.3. Effect of landmarks

Dense correspondence of 3D faces should prioritize
landmark correspondence, since landmarks are the most
prominent feature points. Landmarks control the holistic
facial shape and help to deal with expressions. In the corre-
spondence process, many existing methods [5, 2, 45, 16, 26,
46, 1] use some sparsely corresponded landmarks to guide
the overall deformation process to achieve dense correspon-
dence. These landmarks are detected either manually or au-
tomatically. Recently, Fan et al. [22] deﬁne high-entropy
points to replace the landmarks, and these points can be
considered as denser landmarks. A problem induced by
landmarks is that coherent local motion cannot be strictly
guaranteed, especially when there is a large gap between
the landmark distributions of two faces. A typical case is in
registrations of data with extreme expressions considering
large deformations, where landmark and closest-point cor-
respondence may contradict with each other. This leads to
incoherent shape motions around the landmarks during the
deformation process. We propose an elegant formulation
for shape motions to solve this problem.

3. Rigid-motion estimation between corre-
sponded point sets using weighted least-
square method

Registration of two point sets generally involves a rigid-
motion estimation process. Given two corresponded point
sets P = {p1, p2, ..., pn} and Q = {q1, q2, ..., qn} in R3,
the rigid-motion estimation is represented as a constrained
minimization problem with respect to optimal rotation R
and translation T:

{R, T} = arg min

R∈SO(3),T∈R3

n

X

i=1

wi k(Rpi + T) − qik2

2, (1)

where SO(3) denotes the space of Givens matrices in R3×3
and wi(i = 1, 2, ..., n) is the weight for each point pair.

The solution procedures are outlined as follows.

10945

1. Compute the weighted centroids of both point sets:

The following conditions deﬁne the basic requisites of a

¯p = Pn
i=1 wipi
Pn
i=1 wi

, ¯q = Pn
i=1 wiqi
Pn
i=1 wi

.

(2)

2. Compute the centered vectors:

xi = pi − ¯p, yi = qi − ¯q (i = 1, 2, ..., n).

(3)

3. Compute the R3×3 covariance matrix S = XWYT ,
where X = (x1, x2, ..., xn), Y = (y1, y2, ..., yn), and
W = diag(w1, w2, ..., wn).
4. Compute the singular value decomposition S = UΣVT .
5. Compute the optimal rotation R and translation T:

1

R = V 


1


 UT , T = ¯q − R¯p. (4)

det(VUT )

The rigid-motion estimation process of the well-known
iterative closest points (ICP) [4, 15] algorithm for rigid ob-
ject registration can be considered as a special case in which
wi = 1(i = 1, 2, ..., n). Contrary to that of rigid registra-
tion, a non-uniform weighting strategy provides better ﬂex-
ibility for non-rigid registration of 3D faces.

4. Proposed method

Dense point-to-point correspondence can be viewed as a
non-rigid registration problem and has to be domain specif-
ic. When it applies to 3D human face, the common knowl-
edge of one’s anatomical structures should be considered.
The widely acknowledged facial landmarks, of which the
number varies from a few tens to a hundred, are ﬁducial
points for the anatomically meaningful structures. There-
fore, the landmarks provide clues for correspondence of the
most prominent facial features, particularly for the sense
organs. However, we cannot accurately locate the vessel-
s, muscles, and bones on most areas of the skin surface data
that are not adjacent to the eyes, mouth, and nose regions.
Furthermore, issues on expressions, noise, and partial data
should be settled for practical applications. In this section,
we introduce an automatic, adaptive, and accurate method
for dense correspondence of 3D faces.

4.1. Template deformation using seed points

In a template deformation perspective [5, 2, 45, 16, 26,
46, 1, 22], each speciﬁc landmark should dominate over
other points in a local region around it. Correspondences of
all the landmarks control the holistic deformation and local
dominance of each speciﬁc landmark controls the regional
deformation. The landmark-guided deformation brings up
such a fundamental question: given sparse correspondences
of some seed points, how, at least one step further, to extend
them to achieve dense correspondences of all points?

desirable deformation for dense correspondence.
i. The registration error should be in a decreasing trend.
ii. The corresponded seed points should be matched exactly.
iii. The neighboring points should have coherent motions.

Condition i guarantees that the deformation behaves in
a convergent manner, and condition ii and iii guarantee
stable feature correspondence while preserving local struc-
tures of the 3D face. In fact, many state-of-the-art method-
s [1, 43, 2, 34] for non-rigid registration are designed del-
icately towards these goals. For example, in the NICP [2],
these conditions are modeled as three energy terms for dis-
tance, landmarks, and stiffness, respectively. These terms
are then fed into a common optimization objective func-
tion. However, the general frameworks using control (seed)
points fail to satisfy condition ii and iii simultaneously, but
rather perform as a trade-off between them. The reason lies
in the inconsistent preliminary correspondences of control
points and others. To be speciﬁc, different laws for the cor-
respondences of landmarks and their surroundings hardly
lead to coherent local motions even with large efforts for
regularization. Instead, we propose a uniﬁed law to meet
these conditions.

Suppose P and Q are two dense point sets representing
the template and the target face, respectively. We model
the deformation to be composed of individual elements for
locally rigid motions, as

pi ← Ripi + Ti (i ∈ P ),

(5)

where {Ri, Ti}(i ∈ P ) are the optimal rotation and trans-
lation for each point. They are estimated by a weighted rigid
alignment of the corresponded seed point sets ˜P ⊂ P and
˜Q ⊂ Q, as

{Ri, Ti} =

arg min

Ri∈SO(3),Ti∈R3 X

pj ∈ ˜P ,qj ∈ ˜Q

1
d2
ij

kRipj + Ti − qjk2
2,

(6)

where dij = kpi − pjk(i ∈ P, j ∈ ˜P ) is the distance be-
tween each speciﬁed point and each seed point.

Although modeling non-rigid registration as locally rigid
motions is not a new idea, we explicitly formulate the corre-
spondence process as deformation guided by sparsely cor-
responded seed points. We also model the inﬂuences of the
seed points to be inversely proportional to the squared dis-
tances to the speciﬁed point, which ensures local deforma-
tions guided by the correspondence of each seed point. The
merits of this model are elaborated as follows.

• It can be perfectly customized to ﬁt the three conditions
above. Firstly, we will boost this deformation model for
incremental shape matching (in Sec. 4.3) to meet condi-
tion i. Secondly, the weight 1
approaches inﬁnity when
d2
ij

10946

Seed point augmentation. We initialize the seed points by
some landmarks on the template as shown in Fig. 1. The
seed points are then augmented by some newly selected
ones step by step, in order to match the corresponded fa-
cial surfaces as much as possible. Given a template mesh
S = (V0, E0) and a target mesh T = (V1, E1), where Vi
and Ei(i = 0, 1) denote the vertices and edges of the mesh-
es, respectively, Algorithm 1 gives the details of adaptive
seed point selection in each step.
It can be summarized
brieﬂy as: select points with the largest registration errors
but away from each other with a certain distance threshold
ρ. The purpose is to enable fast convergence while avoiding
redundant local registrations.

Algorithm 1 Seed points selection.
Input:

The template mesh S = (V0, E0);
The target mesh T = (V1, E1);

Output:

Selected point set Vc;

1: Compute the distance di(i ∈ V0) between each point vi(i ∈ V0) and

T ;

2: Initialize Q = (di, vi)(i ∈ V0) and Vc = ∅;
3: repeat
4:

Find di0 = max di(i ∈ Q), and include the corresponding vi0 in
Vc;
Remove {(di, vi)|kvi − vi0 k ≤ ρ} from Q;

5:
6: until Q = ∅
7: return Vc.

Seed point correspondence. Inspired by some of the ideas
on local registrations in [12, 22], we employ reweighted
ICP [50] for accurate correspondence of seed points. The
points on the template surface are weighted differently as
Gaussians of their distances to the corresponding seed point
v0:

−kvi−v0k2

2σ2

wi = e

(i ∈ P ),

(7)

where wi is the weight for each point vi on the template
P , and σ is the standard deviation of the Gaussian func-
tion. We use ﬁve Gaussians with decreasing deviations to
register the template to the target, as shown in Fig. 2 (a).
Large σ ﬂattens the weights and ﬁts globally, while small
σ accounts more for localized shape features. The registra-
tion process is proceeded with a cascade manner towards
smaller σ. Fig. 2 (b) shows the evolution of closest-point1
correspondence for a seed point by registrations with dif-
ferent σ(σ = {+∞, 40, 30, 20, 10}mm), where accurate
correspondence of this seed point is ﬁnally achieved.

Fig. 1. Comparative results between the proposed deformation and
the afﬁne one for the alignment of 3D faces using a few corre-
sponded landmarks (red dots). The bottom and the top row are
two different examples with and without expressions, respective-
ly. Pay attention to the areas with green circles.

pi is a speciﬁc seed point (i = j). According to the solu-
tion procedures in Sec. 3 for Eq. 6, the resulted deforma-
tion {Ri, Ti} will ﬁrst align the seed point pi to qi, and
then estimate a compatible rotation Ri centred on pi(qi).
Thus condition ii holds exactly. Finally, two neighbor-
ing points pi and pk will result in similar deformations
{Ri, Ti} and {Rk, Tk} according to Eq. 6, which satis-
ﬁes condition iii.

• It can be considered as an interpolation algorithm based
on the correspondence of all the seed points. Compared
to some existing methods for dense correspondence, the
extrapolation is more robust by imposing rigidness of
face structures, which renders its applicability for da-
ta with missing parts. Moreover, since the face is a
piecewise smooth surface, adaptive augmentation of seed
points with large registration errors can recover the over-
all correspondence in a few iterations. This avoids the
need for traversing through all the points, leading to not
only robustness to noise but also efﬁcient optimization.

• It is consistent with an intuitive, plausible, but indeﬁnite
idea for 3D face dense correspondence: the correspon-
dence of landmarks should be solid and exact, and be
prioritized, while the relative locations to the landmarks
should be considered for points on the smooth regions.

We depict in Fig. 1 some results of preliminary tem-
plate deformations via Eq. 5 and 6 using a few initialized
seed points (landmarks), compared with those by a com-
mon afﬁne alignment [23, 2, 51]. It shows that our model
is both more stable for extrapolation and more ﬂexible for
large deformation.

4.2. Augmentation and correspondence of seed

4.3. Boosting local shape matching

points

Seed points are deﬁned as the corresponded control
points for the deformation in Sec. 4.1. In this section, we
propose two algorithms for adaptive augmentation and ac-
curate correspondence of the seed points, respectively.

We propose to boost the local shape matching between
the template and the target face by incremental deforma-
tion (in Sec. 4.1) based on the corresponded seed points

1Note that the seed point correspondence is not necessarily on the target

surface but depends on the registration result.

10947

Fig. 2. Different Gaussian functions (a) and the global-to-local registration process (b) for the correspondence of a seed point (white/red
dot at the nose tip). The top and the bottom row in (b) show the weighted template and the results on the target, respectively.

(in Sec. 4.2), to ﬁnally achieve dense correspondence. The
main algorithm is summarized in Algorithm 2, where there
is a hyper-parameter nIter denoting the iteration times.
Ideal stopping criterion should be set according to the regis-
tration error, but we ﬁx nIter = 20 considering noisy data
and computational efﬁciency in this work. Fig. 3 shows a
typical example where the template face is deformed into
the target face gradually. We also show together the regis-
tration errors, selected seed points, and proﬁle views for the
deformation process. This process actually bears a hierar-
chy structure: it ﬁrst ﬁts the global shape and then proceeds
to boost local shape matching. Note that it is an analogy
to the process of wearing a sheet mask on one’s face: the
unmatched parts of the surface are smoothed gradually.

Algorithm 2 Boosting local shape matching.
Input:

The template mesh S = (V0, E0) and some manually selected land-
marks Vs ⊂ V0;
The target mesh T = (V1, E1);

Output:

Deformed template mesh S;

1: Establish correspondences ˜Vs on T for all landmarks Vs on S using

the reweighed ICP in Sec. 4.2;

2: Deform S by Eq. 5 and 6 based on the correspondences ˜Vs ⇔ Vs;
3: for i ∈ {2, 3, ..., nIter} do
4:

Select seed points Vc by Algorithm 1 and increase the seed points
by Vs ← (Vs ∪ Vc);
Establish correspondences ˜Vc on T for the augmented seed points
Vc on S using the reweighed ICP in Sec. 4.2, and let ˜Vs ← ( ˜Vs ∪
˜Vc);
Deform S by Eq. 5 and 6 based on the correspondences ˜Vs ⇔ Vs;

5:

6:
7: end for
8: return S.

cess is given by

{s, R, T} =

s∈R1,R∈SO(3),T∈R3 X

arg min

pi∈Vs,qi∈ ˜Vs

k(sRpi + T) − qik2
2,

(8)

which can be solved efﬁciently by alternative estimations
of the rigid motion {R, T} and the scaling factor s.

• Considering missing parts of the raw target data, we en-
force an additional principle into the seed point selection
Algorithm 1: ﬁrst exclude the candidate points on the
template face whose closest points lie on the boundary of
the target mesh.

• Fig. 4 shows two different templates used for database
with no expressions and with expressions, respectively.
Except for the template differences, we also use geodesic
distance instead of Euclidean distance for dij in Eq. 6 and
k.k in Eq. 7, to handle eyes and mouth separations. The
geodesic distances for all point pairs are computed using
a fast heat-ﬂow based method [19].

• The seed point correspondence process is accelerated by
some pre-organized data structures [3, 10], as well as
trimming and downsampling of data. The template mesh
is ﬁrst downsampled by a factor positively correlated to
the Gaussian deviation σ. And then we eliminate the part-
s on the template mesh whose weights are smaller than
e−2 as shown in Fig. 2 (b) (the top row). Moreover, we
skip ﬁtting by Gaussian weights with large σ in the latter
iterations of the boosting Algorithm 2, since the global
structures of faces are already well aligned.

Implementation details.

5. Experiments

• Considering the face scale varies from individual to indi-
vidual, we normalize the template face by a scaling factor
based on a few corresponded landmarks (seed points) be-
tween two faces before it is fed into the correspondence
process in Step 3 of Algorithm 2 . The optimization pro-

Datasets. We use three datasets, including two publicly
available ones for the evaluation of the proposed method.
1) One is the FRGC v2.0 [48] database from University
of Notre Dame. It includes a total number of 4, 007 3D s-
cans of 466 subjects collected during Fall 2003 and Spring

10948

Fig. 3. An example for the dense correspondence process by the proposed method: the template face is deformed into the target face in 20
iterations. The arrows denote that the selected seed points are associated with large regional registration errors.

Fig. 4. Two different templates for database with expressions (b)
and without expressions (a). The initialized landmarks are marked
as dots, where the green dots need manual correspondences for the
BU-3DFE dataset.

2004. The point clouds in it have relatively high resolutions
for the frontal view compared with the proﬁle views, and
most of the scans are in neutral expressions. Many existing
works include this database, enabling comparison across the
literature quantitatively. 2) Another database is the BU-
3DFE [61], which is made publicly available in 2006. It
includes a total number of 2, 500 3D scans of 100 subjects
with various expressions (neutral, happiness, surprise, fear,
sadness, disgust, and angry) on 4 different levels. It is al-
so a benchmark database for 3D facial expression research.
The resolutions of the raw data are around 10, 000 vertices
per face. 3) In addition, we collect a new database includ-
ing hundreds of high-resolution 3D faces with a modern
structured light device. The collection system merges scans
from 4 different directions, and the resolutions are around
300, 000 vertices per face together with pixel-wise textures.
The subjects in this database are mostly in neutral expres-
sions under a well-controlled environment.

Parameter setting. We have tested different parameters
and ﬁnally set nIter = 20, σ = {+∞, 40, 30, 20, 10}mm,
and ρ = 25mm in all of our experiments. The setting of σ
is trivial if we follow the global-to-local scheme. And larg-
er ρ results in fewer selected seed points but more iterations
nIter, according to which we have made a trade-off.
Computational time. On a machine with Core-i5-6600k
CPU (3.5GHZ, single thread), a MATLAB implementation
of the proposed algorithm takes about 100 seconds for a
template mesh with 19, 334 vertices. Note that almost all
the operations in this algorithm are per-vertex optimizations
that are independent to each other. Therefore, a more efﬁ-
cient version of parallel implementation can be developed.
Assessing the result of 3D face dense correspondence is
not an easy task since there is no universal rules for the
ground-truth in the literature. In this section, we evaluate
the proposed method in three perspectives: feature corre-
spondence, structural correspondence, and correspondence
on some practical issues.

5.1. Feature correspondence

We deﬁne “feature” here as the most signiﬁcant feature
on the face that human can distinguish, particularly for the
eyes, nose, and mouth regions. Two experiments are con-
ducted for the evaluation of it.
1) Texture transfer. Some current works [42, 64] paste the
textures of some corresponded faces on a template face to
assess the results qualitatively. Following them we transfer
the textures between different faces. Fig. 5 shows a well
matching of features for three corresponded samples in our

10949

Fig. 7. Comparisons for the detailed mesh structures between the
corresponded results by our method and that by the NICP. The 2-
ring neighbors of a corresponded point are marked with colored
dots for better viewing.

Fig. 5. Texture transfer results by combinations of different facial
shapes and textures.

Fig. 6. Some examples for landmark detection on FRGC v2.0. Our
results and the manually labeled ones are marked as red and green
dots, respectively. And the red circle shows a better result than
the manual annotation, while the green circles indicate inaccurate
detections.

database.
2) Landmark correspondence. We compare our method
with some existing works for the detection of landmarks on
FRGC v2.0. The ground-truth results are the manual an-
notations provided by Creusot et al. [20]. First we manual-
ly label some landmarks on a template, and then we apply
the correspondence algorithm in Sec. 4.2. Considering in-
accurate manual labeling on the template, we further apply
the algorithm to the neighboring points around a speciﬁed
landmark and replace it by the one with the minimum error.
Fig. 6 shows some examples and Table 1 presents the com-
parative results. Checking the visual results in Fig. 6 care-
fully, we observe that our method is competitive with the
manual annotation owing to the weighted rigid registration
of local features. Our method also achieves state-of-the-art
performance compared to the most recent works.

5.2. Structural correspondence

The meaning of structural correspondence is two-fold:
1) in a narrow sense we think that the local mesh struc-
tures are altered with similar patterns across different faces,

Fig. 8. Compactness of the ﬁtted PCA model by our method com-
pared with that by the NICP and the BFM (also by the NICP).

which is consistent with a universal idea of “coherent local
motion”; 2) in a broad sense we think that all facial data as
a group should gain certain beneﬁts from the reconstruct-
ed canonical representations, and we also view it by the
minimum-description length (MDL) principle [49] as used
by Davies et al. [21] for statistical shape modeling.

In Sec. 4.1, we have discussed a fundamental problem
for shape deformation and our formulation provides an ele-
gant answer to it. To view the effect of our formulation, we
show a corresponded example in Fig. 7 together with the
one reconstructed by NICP [2]. Checking the mesh struc-
tures in details, we observe that our result shows similar
patterns between the template and the target mesh almost
everywhere. In contrast, the NICP cannot guarantee such a
coherent result.

We further apply PCA to 200 corresponded samples in
our database after Procrustes alignment, following the same
routine of 3DMM [5]. Compactness of data is evaluated
using the MDL principle: the less, the better. We also im-
plement the NICP for these facial samples for comparison.
Fig. 8 depicts the percentage of energy preserved by vary-
ing the number of principal components, together with that
from a publicly available BFM model [47].
It manifests
that our method leads to much more compact PCA bases,
as the number of principal components to explain 99% en-
ergy decreases from 59(63) to 43. Note that compactness
is a crucial property of data for dimensional reduction.

10950

Table 1. Comparative results of the mean and standard deviation (mean/SD) of landmark localization error (mm) for 4007 images on the
FRGC v2.0 dataset. The best and the second results are shown in red and blue, respectively. Symbols for landmarks: Ex/En-outer/inner
eye corner, N-nose bridge saddle, Prn-nose tip, Sn-nasal base, Ac-nose corner, Ch-mouth corner, Ls/Li-upper/lower lip midpoint.

Landmarks

Segundo et al. [52]
Creusot et al. [20]
Sukno et al. [54]

Fan et al. [22]

Gilani et al. [27]

Ours

Ex

-

5.9/3.1
4.6/2.7
2.6/1.6
2.5/1.9
2.1/1.9

En

3.5/2.3
4.3/2.2
3.5/1.7
2.5/1.7
2.4/1.2
1.9/1.0

N

-

4.2/2.1
2.5/1.6
2.4/1.4
2.5/1.5
2.4/1.2

Prn

2.7/1.4
3.4/2.0
2.3/1.7
2.1/1.2
2.2/1.8
1.8/1.2

Sn

-

3.7/3.1
2.7/1.1

-

3.4/1.1
1.8/0.9

Ac

5.3/1.9
4.8/3.6
2.6/1.4

-

3.0/2.4
1.9/0.9

Ch

-

5.6/3.5
3.9/2.8
2.9/2.2
2.5/1.8
2.8/2.5

Ls

-

4.2/3.2
3.3/1.8
2.4/2.9
2.4/3.1
2.0/2.2

Li

-

5.5/3.3
4.6/3.4
4.4/3.9
3.5/3.7
4.3/3.1

Improvement

16%/-19% 21%/17% 0%/14% 14%/0% 33%/18% 27%/36% -12%/-39% 17%/-22% -23%/6%

Fig. 10. An example for large expression.

Fig. 9. Examples for problematic data. The top row shows the
raw scans with noise (e.g. stripe, spike, and Gaussian) and missing
parts, and the bottom row shows the ﬁtted results.

5.3. Practical issues

The proposed method has been successfully applied to
problematic data with large noise and missing parts, as well
as data with large expressions. One of the key reasons is that
we devise a shape-motion formulation which is both stable
for extrapolation and ﬂexible for large deformation. The
other reason lies in our strategy for correspondence of seed
points: it matches local patches hierarchically and avoids
searching for correspondence of each individual point.
Fitting to noisy and partial data. Fig. 9 shows some cor-
responded results for noisy and partial data. We can see that
this method can handle problematic data with different type-
s of noise and large missing regions. Furthermore, it is not
difﬁcult to generalize this method to data with occlusions,
since occlusions and missing parts are similar problems.
Fitting to expressions. Fig. 10 shows the ﬁtted result (with
detailed mesh structure) of a face with an extreme expres-
sion in the BU-3DFE database. We also apply our algorith-
m to the whole database and build an expression-PCA mod-
el as shown in Fig. 11. Our method is not fully automatic in
this case. It involves the manual annotations (guided by tex-
tures) of four landmarks around the mouth region as shown
in Fig. 4 (b), but only for the ﬁrst iteration. We suggest that
this process can be automated by incorporating the state-of-

Fig. 11. Variations (±2SD) of the ﬁrst three components of the
expression-PCA model for the BU-3DFE database.

the-art 2D landmark detection methods based on the texture
information. Note that it is even not possible for humans to
identify the correct locations of these landmarks based on
shapes only for many samples in this database.

6. Conclusion

We present a robust algorithm for dense correspondence
of 3D face in this paper. This algorithm models dense point-
to-point correspondence as deformation guided by a num-
ber of seed points, and the seed points are augmented to
boost shape matching step by step, to ﬁnally achieve dense
correspondence. Extensive experiments on several datasets,
and in different perspectives, demonstrate the effectiveness
of the proposed algorithm. Since 3D face is representative
in the ﬁeld of 3D shape analysis, it is possible to generalize
this algorithm to the common non-rigid registration prob-
lem.

10951

References

[1] B. Allen, B. Curless, and Z. Popovi´c. The space of hu-
man body shapes: reconstruction and parameterization from
range scans. ACM Transactions on Graphics, 22(3):587–
594, 2003.

[2] B. Amberg, S. Romdhani, and T. Vetter. Optimal step non-
rigid icp algorithms for surface registration. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 1–8. IEEE, 2007.

[3] J. L. Bentley. Multidimensional binary search trees used
for associative searching. Communications of the ACM,
18(9):509–517, 1975.

[4] P. Besl and N. D. McKay. A method for registration of 3-d
shapes. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 14(2):239–256, 1992.

[5] V. Blanz and T. Vetter. A morphable model for the synthesis
of 3d faces. In Proceedings of the 26th Annual Conference on
Computer Graphics and Interactive Techniques, pages 187–
194. ACM, 1999.

[6] V. Blanz and T. Vetter. Face recognition based on ﬁtting a 3d
IEEE Transactions on Pattern Analysis

morphable model.
and Machine Intelligence, 25(9):1063–1074, 2003.

[7] T. Bolkart and S. Wuhrer. A groupwise multilinear corre-
spondence optimization for 3d faces. In Proceedings of the
IEEE International Conference on Computer Vision, pages
3604–3612. IEEE, 2015.

[8] J. Booth, A. Roussos, A. Ponniah, D. Dunaway, and
S. Zafeiriou. Large scale 3d morphable models.
Interna-
tional Journal of Computer Vision, 126(2-4):233–254, 2018.

[9] J. Booth, A. Roussos, S. Zafeiriou, A. Ponniah, and D. Dun-
away. A 3d morphable model learnt from 10,000 faces. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 5543–5552. IEEE, 2016.

[10] G. Borgefors. Hierarchical chamfer matching: A paramet-
ric edge matching algorithm. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 10(6):849–865, 1988.

[11] A. M. Bronstein, M. M. Bronstein, and R. Kimmel. Three-
dimensional face recognition. International Journal of Com-
puter Vision, 64(1):5–30, 2005.

[12] B. J. Brown and S. Rusinkiewicz. Global non-rigid align-
ment of 3-d scans. ACM Transactions on Graphics, 26(3):21,
2007.

[13] C. Cao, Y. Weng, S. Lin, and K. Zhou. 3d shape regression
for real-time facial animation. ACM Transactions on Graph-
ics, 32(4):41, 2013.

[14] X. Cao, Z. Chen, A. Chen, X. Chen, S. Li, and J. Yu. S-
parse photometric 3d face reconstruction guided by mor-
phable models. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition. IEEE, 2018.

[15] Y. Chen and G. Medioni. Object modelling by registration
Image and Vision Computing,

of multiple range images.
10(3):145–155, 1992.

[17] S. Cheng, I. Marras, S. Zafeiriou, and M. Pantic. Statistical
non-rigid icp algorithm and its application to 3d face align-
ment. Image and Vision Computing, 58:3–12, 2017.

[18] C. A. Corneanu, M. O. Sim´on, J. F. Cohn, and S. E. Guer-
rero. Survey on rgb, 3d, thermal, and multimodal approaches
for facial expression recognition: History, trends, and affect-
related applications. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 38(8):1548–1568, 2016.

[19] K. Crane, C. Weischedel, and M. Wardetzky. Geodesics in
heat: A new approach to computing distance based on heat
ﬂow. ACM Transactions on Graphics, 32(5):152, 2013.

[20] C. Creusot, N. Pears, and J. Austin. A machine-learning ap-
proach to keypoint detection and landmarking on 3d mesh-
es. International Journal of Computer Vision, 102(1-3):146–
179, 2013.

[21] R. H. Davies, C. J. Twining, T. F. Cootes, J. C. Waterton,
and C. J. Taylor. A minimum description length approach
to statistical shape modeling. IEEE Transactions on Medical
Imaging, 21(5):525–537, 2002.

[22] Z. Fan, X. Hu, C. Chen, and S. Peng. Dense semantic and
topological correspondence of 3d faces without landmarks.
In European Conference on Computer Vision, pages 541–
558. Springer, 2018.

[23] J. Feldmar and N. Ayache. Rigid, afﬁne and locally afﬁne
registration of free-form surfaces. International Journal of
Computer Vision, 18(2):99–119, 1996.

[24] C. Ferrari, G. Lisanti, S. Berretti, and A. Del Bimbo. A
dictionary learning based 3d morphable shape model. IEEE
Transactions on Multimedia, 19(12):2666–2679, 2017.

[25] T. Gerig, A. Morel-Forster, C. Blumer, B. Egger, M. Luthi,
S. Sch¨onborn, and T. Vetter. Morphable face models-an open
framework. In Proceedings of the IEEE International Con-
ference on Automatic Face and Gesture Recognition, pages
75–82. IEEE, 2018.

[26] S. Z. Gilani, A. Mian, and P. Eastwood. Deep, dense and
accurate 3d face correspondence for generating population
speciﬁc deformable models. Pattern Recognition, 69:238–
250, 2017.

[27] S. Z. Gilani, A. Mian, F. Shafait, and I. Reid. Dense 3d face
correspondence. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 40(7):1584–1598, 2018.

[28] S. Z. Gilani, F. Shafait, and A. Mian. Shape-based automatic
detection of a large number of 3d facial landmarks. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 4639–4648. IEEE, 2015.

[29] G. G. Gordon. Face recognition based on depth and cur-
vature features. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 808–810.
IEEE, 1992.

[30] C. M. Grewe and S. Zachow. Fully automated and highly ac-
curate dense correspondence for facial surfaces. In European
Conference on Computer Vision, pages 552–568. Springer,
2016.

[16] S. Cheng, I. Marras, S. Zafeiriou, and M. Pantic. Active non-
rigid icp algorithm. In Proceedings of the IEEE International
Conference and Workshops on Automatic Face and Gesture
Recognition, volume 1, pages 1–8. IEEE, 2015.

[31] X. Gu, S. Wang, J. Kim, Y. Zeng, Y. Wang, H. Qin, and
D. Samaras. Ricci ﬂow for 3d shape analysis. In Proceedings
of the IEEE International Conference on Computer Vision,
pages 1–8. IEEE, 2007.

10952

[32] S. Gupta, M. K. Markey, and A. C. Bovik. Anthropomet-
ric 3d face recognition. International Journal of Computer
Vision, 90(3):331–349, 2010.

[33] X. Huang, S. Zhang, Y. Wang, D. Metaxas, and D. Sama-
ras. A hierarchical framework for high resolution facial ex-
pression tracking. In the IEEE Conference on Computer Vi-
sion and Pattern Recognition Workshop, pages 22–22. IEEE,
2004.

[34] B. Jian and B. C. Vemuri. Robust point set registration us-
ing gaussian mixture models. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 33(8):1633–1645, 2011.
[35] H. Li, R. W. Sumner, and M. Pauly. Global correspondence
optimization for non-rigid registration of depth scans. Com-
puter Graphics Forum, 27(5):1421–1430, 2008.

[36] H. Li, T. Weise, and M. Pauly. Example-based facial rigging.

ACM Transactions on Graphics, 29(4):32, 2010.

[37] T. Li, T. Bolkart, M. J. Black, H. Li, and J. Romero. Learning
a model of facial shape and expression from 4d scans. ACM
Transactions on Graphics, 36(6):194, 2017.

[38] Y. Lipman and T. Funkhouser. M¨obius voting for surface
correspondence. ACM Transactions on Graphics, 28(3):72,
2009.

[39] F. Liu, D. Zeng, Q. Zhao, and X. Liu. Joint face alignmen-
In European Conference on

t and 3d face reconstruction.
Computer Vision, pages 545–560. Springer, 2016.

[40] B. Maiseli, Y. Gu, and H. Gao. Recent developments and
trends in point set registration methods. Journal of Visu-
al Communication and Image Representation, 46:95–106,
2017.

[41] I. Matthews, J. Xiao, and S. Baker. 2d vs. 3d deformable face
models: Representational power, construction, and real-time
ﬁtting. International Journal of Computer Vision, 75(1):93–
113, 2007.

[42] H. Mohammadzade and D. Hatzinakos. Iterative closest nor-
mal point for 3d face recognition.
IEEE Transactions on
Pattern Analysis and Machine Intelligence, 35(2):381–397,
2013.

[43] A. Myronenko and X. Song. Point set registration: Coher-
ent point drift. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 32(12):2262–2275, 2010.

[44] M. Ovsjanikov, M. Ben-Chen, J. Solomon, A. Butscher,
and L. Guibas. Functional maps: a ﬂexible representation
of maps between shapes. ACM Transactions on Graphics,
31(4):30, 2012.

[45] G. Pan, X. Zhang, Y. Wang, Z. Hu, X. Zheng, and Z. Wu. Es-
tablishing point correspondence of 3d faces via sparse facial
deformable model. IEEE Transactions on Image Processing,
22(11):4170–4181, 2013.

[46] A. Patel and W. A. Smith. 3d morphable face models re-
visited. In Proceedings of the IEEE Conference on Comput-
er Vision and Pattern Recognition, pages 1327–1334. IEEE,
2009.

[47] P. Paysan, R. Knothe, B. Amberg, S. Romdhani, and T. Vet-
ter. A 3d face model for pose and illumination invariant face
recognition. In Proceedings of the IEEE International Con-
ference on Advanced video and Signal Based Surveillance,
pages 296–301. IEEE, 2009.

[48] P. J. Phillips, P. J. Flynn, T. Scruggs, K. W. Bowyer, J. Chang,
K. Hoffman, J. Marques, J. Min, and W. Worek. Overview of
the face recognition grand challenge. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, volume 1, pages 947–954. IEEE, 2005.

[49] J. Rissanen. Modeling by shortest data description. Auto-

matica, 14(5):465–471, 1978.

[50] S. Rusinkiewicz and M. Levoy. Efﬁcient variants of the icp
algorithm. In Proceedings of the IEEE International Confer-
ence on 3-D Digital Imaging and Modeling, pages 145–152.
IEEE, 2001.

[51] A. Salazar, S. Wuhrer, C. Shu, and F. Prieto. Fully automatic
expression-invariant face correspondence. Machine Vision
and Applications, 25(4):859–879, 2014.

[52] M. P. Segundo, L. Silva, O. R. P. Bellon, and C. C. Queirolo.
Automatic face segmentation and facial landmark detection
in range images. IEEE Transactions on Systems, Man, and
Cybernetics, Part B, 40(5):1319–1330, 2010.

[53] K. A. Sidorov, S. Richmond, and D. Marshall. Efﬁcient
groupwise non-rigid registration of textured surfaces. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 2401–2408. IEEE, 2011.

[54] F. M. Sukno, J. L. Waddington, and P. F. Whelan. 3-d facial
landmark localization with asymmetry patterns and shape re-
gression from incomplete local features. IEEE Transactions
on Cybernetics, 45(9):1717–1730, 2015.

[55] G. K. Tam, Z.-Q. Cheng, Y.-K. Lai, F. C. Langbein, Y. Liu,
D. Marshall, R. R. Martin, X.-F. Sun, and P. L. Rosin. Regis-
tration of 3d point clouds and meshes: a survey from rigid to
nonrigid. IEEE Transactions on Visualization and Computer
Graphics, 19(7):1199–1217, 2013.

[56] L. Tran and X. Liu. Nonlinear 3d face morphable model.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. IEEE, 2018.

[57] O. Van Kaick, H. Zhang, G. Hamarneh, and D. Cohen-Or.
A survey on shape correspondence. Computer Graphics Fo-
rum, 30(6):1681–1707, 2011.

[58] D. Vlasic, M. Brand, H. Pﬁster, and J. Popovi´c. Face transfer
with multilinear models. ACM Transactions on Graphics,
24(3):426–433, 2005.

[59] Y. Wang, M. Gupta, S. Zhang, S. Wang, X. Gu, D. Samaras,
and P. Huang. High resolution tracking of non-rigid motion
of densely sampled 3d data using harmonic maps. Interna-
tional Journal of Computer Vision, 76(3):283–300, 2008.

[60] T. Weise, S. Bouaziz, H. Li, and M. Pauly. Realtime
performance-based facial animation. ACM Transactions on
Graphics, 30(4):77, 2011.

[61] L. Yin, X. Wei, Y. Sun, J. Wang, and M. J. Rosato. A 3d
In
facial expression database for facial behavior research.
Proceedings of the IEEE International Conference on Auto-
matic Face and Gesture Recognition, pages 211–216. IEEE,
2006.

[62] Y. Zeng, C. Wang, X. Gu, D. Samaras, and N. Paragios.
Higher-order graph principles towards non-rigid surface reg-
istration.
IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 38(12):2416–2429, 2016.

10953

[63] Y. Zeng, C. Wang, Y. Wang, X. Gu, D. Samaras, and N. Para-
gios. Dense non-rigid surface registration using high-order
graph matching. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition. IEEE, 2010.

[64] C. Zhang, W. A. Smith, A. Dessein, N. Pears, and H. Dai.
Functional faces: Groupwise dense correspondence using
functional maps.
In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 5033–
5041. IEEE, 2016.

[65] H. Zhang, A. Sheffer, D. Cohen-Or, Q. Zhou, O. Van Kaick,
and A. Tagliasacchi. Deformation-driven shape correspon-
dence.
In Computer Graphics Forum, volume 27, pages
1431–1439. Wiley, 2008.

[66] X. Zhu, Z. Lei, X. Liu, H. Shi, and S. Z. Li. Face alignmen-
t across large poses: A 3d solution. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 146–155. IEEE, 2016.

10954

