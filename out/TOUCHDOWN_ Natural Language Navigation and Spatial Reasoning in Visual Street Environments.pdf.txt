TOUCHDOWN: Natural Language Navigation and Spatial Reasoning

in Visual Street Environments

Howard Chen∗
ASAPP Inc.

New York, NY

hchen@asapp.com

Alane Suhr

Dipendra Misra

Noah Snavely

Yoav Artzi

Department of Computer Science & Cornell Tech, Cornell University

New York, NY

{suhr, dkm, snavely, yoav}@cs.cornell.edu

Abstract

We study the problem of jointly reasoning about lan-
guage and vision through a navigation and spatial reason-
ing task. We introduce the TOUCHDOWN task and dataset,
where an agent must ﬁrst follow navigation instructions in
a real-life visual urban environment, and then identify a lo-
cation described in natural language to ﬁnd a hidden ob-
ject at the goal position. The data contains 9,326 examples
of English instructions and spatial descriptions paired with
demonstrations. Empirical analysis shows the data presents
an open challenge to existing methods, and qualitative lin-
guistic analysis shows that the data displays richer use of
spatial reasoning compared to related resources. The envi-
ronment and data are available at https://touchdown.ai.

1. Introduction

Consider the visual challenges of following natural lan-
guage instructions in a busy urban environment. Figure 1
illustrates this problem. The agent must identify objects
and their properties to resolve mentions to trafﬁc light and
American ﬂags, identify patterns in how objects are ar-
ranged to ﬁnd the ﬂow of trafﬁc, and reason about how
the relative position of objects changes as it moves to go
past objects. Reasoning about vision and language has
been studied extensively with various tasks, including vi-
sual question answering [3, 34], visual navigation [2, 25],
interactive question answering [9, 12], and referring expres-
sion resolution [16, 22, 23]. However, existing work has
largely focused on relatively simple visual input, including
object-focused photographs [20, 28] or simulated environ-
ments [4, 9, 19, 25, 33]. While this has enabled signiﬁcant
progress in visual understanding, the use of real-world vi-
sual input not only increases the challenge of the vision task,
it also drastically changes the kind of language it elicits and
requires fundamentally different reasoning.

Turn and go with the ﬂow of trafﬁc. At the ﬁrst trafﬁc light turn left. Go
past the next two trafﬁc light, As you come to the third trafﬁc light you
will see a white building on your left with many American ﬂags on it.
Touchdown is sitting in the stars of the ﬁrst ﬂag.

Figure 1. An illustration of the task. The agent follows the in-
structions to reach the goal, starting by re-orientating itself (top
image) and continuing by moving through the streets (two middle
images). At the goal (bottom), the agent uses the spatial descrip-
tion (underlined) to locate Touchdown the bear. Touchdown only
appears if the guess is correct (see bottom right detail).

In this paper, we study the problem of reasoning about
vision and natural language using an interactive visual nav-
igation environment based on Google Street View.1 We de-
sign the task of ﬁrst following instructions to reach a goal

⇤Work done at Cornell University.

1https://developers.google.com/maps/documentation/streetview/intro

112538

position, and then resolving a spatial description at the goal
by identifying the location in the observed image of Touch-
down, a hidden teddy bear. Using this environment and
task, we release TOUCHDOWN,2 a dataset for navigation
and spatial reasoning with real-life observations.

We design our task for diverse use of spatial reasoning,
including for following instructions and resolving the spa-
tial descriptions. Navigation requires the agent to reason
about its relative position to objects and how these relations
change as it moves through the environment. In contrast,
understanding the description of the location of Touchdown
requires the agent to reason about the spatial relations be-
tween observed objects. The two tasks also diverge in their
learning challenges. While in both learning requires re-
lying on indirect supervision to acquire spatial knowledge
and language grounding, for navigation, the training data
includes demonstrated actions, and for spatial description
resolution, annotated target locations. The task can be ad-
dressed as a whole, or decomposed to its two portions.

The key data collection challenge is designing a scal-
able process to obtain natural language data that reﬂects the
richness of the visual input while discouraging overly ver-
bose and unnatural language. In our data collection process,
workers write and follow instructions. The writers navigate
in the environment and hide Touchdown. Their goal is to
make sure the follower can execute the instruction to ﬁnd
Touchdown. The measurable goal allows us to reward effec-
tive writers, and discourages overly verbose descriptions.

We collect 9,326 examples of the complete task, which
decompose to the same number of navigation tasks and
27,575 spatial description resolution (SDR) tasks. Each
example is annotated with a navigation demonstration and
the location of Touchdown. Our linguistically-driven analy-
sis shows the data requires signiﬁcantly more complex rea-
soning than related datasets. Nearly all examples require
resolving spatial relations between observable objects and
between the agent and its surroundings, and each exam-
ple contains on average 5.3 commands and refers to 10.7
unique entities in its environment.

We empirically study the navigation and SDR tasks inde-
pendently. For navigation, we focus on the performance of
existing models trained with supervised learning. For SDR,
we cast the problem of identifying Touchdown’s location as
an image feature reconstruction problem using a language-
conditioned variant of the UNET architecture [29, 25]. This
approach signiﬁcantly outperforms several strong baselines.

2. Related Work and Datasets

Jointly reasoning about vision and language has been
studied extensively, most commonly focusing on static vi-
sual input for reasoning about image captions [20, 8, 28, 31,

2 Touchdown is the unofﬁcial mascot of Cornell University.

32] and grounded question answering [3, 13, 34]. Recently,
the problem has been studied in interactive simulated envi-
ronments where the visual input changes as the agent acts,
such as interactive question answering [9, 12, ] and instruc-
tion following [25, 26]. In contrast, we focus on an interac-
tive environment with real-world observations.

The most related resources to ours are R2R [2] and Talk
the Walk [10]. R2R uses panorama graphs of house envi-
ronments for the task of navigation instruction following. It
includes 90 unique environments, each containing an aver-
age of 119 panoramas, signiﬁcantly smaller than our 29,641
panoramas. Our larger environment requires following the
instructions closely, as ﬁnding the goal using search strate-
gies is unlikely, even given a large number of steps. We also
observe that the language in our data is signiﬁcantly more
complex than in R2R (Section 5). Our environment setup is
related to Talk the Walk, which uses panoramas in small ur-
ban environments for a navigation dialogue task. In contrast
to our setup, the instructor does not observe the panoramas,
but instead sees a simpliﬁed diagram of the environment
with a small set of pre-selected landmarks. As a result, the
instructor has less spatial information compared to TOUCH-
DOWN. Instead the focus is on conversational coordination.
SDR is related to the task of referring expression res-
olution, for example as studied in ReferItGame [16] and
Google Refexp [22]. Referring expressions describe an ob-
served object, mostly requiring disambiguation between the
described object and other objects of the same type. In con-
trast, the goal of SDR is to describe a speciﬁc location rather
than discriminating. This leads to more complex language,
as illustrated by the comparatively longer sentences of SDR
(Section 5). Kitaev and Klein [18] proposed a similar task
to SDR, where given a spatial description and a small set of
locations in a fully-observed simulated 3D environment, the
system must select the location described from the set. We
do not use distractor locations, requiring a system to con-
sider all areas of the image to resolve a spatial description.

3. Environment and Tasks

We use Google Street View to create a large naviga-
tion environment. Each position includes a 360  RGB
panorama. The panoramas are connected in a graph-like
structure with undirected edges connecting neighboring
panoramas. Each edge connects to a panorama in a speciﬁc
heading. For each panorama, we render perspective images
for all headings that have edges. Our environment includes
29,641 panoramas and 61,319 edges from New York City.
Figure 2 illustrates the environment.

We design two tasks: navigation and spatial description
resolution (SDR). Both tasks require recognizing objects
and the spatial relations between them. Navigation focuses
on egocentric spatial reasoning, where instructions refer to
the agent’s relationship with its environment, including the

12539

Pano B

211°

31°

90°

Pano A

270°

145°

325°

Figure 2. An illustration of the environment. Left: part of the graph
structure with polarly projected panoramas illustrating positions
linked by edges, each labeled with its heading. Heading angles
shown closer to each panorama represent the outgoing angle from
that panorama; for example, the heading from Pano A to Pano B
is 31 . Right: the area in New York City covered by the graph.

objects it observes. The SDR task displays more allocentric
reasoning, where the language requires understanding the
relations between the observed objects to identify the target
location. While navigation requires generating a sequence
of actions from a small set of possible actions, SDR requires
choosing a speciﬁc pixel in the observed image. Both tasks
present different learning challenges. The navigation task
could beneﬁt from reward-based learning, while the SDR
task deﬁnes a supervised learning problem. The two tasks
can be addressed separately, or combined by completing the
SDR task at the goal position at the end of the navigation.

3.1. Navigation

The agent’s goal is to follow a natural language instruc-
tion and reach a goal position. Let S be the set of all states.
A state s 2 S is a pair (I, α), where I is a panorama and
α is the heading angle indicating the agent heading. We
only allow states where there is an edge connecting to a
neighboring panorama in the heading α. Given a navi-
gation instruction ¯xn and a start state s1 2 S, the agent
performs a sequence of actions. The set of actions A is
{FORWARD, LEFT, RIGHT, STOP}. Given a state s and an ac-
tion a 2 A, the state is deterministically updated using a
transition function T : S ⇥ A ! S. The FORWARD action
moves the agent along the edge in its current heading. For-
mally, if the environment includes the edge (Ii, Ij) at head-
0).
ing α in Ii, the transition is T ((Ii, α), FORWARD) = (Ij, α
0 is the heading of the edge in Ij with
The new heading α
the closest heading to α. The LEFT (RIGHT) action changes
the agent heading to the heading of the closest edge on
the left (right). Formally, if the position panorama I has
00, T ((I, α), LEFT) = (I, α
0 > α
0)
edges at headings α > α
00). Given a start state s1
and T ((I, α), RIGHT) = (I, α
and a navigation instruction ¯xn, an execution ¯e is a se-
quence of state-action pairs h(s1, a1), ..., (sm, am)i, where
T (si, ai) = si+1 and am = STOP.

Evaluation We use three evaluation metrics: task com-
pletion, shortest-path distance, and success-weighted edit
distance. Task completion (TC) measures the accuracy
of completing the task correctly. We consider an exe-
cution correct if the agent reaches the exact goal posi-
tion or one of its neighboring nodes in the environment
graph. Shortest-path distance (SPD) measures the mean
distance in the graph between the agent’s ﬁnal panorama
and the goal. SPD ignores turning actions and the agent
heading.
Success weighted by edit distance (SED) is
N PN
1
max(|¯e|,|ˆ¯e|) ), where the summation is over
N examples, Si is a binary task completion indicator, ¯e
is the reference execution, ˆ¯e is the predicted execution,
lev(·, ·) is the Levenshtein edit distance, and | · | is the exe-
cution length. The edit distance is normalized and inversed.
We measure the distance and length over the sequence of
panoramas in the execution, and ignore changes of orien-
tation. SED is related to success weighted by path length
(SPL) [1], but is designed for instruction following in graph-
based environments, where a speciﬁc correct path exists.

i=1 Si(1   lev(¯e,ˆ¯e)

3.2. Spatial Description Resolution (SDR)

Given an image I and a natural language description ¯xs,
the task is to identify the point in the image that is referred
to by the description. We instantiate this task as ﬁnding the
location of Touchdown, a teddy bear, in the environment.
Touchdown is hidden and not visible in the input. The im-
age I is a 360  RGB panorama, and the output is a pair of
(x, y) coordinates specifying a location in the image.

Evaluation We use three evaluation metrics: accuracy,
consistency, and distance error. Accuracy is computed with
regard to an annotated location. We consider a prediction
as correct if the coordinates are within a slack radius of the
annotation. We measure accuracy for radiuses of 40, 80,
and 120 pixels and use euclidean distance. Our data collec-
tion process results in multiple images for each sentence.
We use this to measure consistency over unique sentences,
which is measured similar to accuracy, but with a unique
sentence considered correct only if all its examples are cor-
rect [11]. We compute consistency for each slack value.
We also measure the mean euclidean distance between the
annotated location and the predicted location.

4. Data Collection

We frame the data collection process as a treasure-hunt
task where a leader hides a treasure and writes directions
to ﬁnd it, and a follower follows the directions to ﬁnd the
treasure. The process is split into four crowdsourcing tasks
(Figure 3). The two main tasks are writing and following.
In the writing task, a leader follows a prescribed route and
hides Touchdown the bear at the end, while writing instruc-
tions that describe the path and how to ﬁnd Touchdown.

12540

Task I: Instruction Writing The worker starts at the beginning of the route facing north (a). The prescribed route is shown in the overhead map (bottom
left of each image). The worker faces the correct direction and follows the path, while writing instructions that describe these actions (b). After following
the path, the worker reaches the goal position, places Touchdown, and completes writing the instructions (c).

Place Touchdown

Can’t Place 
Touchdown

Turn so that the trees are 
to your left. At the ﬁrst 
intersection, turn left and 
stop.

Place Touchdown

Can’t Place 
Touchdown

Turn so that the trees are 
to your left. At the ﬁrst 
intersection, turn left and 
stop. Touchdown is on 
top of the blue mailbox 
on the right hand corner.

Place Touchdown

Can’t Place 
Touchdown

(a)

(b)

(c)

Turn so that 
the trees are to 
your left. At the 
ﬁrst 
intersection, 
turn left and 
stop. 
Touchdown is 
on top of the 
blue mailbox 
on the right 
hand corner.

Place Touchdown

Bear is Occluded

Turn so that the trees are 
to your left. At the ﬁrst 
intersection, turn left and 
stop. Touchdown is on 
top of the blue mailbox 
on the right hand corner.

You Found 
Touchdown!

Remaining 
Attempts: 2

Turn so that the 
trees are to your 
left. At the ﬁrst 
intersection, turn 
left and stop. 
Touchdown is on 
top of the blue 
mailbox on the 
right hand corner.

Target Location 

Instructions:

Touchdown is on top 
of the blue mailbox on 
the right hand corner.

Submit

Task II: Panorama Propagation Given the im-
age from the leader’s ﬁnal position (top),
in-
cluding Touchdown’s placement, and the instruc-
tions (right), the worker annotates the location of
Touchdown in the neighboring image (bottom).

Task III: Validation The worker begins in the
same heading as the leader, and follows the in-
structions (bottom left) by navigating the envi-
ronment. When the worker believes they have
reached the goal, they guess the target location
by clicking in the Street View image.

Task IV: Instruction Segmentation The in-
structions are shown (left). The worker high-
lights segments corresponding to the navigation
and target location subtasks. The highlighted
segment is shown to the worker (right).

Figure 3. Illustration of the data collection process.

The following task requires following the instructions from
the same starting position to navigate and ﬁnd Touchdown.
Additional tasks are used to segment the instructions into
the navigation and target location tasks, and to propagate
Touchdown’s location to panoramas that neighbor the ﬁnal
panorama. We use a customized Street View interface for
data collection. However, the ﬁnal data uses a static set of
panoramas that do not require the Street View interface.

Task I: Instruction Writing We generate routes by sam-
pling start and end positions. The sampling process results
in routes that often end in the middle of a city block. This
encourages richer language, for example by requiring to de-
scribe the goal position rather than simply directing to the
next intersection. The route generation details are described
in the Supplementary Material. For each task, the worker is
placed at the starting position facing north, and asked to
follow a route speciﬁed in an overhead map view to a goal
position. Throughout, they write instructions describing the
path. The initial heading requires the worker to re-orient

to the path, and thereby familiarize with their surroundings
better. It also elicits interesting re-orientation instructions
that often include references to the direction of objects (e.g.,
ﬂow of trafﬁc) or their relation to the agent (e.g., the um-
brellas are to the right). At the goal panorama, the worker
is asked to place Touchdown in a location of their choice
that is not a moving object (e.g., a car or pedestrian) and to
describe the location in their instructions. The worker goal
is to write instructions that a human follower can use to cor-
rectly navigate and locate the target without knowing the
correct path or location of Touchdown. They are not per-
mitted to write instructions that refer to text in the images,
including street names, store names, or numbers.

Task II: Target Propagation to Panoramas The writ-
ing task results in the location of Touchdown in a single
panorama in the Street View interface. However, resolving
the spatial description to the exact location is also possible
from neighboring panoramas where the target location is
visible. We use a crowdsourcing task to propagate the loca-

12541

Orient yourself in the direction of the red ladder. Go straight and take
a left at the intersection with islands. Take another left at the intersec-
tion with a gray trash can to the left. Go straight until near the end of
the fenced in playground and court to the right near the end of the
fenced in playground and court to the right. Touchdown is on the
last basketball hoop to the right.

Figure 4. Example instruction where the annotated navigation (un-
derlined) and SDR (bolded) segments overlap.

Task

Number of Workers

Instruction Writing
Target Propagation
Validation
Instruction Segmentation

224

218

291

46

Table 1. Number of workers who participated in each task.

tion of Touchdown to neighboring panoramas in the Street
View interface, and to the identical panoramas in our static
data. This allows to complete the task correctly even if not
stopping at the exact location, but still reaching a seman-
tically equivalent position. The propagation in the Street
View interface is used for our validation task. The task in-
cludes multiple steps. At each step, we show the instruction
text and the original Street View panorama with Touchdown
placed, and ask for the location for a single panorama, ei-
ther from the Street View interface or from our static im-
ages. The worker can indicate if the target is occluded. The
propagation annotation allows us to create multiple exam-
ples for each SDR, where each example uses the same SDR
but shows the environment from a different position.

Task III: Validation We use a separate task to validate
each instruction. The worker is asked to follow the instruc-
tion in the customized Street View interface and ﬁnd Touch-
down. The worker sees only the Street View interface, and
has no access to the overhead map. The task requires nav-
igation and identifying the location of Touchdown.
It is
completed correctly if the follower clicks within a 90-pixel
radius3 of the ground truth target location of Touchdown.
This requires the follower to be in the exact goal panorama,
or in one of the neighboring panoramas we propagated the
location to. The worker has ﬁve attempts to ﬁnd Touch-
down. Each attempt is a click. If the worker fails, we create
another task for the same example to attempt again. If the
second worker fails as well, the example is discarded.

Task IV: Segmentation We annotate each token in the
instruction to indicate if it describes the navigation or SDR
tasks. This allows us to address the tasks separately. First, a
worker highlights a consecutive preﬁx of tokens to indicate
the navigation segment. They then highlight a sufﬁx of to-
kens for the SDR task. The navigation and target location
segments may overlap (Figure 4).

Workers and Qualiﬁcation We require passing a qualiﬁ-
cation task to do the writing task. The qualiﬁer task requires

3This is roughly the size of Touchdown. The number is not directly

comparable to the SDR accuracy measures due to different scaling.

Dataset

TOUCHDOWN
Navigation
SDR
R2R [2]
SAIL [21]
LANI [25]

Dataset

Vocab. Mean Text

Real

Size
9,326
9,326
25,575
21,567

706

5,487

Size
5,625
4,999
3,419
3,156
563

2,292

Length
108.0
89.6
29.7
29.3
36.7
61.9

Vision?

3

3

7

7

Table 2. Data statistics of TOUCHDOWN, compared to related cor-
pora. For TOUCHDOWN, we report statistics for the complete task,
navigation only, and SDR only. Vocabulary size and text length are
computed on the combined training and development sets. SAIL
and LANI statistics are computed using paragraph data.

s
e
l
p
m
a
x
e

f
o
%

45

40

35

30

25

20

15

10

5

0

SAIL (paragraphs)
LANI (paragraphs)
R2R
TOUCHDOWN (SDR)
TOUCHDOWN (navigation)

0

50

100

150

200

Text length

Figure 5. Text lengths in TOUCHDOWN and related corpora.

correctly navigating and ﬁnding Touchdown for a prede-
ﬁned set of instructions. We consider workers that succeed
in three out of the four tasks as qualiﬁed. The other three
tasks do not require qualiﬁcation. Table 1 shows how many
workers participated in each task.

Payment and Incentive Structure The base pay for in-
struction writing is $0.60. For target propagation, valida-
tion, and segmentation we paid $0.15, $0.25, and $0.12.
We incentivize the instruction writers and followers with a
bonus system. For each instruction that passes validation,
we give the writer a bonus of $0.25 and the follower a bonus
of $0.10. Both sides have an interest in completing the task
correctly. The size of the graph makes it difﬁcult, and even
impossible, for the follower to complete the task and get the
bonus if the instructions are wrong.

5. Data Statistics and Analysis

Workers completed 11,019 instruction-writing tasks, and
12,664 validation tasks. 89.1% examples were correctly
validated, 80.1% on the ﬁrst attempt and 9.0% on the sec-
ond.4 While we allowed ﬁve attempts at ﬁnding Touchdown
during validation tasks, 64% of the tasks required a single
attempt. The value of additional attempts decayed quickly:
only 1.4% of the tasks were only successful after ﬁve at-
tempts. For the full task and navigation-only, TOUCH-
DOWN includes 9,326 examples with 6,526 in the training
set, 1,391 in the development set, and 1,409 in the test set.
For the SDR task, TOUCHDOWN includes 9,326 unique de-
scriptions and 25,575 examples with 17,880 for training,
3,836 for development, and 3,859 for testing. We use our

4Several paths were discarded due to updates in Street View data.

12542

initial paths as gold-standard demonstrations, and the place-
ment of Touchdown by the original writer as the reference
location. Table 2 shows basic data statistics. The mean in-
struction length is 108.0 tokens. The average overlap be-
tween navigation and SDR is 11.4 tokens. Figure 5 shows
the distribution of text lengths. Overall, TOUCHDOWN con-
tains a larger vocabulary and longer navigation instructions
than related corpora. The paths in TOUCHDOWN are longer
than in R2R [2], on average 35.2 panoramas compared to
6.0. SDR segments have a mean length of 29.8 tokens,
longer than in common referring expression datasets; Refer-
ItGame [16] expressions 4.4 tokens on average and Google
RefExp [22] expressions are 8.5.

We perform qualitative linguistic analysis of TOUCH-
DOWN to understand the type of reasoning required to solve
the navigation and SDR tasks. We identify a set of phe-
nomena, and randomly sample 25 examples from the devel-
opment set, annotating each with the number of times each
phenomenon occurs in the text. Table 3 shows results com-
paring TOUCHDOWN with R2R.5 Sentences in TOUCH-
DOWN refer to many more unique, observable entities (10.7
vs 3.7), and almost all examples in TOUCHDOWN include
coreference to a previously-mentioned entity. More exam-
ples in TOUCHDOWN require reasoning about counts, se-
quences, comparisons, and spatial relationships of objects.
Correct execution in TOUCHDOWN requires taking actions
only when certain conditions are met, and ensuring that the
agent’s observations match a described scene, while this is
rarely required in R2R. Our data is rich in spatial reasoning.
We distinguish two types: between multiple objects (allo-
centric) and between the agent and its environment (ego-
centric). We ﬁnd that navigation segments contain more
egocentric spatial relations than SDR segments, and SDR
segments require more allocentric reasoning. This corre-
sponds to the two tasks: navigation mainly requires moving
the agent relative to its environment, while SDR requires
resolving a point in space relative to other objects.

6. Spatial Reasoning with LINGUNET

We cast the SDR task as a language-conditioned image
reconstruction problem, where we predict a distribution of
the location of Touchdown over the entire observed image.

6.1. Model

We use the LINGUNET architecture [25, 5], which was
originally introduced for goal prediction and planning in in-
struction following. LINGUNET is a language-conditioned
variant of the UNET architecture [29], an image-to-image
encoder-decoder architecture widely used for image seg-
mentation. LINGUNET incorporates language into the im-
age reconstruction phase to fuse the two modalities. We

5See the Supplementary Material for analysis of SAIL and LANI.

Instruction Tokens ¯xS

...Touchdown is on top the pillar

the bike is resting on.

Panorama I

Gold Distribution I

g

BiLSTM

Representation u

Predicted Distribution P

KL Divergence Loss

F0

K1

K2

Softmax

MLP

F1

G1

H1

F2

G2

H2

LingUNet

Figure 6. LingUNet architecture with two layers (m = 2).

modify the architecture to predict a probability distribution
over the input panorama image.

We process

the description text

tokens ¯xs =
hx1, x2, . . . , xli using a bi-directional Long Short-term
Memory (LSTM) recurrent neural network to generate
The forward computation is hf
i =
l hidden states.
BiLSTM(ϕ(xi), hf
i 1), i = 1, . . . , l, where ϕ is a learned
word embedding function. We compute the backward hid-
den states hb
i similarly. The text representation is an aver-
age of the concatenated hidden states x = 1
i ; hb
i ].
We map the RGB panorama I to a feature representation F0
with a pre-trained RESNET18 [14].

i=1[hf

l Pl

LINGUNET performs m levels of convolution and de-
convolution operations. We generate a sequence of feature
maps Fk = CNNk(Fk 1), k = 1, . . . , m with learned con-
volutional layers CNNk. We slice the text representation
x to m equal-sized slices, and reshape each with a linear
projection to a 1 ⇥ 1 ﬁlter Kk. We convolve each feature
map Fk with Kk to obtain a text-conditioned feature map
Gk = CONV(Kk, Fk). We use m deconvolution operations
to generate feature maps of increasing size to create H1:

Hk =(DECONVk([Hk+1; Gk]),

DECONVk(Gk),

if k = 1, . . . , m − 1
if k = m .

We compute a single value for each pixel by projecting the
channel vector for each pixel using a single-layer perceptron
with a ReLU non-linearity. Finally, we compute a proba-
bility distribution over the feature map using a SOFTMAX.
The predicted location is the mode of the distribution.

6.2. Experimental Setup

The evaluation metrics are described in Section 3.2 and

the data in Section 5.

Learning We use supervised learning. The gold label is a
Gaussian smoothed distribution. The coordinate of the max-
imal value of the distribution is the exact coordinate where
Touchdown is placed. We minimize the KL-divergence be-
tween the Gaussian and the predicted distribution.

Systems We evaluate three non-learning baselines:
(a)
RANDOM: predict a pixel at random; (b) CENTER: predict

12543

<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
6
3
j
p
u
E
/
m
3
W
P
W
M
l
0
1
L
8
P
i
X
0
S
Q
V
5
w
=
"
>
A
A
A
C
K
n
i
c
b
V
C
7
S
s
R
A
F
J
3
4
N
r
6
1
t
B
l
c
B
K
s
l
E
U
H
L
B
R
t
L
R
V
e
F
T
Z
T
J
5
E
Y
H
5
x
F
m
b
t
Q
l
5
D
9
s
t
f
Z
r
7
M
T
W
D
3
F
2
3
U
J
X
D
1
w
4
n
H
N
f
n
K
y
U
w
m
E
U
v
Q
c
T
k
1
P
T
M
7
N
z
8
+
H
C
4
t
L
y
y
u
r
a
+
r
k
z
l
e
X
Q
5
U
Y
a
e
5
k
x
B
1
J
o
6
K
J
A
C
Z
e
l
B
a
Y
y
C
R
f
Z
3
e
H
A
v
7
g
H
6
4
T
R
Z
9
g
v
I
V
X
s
R
o
t
C
c
I
Z
e
u
k
o
Q
H
r
E
+
N
Q
U
q
9
t
h
c
r
7
a
i
d
j
Q
E
/
U
v
i
E
W
m
R
E
Y
6
v
1
4
K
Z
J
D
e
8
U
q
C
R
S
+
Z
c
L
4
5
K
T
G
t
m
U
X
A
J
T
Z
h
U
D
k
r
G
7
9
g
N
9
D
z
V
T
I
F
L
6
+
H
b
D
d
3
2
S
k
4
L
Y
3
1
p
p
E
P
1
5
0
T
N
l
H
N
9
l
f
l
O
x
f
D
W
j
X
s
D
8
V
8
v
d
4
O
F
Y
9
e
x
O
E
h
r
o
c
s
K
Q
f
P
v
4
0
U
l
K
R
o
6
y
I
X
m
w
g
J
H
2
f
e
E
c
S
v
8
/
5
T
f
M
s
s
4
+
v
T
C
M
L
G
g
4
Y
E
b
p
Z
j
O
6
4
Q
3
v
T
i
t
6
8
Q
q
2
o
q
b
J
v
T
J
x
e
M
5
/
S
X
n
u
+
0
4
a
s
c
n
e
6
1
O
N
M
p
w
j
m
y
S
L
b
J
D
Y
r
J
P
O
u
S
I
H
J
M
u
4
c
S
S
J
/
J
M
X
o
L
X
4
C
1
4
D
z
6
+
W
y
e
C
0
c
w
G
+
Y
X
g
8
w
u
d
k
a
b
i
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
6
3
j
p
u
E
/
m
3
W
P
W
M
l
0
1
L
8
P
i
X
0
S
Q
V
5
w
=
"
>
A
A
A
C
K
n
i
c
b
V
C
7
S
s
R
A
F
J
3
4
N
r
6
1
t
B
l
c
B
K
s
l
E
U
H
L
B
R
t
L
R
V
e
F
T
Z
T
J
5
E
Y
H
5
x
F
m
b
t
Q
l
5
D
9
s
t
f
Z
r
7
M
T
W
D
3
F
2
3
U
J
X
D
1
w
4
n
H
N
f
n
K
y
U
w
m
E
U
v
Q
c
T
k
1
P
T
M
7
N
z
8
+
H
C
4
t
L
y
y
u
r
a
+
r
k
z
l
e
X
Q
5
U
Y
a
e
5
k
x
B
1
J
o
6
K
J
A
C
Z
e
l
B
a
Y
y
C
R
f
Z
3
e
H
A
v
7
g
H
6
4
T
R
Z
9
g
v
I
V
X
s
R
o
t
C
c
I
Z
e
u
k
o
Q
H
r
E
+
N
Q
U
q
9
t
h
c
r
7
a
i
d
j
Q
E
/
U
v
i
E
W
m
R
E
Y
6
v
1
4
K
Z
J
D
e
8
U
q
C
R
S
+
Z
c
L
4
5
K
T
G
t
m
U
X
A
J
T
Z
h
U
D
k
r
G
7
9
g
N
9
D
z
V
T
I
F
L
6
+
H
b
D
d
3
2
S
k
4
L
Y
3
1
p
p
E
P
1
5
0
T
N
l
H
N
9
l
f
l
O
x
f
D
W
j
X
s
D
8
V
8
v
d
4
O
F
Y
9
e
x
O
E
h
r
o
c
s
K
Q
f
P
v
4
0
U
l
K
R
o
6
y
I
X
m
w
g
J
H
2
f
e
E
c
S
v
8
/
5
T
f
M
s
s
4
+
v
T
C
M
L
G
g
4
Y
E
b
p
Z
j
O
6
4
Q
3
v
T
i
t
6
8
Q
q
2
o
q
b
J
v
T
J
x
e
M
5
/
S
X
n
u
+
0
4
a
s
c
n
e
6
1
O
N
M
p
w
j
m
y
S
L
b
J
D
Y
r
J
P
O
u
S
I
H
J
M
u
4
c
S
S
J
/
J
M
X
o
L
X
4
C
1
4
D
z
6
+
W
y
e
C
0
c
w
G
+
Y
X
g
8
w
u
d
k
a
b
i
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
6
3
j
p
u
E
/
m
3
W
P
W
M
l
0
1
L
8
P
i
X
0
S
Q
V
5
w
=
"
>
A
A
A
C
K
n
i
c
b
V
C
7
S
s
R
A
F
J
3
4
N
r
6
1
t
B
l
c
B
K
s
l
E
U
H
L
B
R
t
L
R
V
e
F
T
Z
T
J
5
E
Y
H
5
x
F
m
b
t
Q
l
5
D
9
s
t
f
Z
r
7
M
T
W
D
3
F
2
3
U
J
X
D
1
w
4
n
H
N
f
n
K
y
U
w
m
E
U
v
Q
c
T
k
1
P
T
M
7
N
z
8
+
H
C
4
t
L
y
y
u
r
a
+
r
k
z
l
e
X
Q
5
U
Y
a
e
5
k
x
B
1
J
o
6
K
J
A
C
Z
e
l
B
a
Y
y
C
R
f
Z
3
e
H
A
v
7
g
H
6
4
T
R
Z
9
g
v
I
V
X
s
R
o
t
C
c
I
Z
e
u
k
o
Q
H
r
E
+
N
Q
U
q
9
t
h
c
r
7
a
i
d
j
Q
E
/
U
v
i
E
W
m
R
E
Y
6
v
1
4
K
Z
J
D
e
8
U
q
C
R
S
+
Z
c
L
4
5
K
T
G
t
m
U
X
A
J
T
Z
h
U
D
k
r
G
7
9
g
N
9
D
z
V
T
I
F
L
6
+
H
b
D
d
3
2
S
k
4
L
Y
3
1
p
p
E
P
1
5
0
T
N
l
H
N
9
l
f
l
O
x
f
D
W
j
X
s
D
8
V
8
v
d
4
O
F
Y
9
e
x
O
E
h
r
o
c
s
K
Q
f
P
v
4
0
U
l
K
R
o
6
y
I
X
m
w
g
J
H
2
f
e
E
c
S
v
8
/
5
T
f
M
s
s
4
+
v
T
C
M
L
G
g
4
Y
E
b
p
Z
j
O
6
4
Q
3
v
T
i
t
6
8
Q
q
2
o
q
b
J
v
T
J
x
e
M
5
/
S
X
n
u
+
0
4
a
s
c
n
e
6
1
O
N
M
p
w
j
m
y
S
L
b
J
D
Y
r
J
P
O
u
S
I
H
J
M
u
4
c
S
S
J
/
J
M
X
o
L
X
4
C
1
4
D
z
6
+
W
y
e
C
0
c
w
G
+
Y
X
g
8
w
u
d
k
a
b
i
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
6
3
j
p
u
E
/
m
3
W
P
W
M
l
0
1
L
8
P
i
X
0
S
Q
V
5
w
=
"
>
A
A
A
C
K
n
i
c
b
V
C
7
S
s
R
A
F
J
3
4
N
r
6
1
t
B
l
c
B
K
s
l
E
U
H
L
B
R
t
L
R
V
e
F
T
Z
T
J
5
E
Y
H
5
x
F
m
b
t
Q
l
5
D
9
s
t
f
Z
r
7
M
T
W
D
3
F
2
3
U
J
X
D
1
w
4
n
H
N
f
n
K
y
U
w
m
E
U
v
Q
c
T
k
1
P
T
M
7
N
z
8
+
H
C
4
t
L
y
y
u
r
a
+
r
k
z
l
e
X
Q
5
U
Y
a
e
5
k
x
B
1
J
o
6
K
J
A
C
Z
e
l
B
a
Y
y
C
R
f
Z
3
e
H
A
v
7
g
H
6
4
T
R
Z
9
g
v
I
V
X
s
R
o
t
C
c
I
Z
e
u
k
o
Q
H
r
E
+
N
Q
U
q
9
t
h
c
r
7
a
i
d
j
Q
E
/
U
v
i
E
W
m
R
E
Y
6
v
1
4
K
Z
J
D
e
8
U
q
C
R
S
+
Z
c
L
4
5
K
T
G
t
m
U
X
A
J
T
Z
h
U
D
k
r
G
7
9
g
N
9
D
z
V
T
I
F
L
6
+
H
b
D
d
3
2
S
k
4
L
Y
3
1
p
p
E
P
1
5
0
T
N
l
H
N
9
l
f
l
O
x
f
D
W
j
X
s
D
8
V
8
v
d
4
O
F
Y
9
e
x
O
E
h
r
o
c
s
K
Q
f
P
v
4
0
U
l
K
R
o
6
y
I
X
m
w
g
J
H
2
f
e
E
c
S
v
8
/
5
T
f
M
s
s
4
+
v
T
C
M
L
G
g
4
Y
E
b
p
Z
j
O
6
4
Q
3
v
T
i
t
6
8
Q
q
2
o
q
b
J
v
T
J
x
e
M
5
/
S
X
n
u
+
0
4
a
s
c
n
e
6
1
O
N
M
p
w
j
m
y
S
L
b
J
D
Y
r
J
P
O
u
S
I
H
J
M
u
4
c
S
S
J
/
J
M
X
o
L
X
4
C
1
4
D
z
6
+
W
y
e
C
0
c
w
G
+
Y
X
g
8
w
u
d
k
a
b
i
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
H
G
k
Y
r
D
n
U
4
w
9
h
N
J
l
r
L
x
v
H
u
N
2
z
S
d
s
=
"
>
A
A
A
C
L
X
i
c
b
V
D
L
S
s
N
A
F
J
3
4
r
P
H
R
q
k
s
3
g
0
V
w
V
R
I
R
d
C
m
4
c
S
F
S
w
a
r
Q
h
D
K
Z
3
N
b
B
m
U
m
Y
u
V
F
L
y
J
e
4
1
b
V
f
4
0
I
Q
t
/
6
G
0
9
q
F
V
g
9
c
O
J
x
z
X
5
w
k
l
8
J
i
E
L
x
5
M
7
N
z
8
w
u
L
t
S
V
/
e
W
V
1
r
d
5
Y
3
7
i
0
W
W
E
4
d
H
g
m
M
3
O
d
M
A
t
S
a
O
i
g
Q
A
n
X
u
Q
G
m
E
g
l
X
y
e
3
x
y
L
+
6
A
2
N
F
p
i
9
w
m
E
O
s
2
E
C
L
v
u
A
M
n
d
R
r
1
C
O
E
B
y
x
P
h
R
5
0
z
g
C
r
X
q
M
Z
t
I
I
x
6
F
8
S
T
k
i
T
T
N
D
u
r
X
s
L
U
Z
r
x
Q
o
F
G
L
p
m
1
3
T
D
I
M
S
6
Z
Q
c
E
l
V
H
5
U
W
M
g
Z
v
2
U
D
6
D
q
q
m
Q
I
b
l
+
P
P
K
7
r
j
l
J
T
2
M
+
N
K
I
x
2
r
P
y
d
K
p
q
w
d
q
s
R
1
K
o
Y
3
d
t
o
b
i
f
9
6
q
R
0
t
n
L
q
O
/
c
O
4
F
D
o
v
E
D
T
/
P
t
4
v
J
M
W
M
j
q
K
h
q
T
D
A
U
Q
4
d
Y
d
w
I
9
z
/
l
N
8
w
w
j
i
5
A
3
4
8
M
a
L
j
n
m
V
J
M
p
2
X
E
q
2
4
Y
l
2
V
k
F
G
2
G
V
e
W
7
5
M
L
p
n
P
6
S
y
7
1
W
G
L
T
C
8
/
3
m
U
T
D
J
s
E
a
2
y
D
b
Z
J
S
E
5
I
E
f
k
h
L
R
J
h
3
B
S
k
E
f
y
R
J
6
9
F
+
/
V
e
/
c
+
v
l
t
n
v
M
n
M
J
v
k
F
7
/
M
L
g
7
e
n
Q
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
H
G
k
Y
r
D
n
U
4
w
9
h
N
J
l
r
L
x
v
H
u
N
2
z
S
d
s
=
"
>
A
A
A
C
L
X
i
c
b
V
D
L
S
s
N
A
F
J
3
4
r
P
H
R
q
k
s
3
g
0
V
w
V
R
I
R
d
C
m
4
c
S
F
S
w
a
r
Q
h
D
K
Z
3
N
b
B
m
U
m
Y
u
V
F
L
y
J
e
4
1
b
V
f
4
0
I
Q
t
/
6
G
0
9
q
F
V
g
9
c
O
J
x
z
X
5
w
k
l
8
J
i
E
L
x
5
M
7
N
z
8
w
u
L
t
S
V
/
e
W
V
1
r
d
5
Y
3
7
i
0
W
W
E
4
d
H
g
m
M
3
O
d
M
A
t
S
a
O
i
g
Q
A
n
X
u
Q
G
m
E
g
l
X
y
e
3
x
y
L
+
6
A
2
N
F
p
i
9
w
m
E
O
s
2
E
C
L
v
u
A
M
n
d
R
r
1
C
O
E
B
y
x
P
h
R
5
0
z
g
C
r
X
q
M
Z
t
I
I
x
6
F
8
S
T
k
i
T
T
N
D
u
r
X
s
L
U
Z
r
x
Q
o
F
G
L
p
m
1
3
T
D
I
M
S
6
Z
Q
c
E
l
V
H
5
U
W
M
g
Z
v
2
U
D
6
D
q
q
m
Q
I
b
l
+
P
P
K
7
r
j
l
J
T
2
M
+
N
K
I
x
2
r
P
y
d
K
p
q
w
d
q
s
R
1
K
o
Y
3
d
t
o
b
i
f
9
6
q
R
0
t
n
L
q
O
/
c
O
4
F
D
o
v
E
D
T
/
P
t
4
v
J
M
W
M
j
q
K
h
q
T
D
A
U
Q
4
d
Y
d
w
I
9
z
/
l
N
8
w
w
j
i
5
A
3
4
8
M
a
L
j
n
m
V
J
M
p
2
X
E
q
2
4
Y
l
2
V
k
F
G
2
G
V
e
W
7
5
M
L
p
n
P
6
S
y
7
1
W
G
L
T
C
8
/
3
m
U
T
D
J
s
E
a
2
y
D
b
Z
J
S
E
5
I
E
f
k
h
L
R
J
h
3
B
S
k
E
f
y
R
J
6
9
F
+
/
V
e
/
c
+
v
l
t
n
v
M
n
M
J
v
k
F
7
/
M
L
g
7
e
n
Q
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
H
G
k
Y
r
D
n
U
4
w
9
h
N
J
l
r
L
x
v
H
u
N
2
z
S
d
s
=
"
>
A
A
A
C
L
X
i
c
b
V
D
L
S
s
N
A
F
J
3
4
r
P
H
R
q
k
s
3
g
0
V
w
V
R
I
R
d
C
m
4
c
S
F
S
w
a
r
Q
h
D
K
Z
3
N
b
B
m
U
m
Y
u
V
F
L
y
J
e
4
1
b
V
f
4
0
I
Q
t
/
6
G
0
9
q
F
V
g
9
c
O
J
x
z
X
5
w
k
l
8
J
i
E
L
x
5
M
7
N
z
8
w
u
L
t
S
V
/
e
W
V
1
r
d
5
Y
3
7
i
0
W
W
E
4
d
H
g
m
M
3
O
d
M
A
t
S
a
O
i
g
Q
A
n
X
u
Q
G
m
E
g
l
X
y
e
3
x
y
L
+
6
A
2
N
F
p
i
9
w
m
E
O
s
2
E
C
L
v
u
A
M
n
d
R
r
1
C
O
E
B
y
x
P
h
R
5
0
z
g
C
r
X
q
M
Z
t
I
I
x
6
F
8
S
T
k
i
T
T
N
D
u
r
X
s
L
U
Z
r
x
Q
o
F
G
L
p
m
1
3
T
D
I
M
S
6
Z
Q
c
E
l
V
H
5
U
W
M
g
Z
v
2
U
D
6
D
q
q
m
Q
I
b
l
+
P
P
K
7
r
j
l
J
T
2
M
+
N
K
I
x
2
r
P
y
d
K
p
q
w
d
q
s
R
1
K
o
Y
3
d
t
o
b
i
f
9
6
q
R
0
t
n
L
q
O
/
c
O
4
F
D
o
v
E
D
T
/
P
t
4
v
J
M
W
M
j
q
K
h
q
T
D
A
U
Q
4
d
Y
d
w
I
9
z
/
l
N
8
w
w
j
i
5
A
3
4
8
M
a
L
j
n
m
V
J
M
p
2
X
E
q
2
4
Y
l
2
V
k
F
G
2
G
V
e
W
7
5
M
L
p
n
P
6
S
y
7
1
W
G
L
T
C
8
/
3
m
U
T
D
J
s
E
a
2
y
D
b
Z
J
S
E
5
I
E
f
k
h
L
R
J
h
3
B
S
k
E
f
y
R
J
6
9
F
+
/
V
e
/
c
+
v
l
t
n
v
M
n
M
J
v
k
F
7
/
M
L
g
7
e
n
Q
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
H
G
k
Y
r
D
n
U
4
w
9
h
N
J
l
r
L
x
v
H
u
N
2
z
S
d
s
=
"
>
A
A
A
C
L
X
i
c
b
V
D
L
S
s
N
A
F
J
3
4
r
P
H
R
q
k
s
3
g
0
V
w
V
R
I
R
d
C
m
4
c
S
F
S
w
a
r
Q
h
D
K
Z
3
N
b
B
m
U
m
Y
u
V
F
L
y
J
e
4
1
b
V
f
4
0
I
Q
t
/
6
G
0
9
q
F
V
g
9
c
O
J
x
z
X
5
w
k
l
8
J
i
E
L
x
5
M
7
N
z
8
w
u
L
t
S
V
/
e
W
V
1
r
d
5
Y
3
7
i
0
W
W
E
4
d
H
g
m
M
3
O
d
M
A
t
S
a
O
i
g
Q
A
n
X
u
Q
G
m
E
g
l
X
y
e
3
x
y
L
+
6
A
2
N
F
p
i
9
w
m
E
O
s
2
E
C
L
v
u
A
M
n
d
R
r
1
C
O
E
B
y
x
P
h
R
5
0
z
g
C
r
X
q
M
Z
t
I
I
x
6
F
8
S
T
k
i
T
T
N
D
u
r
X
s
L
U
Z
r
x
Q
o
F
G
L
p
m
1
3
T
D
I
M
S
6
Z
Q
c
E
l
V
H
5
U
W
M
g
Z
v
2
U
D
6
D
q
q
m
Q
I
b
l
+
P
P
K
7
r
j
l
J
T
2
M
+
N
K
I
x
2
r
P
y
d
K
p
q
w
d
q
s
R
1
K
o
Y
3
d
t
o
b
i
f
9
6
q
R
0
t
n
L
q
O
/
c
O
4
F
D
o
v
E
D
T
/
P
t
4
v
J
M
W
M
j
q
K
h
q
T
D
A
U
Q
4
d
Y
d
w
I
9
z
/
l
N
8
w
w
j
i
5
A
3
4
8
M
a
L
j
n
m
V
J
M
p
2
X
E
q
2
4
Y
l
2
V
k
F
G
2
G
V
e
W
7
5
M
L
p
n
P
6
S
y
7
1
W
G
L
T
C
8
/
3
m
U
T
D
J
s
E
a
2
y
D
b
Z
J
S
E
5
I
E
f
k
h
L
R
J
h
3
B
S
k
E
f
y
R
J
6
9
F
+
/
V
e
/
c
+
v
l
t
n
v
M
n
M
J
v
k
F
7
/
M
L
g
7
e
n
Q
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
K
i
B
Q
V
7
1
N
2
b
L
5
0
J
j
1
u
T
a
c
U
W
v
C
E
J
Q
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
x
U
r
R
q
/
q
h
6
9
L
A
b
B
U
0
l
E
0
G
N
B
E
I
8
K
V
g
t
N
K
J
v
N
i
1
2
6
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
B
O
v
/
h
I
3
N
Q
d
t
H
V
g
Y
Z
t
7
b
N
0
y
c
c
6
a
N
7
3
8
6
r
a
X
l
l
f
b
q
2
r
q
7
s
b
m
1
v
d
P
Z
3
b
v
T
W
a
E
o
9
G
n
G
M
z
W
I
i
Q
b
O
J
P
Q
N
M
x
w
G
u
Q
I
i
Y
g
7
3
8
e
S
i
9
u
8
f
Q
W
m
W
y
V
s
z
z
S
E
S
5
E
G
y
l
F
F
i
r
B
S
G
g
p
h
x
n
J
a
X
1
c
g
f
d
T
y
/
6
8
+
A
F
0
n
Q
E
A
8
1
u
B
7
t
O
u
0
w
y
W
g
h
Q
B
r
K
i
d
b
D
w
M
9
N
V
B
J
l
G
O
V
Q
u
W
G
h
I
S
d
0
Q
h
5
g
a
K
k
k
A
n
R
U
z
k
J
X
+
M
g
q
C
U
4
z
Z
Z
8
0
e
K
b
+
3
i
i
J
0
H
o
q
Y
j
t
Z
h
9
T
z
X
i
3
+
6
y
W
6
/
n
D
u
u
k
n
P
o
5
L
J
v
D
A
g
6
c
/
x
t
O
D
Y
Z
L
h
u
B
S
d
M
A
T
V
8
a
g
m
h
i
t
n
8
m
I
6
J
I
t
T
Y
7
l
w
3
V
C
D
h
i
W
Z
C
E
J
m
U
I
a
2
G
Q
V
S
W
o
R
L
Y
C
6
r
K
t
c
0
F
8
z
0
t
k
r
u
T
b
u
B
3
g
5
t
T
r
+
c
3
H
a
6
h
A
3
S
I
j
l
G
A
z
l
A
P
X
a
F
r
1
E
c
U
5
e
g
Z
v
a
B
X
5
8
1
5
d
z
6
c
z
5
/
R
l
t
P
s
7
K
M
/
c
L
6
+
A
e
j
f
p
W
4
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
K
i
B
Q
V
7
1
N
2
b
L
5
0
J
j
1
u
T
a
c
U
W
v
C
E
J
Q
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
x
U
r
R
q
/
q
h
6
9
L
A
b
B
U
0
l
E
0
G
N
B
E
I
8
K
V
g
t
N
K
J
v
N
i
1
2
6
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
B
O
v
/
h
I
3
N
Q
d
t
H
V
g
Y
Z
t
7
b
N
0
y
c
c
6
a
N
7
3
8
6
r
a
X
l
l
f
b
q
2
r
q
7
s
b
m
1
v
d
P
Z
3
b
v
T
W
a
E
o
9
G
n
G
M
z
W
I
i
Q
b
O
J
P
Q
N
M
x
w
G
u
Q
I
i
Y
g
7
3
8
e
S
i
9
u
8
f
Q
W
m
W
y
V
s
z
z
S
E
S
5
E
G
y
l
F
F
i
r
B
S
G
g
p
h
x
n
J
a
X
1
c
g
f
d
T
y
/
6
8
+
A
F
0
n
Q
E
A
8
1
u
B
7
t
O
u
0
w
y
W
g
h
Q
B
r
K
i
d
b
D
w
M
9
N
V
B
J
l
G
O
V
Q
u
W
G
h
I
S
d
0
Q
h
5
g
a
K
k
k
A
n
R
U
z
k
J
X
+
M
g
q
C
U
4
z
Z
Z
8
0
e
K
b
+
3
i
i
J
0
H
o
q
Y
j
t
Z
h
9
T
z
X
i
3
+
6
y
W
6
/
n
D
u
u
k
n
P
o
5
L
J
v
D
A
g
6
c
/
x
t
O
D
Y
Z
L
h
u
B
S
d
M
A
T
V
8
a
g
m
h
i
t
n
8
m
I
6
J
I
t
T
Y
7
l
w
3
V
C
D
h
i
W
Z
C
E
J
m
U
I
a
2
G
Q
V
S
W
o
R
L
Y
C
6
r
K
t
c
0
F
8
z
0
t
k
r
u
T
b
u
B
3
g
5
t
T
r
+
c
3
H
a
6
h
A
3
S
I
j
l
G
A
z
l
A
P
X
a
F
r
1
E
c
U
5
e
g
Z
v
a
B
X
5
8
1
5
d
z
6
c
z
5
/
R
l
t
P
s
7
K
M
/
c
L
6
+
A
e
j
f
p
W
4
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
K
i
B
Q
V
7
1
N
2
b
L
5
0
J
j
1
u
T
a
c
U
W
v
C
E
J
Q
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
x
U
r
R
q
/
q
h
6
9
L
A
b
B
U
0
l
E
0
G
N
B
E
I
8
K
V
g
t
N
K
J
v
N
i
1
2
6
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
B
O
v
/
h
I
3
N
Q
d
t
H
V
g
Y
Z
t
7
b
N
0
y
c
c
6
a
N
7
3
8
6
r
a
X
l
l
f
b
q
2
r
q
7
s
b
m
1
v
d
P
Z
3
b
v
T
W
a
E
o
9
G
n
G
M
z
W
I
i
Q
b
O
J
P
Q
N
M
x
w
G
u
Q
I
i
Y
g
7
3
8
e
S
i
9
u
8
f
Q
W
m
W
y
V
s
z
z
S
E
S
5
E
G
y
l
F
F
i
r
B
S
G
g
p
h
x
n
J
a
X
1
c
g
f
d
T
y
/
6
8
+
A
F
0
n
Q
E
A
8
1
u
B
7
t
O
u
0
w
y
W
g
h
Q
B
r
K
i
d
b
D
w
M
9
N
V
B
J
l
G
O
V
Q
u
W
G
h
I
S
d
0
Q
h
5
g
a
K
k
k
A
n
R
U
z
k
J
X
+
M
g
q
C
U
4
z
Z
Z
8
0
e
K
b
+
3
i
i
J
0
H
o
q
Y
j
t
Z
h
9
T
z
X
i
3
+
6
y
W
6
/
n
D
u
u
k
n
P
o
5
L
J
v
D
A
g
6
c
/
x
t
O
D
Y
Z
L
h
u
B
S
d
M
A
T
V
8
a
g
m
h
i
t
n
8
m
I
6
J
I
t
T
Y
7
l
w
3
V
C
D
h
i
W
Z
C
E
J
m
U
I
a
2
G
Q
V
S
W
o
R
L
Y
C
6
r
K
t
c
0
F
8
z
0
t
k
r
u
T
b
u
B
3
g
5
t
T
r
+
c
3
H
a
6
h
A
3
S
I
j
l
G
A
z
l
A
P
X
a
F
r
1
E
c
U
5
e
g
Z
v
a
B
X
5
8
1
5
d
z
6
c
z
5
/
R
l
t
P
s
7
K
M
/
c
L
6
+
A
e
j
f
p
W
4
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
K
i
B
Q
V
7
1
N
2
b
L
5
0
J
j
1
u
T
a
c
U
W
v
C
E
J
Q
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
x
U
r
R
q
/
q
h
6
9
L
A
b
B
U
0
l
E
0
G
N
B
E
I
8
K
V
g
t
N
K
J
v
N
i
1
2
6
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
B
O
v
/
h
I
3
N
Q
d
t
H
V
g
Y
Z
t
7
b
N
0
y
c
c
6
a
N
7
3
8
6
r
a
X
l
l
f
b
q
2
r
q
7
s
b
m
1
v
d
P
Z
3
b
v
T
W
a
E
o
9
G
n
G
M
z
W
I
i
Q
b
O
J
P
Q
N
M
x
w
G
u
Q
I
i
Y
g
7
3
8
e
S
i
9
u
8
f
Q
W
m
W
y
V
s
z
z
S
E
S
5
E
G
y
l
F
F
i
r
B
S
G
g
p
h
x
n
J
a
X
1
c
g
f
d
T
y
/
6
8
+
A
F
0
n
Q
E
A
8
1
u
B
7
t
O
u
0
w
y
W
g
h
Q
B
r
K
i
d
b
D
w
M
9
N
V
B
J
l
G
O
V
Q
u
W
G
h
I
S
d
0
Q
h
5
g
a
K
k
k
A
n
R
U
z
k
J
X
+
M
g
q
C
U
4
z
Z
Z
8
0
e
K
b
+
3
i
i
J
0
H
o
q
Y
j
t
Z
h
9
T
z
X
i
3
+
6
y
W
6
/
n
D
u
u
k
n
P
o
5
L
J
v
D
A
g
6
c
/
x
t
O
D
Y
Z
L
h
u
B
S
d
M
A
T
V
8
a
g
m
h
i
t
n
8
m
I
6
J
I
t
T
Y
7
l
w
3
V
C
D
h
i
W
Z
C
E
J
m
U
I
a
2
G
Q
V
S
W
o
R
L
Y
C
6
r
K
t
c
0
F
8
z
0
t
k
r
u
T
b
u
B
3
g
5
t
T
r
+
c
3
H
a
6
h
A
3
S
I
j
l
G
A
z
l
A
P
X
a
F
r
1
E
c
U
5
e
g
Z
v
a
B
X
5
8
1
5
d
z
6
c
z
5
/
R
l
t
P
s
7
K
M
/
c
L
6
+
A
e
j
f
p
W
4
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
2
V
d
1
v
j
q
3
3
i
j
D
m
G
T
K
L
V
f
1
E
e
N
d
R
o
E
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
E
8
a
h
g
q
9
B
d
S
j
b
7
1
o
Y
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
s
2
4
N
W
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
c
R
r
L
C
2
v
N
F
d
b
a
/
7
6
x
u
b
W
9
s
7
u
X
s
9
k
h
W
b
Q
Z
Z
n
I
9
E
N
M
D
Q
i
u
o
G
u
5
F
f
C
Q
a
6
A
y
F
n
A
f
j
y
5
r
/
/
4
J
t
O
G
Z
u
r
P
j
H
C
J
J
H
x
V
P
O
a
P
W
S
W
E
o
q
R
3
G
a
X
l
V
D
c
h
g
p
x
1
0
g
i
n
w
X
0
L
m
p
I
3
m
u
B
n
s
e
s
0
w
y
V
g
h
Q
V
k
m
q
D
F
9
E
u
Q
2
K
q
m
2
n
A
m
o
/
L
A
w
k
F
M
2
o
o
/
Q
d
1
R
R
C
S
Y
q
p
6
E
r
f
O
S
U
B
K
e
Z
d
k
9
Z
P
F
V
/
b
p
R
U
G
j
O
W
s
Z
u
s
Q
5
p
F
r
x
b
/
9
R
J
T
f
7
h
w
3
a
b
n
U
c
l
V
X
l
h
Q
b
H
Y
8
L
Q
S
2
G
a
5
b
w
Q
n
X
w
K
w
Y
O
0
K
Z
5
i
4
/
Z
k
O
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
+
i
c
o
y
1
B
K
3
S
V
X
5
r
j
m
y
2
N
N
f
0
j
v
p
k
K
B
D
b
k
/
b
F
8
G
8
w
x
Y
6
Q
I
f
o
G
B
F
0
h
i
7
Q
N
b
p
B
X
c
R
Q
j
l
7
Q
K
3
r
z
3
r
0
P
7
9
O
b
z
E
Y
b
3
n
x
n
H
/
2
C
9
/
U
N
6
p
i
l
b
w
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
2
V
d
1
v
j
q
3
3
i
j
D
m
G
T
K
L
V
f
1
E
e
N
d
R
o
E
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
E
8
a
h
g
q
9
B
d
S
j
b
7
1
o
Y
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
s
2
4
N
W
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
c
R
r
L
C
2
v
N
F
d
b
a
/
7
6
x
u
b
W
9
s
7
u
X
s
9
k
h
W
b
Q
Z
Z
n
I
9
E
N
M
D
Q
i
u
o
G
u
5
F
f
C
Q
a
6
A
y
F
n
A
f
j
y
5
r
/
/
4
J
t
O
G
Z
u
r
P
j
H
C
J
J
H
x
V
P
O
a
P
W
S
W
E
o
q
R
3
G
a
X
l
V
D
c
h
g
p
x
1
0
g
i
n
w
X
0
L
m
p
I
3
m
u
B
n
s
e
s
0
w
y
V
g
h
Q
V
k
m
q
D
F
9
E
u
Q
2
K
q
m
2
n
A
m
o
/
L
A
w
k
F
M
2
o
o
/
Q
d
1
R
R
C
S
Y
q
p
6
E
r
f
O
S
U
B
K
e
Z
d
k
9
Z
P
F
V
/
b
p
R
U
G
j
O
W
s
Z
u
s
Q
5
p
F
r
x
b
/
9
R
J
T
f
7
h
w
3
a
b
n
U
c
l
V
X
l
h
Q
b
H
Y
8
L
Q
S
2
G
a
5
b
w
Q
n
X
w
K
w
Y
O
0
K
Z
5
i
4
/
Z
k
O
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
+
i
c
o
y
1
B
K
3
S
V
X
5
r
j
m
y
2
N
N
f
0
j
v
p
k
K
B
D
b
k
/
b
F
8
G
8
w
x
Y
6
Q
I
f
o
G
B
F
0
h
i
7
Q
N
b
p
B
X
c
R
Q
j
l
7
Q
K
3
r
z
3
r
0
P
7
9
O
b
z
E
Y
b
3
n
x
n
H
/
2
C
9
/
U
N
6
p
i
l
b
w
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
2
V
d
1
v
j
q
3
3
i
j
D
m
G
T
K
L
V
f
1
E
e
N
d
R
o
E
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
E
8
a
h
g
q
9
B
d
S
j
b
7
1
o
Y
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
s
2
4
N
W
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
c
R
r
L
C
2
v
N
F
d
b
a
/
7
6
x
u
b
W
9
s
7
u
X
s
9
k
h
W
b
Q
Z
Z
n
I
9
E
N
M
D
Q
i
u
o
G
u
5
F
f
C
Q
a
6
A
y
F
n
A
f
j
y
5
r
/
/
4
J
t
O
G
Z
u
r
P
j
H
C
J
J
H
x
V
P
O
a
P
W
S
W
E
o
q
R
3
G
a
X
l
V
D
c
h
g
p
x
1
0
g
i
n
w
X
0
L
m
p
I
3
m
u
B
n
s
e
s
0
w
y
V
g
h
Q
V
k
m
q
D
F
9
E
u
Q
2
K
q
m
2
n
A
m
o
/
L
A
w
k
F
M
2
o
o
/
Q
d
1
R
R
C
S
Y
q
p
6
E
r
f
O
S
U
B
K
e
Z
d
k
9
Z
P
F
V
/
b
p
R
U
G
j
O
W
s
Z
u
s
Q
5
p
F
r
x
b
/
9
R
J
T
f
7
h
w
3
a
b
n
U
c
l
V
X
l
h
Q
b
H
Y
8
L
Q
S
2
G
a
5
b
w
Q
n
X
w
K
w
Y
O
0
K
Z
5
i
4
/
Z
k
O
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
+
i
c
o
y
1
B
K
3
S
V
X
5
r
j
m
y
2
N
N
f
0
j
v
p
k
K
B
D
b
k
/
b
F
8
G
8
w
x
Y
6
Q
I
f
o
G
B
F
0
h
i
7
Q
N
b
p
B
X
c
R
Q
j
l
7
Q
K
3
r
z
3
r
0
P
7
9
O
b
z
E
Y
b
3
n
x
n
H
/
2
C
9
/
U
N
6
p
i
l
b
w
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
2
V
d
1
v
j
q
3
3
i
j
D
m
G
T
K
L
V
f
1
E
e
N
d
R
o
E
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
E
8
a
h
g
q
9
B
d
S
j
b
7
1
o
Y
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
s
2
4
N
W
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
c
R
r
L
C
2
v
N
F
d
b
a
/
7
6
x
u
b
W
9
s
7
u
X
s
9
k
h
W
b
Q
Z
Z
n
I
9
E
N
M
D
Q
i
u
o
G
u
5
F
f
C
Q
a
6
A
y
F
n
A
f
j
y
5
r
/
/
4
J
t
O
G
Z
u
r
P
j
H
C
J
J
H
x
V
P
O
a
P
W
S
W
E
o
q
R
3
G
a
X
l
V
D
c
h
g
p
x
1
0
g
i
n
w
X
0
L
m
p
I
3
m
u
B
n
s
e
s
0
w
y
V
g
h
Q
V
k
m
q
D
F
9
E
u
Q
2
K
q
m
2
n
A
m
o
/
L
A
w
k
F
M
2
o
o
/
Q
d
1
R
R
C
S
Y
q
p
6
E
r
f
O
S
U
B
K
e
Z
d
k
9
Z
P
F
V
/
b
p
R
U
G
j
O
W
s
Z
u
s
Q
5
p
F
r
x
b
/
9
R
J
T
f
7
h
w
3
a
b
n
U
c
l
V
X
l
h
Q
b
H
Y
8
L
Q
S
2
G
a
5
b
w
Q
n
X
w
K
w
Y
O
0
K
Z
5
i
4
/
Z
k
O
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
+
i
c
o
y
1
B
K
3
S
V
X
5
r
j
m
y
2
N
N
f
0
j
v
p
k
K
B
D
b
k
/
b
F
8
G
8
w
x
Y
6
Q
I
f
o
G
B
F
0
h
i
7
Q
N
b
p
B
X
c
R
Q
j
l
7
Q
K
3
r
z
3
r
0
P
7
9
O
b
z
E
Y
b
3
n
x
n
H
/
2
C
9
/
U
N
6
p
i
l
b
w
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
u
r
S
1
Z
Y
Y
a
A
Q
t
B
Z
F
5
0
Q
4
d
4
Y
B
H
B
N
T
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
w
I
4
l
H
B
1
k
I
T
y
m
b
z
o
o
u
7
m
7
C
7
U
U
r
I
3
/
C
q
Z
3
+
N
N
+
n
V
X
+
K
m
z
U
F
b
B
x
a
G
m
f
f
2
D
R
P
n
n
G
n
j
+
x
N
n
a
X
l
l
d
W
2
9
t
e
F
u
b
m
3
v
7
L
b
3
9
v
s
6
K
x
S
F
H
s
1
4
p
g
Y
x
0
c
C
Z
h
J
5
h
h
s
M
g
V
0
B
E
z
O
E
+
f
r
q
s
/
f
t
n
U
J
p
l
8
s
6
M
c
4
g
E
e
Z
A
s
Z
Z
Q
Y
K
4
W
h
I
O
Y
x
T
s
u
r
a
n
Q
6
a
n
t
+
x
5
8
C
L
5
K
g
I
R
5
q
c
D
P
a
c
9
b
C
J
K
O
F
A
G
k
o
J
1
o
P
A
z
8
3
U
U
m
U
Y
Z
R
D
5
Y
a
F
h
p
z
Q
J
/
I
A
Q
0
s
l
E
a
C
j
c
h
q
6
w
s
d
W
S
X
C
a
K
f
u
k
w
V
P
1
9
0
Z
J
h
N
Z
j
E
d
v
J
O
q
S
e
9
2
r
x
X
y
/
R
9
Y
d
z
1
0
1
6
E
Z
V
M
5
o
U
B
S
W
f
H
0
4
J
j
k
+
G
6
F
Z
w
w
B
d
T
w
s
S
W
E
K
m
b
z
Y
/
p
I
F
K
H
G
d
u
e
6
o
Q
I
J
L
z
Q
T
g
s
i
k
D
G
k
1
D
K
K
y
D
J
X
A
X
l
B
V
r
m
0
u
m
O
9
p
k
f
R
P
O
4
H
f
C
W
7
P
v
K
7
f
d
N
h
C
h
+
g
I
n
a
A
A
n
a
M
u
u
k
Y
3
q
I
c
o
y
t
E
r
e
k
P
v
z
o
f
z
6
X
w
5
k
9
n
o
k
t
P
s
H
K
A
/
c
L
5
/
A
O
x
R
p
X
A
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
u
r
S
1
Z
Y
Y
a
A
Q
t
B
Z
F
5
0
Q
4
d
4
Y
B
H
B
N
T
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
w
I
4
l
H
B
1
k
I
T
y
m
b
z
o
o
u
7
m
7
C
7
U
U
r
I
3
/
C
q
Z
3
+
N
N
+
n
V
X
+
K
m
z
U
F
b
B
x
a
G
m
f
f
2
D
R
P
n
n
G
n
j
+
x
N
n
a
X
l
l
d
W
2
9
t
e
F
u
b
m
3
v
7
L
b
3
9
v
s
6
K
x
S
F
H
s
1
4
p
g
Y
x
0
c
C
Z
h
J
5
h
h
s
M
g
V
0
B
E
z
O
E
+
f
r
q
s
/
f
t
n
U
J
p
l
8
s
6
M
c
4
g
E
e
Z
A
s
Z
Z
Q
Y
K
4
W
h
I
O
Y
x
T
s
u
r
a
n
Q
6
a
n
t
+
x
5
8
C
L
5
K
g
I
R
5
q
c
D
P
a
c
9
b
C
J
K
O
F
A
G
k
o
J
1
o
P
A
z
8
3
U
U
m
U
Y
Z
R
D
5
Y
a
F
h
p
z
Q
J
/
I
A
Q
0
s
l
E
a
C
j
c
h
q
6
w
s
d
W
S
X
C
a
K
f
u
k
w
V
P
1
9
0
Z
J
h
N
Z
j
E
d
v
J
O
q
S
e
9
2
r
x
X
y
/
R
9
Y
d
z
1
0
1
6
E
Z
V
M
5
o
U
B
S
W
f
H
0
4
J
j
k
+
G
6
F
Z
w
w
B
d
T
w
s
S
W
E
K
m
b
z
Y
/
p
I
F
K
H
G
d
u
e
6
o
Q
I
J
L
z
Q
T
g
s
i
k
D
G
k
1
D
K
K
y
D
J
X
A
X
l
B
V
r
m
0
u
m
O
9
p
k
f
R
P
O
4
H
f
C
W
7
P
v
K
7
f
d
N
h
C
h
+
g
I
n
a
A
A
n
a
M
u
u
k
Y
3
q
I
c
o
y
t
E
r
e
k
P
v
z
o
f
z
6
X
w
5
k
9
n
o
k
t
P
s
H
K
A
/
c
L
5
/
A
O
x
R
p
X
A
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
u
r
S
1
Z
Y
Y
a
A
Q
t
B
Z
F
5
0
Q
4
d
4
Y
B
H
B
N
T
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
w
I
4
l
H
B
1
k
I
T
y
m
b
z
o
o
u
7
m
7
C
7
U
U
r
I
3
/
C
q
Z
3
+
N
N
+
n
V
X
+
K
m
z
U
F
b
B
x
a
G
m
f
f
2
D
R
P
n
n
G
n
j
+
x
N
n
a
X
l
l
d
W
2
9
t
e
F
u
b
m
3
v
7
L
b
3
9
v
s
6
K
x
S
F
H
s
1
4
p
g
Y
x
0
c
C
Z
h
J
5
h
h
s
M
g
V
0
B
E
z
O
E
+
f
r
q
s
/
f
t
n
U
J
p
l
8
s
6
M
c
4
g
E
e
Z
A
s
Z
Z
Q
Y
K
4
W
h
I
O
Y
x
T
s
u
r
a
n
Q
6
a
n
t
+
x
5
8
C
L
5
K
g
I
R
5
q
c
D
P
a
c
9
b
C
J
K
O
F
A
G
k
o
J
1
o
P
A
z
8
3
U
U
m
U
Y
Z
R
D
5
Y
a
F
h
p
z
Q
J
/
I
A
Q
0
s
l
E
a
C
j
c
h
q
6
w
s
d
W
S
X
C
a
K
f
u
k
w
V
P
1
9
0
Z
J
h
N
Z
j
E
d
v
J
O
q
S
e
9
2
r
x
X
y
/
R
9
Y
d
z
1
0
1
6
E
Z
V
M
5
o
U
B
S
W
f
H
0
4
J
j
k
+
G
6
F
Z
w
w
B
d
T
w
s
S
W
E
K
m
b
z
Y
/
p
I
F
K
H
G
d
u
e
6
o
Q
I
J
L
z
Q
T
g
s
i
k
D
G
k
1
D
K
K
y
D
J
X
A
X
l
B
V
r
m
0
u
m
O
9
p
k
f
R
P
O
4
H
f
C
W
7
P
v
K
7
f
d
N
h
C
h
+
g
I
n
a
A
A
n
a
M
u
u
k
Y
3
q
I
c
o
y
t
E
r
e
k
P
v
z
o
f
z
6
X
w
5
k
9
n
o
k
t
P
s
H
K
A
/
c
L
5
/
A
O
x
R
p
X
A
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
u
r
S
1
Z
Y
Y
a
A
Q
t
B
Z
F
5
0
Q
4
d
4
Y
B
H
B
N
T
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
w
I
4
l
H
B
1
k
I
T
y
m
b
z
o
o
u
7
m
7
C
7
U
U
r
I
3
/
C
q
Z
3
+
N
N
+
n
V
X
+
K
m
z
U
F
b
B
x
a
G
m
f
f
2
D
R
P
n
n
G
n
j
+
x
N
n
a
X
l
l
d
W
2
9
t
e
F
u
b
m
3
v
7
L
b
3
9
v
s
6
K
x
S
F
H
s
1
4
p
g
Y
x
0
c
C
Z
h
J
5
h
h
s
M
g
V
0
B
E
z
O
E
+
f
r
q
s
/
f
t
n
U
J
p
l
8
s
6
M
c
4
g
E
e
Z
A
s
Z
Z
Q
Y
K
4
W
h
I
O
Y
x
T
s
u
r
a
n
Q
6
a
n
t
+
x
5
8
C
L
5
K
g
I
R
5
q
c
D
P
a
c
9
b
C
J
K
O
F
A
G
k
o
J
1
o
P
A
z
8
3
U
U
m
U
Y
Z
R
D
5
Y
a
F
h
p
z
Q
J
/
I
A
Q
0
s
l
E
a
C
j
c
h
q
6
w
s
d
W
S
X
C
a
K
f
u
k
w
V
P
1
9
0
Z
J
h
N
Z
j
E
d
v
J
O
q
S
e
9
2
r
x
X
y
/
R
9
Y
d
z
1
0
1
6
E
Z
V
M
5
o
U
B
S
W
f
H
0
4
J
j
k
+
G
6
F
Z
w
w
B
d
T
w
s
S
W
E
K
m
b
z
Y
/
p
I
F
K
H
G
d
u
e
6
o
Q
I
J
L
z
Q
T
g
s
i
k
D
G
k
1
D
K
K
y
D
J
X
A
X
l
B
V
r
m
0
u
m
O
9
p
k
f
R
P
O
4
H
f
C
W
7
P
v
K
7
f
d
N
h
C
h
+
g
I
n
a
A
A
n
a
M
u
u
k
Y
3
q
I
c
o
y
t
E
r
e
k
P
v
z
o
f
z
6
X
w
5
k
9
n
o
k
t
P
s
H
K
A
/
c
L
5
/
A
O
x
R
p
X
A
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
/
P
P
w
Q
n
S
y
q
T
E
W
T
L
t
+
U
W
B
I
Z
k
p
v
Y
y
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
x
4
0
K
O
C
r
Y
U
m
l
M
3
m
R
R
d
3
N
2
F
3
o
5
S
Q
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
N
m
4
O
2
D
i
w
M
M
+
/
t
G
y
b
O
O
d
P
G
9
y
f
O
0
v
L
K
6
t
p
6
a
8
P
d
3
N
r
e
2
W
3
v
7
f
d
1
V
i
g
K
P
Z
r
x
T
A
1
i
o
o
E
z
C
T
3
D
D
I
d
B
r
o
C
I
m
M
N
9
/
H
R
Z
+
/
f
P
o
D
T
L
5
J
0
Z
5
x
A
J
8
i
B
Z
y
i
g
x
V
g
p
D
Q
c
x
j
n
J
Z
X
1
e
h
0
1
P
b
8
j
j
8
F
X
i
R
B
Q
z
z
U
4
G
a
0
5
6
y
F
S
U
Y
L
A
d
J
Q
T
r
Q
e
B
n
5
u
o
p
I
o
w
y
i
H
y
g
0
L
D
T
m
h
T
+
Q
B
h
p
Z
K
I
k
B
H
5
T
R
0
h
Y
+
t
k
u
A
0
U
/
Z
J
g
6
f
q
7
4
2
S
C
K
3
H
I
r
a
T
d
U
g
9
7
9
X
i
v
1
6
i
6
w
/
n
r
p
v
0
I
i
q
Z
z
A
s
D
k
s
6
O
p
w
X
H
J
s
N
1
K
z
h
h
C
q
j
h
Y
0
s
I
V
c
z
m
x
/
S
R
K
E
K
N
7
c
5
1
Q
w
U
S
X
m
g
m
B
J
F
J
G
d
J
q
G
E
R
l
G
S
q
B
v
a
C
q
X
N
t
c
M
N
/
T
I
u
m
f
d
g
K
/
E
9
y
e
e
V
2
/
6
b
C
F
D
t
E
R
O
k
E
B
O
k
d
d
d
I
1
u
U
A
9
R
l
K
N
X
9
I
b
e
n
Q
/
n
0
/
l
y
J
r
P
R
J
a
f
Z
O
U
B
/
4
H
z
/
A
O
4
N
p
X
E
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
/
P
P
w
Q
n
S
y
q
T
E
W
T
L
t
+
U
W
B
I
Z
k
p
v
Y
y
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
x
4
0
K
O
C
r
Y
U
m
l
M
3
m
R
R
d
3
N
2
F
3
o
5
S
Q
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
N
m
4
O
2
D
i
w
M
M
+
/
t
G
y
b
O
O
d
P
G
9
y
f
O
0
v
L
K
6
t
p
6
a
8
P
d
3
N
r
e
2
W
3
v
7
f
d
1
V
i
g
K
P
Z
r
x
T
A
1
i
o
o
E
z
C
T
3
D
D
I
d
B
r
o
C
I
m
M
N
9
/
H
R
Z
+
/
f
P
o
D
T
L
5
J
0
Z
5
x
A
J
8
i
B
Z
y
i
g
x
V
g
p
D
Q
c
x
j
n
J
Z
X
1
e
h
0
1
P
b
8
j
j
8
F
X
i
R
B
Q
z
z
U
4
G
a
0
5
6
y
F
S
U
Y
L
A
d
J
Q
T
r
Q
e
B
n
5
u
o
p
I
o
w
y
i
H
y
g
0
L
D
T
m
h
T
+
Q
B
h
p
Z
K
I
k
B
H
5
T
R
0
h
Y
+
t
k
u
A
0
U
/
Z
J
g
6
f
q
7
4
2
S
C
K
3
H
I
r
a
T
d
U
g
9
7
9
X
i
v
1
6
i
6
w
/
n
r
p
v
0
I
i
q
Z
z
A
s
D
k
s
6
O
p
w
X
H
J
s
N
1
K
z
h
h
C
q
j
h
Y
0
s
I
V
c
z
m
x
/
S
R
K
E
K
N
7
c
5
1
Q
w
U
S
X
m
g
m
B
J
F
J
G
d
J
q
G
E
R
l
G
S
q
B
v
a
C
q
X
N
t
c
M
N
/
T
I
u
m
f
d
g
K
/
E
9
y
e
e
V
2
/
6
b
C
F
D
t
E
R
O
k
E
B
O
k
d
d
d
I
1
u
U
A
9
R
l
K
N
X
9
I
b
e
n
Q
/
n
0
/
l
y
J
r
P
R
J
a
f
Z
O
U
B
/
4
H
z
/
A
O
4
N
p
X
E
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
/
P
P
w
Q
n
S
y
q
T
E
W
T
L
t
+
U
W
B
I
Z
k
p
v
Y
y
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
x
4
0
K
O
C
r
Y
U
m
l
M
3
m
R
R
d
3
N
2
F
3
o
5
S
Q
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
N
m
4
O
2
D
i
w
M
M
+
/
t
G
y
b
O
O
d
P
G
9
y
f
O
0
v
L
K
6
t
p
6
a
8
P
d
3
N
r
e
2
W
3
v
7
f
d
1
V
i
g
K
P
Z
r
x
T
A
1
i
o
o
E
z
C
T
3
D
D
I
d
B
r
o
C
I
m
M
N
9
/
H
R
Z
+
/
f
P
o
D
T
L
5
J
0
Z
5
x
A
J
8
i
B
Z
y
i
g
x
V
g
p
D
Q
c
x
j
n
J
Z
X
1
e
h
0
1
P
b
8
j
j
8
F
X
i
R
B
Q
z
z
U
4
G
a
0
5
6
y
F
S
U
Y
L
A
d
J
Q
T
r
Q
e
B
n
5
u
o
p
I
o
w
y
i
H
y
g
0
L
D
T
m
h
T
+
Q
B
h
p
Z
K
I
k
B
H
5
T
R
0
h
Y
+
t
k
u
A
0
U
/
Z
J
g
6
f
q
7
4
2
S
C
K
3
H
I
r
a
T
d
U
g
9
7
9
X
i
v
1
6
i
6
w
/
n
r
p
v
0
I
i
q
Z
z
A
s
D
k
s
6
O
p
w
X
H
J
s
N
1
K
z
h
h
C
q
j
h
Y
0
s
I
V
c
z
m
x
/
S
R
K
E
K
N
7
c
5
1
Q
w
U
S
X
m
g
m
B
J
F
J
G
d
J
q
G
E
R
l
G
S
q
B
v
a
C
q
X
N
t
c
M
N
/
T
I
u
m
f
d
g
K
/
E
9
y
e
e
V
2
/
6
b
C
F
D
t
E
R
O
k
E
B
O
k
d
d
d
I
1
u
U
A
9
R
l
K
N
X
9
I
b
e
n
Q
/
n
0
/
l
y
J
r
P
R
J
a
f
Z
O
U
B
/
4
H
z
/
A
O
4
N
p
X
E
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
/
P
P
w
Q
n
S
y
q
T
E
W
T
L
t
+
U
W
B
I
Z
k
p
v
Y
y
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
1
a
O
X
x
S
B
4
K
o
k
I
e
i
x
4
0
K
O
C
r
Y
U
m
l
M
3
m
R
R
d
3
N
2
F
3
o
5
S
Q
v
+
F
V
z
/
4
a
b
9
K
r
v
8
R
N
m
4
O
2
D
i
w
M
M
+
/
t
G
y
b
O
O
d
P
G
9
y
f
O
0
v
L
K
6
t
p
6
a
8
P
d
3
N
r
e
2
W
3
v
7
f
d
1
V
i
g
K
P
Z
r
x
T
A
1
i
o
o
E
z
C
T
3
D
D
I
d
B
r
o
C
I
m
M
N
9
/
H
R
Z
+
/
f
P
o
D
T
L
5
J
0
Z
5
x
A
J
8
i
B
Z
y
i
g
x
V
g
p
D
Q
c
x
j
n
J
Z
X
1
e
h
0
1
P
b
8
j
j
8
F
X
i
R
B
Q
z
z
U
4
G
a
0
5
6
y
F
S
U
Y
L
A
d
J
Q
T
r
Q
e
B
n
5
u
o
p
I
o
w
y
i
H
y
g
0
L
D
T
m
h
T
+
Q
B
h
p
Z
K
I
k
B
H
5
T
R
0
h
Y
+
t
k
u
A
0
U
/
Z
J
g
6
f
q
7
4
2
S
C
K
3
H
I
r
a
T
d
U
g
9
7
9
X
i
v
1
6
i
6
w
/
n
r
p
v
0
I
i
q
Z
z
A
s
D
k
s
6
O
p
w
X
H
J
s
N
1
K
z
h
h
C
q
j
h
Y
0
s
I
V
c
z
m
x
/
S
R
K
E
K
N
7
c
5
1
Q
w
U
S
X
m
g
m
B
J
F
J
G
d
J
q
G
E
R
l
G
S
q
B
v
a
C
q
X
N
t
c
M
N
/
T
I
u
m
f
d
g
K
/
E
9
y
e
e
V
2
/
6
b
C
F
D
t
E
R
O
k
E
B
O
k
d
d
d
I
1
u
U
A
9
R
l
K
N
X
9
I
b
e
n
Q
/
n
0
/
l
y
J
r
P
R
J
a
f
Z
O
U
B
/
4
H
z
/
A
O
4
N
p
X
E
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
a
i
7
/
g
5
L
8
U
P
D
b
t
a
X
/
L
T
5
9
o
J
d
W
T
v
4
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
8
6
F
H
B
V
q
G
7
l
G
z
2
r
Q
1
N
s
k
u
S
V
c
q
y
f
8
O
r
n
v
0
1
3
q
R
X
f
4
n
Z
t
g
e
t
D
g
S
G
m
f
f
y
h
o
l
z
w
Y
0
N
g
o
n
X
W
F
p
e
a
a
6
2
1
v
z
1
j
c
2
t
7
Z
3
d
v
Z
7
J
C
s
2
g
y
z
K
R
6
Y
e
Y
G
h
B
c
Q
d
d
y
K
+
A
h
1
0
B
l
L
O
A
+
H
l
3
W
/
v
0
T
a
M
M
z
d
W
f
H
O
U
S
S
P
i
q
e
c
k
a
t
k
8
J
Q
U
j
u
M
0
/
K
q
G
p
D
B
T
j
v
o
B
F
P
g
v
4
T
M
S
R
v
N
c
T
P
Y
9
Z
p
h
k
r
F
C
g
r
J
M
U
G
P
6
J
M
h
t
V
F
J
t
O
R
N
Q
+
W
F
h
I
K
d
s
R
B
+
h
7
6
i
i
E
k
x
U
T
k
N
X
+
M
g
p
C
U
4
z
7
Z
6
y
e
K
r
+
3
C
i
p
N
G
Y
s
Y
z
d
Z
h
z
S
L
X
i
3
+
6
y
W
m
/
n
D
h
u
k
3
P
o
5
K
r
v
L
C
g
2
O
x
4
W
g
h
s
M
1
y
3
g
h
O
u
g
V
k
x
d
o
Q
y
z
V
1
+
z
I
Z
U
U
2
Z
d
d
7
4
f
a
l
D
w
z
D
I
p
q
U
r
K
k
F
V
9
E
p
V
l
q
C
V
u
k
6
r
y
X
X
N
k
s
a
e
/
p
H
f
S
I
U
G
H
3
J
6
2
L
4
J
5
h
y
1
0
g
A
7
R
M
S
L
o
D
F
2
g
a
3
S
D
u
o
i
h
H
L
2
g
V
/
T
m
v
X
s
f
3
q
c
3
m
Y
0
2
v
P
n
O
P
v
o
F
7
+
s
b
7
F
S
l
c
A
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
a
i
7
/
g
5
L
8
U
P
D
b
t
a
X
/
L
T
5
9
o
J
d
W
T
v
4
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
8
6
F
H
B
V
q
G
7
l
G
z
2
r
Q
1
N
s
k
u
S
V
c
q
y
f
8
O
r
n
v
0
1
3
q
R
X
f
4
n
Z
t
g
e
t
D
g
S
G
m
f
f
y
h
o
l
z
w
Y
0
N
g
o
n
X
W
F
p
e
a
a
6
2
1
v
z
1
j
c
2
t
7
Z
3
d
v
Z
7
J
C
s
2
g
y
z
K
R
6
Y
e
Y
G
h
B
c
Q
d
d
y
K
+
A
h
1
0
B
l
L
O
A
+
H
l
3
W
/
v
0
T
a
M
M
z
d
W
f
H
O
U
S
S
P
i
q
e
c
k
a
t
k
8
J
Q
U
j
u
M
0
/
K
q
G
p
D
B
T
j
v
o
B
F
P
g
v
4
T
M
S
R
v
N
c
T
P
Y
9
Z
p
h
k
r
F
C
g
r
J
M
U
G
P
6
J
M
h
t
V
F
J
t
O
R
N
Q
+
W
F
h
I
K
d
s
R
B
+
h
7
6
i
i
E
k
x
U
T
k
N
X
+
M
g
p
C
U
4
z
7
Z
6
y
e
K
r
+
3
C
i
p
N
G
Y
s
Y
z
d
Z
h
z
S
L
X
i
3
+
6
y
W
m
/
n
D
h
u
k
3
P
o
5
K
r
v
L
C
g
2
O
x
4
W
g
h
s
M
1
y
3
g
h
O
u
g
V
k
x
d
o
Q
y
z
V
1
+
z
I
Z
U
U
2
Z
d
d
7
4
f
a
l
D
w
z
D
I
p
q
U
r
K
k
F
V
9
E
p
V
l
q
C
V
u
k
6
r
y
X
X
N
k
s
a
e
/
p
H
f
S
I
U
G
H
3
J
6
2
L
4
J
5
h
y
1
0
g
A
7
R
M
S
L
o
D
F
2
g
a
3
S
D
u
o
i
h
H
L
2
g
V
/
T
m
v
X
s
f
3
q
c
3
m
Y
0
2
v
P
n
O
P
v
o
F
7
+
s
b
7
F
S
l
c
A
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
a
i
7
/
g
5
L
8
U
P
D
b
t
a
X
/
L
T
5
9
o
J
d
W
T
v
4
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
8
6
F
H
B
V
q
G
7
l
G
z
2
r
Q
1
N
s
k
u
S
V
c
q
y
f
8
O
r
n
v
0
1
3
q
R
X
f
4
n
Z
t
g
e
t
D
g
S
G
m
f
f
y
h
o
l
z
w
Y
0
N
g
o
n
X
W
F
p
e
a
a
6
2
1
v
z
1
j
c
2
t
7
Z
3
d
v
Z
7
J
C
s
2
g
y
z
K
R
6
Y
e
Y
G
h
B
c
Q
d
d
y
K
+
A
h
1
0
B
l
L
O
A
+
H
l
3
W
/
v
0
T
a
M
M
z
d
W
f
H
O
U
S
S
P
i
q
e
c
k
a
t
k
8
J
Q
U
j
u
M
0
/
K
q
G
p
D
B
T
j
v
o
B
F
P
g
v
4
T
M
S
R
v
N
c
T
P
Y
9
Z
p
h
k
r
F
C
g
r
J
M
U
G
P
6
J
M
h
t
V
F
J
t
O
R
N
Q
+
W
F
h
I
K
d
s
R
B
+
h
7
6
i
i
E
k
x
U
T
k
N
X
+
M
g
p
C
U
4
z
7
Z
6
y
e
K
r
+
3
C
i
p
N
G
Y
s
Y
z
d
Z
h
z
S
L
X
i
3
+
6
y
W
m
/
n
D
h
u
k
3
P
o
5
K
r
v
L
C
g
2
O
x
4
W
g
h
s
M
1
y
3
g
h
O
u
g
V
k
x
d
o
Q
y
z
V
1
+
z
I
Z
U
U
2
Z
d
d
7
4
f
a
l
D
w
z
D
I
p
q
U
r
K
k
F
V
9
E
p
V
l
q
C
V
u
k
6
r
y
X
X
N
k
s
a
e
/
p
H
f
S
I
U
G
H
3
J
6
2
L
4
J
5
h
y
1
0
g
A
7
R
M
S
L
o
D
F
2
g
a
3
S
D
u
o
i
h
H
L
2
g
V
/
T
m
v
X
s
f
3
q
c
3
m
Y
0
2
v
P
n
O
P
v
o
F
7
+
s
b
7
F
S
l
c
A
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
a
i
7
/
g
5
L
8
U
P
D
b
t
a
X
/
L
T
5
9
o
J
d
W
T
v
4
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
x
W
r
X
X
9
1
q
O
X
Y
B
E
8
l
Y
0
I
e
h
Q
8
6
F
H
B
V
q
G
7
l
G
z
2
r
Q
1
N
s
k
u
S
V
c
q
y
f
8
O
r
n
v
0
1
3
q
R
X
f
4
n
Z
t
g
e
t
D
g
S
G
m
f
f
y
h
o
l
z
w
Y
0
N
g
o
n
X
W
F
p
e
a
a
6
2
1
v
z
1
j
c
2
t
7
Z
3
d
v
Z
7
J
C
s
2
g
y
z
K
R
6
Y
e
Y
G
h
B
c
Q
d
d
y
K
+
A
h
1
0
B
l
L
O
A
+
H
l
3
W
/
v
0
T
a
M
M
z
d
W
f
H
O
U
S
S
P
i
q
e
c
k
a
t
k
8
J
Q
U
j
u
M
0
/
K
q
G
p
D
B
T
j
v
o
B
F
P
g
v
4
T
M
S
R
v
N
c
T
P
Y
9
Z
p
h
k
r
F
C
g
r
J
M
U
G
P
6
J
M
h
t
V
F
J
t
O
R
N
Q
+
W
F
h
I
K
d
s
R
B
+
h
7
6
i
i
E
k
x
U
T
k
N
X
+
M
g
p
C
U
4
z
7
Z
6
y
e
K
r
+
3
C
i
p
N
G
Y
s
Y
z
d
Z
h
z
S
L
X
i
3
+
6
y
W
m
/
n
D
h
u
k
3
P
o
5
K
r
v
L
C
g
2
O
x
4
W
g
h
s
M
1
y
3
g
h
O
u
g
V
k
x
d
o
Q
y
z
V
1
+
z
I
Z
U
U
2
Z
d
d
7
4
f
a
l
D
w
z
D
I
p
q
U
r
K
k
F
V
9
E
p
V
l
q
C
V
u
k
6
r
y
X
X
N
k
s
a
e
/
p
H
f
S
I
U
G
H
3
J
6
2
L
4
J
5
h
y
1
0
g
A
7
R
M
S
L
o
D
F
2
g
a
3
S
D
u
o
i
h
H
L
2
g
V
/
T
m
v
X
s
f
3
q
c
3
m
Y
0
2
v
P
n
O
P
v
o
F
7
+
s
b
7
F
S
l
c
A
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
b
K
6
S
y
s
y
o
0
z
W
n
L
8
d
t
S
f
O
h
y
h
h
e
d
f
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
z
6
7
f
r
V
6
t
F
L
s
A
i
e
y
k
Y
E
P
R
a
8
9
F
j
B
t
k
J
3
K
d
n
s
W
w
0
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
+
L
V
X
2
K
2
7
U
F
b
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
Z
e
3
s
r
q
2
v
r
G
5
t
e
3
v
7
O
7
t
H
z
S
a
h
w
O
T
F
Z
p
B
n
2
U
i
0
3
c
x
N
S
C
4
g
r
7
l
V
s
B
d
r
o
H
K
W
M
A
w
f
r
y
u
/
e
E
T
a
M
M
z
d
W
s
n
O
U
S
S
3
i
u
e
c
k
a
t
k
8
J
Q
U
v
s
Q
p
2
W
3
G
p
N
x
o
x
W
0
g
y
n
w
M
i
F
z
0
k
J
z
9
M
Z
N
b
y
N
M
M
l
Z
I
U
J
Y
J
a
s
y
I
B
L
m
N
S
q
o
t
Z
w
I
q
P
y
w
M
5
J
Q
9
0
n
s
Y
O
a
q
o
B
B
O
V
0
9
A
V
P
n
V
K
g
t
N
M
u
6
c
s
n
q
q
/
N
0
o
q
j
Z
n
I
2
E
3
W
I
c
2
i
V
4
v
/
e
o
m
p
P
1
y
4
b
t
O
r
q
O
Q
q
L
y
w
o
N
j
u
e
F
g
L
b
D
N
e
t
4
I
R
r
Y
F
Z
M
H
K
F
M
c
5
c
f
s
w
e
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
R
i
c
o
y
1
B
K
3
S
F
X
5
r
j
m
y
2
N
M
y
G
Z
y
3
S
d
A
m
N
x
e
t
T
j
D
v
c
A
s
d
o
x
N
0
h
g
i
6
R
B
3
U
R
T
3
U
R
w
z
l
6
A
W
9
o
j
f
v
3
f
v
w
P
r
2
v
2
e
i
K
N
9
8
5
Q
n
/
g
f
f
8
A
7
h
C
l
c
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
b
K
6
S
y
s
y
o
0
z
W
n
L
8
d
t
S
f
O
h
y
h
h
e
d
f
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
z
6
7
f
r
V
6
t
F
L
s
A
i
e
y
k
Y
E
P
R
a
8
9
F
j
B
t
k
J
3
K
d
n
s
W
w
0
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
+
L
V
X
2
K
2
7
U
F
b
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
Z
e
3
s
r
q
2
v
r
G
5
t
e
3
v
7
O
7
t
H
z
S
a
h
w
O
T
F
Z
p
B
n
2
U
i
0
3
c
x
N
S
C
4
g
r
7
l
V
s
B
d
r
o
H
K
W
M
A
w
f
r
y
u
/
e
E
T
a
M
M
z
d
W
s
n
O
U
S
S
3
i
u
e
c
k
a
t
k
8
J
Q
U
v
s
Q
p
2
W
3
G
p
N
x
o
x
W
0
g
y
n
w
M
i
F
z
0
k
J
z
9
M
Z
N
b
y
N
M
M
l
Z
I
U
J
Y
J
a
s
y
I
B
L
m
N
S
q
o
t
Z
w
I
q
P
y
w
M
5
J
Q
9
0
n
s
Y
O
a
q
o
B
B
O
V
0
9
A
V
P
n
V
K
g
t
N
M
u
6
c
s
n
q
q
/
N
0
o
q
j
Z
n
I
2
E
3
W
I
c
2
i
V
4
v
/
e
o
m
p
P
1
y
4
b
t
O
r
q
O
Q
q
L
y
w
o
N
j
u
e
F
g
L
b
D
N
e
t
4
I
R
r
Y
F
Z
M
H
K
F
M
c
5
c
f
s
w
e
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
R
i
c
o
y
1
B
K
3
S
F
X
5
r
j
m
y
2
N
M
y
G
Z
y
3
S
d
A
m
N
x
e
t
T
j
D
v
c
A
s
d
o
x
N
0
h
g
i
6
R
B
3
U
R
T
3
U
R
w
z
l
6
A
W
9
o
j
f
v
3
f
v
w
P
r
2
v
2
e
i
K
N
9
8
5
Q
n
/
g
f
f
8
A
7
h
C
l
c
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
b
K
6
S
y
s
y
o
0
z
W
n
L
8
d
t
S
f
O
h
y
h
h
e
d
f
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
z
6
7
f
r
V
6
t
F
L
s
A
i
e
y
k
Y
E
P
R
a
8
9
F
j
B
t
k
J
3
K
d
n
s
W
w
0
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
+
L
V
X
2
K
2
7
U
F
b
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
Z
e
3
s
r
q
2
v
r
G
5
t
e
3
v
7
O
7
t
H
z
S
a
h
w
O
T
F
Z
p
B
n
2
U
i
0
3
c
x
N
S
C
4
g
r
7
l
V
s
B
d
r
o
H
K
W
M
A
w
f
r
y
u
/
e
E
T
a
M
M
z
d
W
s
n
O
U
S
S
3
i
u
e
c
k
a
t
k
8
J
Q
U
v
s
Q
p
2
W
3
G
p
N
x
o
x
W
0
g
y
n
w
M
i
F
z
0
k
J
z
9
M
Z
N
b
y
N
M
M
l
Z
I
U
J
Y
J
a
s
y
I
B
L
m
N
S
q
o
t
Z
w
I
q
P
y
w
M
5
J
Q
9
0
n
s
Y
O
a
q
o
B
B
O
V
0
9
A
V
P
n
V
K
g
t
N
M
u
6
c
s
n
q
q
/
N
0
o
q
j
Z
n
I
2
E
3
W
I
c
2
i
V
4
v
/
e
o
m
p
P
1
y
4
b
t
O
r
q
O
Q
q
L
y
w
o
N
j
u
e
F
g
L
b
D
N
e
t
4
I
R
r
Y
F
Z
M
H
K
F
M
c
5
c
f
s
w
e
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
R
i
c
o
y
1
B
K
3
S
F
X
5
r
j
m
y
2
N
M
y
G
Z
y
3
S
d
A
m
N
x
e
t
T
j
D
v
c
A
s
d
o
x
N
0
h
g
i
6
R
B
3
U
R
T
3
U
R
w
z
l
6
A
W
9
o
j
f
v
3
f
v
w
P
r
2
v
2
e
i
K
N
9
8
5
Q
n
/
g
f
f
8
A
7
h
C
l
c
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
b
K
6
S
y
s
y
o
0
z
W
n
L
8
d
t
S
f
O
h
y
h
h
e
d
f
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
w
M
x
F
M
z
6
7
f
r
V
6
t
F
L
s
A
i
e
y
k
Y
E
P
R
a
8
9
F
j
B
t
k
J
3
K
d
n
s
W
w
0
m
2
S
X
J
K
m
X
Z
v
+
F
V
z
/
4
a
b
+
L
V
X
2
K
2
7
U
F
b
B
w
L
D
z
H
t
5
w
8
S
5
4
M
Y
G
w
Z
e
3
s
r
q
2
v
r
G
5
t
e
3
v
7
O
7
t
H
z
S
a
h
w
O
T
F
Z
p
B
n
2
U
i
0
3
c
x
N
S
C
4
g
r
7
l
V
s
B
d
r
o
H
K
W
M
A
w
f
r
y
u
/
e
E
T
a
M
M
z
d
W
s
n
O
U
S
S
3
i
u
e
c
k
a
t
k
8
J
Q
U
v
s
Q
p
2
W
3
G
p
N
x
o
x
W
0
g
y
n
w
M
i
F
z
0
k
J
z
9
M
Z
N
b
y
N
M
M
l
Z
I
U
J
Y
J
a
s
y
I
B
L
m
N
S
q
o
t
Z
w
I
q
P
y
w
M
5
J
Q
9
0
n
s
Y
O
a
q
o
B
B
O
V
0
9
A
V
P
n
V
K
g
t
N
M
u
6
c
s
n
q
q
/
N
0
o
q
j
Z
n
I
2
E
3
W
I
c
2
i
V
4
v
/
e
o
m
p
P
1
y
4
b
t
O
r
q
O
Q
q
L
y
w
o
N
j
u
e
F
g
L
b
D
N
e
t
4
I
R
r
Y
F
Z
M
H
K
F
M
c
5
c
f
s
w
e
q
K
b
O
u
O
9
8
P
N
S
h
4
Z
p
m
U
V
C
V
l
y
K
o
R
i
c
o
y
1
B
K
3
S
F
X
5
r
j
m
y
2
N
M
y
G
Z
y
3
S
d
A
m
N
x
e
t
T
j
D
v
c
A
s
d
o
x
N
0
h
g
i
6
R
B
3
U
R
T
3
U
R
w
z
l
6
A
W
9
o
j
f
v
3
f
v
w
P
r
2
v
2
e
i
K
N
9
8
5
Q
n
/
g
f
f
8
A
7
h
C
l
c
Q
=
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
z
t
W
h
a
i
n
N
o
3
W
l
r
Y
s
f
C
P
e
u
t
4
a
p
u
t
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
q
0
c
v
i
0
X
w
V
B
I
R
9
F
j
w
0
m
M
F
2
w
p
N
K
J
v
N
S
7
u
4
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
J
N
e
/
S
V
u
2
h
6
0
d
W
B
h
m
H
l
v
3
z
B
R
x
p
k
2
n
j
d
z
N
j
a
3
t
n
d
2
a
3
v
u
/
s
H
h
0
X
G
9
c
d
L
X
a
a
4
o
9
G
j
K
U
/
U
Y
E
Q
2
c
S
e
g
Z
Z
j
g
8
Z
g
q
I
i
D
g
M
o
q
e
7
y
h
8
8
g
9
I
s
l
Q
9
m
m
k
E
o
y
F
i
y
h
F
F
i
r
B
Q
E
g
p
h
J
l
B
S
d
c
n
Q
1
q
j
e
9
l
j
c
H
X
i
f
+
k
j
T
R
E
t
1
R
w
9
k
J
4
p
T
m
A
q
S
h
n
G
g
9
9
L
3
M
h
A
V
R
h
l
E
O
p
R
v
k
G
j
J
C
n
8
g
Y
h
p
Z
K
I
k
C
H
x
T
x
0
i
S
+
s
E
u
M
k
V
f
Z
J
g
+
f
q
7
4
2
C
C
K
2
n
I
r
K
T
V
U
i
9
6
l
X
i
v
1
6
s
q
w
9
X
r
p
v
k
N
i
y
Y
z
H
I
D
k
i
6
O
J
z
n
H
J
s
V
V
K
z
h
m
C
q
j
h
U
0
s
I
V
c
z
m
x
3
R
C
F
K
H
G
d
u
e
6
g
Q
I
J
L
z
Q
V
g
s
i
4
C
G
g
5
9
M
O
i
C
J
T
A
T
b
8
s
X
d
u
c
v
9
r
T
O
u
l
f
t
X
y
v
5
d
9
f
N
9
v
e
s
s
M
a
O
k
P
n
6
B
L
5
6
A
a
1
U
Q
d
1
U
Q
9
R
l
K
F
X
9
I
b
e
n
Q
/
n
0
/
l
y
Z
o
v
R
D
W
e
5
c
4
r
+
w
P
n
+
A
e
/
J
p
X
I
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
z
t
W
h
a
i
n
N
o
3
W
l
r
Y
s
f
C
P
e
u
t
4
a
p
u
t
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
q
0
c
v
i
0
X
w
V
B
I
R
9
F
j
w
0
m
M
F
2
w
p
N
K
J
v
N
S
7
u
4
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
J
N
e
/
S
V
u
2
h
6
0
d
W
B
h
m
H
l
v
3
z
B
R
x
p
k
2
n
j
d
z
N
j
a
3
t
n
d
2
a
3
v
u
/
s
H
h
0
X
G
9
c
d
L
X
a
a
4
o
9
G
j
K
U
/
U
Y
E
Q
2
c
S
e
g
Z
Z
j
g
8
Z
g
q
I
i
D
g
M
o
q
e
7
y
h
8
8
g
9
I
s
l
Q
9
m
m
k
E
o
y
F
i
y
h
F
F
i
r
B
Q
E
g
p
h
J
l
B
S
d
c
n
Q
1
q
j
e
9
l
j
c
H
X
i
f
+
k
j
T
R
E
t
1
R
w
9
k
J
4
p
T
m
A
q
S
h
n
G
g
9
9
L
3
M
h
A
V
R
h
l
E
O
p
R
v
k
G
j
J
C
n
8
g
Y
h
p
Z
K
I
k
C
H
x
T
x
0
i
S
+
s
E
u
M
k
V
f
Z
J
g
+
f
q
7
4
2
C
C
K
2
n
I
r
K
T
V
U
i
9
6
l
X
i
v
1
6
s
q
w
9
X
r
p
v
k
N
i
y
Y
z
H
I
D
k
i
6
O
J
z
n
H
J
s
V
V
K
z
h
m
C
q
j
h
U
0
s
I
V
c
z
m
x
3
R
C
F
K
H
G
d
u
e
6
g
Q
I
J
L
z
Q
V
g
s
i
4
C
G
g
5
9
M
O
i
C
J
T
A
T
b
8
s
X
d
u
c
v
9
r
T
O
u
l
f
t
X
y
v
5
d
9
f
N
9
v
e
s
s
M
a
O
k
P
n
6
B
L
5
6
A
a
1
U
Q
d
1
U
Q
9
R
l
K
F
X
9
I
b
e
n
Q
/
n
0
/
l
y
Z
o
v
R
D
W
e
5
c
4
r
+
w
P
n
+
A
e
/
J
p
X
I
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
z
t
W
h
a
i
n
N
o
3
W
l
r
Y
s
f
C
P
e
u
t
4
a
p
u
t
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
q
0
c
v
i
0
X
w
V
B
I
R
9
F
j
w
0
m
M
F
2
w
p
N
K
J
v
N
S
7
u
4
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
J
N
e
/
S
V
u
2
h
6
0
d
W
B
h
m
H
l
v
3
z
B
R
x
p
k
2
n
j
d
z
N
j
a
3
t
n
d
2
a
3
v
u
/
s
H
h
0
X
G
9
c
d
L
X
a
a
4
o
9
G
j
K
U
/
U
Y
E
Q
2
c
S
e
g
Z
Z
j
g
8
Z
g
q
I
i
D
g
M
o
q
e
7
y
h
8
8
g
9
I
s
l
Q
9
m
m
k
E
o
y
F
i
y
h
F
F
i
r
B
Q
E
g
p
h
J
l
B
S
d
c
n
Q
1
q
j
e
9
l
j
c
H
X
i
f
+
k
j
T
R
E
t
1
R
w
9
k
J
4
p
T
m
A
q
S
h
n
G
g
9
9
L
3
M
h
A
V
R
h
l
E
O
p
R
v
k
G
j
J
C
n
8
g
Y
h
p
Z
K
I
k
C
H
x
T
x
0
i
S
+
s
E
u
M
k
V
f
Z
J
g
+
f
q
7
4
2
C
C
K
2
n
I
r
K
T
V
U
i
9
6
l
X
i
v
1
6
s
q
w
9
X
r
p
v
k
N
i
y
Y
z
H
I
D
k
i
6
O
J
z
n
H
J
s
V
V
K
z
h
m
C
q
j
h
U
0
s
I
V
c
z
m
x
3
R
C
F
K
H
G
d
u
e
6
g
Q
I
J
L
z
Q
V
g
s
i
4
C
G
g
5
9
M
O
i
C
J
T
A
T
b
8
s
X
d
u
c
v
9
r
T
O
u
l
f
t
X
y
v
5
d
9
f
N
9
v
e
s
s
M
a
O
k
P
n
6
B
L
5
6
A
a
1
U
Q
d
1
U
Q
9
R
l
K
F
X
9
I
b
e
n
Q
/
n
0
/
l
y
Z
o
v
R
D
W
e
5
c
4
r
+
w
P
n
+
A
e
/
J
p
X
I
=
<
/
l
a
t
e
x
i
t
>
<
l
a
t
e
x
i
t
 
s
h
a
1
_
b
a
s
e
6
4
=
"
z
t
W
h
a
i
n
N
o
3
W
l
r
Y
s
f
C
P
e
u
t
4
a
p
u
t
I
=
"
>
A
A
A
C
K
H
i
c
b
V
B
N
S
8
N
A
F
N
z
4
W
e
N
X
q
0
c
v
i
0
X
w
V
B
I
R
9
F
j
w
0
m
M
F
2
w
p
N
K
J
v
N
S
7
u
4
u
w
m
7
G
6
W
E
/
A
2
v
e
v
b
X
e
J
N
e
/
S
V
u
2
h
6
0
d
W
B
h
m
H
l
v
3
z
B
R
x
p
k
2
n
j
d
z
N
j
a
3
t
n
d
2
a
3
v
u
/
s
H
h
0
X
G
9
c
d
L
X
a
a
4
o
9
G
j
K
U
/
U
Y
E
Q
2
c
S
e
g
Z
Z
j
g
8
Z
g
q
I
i
D
g
M
o
q
e
7
y
h
8
8
g
9
I
s
l
Q
9
m
m
k
E
o
y
F
i
y
h
F
F
i
r
B
Q
E
g
p
h
J
l
B
S
d
c
n
Q
1
q
j
e
9
l
j
c
H
X
i
f
+
k
j
T
R
E
t
1
R
w
9
k
J
4
p
T
m
A
q
S
h
n
G
g
9
9
L
3
M
h
A
V
R
h
l
E
O
p
R
v
k
G
j
J
C
n
8
g
Y
h
p
Z
K
I
k
C
H
x
T
x
0
i
S
+
s
E
u
M
k
V
f
Z
J
g
+
f
q
7
4
2
C
C
K
2
n
I
r
K
T
V
U
i
9
6
l
X
i
v
1
6
s
q
w
9
X
r
p
v
k
N
i
y
Y
z
H
I
D
k
i
6
O
J
z
n
H
J
s
V
V
K
z
h
m
C
q
j
h
U
0
s
I
V
c
z
m
x
3
R
C
F
K
H
G
d
u
e
6
g
Q
I
J
L
z
Q
V
g
s
i
4
C
G
g
5
9
M
O
i
C
J
T
A
T
b
8
s
X
d
u
c
v
9
r
T
O
u
l
f
t
X
y
v
5
d
9
f
N
9
v
e
s
s
M
a
O
k
P
n
6
B
L
5
6
A
a
1
U
Q
d
1
U
Q
9
R
l
K
F
X
9
I
b
e
n
Q
/
n
0
/
l
y
Z
o
v
R
D
W
e
5
c
4
r
+
w
P
n
+
A
e
/
J
p
X
I
=
<
/
l
a
t
e
x
i
t
>
Phenomenon

R2R

TOUCHDOWN

Overall

Navigation

SDR

Example from TOUCHDOWN

c

µ

c

µ

c

µ

c

µ

Reference to
unique entity
Coreference
Comparison
Sequencing
Count
Allocentric
spatial relation
Egocentric
spatial relation
Imperative
Direction
Temporal condition
State veriﬁcation

25

8

1

4

4

5

20

25

22

7

2

3.7

0.5
0.0
0.2
0.2

0.2

1.2

4.0
2.8
0.4
0.1

25

22

6

22

11

25

25

25

24

21

21

10.7

2.4
0.3
1.9
0.5

2.9

4.0

5.3
3.7
1.9
1.8

25

15

3

21

9

17

23

25

24

21

18

9.2

1.1
0.1
1.6
0.4

1.2

3.6

5.2
3.7
1.9
1.5

25

22

5

9

8

25

19

4

1

2

16

3.2

1.5
0.2
0.4
0.3

2.2

1.1

0.2
0.0
0.1
0.8

. . . You’ll pass three trashcans on your left . . .

. . . a brownish colored brick building with a black fence around it. . .
. . . The bear is in the middle of the closest tire.
. . . Turn left at the next intersection . . .
. . . there are two tiny green signs you can see in the distance . . .

. . . There is a ﬁre hydrant, the bear is on top

. . . up ahead there is some ﬂag poles on your right hand side. . .

. . . Enter the next intersection and stop . . .
. . . Turn left. Continue forward . . .
. . . Follow the road until you see a school on your right. . .
. . . You should see a small bridge ahead . . .

Table 3. Linguistic analysis of 25 randomly sampled development examples in TOUCHDOWN and R2R. We annotate each example for
the presence and count of each phenomenon. We distinguish statistics for the entire text, navigation, and SDR segments in TOUCHDOWN.
c is the number of instructions out of the 25 containing at least one example of the phenomenon; µ is the mean number of times each
phenomenon appears in each of the 25 instructions.

the center pixel; (c) AVERAGE: predict the average pixel,
computed over the training set. In addition to a two-level
LINGUNET (m = 2), we evaluate three learning baselines:
CONCAT, CONCATCONV, and TEXT2CONV. The ﬁrst two
compute a RESNET18 feature map representation of the im-
age and then fuse it with the text representation to compute
pixel probabilities. The third uses the text to compute ker-
nels to convolve over the RESNET18 image representation.
The Supplementary Material provides further details.

6.3. Results

Table 4 shows development and test results. The low per-
formance of the non-learning baselines illustrates the chal-
lenge of the task. We also experiment with a UNET archi-
tecture that is similar to our LINGUNET but has no access to
the language. This result illustrates that visual biases exist
in the data, but only enable relatively low performance. All
the learning systems outperform the non-learning baselines
and the UNET, with LINGUNET performing best.

Figure 7 shows pixel-level predictions using LIN-
GUNET. The distribution prediction is visualized as a
heatmap overlaid on the image. LINGUNET often success-
fully solves descriptions anchored in objects that are unique
in the image, such the ﬁre hydrant at the top image. The
lower example is more challenging. While the model cor-
rectly reasons that Touchdown is on a light just above the
doorway, it fails to ﬁnd the exact door. Instead, the prob-
ability distribution is shared between multiple similar loca-
tions, the space above three other doors in the image.

7. Navigation Baselines

7.1. Methods and Setup

Method

A/C@40px

A/C@80px

A/C@120px

Dist

Development Results

RANDOM
CENTER
AVERAGE
UNET
CONCAT
CONCATCONV
TEXT2CONV
LINGUNET

Test Results

RANDOM
CENTER
AVERAGE
TEXT2CONV
LINGUNET

0.18 / 0.00
0.55 / 0.07
1.88 / 0.07
10.86 / 2.69
13.70 / 3.22
13.56 / 3.24
24.03 / 7.60
24.81 / 7.73

0.59 / 0.00
1.62 / 0.07
4.22 / 0.29
13.94 / 3.31
17.85 / 4.46
18.00 / 4.58
29.36 / 10.02
32.83 / 13.00

1.28 / 0.00
3.26 / 0.36
7.14 / 0.79
16.69 / 3.91
21.16 / 5.47
21.42 / 5.71
32.60 / 11.42
36.44 / 15.01

0.21 / 0.00
0.31 / 0.00
2.43 / 0.07
24.82 / 8.21
26.11 / 8.80

0.78 / 0.00
1.61 / 0.21
5.21 / 0.57

1.89 / 0.00
3.93 / 0.57
7.96 / 1.06

30.40 / 11.73
34.59 / 14.57

34.13 / 13.32
37.81 / 16.11

1185

777

762

957

917

918

783

729

1179

759

744

747

708

Table 4. Development and test results on the SDR task. We report
accuracy/consistency (A/C) with different thresholds (40, 80, and
120) and mean distance error.

non-stop actions uniformly until reaching the action hori-
zon; and (c) FREQUENT: agent always takes the most
frequent action in the training set (FORWARD). We also
evaluate two recent navigation models:
(a) GA: gated-
attention [6]; and (b) RCONCAT: a recently introduced
model for landmark-based navigation in an environment
that uses Street View images [24]. We represent the input
images with RESNET18 features similar to the SDR task.

We use asynchronous training using multiple clients
to generate rollouts on different partitions of the training
data. We compute the gradients and updates using HOG-
WILD! [27] and ADAM learning rates [17]. We use super-
vised learning by maximizing the log-likelihood of actions
in the reference demonstrations.

We evaluate three non-learning baselines:

(a) STOP:
agent stops immediately; (b) RANDOM: Agent samples

The details of the models, learning, and hyperparameters

are provided in the Supplementary Material.

12544

there will be a white/grey van parked on the right side of the road, and right behind the van on the walkway, there is a
black ﬁre hydrant with silver top, the touchdown is on the silver part of the ﬁre hydrant.

a black doorway with red brick to the right of it, and green brick to the left of it. it has a light just above the doorway,
and on that light is where you will ﬁnd touchdown.

Figure 7. SDR pixel-level predictions with LINGUNET. Red-overlaid pixels indicate the Gaussian smoothed target location. Bright green
overlay indicates the model’s predicted probability distribution over pixels.

7.2. Results

Table 7 shows development and test results for our three
valuation metrics (Section 3.1). The STOP, FREQUENT and
RANDOM illustrate the complexity of the task. The learned
baselines perform better. We observe that RCONCAT out-
performs GA across all three metrics. In general though,
the performance illustrates the challenge of the task.

8. Complete Task Performance

We use a simple pipeline combination of the best mod-
els of the SDR and navigation tasks to complete the full
task. Task completion is measured as ﬁnding Touchdown.
We observe an accuracy of 4.5% for a threshold of 80px.
In contrast, human performance is signiﬁcantly higher. We
estimate human performance using our annotation statis-
tics [32]. To avoid spam and impossible examples, we con-
sider only examples that were successfully validated. We
then measure the performance of workers that completed
over 30 tasks for these valid examples. This includes 55
workers. Because some examples required multiple tries to
validate this set includes tasks that workers failed to execute
but were later validated. The mean performance across this
set of workers using the set of valid tasks is 92% accuracy.

9. Data Distribution and Licensing

We release the environment graph as panorama IDs and
edges, scripts to download the RGB panoramas using the
Google API, the collected data, and our code at touch-
down.ai. These parts of the data are released with a CC-
BY 4.0 license. Retention of downloaded panoramas should
follow Google’s policies. We also release RESNET18 im-
age features of the RGB panoramas through a request form.
The complete license is available with the data.

Method

TC

SPD

SED

Development Results

STOP
FREQUENT
RANDOM
GA
RCONCAT

Test Results

STOP
FREQUENT
RANDOM
GA
RCONCAT

0.0
0.1
0.2
7.9
9.8

0.0
0.0
0.2
5.5
10.7

26.7
52.3
26.8
21.5
19.1

27.0
53.1
26.9
21.3
19.5

0.0
0.001
0.001
0.077
0.094

0.0
0.0
0.001
0.054
0.104

Table 5. Development and test navigation results.

10. Conclusion

We introduce TOUCHDOWN, a dataset for natural lan-
guage navigation and spatial reasoning using real-life vi-
sual observations. We deﬁne two tasks that require address-
ing a diverse set of reasoning and learning challenges. Our
linguistically-driven analysis shows the data presents com-
plex spatial reasoning challenges. This illustrates the bene-
ﬁt of using visual input that reﬂects the type of observations
people see in their daily life, and demonstrates the effective-
ness of our goal-driven data collection process.

Acknowledgements

This research was supported by a Google Faculty Award,
NSF award CAREER-1750499, NSF Graduate Research
Fellowship DGE-1650441, and the generosity of Eric and
Wendy Schmidt by recommendation of the Schmidt Futures
program. We wish to thank Jason Baldridge for his exten-
sive help and advice, and Valts Blukis and the anonymous
reviewers for their helpful comments.

12545

References

[1] P. Anderson, A. X. Chang, D. S. Chaplot, A. Dosovitskiy,
S. Gupta, V. Koltun, J. Kosecka, J. Malik, R. Mottaghi,
M. Savva, and A. R. Zamir. On evaluation of embodied nav-
igation agents. CoRR, abs/1807.06757, 2018. 3

[2] P. Anderson, Q. Wu, D. Teney, J. Bruce, M. Johnson,
N. S¨underhauf, I. D. Reid, S. Gould, and A. van den Hen-
gel. Vision-and-Language Navigation: Interpreting visually-
grounded navigation instructions in real environments.
In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, 2018. 1, 2, 5, 6

[3] S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L.
Zitnick, and D. Parikh. VQA: Visual question answering. In
IEEE International Conference on Computer Vision, pages
2425–2433, 2015. 1, 2

[4] Y. Bisk, D. Marcu, and W. Wong. Towards a Dataset for
Human Computer Communication via Grounded Language
Acquisition. In Proceedings of the AAAI Workshop on Sym-
biotic Cognitive Systems, 2016. 1

[5] V. Blukis, D. Misra, R. A. Knepper, and Y. Artzi. Mapping
Navigation Instructions to Continuous Control Actions with
Position Visitation Prediction. In Proceedings of the Confer-
ence on Robot Learning, 2018. 6

[6] D. S. Chaplot, K. M. Sathyendra, R. K. Pasumarthi, D. Ra-
jagopal, and R. Salakhutdinov. Gated-Attention Architec-
tures for Task-Oriented Language Grounding. In Proceed-
ings of the AAAI Conference on Artiﬁcial Intelligence, 2018.
7

[7] D. L. Chen and R. J. Mooney. Learning to interpret natu-
ral language navigation instructions from observations.
In
Proceedings of the National Conference on Artiﬁcial Intelli-
gence, 2011. 11

[8] X. Chen, H. Fang, T.-Y. Lin, R. Vedantam, S. Gupta,
P. Doll´ar, and C. L. Zitnick. Microsoft COCO Captions: Data
Collection and Evaluation Server. CoRR, 2015. 2

[9] A. Das, S. Datta, G. Gkioxari, S. Lee, D. Parikh, and D. Ba-
tra. Embodied Question Answering. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, 2018. 1, 2

[10] H. de Vries, K. Shuster, D. Batra, D. Parikh, J. Weston, and
D. Kiela. Talk the Walk: Navigating New York City through
Grounded Dialogue.
arXiv preprint arXiv:1807.03367,
2018. 2

[11] O. Goldman, V. Latcinnik, E. Nave, A. Globerson, and J. Be-
rant. Weakly supervised semantic parsing with abstract ex-
amples.
In Proceedings of the Annual Meeting of the As-
sociation for Computational Linguistics, pages 1809–1819,
2018. 3

[12] D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox,
and A. Farhadi. IQA: Visual Question Answering in Interac-
tive Environments. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, 2018. 1, 2

[13] Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, and
D. Parikh. Making the V in VQA Matter: Elevating the
Role of Image Understanding in Visual Question Answer-
ing. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, 2017. 2

[14] K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning
for Image Recognition.
In IEEE Conference on Computer
Vision and Pattern Recognition, pages 770–778, 2016. 6, 11
[15] S. Hochreiter and J. Schmidhuber. Long short-term memory.

Neural computation, 9, 1997. 11

[16] S. Kazemzadeh, V. Ordonez, M. Matten, and T. Berg. Refer-
ItGame: Referring to Objects in Photographs of Natural
Scenes.
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing, pages 787–798,
2014. 1, 2, 6

[17] D. Kingma and J. Ba. Adam: A Method for Stochastic Opti-
mization. In Proceedings of the International Conference on
Learning Representations, 2014. 7, 12, 13

[18] N. Kitaev and D. Klein. Where is Misty? Interpreting Spatial
Descriptors by Modeling Regions in Space. In Proceedings
of the Conference on Empirical Methods in Natural Lan-
guage Processing, pages 157–166, 2017. 2

[19] E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and
A. Farhadi. AI2-THOR: An Interactive 3D Environment for
Visual AI. arXiv preprint arXiv:1712.05474, 2017. 1

[20] T.-Y. Lin, M. Maire, S. J. Belongie, L. D. Bourdev, R. B. Gir-
shick, J. Hays, P. Perona, D. Ramanan, P. Doll´ar, and C. L.
Zitnick. Microsoft COCO: Common Objects in Context. In
European Conference on Computer Vision, 2014. 1, 2

[21] M. MacMahon, B. Stankiewics, and B. Kuipers. Walk the
Talk: Connecting Language, Knowledge, Action in Route
Instructions. In Proceedings of the National Conference on
Artiﬁcial Intelligence, 2006. 5, 11, 12

[22] J. Mao, J. Huang, A. Toshev, O. Camburu, A. Yuille, and
K. Murphy. Generation and Comprehension of Unambigu-
ous Object Descriptions. In IEEE Conference on Computer
Vision and Pattern Recognition, pages 11–20, 2016. 1, 2, 6

[23] C. Matuszek, N. FitzGerald, L. S. Zettlemoyer, L. Bo, and
D. Fox. A Joint Model of Language and Perception for
Grounded Attribute Learning. In Proceedings of the Inter-
national Conference on Machine Learning, 2012. 1

[24] P. Mirowski, M. K. Grimes, M. Malinowski, K. M. Hermann,
K. Anderson, D. Teplyashin, K. Simonyan, K. Kavukcuoglu,
A. Zisserman, and R. Hadsell. Learning to Navigate in Cities
without a Map. Advances in Neural Information Processing
Systems, 2018. 7, 12, 13

[25] D. Misra, A. Bennett, V. Blukis, E. Niklasson, M. Shatkhin,
and Y. Artzi. Mapping Instructions to Actions in 3D Envi-
ronments with Visual Goal Prediction. In Proceedings of the
Conference on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics, 2018. 1,
2, 5, 6, 11, 12

[26] D. Misra, J. Langford, and Y. Artzi. Mapping Instruc-
tions and Visual Observations to Actions with Reinforce-
ment Learning. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, pages 1004–
1015, 2017. 2

[27] B. Recht, C. Re, S. Wright, and F. Niu. Hogwild: A
Lock-Free Approach to Parallelizing Stochastic Gradient
Descent. In Advances in Neural Information Processing Sys-
tems, 2011. 7, 13

12546

[28] S. Reed, Z. Akata, H. Lee, and B. Schiele. Learning Deep
Representations of Fine-Grained Visual Descriptions.
In
IEEE Conference on Computer Vision and Pattern Recog-
nition, pages 49–58, 2016. 1, 2

[29] O. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolu-
tional Networks for Biomedical Image Segmentation. CoRR,
abs/1505.04597, 2015. 2, 6

[30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
A. C. Berg, and L. Fei-Fei.
ImageNet Large Scale Visual
Recognition Challenge. International Journal of Computer
Vision, 115(3):211–252, 2015. 11

[31] A. Suhr, M. Lewis, J. Yeh, and Y. Artzi. A Corpus of Nat-

ural Language for Visual Reasoning. In Proceedings of the
Annual Meeting of the Association for Computational Lin-
guistics, pages 217–223, 2017. 2

[32] A. Suhr, S. Zhou, I. F. Zhang, H. Bai, and Y. Artzi. A cor-
pus for reasoning about natural language grounded in pho-
tographs. CoRR, abs/1811.00491, 2018. 2, 8

[33] C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and
Y. Artzi. CHALET: Cornell House Agent Learning Environ-
ment. arXiv preprint arXiv:1801.07357, 2018. 1

[34] C. L. Zitnick and D. Parikh. Bringing Semantics into Focus
Using Visual Abstraction. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
3009–3016, 2013. 1, 2

12547

