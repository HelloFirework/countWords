Min-Max Statistical Alignment for Transfer Learning

Samitha Herath1
1The Australian National University, 2Monash University, 3The University of Sydney

5, and Richard Nock1

4, Mehrtash Harandi2

4, Basura Fernando1

3

4

,

,

,

,

,

4DATA61-CSIRO, Australia

5Human-Centric AI Programme, A*STAR, Singapore

Samitha.Herath@data61.csiro.au, Mehrtash.Harandi@monash.edu,

Fernando Basura@scei.a-star.edu.sg, Richard.Nock@data61.csiro.au

Abstract

A profound idea in learning invariant features for trans-
fer learning is to align statistical properties of the domains.
In practice, this is achieved by minimizing the disparity be-
tween the domains, usually measured in terms of their sta-
tistical properties. We question the capability of this school
of thought and propose to minimize the maximum dispar-
ity between domains. Furthermore, we develop an end-to-
end learning scheme that enables us to beneﬁt from the pro-
posed min-max strategy in training deep models. We show
that the min-max solution can outperform the existing sta-
tistical alignment solutions, and can compete with state-of-
the-art solutions on two challenging learning tasks, namely,
Unsupervised Domain Adaptation (UDA) and Zero-Shot
Learning (ZSL).

1. Introduction

Minimizing the statistical disparity between distributions
is a fundamental approach used to learn domain invariant
features [25, 26, 14]. In this work and in contrast to the pre-
vious attempts, we propose to learn features by minimizing
the maximum statistical disparity. We show that by min-
imizing the maximum (i.e., min-max) statistical disparity,
we can learn better domain invariant features (compared to
features attained by only minimizing the disparities). In par-
ticular, we demonstrate that in Unsupervised Domain Adap-
tation (UDA) [8, 24] and Zero-Shot Learning (ZSL) [31],
the learned features by min-max alignment lead to com-
parable performances to the very involved state-of-the-art
methods speciﬁcally designed to address each task (e.g., ad-
versarial solutions).

Recent techniques for UDA and ZSL aim to learn task-
independent and discriminative features through end-to-end
learning [9, 26, 30]. A prominent idea here is to learn a mu-
tual space where examples from the source and target do-

mains behave similarly from a statistical point of view. For
example, the CORrelation ALignment (CORAL) [25] and
its variants [27, 26] opt to minimize the statistical disparity
of data measured by the second order statistics.

Our idea goes beyond minimizing statistical disparities
and makes use of a novel structure, namely the confusion
network to align distributions in a min-max framework. The
confusion network, as the name implies, is by itself a neural
network. Therefore, the proposed min-max solution can be
seamlessly used in deep learning frameworks for end-to-end
training (see Fig. 1). Our code is available at https://
bitbucket.org/sherath.

One may wonder why min-max? In other words, what
power such a solution endows that a min solution does not.
In learning theory, methods such as SVM [3] , aim at min-
imizing the maximal loss. Nevertheless, very few studies
in deep learning [23, 20] make use of the min-max frame-
work, our paper being one. This can be attributed to the fact
that minimizing a loss can be conveniently achieved using
stochastic techniques.

For the problem of interest in this paper, the min-max
solution has a somehow intuitive meaning. We are inter-
ested in ﬁnding invariant features across domains with mis-
matched statistics. Learning representations by minimiza-
tion may result in degeneracy (e.g., by collapsing the space
into a point). On the other hand, maximization can preserve
the variance of the distributions, avoiding degeneracies.

To visualize the difference between min and min-max
frameworks, we designed a toy example (see Fig. 1) where
the task is to align an input distribution (given in purple,
yellow and red points) to a ﬁxed target distribution (given in
blue). The top row shows the alignment by minimization
according to [26]. In the second row, we aligned the yellow
points, again by minimizing the disparities using the Kull-
backLeibler (KL) divergence. Finally, the third row shows
our min-max alignment. The ﬁgure is self-explanatory, with
the proposed min-max solution showing the most consistent
alignment on all studied cases.

9288

Figure 1. Toy data demonstration (Should be viewed in color). A comparison of aligning the input data, D1 (i.e., Gaussian noise) to
synthetic target data, D0 (given in blue color points) with Deep CORAL [27], minimization of KL divergence and min-max alignment with
KL divergence. (a) The schematic diagram for aligning the output features of f1 with D0 by minimizing a statistical alignment loss (e.g.,
correlation loss as in Deep CORAL, KL divergence). (b) The schematic diagram using the proposed confusion network, g for min-max
alignment of the output features from f1. (c) Comparison of statistically aligned outputs of f1 at the beginning and after training for Deep
CORAL, minimization and Min-max alignment. We provide details of this experiment in our supplementary material.

In summary, our contributions in this paper are;

• We propose min-max statistical alignment for domain
invariant feature learning using a novel confusion net-
work.

• We provide two frameworks to use the proposed statis-

tical alignment for UDA and ZSL.

2. Min-Max Statistical Alignment

In this section, we introduce our proposed min-max so-
lution. We start by describing the notations. Bold capital
letters denote matrices (e.g., X) and bold lower case let-
ters show column vectors (e.g., x). We represent sets with
curled capital letters, (e.g., X ) and their cardinality with | · |
(e.g., |X |). The Frobenius norm of a matrix is shown by
k·kF . We use DKL(P0kP1) to denote the Kullback-Leibler
divergence between two distributions P0 and P1. We use the
notation D to represent a domain (e.g., D0 for domain 0).
For simplicity, we also use this notation D when referring
to the data samples from a domain (e.g., x(0)
i ∈ D0, for
i = 1, 2, 3, · · · , N0 to denote the samples with y(0)
i ∈ D0
being their labels from domain 0.). We consider the di-
mensionality of samples from a domain Dk to be nk (e.g.,
x(0)

i ∈ Rn0 ).
Our objective is to learn two non-linear mappings,
fk(·, θk) : Rnk → Rd, k ∈ {0, 1} to embed samples
from domains Dk, k ∈ {0, 1} to a shared feature space such
that they are statistically aligned . The non-linear mappings
are parametrized by θ0 and θ1 and realized by two neural
networks. In particular, we consider the case where there
is no direct pair-wise correspondences between instances
from the two domains. This is due to the fact that statis-
tical alignment is widely used to address problems such as
UDA and ZSL where associations are not available.

As such, statistical alignment can be performed by min-
imizing a loss reﬂecting the statistical disparity such as
KL-divergence (DKL) between domain feature distribu-
tions.When the feature distribution, Pk of domain k is
i=1 fk(x(k)
parameterized with the mean, µk = 1
)
i
(Nk−1) PNk
) −
and the covariance, Σk =
µk)(fk(x(k)
) − µk)T the statistical misalignment loss, Lu
between D0 and D1 can be expressed using symmetric KL-
divergence as,

Nk PNk
i=1(fk(x(k)

1

i

i

1

Lu =

2(cid:0)DKL(P0kP1) + DKL(P1kP0)(cid:1).

(1)

A widely accepted assumption is to model distributions as
Gaussians, leading to

DKL(P0kP1) =

1

1

2(cid:0)tr(cid:0)Σ−1
+(cid:0)µ1 − µ0(cid:1)T

det Σ0(cid:19)
Σ0(cid:1) + log(cid:18) det Σ1
1 (cid:0)µ1 − µ0(cid:1) − d(cid:1).

Σ−1

(2)

In realizing min-max alignment we propose to make
use of an additional mapping (i.e., the confusion network),
g(·, θg) : Rd → Rp. The inputs to the confusion net-
work are the domain features from the functions f0(·, θ0)
and f1(·, θ1). We refer to the output features of g(·, θg)
as the confused features. We implement the confusion net-
work, g(·, θg) using a neural network parameterized by θg.
Thereafter, we propose to perform the min-max alignment
by optimizing,

min
θ0, θ1

max
θg

˜Lu ,

˜Lu =

1

2(cid:0)DKL( ˜P0k ˜P1) + DKL( ˜P1k ˜P0)(cid:1).

(3)

(4)

with

9289

Case 1Case 3Case 4Case 2Deep CORALMinimizationMin - Max(c)Statistical alignment lossObserved outputMin-max align moduleStatistical alignment lossObserved outputMin align module(a)(b)Before trainingAfter trainingBefore trainingAfter trainingAfter trainingBefore trainingAfter trainingBefore trainingAfter trainingBefore trainingBefore trainingAfter trainingBefore trainingBefore trainingBefore trainingAfter trainingAfter trainingAfter trainingBefore trainingAfter trainingBefore trainingAfter trainingBefore trainingAfter trainingFigure 2. Schematic diagram for the proposed min-max statistical alignment (Best viewed in color). The input domains D0 (square
markers) and D1 (circular markers) are aligned by min-max optimization of the statistical loss ˜Lu.To realize the min-max training we
propose using the additional confusion model, g. We propose accumulation of computed mini-batch moments (i.e., means and covariances)
prior to computing the statistical alignment loss. The statistically aligned features are obtained through the feature extraction models f0 and
f1. We use marker colors to represent the class labels of the instances. To incorporate the min-max optimization we contain our proposed
confusion network between two gradient reversal layers (i.e., grl).

g ◦fk(x(k)

i

),

(5)

2.1. Maximization with the Confusion Network

However, distinct to the deﬁned statistical loss in equa-
tion (1), the feature distributions, ˜Pk , k ∈ {0, 1} are pa-
rameterized with,

˜µk =

˜Σk =

1
Nk

Nk

Xi=1

1

Nk − 1

Nk

Xi=1(cid:16)g ◦fk(x(k)

i

) − ˜µk(cid:17)(cid:16)g ◦fk(x(k)

i

) − ˜µk(cid:17)⊤

.

The objective of the confusion network is to maximize the
statistical disparity (see (3)). Furthermore, we learn f0 and
f1 to minimize the statistical disparity of the confused fea-
tures. Therefore, we perform a minimization of the maxi-
mum statistical disparity between the two domain features.
In a way, our confusion network can be considered as
an attention model. The attention is in particular given for
features that maximizes the statistical disparity between the
domains. The theorem below establishes the condition to
recover minimization as an especial case of the min-max
framework.

Theorem 1. If the confusion function, g is a linear invert-
ible transformation, Q with QQ−1 = Q−1Q = I ∈ Rd×d
then the proposed min-max statistical alignment by confu-
sion is equivalent to statistical alignment by minimization.
Here, d is the dimensionality of the domain input and con-
fused features.

Proof. The proof is provided in the supplementary material
due to space limitations.
(cid:4)

The behaviour of the proposed confusion network is sim-
ilar in spirit to the discriminator in Generative Adversarial
Networks (GANs) [11]. However, unlike the classiﬁcation
objective of the GAN’s discriminator, the confusion net-
work is trained to maximize a statistical misalignment.

To train a Deep Neural Network (DNN), parameters of
the network are updated such that the end loss is minimized.
That is, each parameter is updated in the negative direc-
tion of the gradient of the loss function with respect to it.
However, in the case of the confusion network, we need to
learn the parameters in a way that the end loss is maximized
(see (3)). In other words, we require to perform a gradient
ascent for the confusion network. To seamlessly integrate
this gradient ascent into our solution, we perform a direction
reversal of the back propagated gradients into the confusion
network. For this we use the gradient reversal layer (i.e., grl
layer) of Ganin and Lempitsky, [8]. The grl layer acts as an
identity mapping in the forward pass. However, during the
backward pass it reverses the back-propagated gradient di-
rection by negation. Furthermore, we enclose the confusion
network between two grl layers (see Fig. 2). Thereby, we
make sure that the gradients back-propagated into f0 and
f1 are compatible with gradient descent for minimization.

2.2. Moment Accumulation

Training a network by stochastic optimization is central
to deep learning. In the context of statistical alignment, this
translates into computing statistics (i.e., means and covari-

9290

Statistical alignment lossStatistical Alignment ModuleAligned domain features in the shared spaceInput domainsAccum. momentsAccum. momentsForward PassBackward Pass with Gradient Reversalances) per mini-batch, followed by aligning the mini-batch
statistics. For the min-max framework, we propose to make
use of the accumulated statistics instead. When ˜Σ
and
˜µ(t) are the computed covariance matrix and the mean vec-
tor for mini-batch at iteration t, the accumulated moments,
˜Σ

(t)

accu. are computed as,

(t)
accu. and ˜µ(t)

˜Σ

(t)
accu. = m × ˜Σ
accu. = m × ˜µ(t−1)

(t−1)
accu. + (1 − m) × ˜Σ
,
accu. + (1 − m) × ˜µ(t).

(t)

˜µ(t)

(6)

(7)

Here, 0 ≤ m < 1 is the momentum hyper-parameter for
the accumulation. We integrate this moment accumulation
along with the proposed min-max alignment into a single
statistical alignment module as in Fig. 2. In the supplemen-
tary material, we provide a study of the effect of accumula-
tion.

3. Case studies : Min-Max Statistical Align

In this section, we will show how the min-max frame-
work can be used to address two case studies, namely UDA
and ZSL.

3.1. Case 1 : Unsupervised Domain Adaptation

In UDA, labeled samples from a source domain, Ds
are used to train a classiﬁer to classify unlabeled sam-
ples from the target domain, Dt. Samples from both do-
mains are assumed to share the same set of classes, C =
{1, 2, 3,
· · · , c}. Here, we use letters “s” and “t” to refer
to source and target domains respectively 1.

It is typical to use a two-stream network in deep UDA
where each stream corresponds to a speciﬁc domain (i.e.,
either Ds or Dt). Thereafter, the source domain stream is
trained on classifying labeled source samples and the target
domain stream is trained to generate features that match the
source features distribution [8, 27]. We realize our UDA
model with two deep network streams, hs = softmax ◦ h ◦
fs and ht = softmax ◦ h ◦ ft. Here, hs and ht are the
source and target domain model streams, respectively. The
model, h(·, θh) : Rd → Rc represents a shared classiﬁer
with parameters, θh. The source and target domain feature
extraction models, fs and ft are parameterized with θs and
θt, respectively (see Fig. 3(a) for a schematic).

For UDA, our objective is to jointly learn the shared fea-
ture space and the classiﬁer h(·, θh). Per the discussion
in § 2, the proposed min-max alignment will be used for
learning the shared feature space. We use the softmax cross-
entropy loss on labeled source domain samples to train the
classiﬁer. All in all, the UDA model is trained end-to-end
by optimizing,

min

θs, θt, θh

max
θg

Ld,s + λtLd,t + λu ˜Lu.

(8)

Here, Ld,s is the softmax cross-entropy loss computed
using the labeled source samples, the loss term Ld,t is the
entropy loss,

Ld,t = − Ex∼Dt [ht(x)T log ht(x)],

(9)

computed from unlabeled target domain samples as in [24].
We denote the proposed statistical alignment loss with ˜Lu.
The parameter λu and λt are training hyper-parameters. We
will provide a study on the effect of these parameters in the
supplementary material.

3.2. Case 2 : Zero Shot Learning

ZSL is the problem of identifying instances never seen
during the training. We use C and ˜C to represent the set
of seen and unseen classes, respectively2. We deﬁne the
domain, Ds to contain the labeled training instances from
classes in C. For training, we are provided with semantic
descriptions for all the classes, ˜C ∪ C. Without losing gener-
ality and inline with general practice (e.g., [31]), semantic
descriptions are in the form of attribute vectors. Each el-
ement of an attribute vector represents a meaningful prop-
erty of the seen and unseen classes (e.g., has stripes, has
four legs, has a long tail). We will use Datt. and ˜Datt. to
represent the domains related to attribute vectors describing
classes C and ˜C, respectively.

Following [30], we propose a two-stage ZSL solution.
In the ﬁrst stage, we will train a conditional generator,
fatt.(·, θatt.) : Rnatt. → Rd with natt. denoting the di-
mensionality of the attribute vectors. To be speciﬁc, we use
our min-max statistical alignment to train a model to gener-
ate discriminative instance features given an attribute vector
from a seen class. Note that D0 ∼ Ds and D1 ∼ Datt. per
notations used in § 2. Later, we use fatt. to generate features
for unseen classes, ˜C given their attributes.

As for the ﬁrst stage, we deﬁne two network streams,
hs = softmax ◦ h ◦ fs and hatt. = softmax ◦ h ◦ fatt. (see
Fig. 3 for a schematic). Here, fs(·, θs) : Rs → Rd is a fea-
ture extraction network for real seen class instances. The
function h(·, θh) : Rd → R|C| is a shared classiﬁer for real
and generated seen class features. We parameterize h, fatt.
and fs with θh, θatt. and θs, respectively. Thereafter, we
learn our generator network by following the two optimiza-
tions,

min
θs, θh

Ld,s,

min
θatt.

max
θg

Ld,att. + λu ˜Lu.

(10)

(11)

1Note the domain equivalences D0 ∼ Ds and D1 ∼ Dt with the

discussion in § 2.

2Note C ∩ ˜C = ∅

9291

Figure 3. Schematic diagram for UDA and ZSL models with the proposed statistical alignment (a) The UDA model is trained on
the softmax cross entropy loss, Ld,s on labeled source data, the discriminative cross-entropy loss, Ld,t on unlabeled target domain data
and the statistical alignment loss, ˜Lu. (b) The generator training stage of the proposed two staged ZSL model. The model is trained on
discriminative losses, Ls , Latt. and the statistical alignment loss, ˜Lu.

Here, Ld,s and Ld,att. are softmax cross-entropy loss func-
tions computed on predictions from networks hs and hatt.,
respectively. The scalar constant λu is a training hyper-
parameter. The proposed statistical alignment losses be-
tween the domains Ds and Datt. is given by ˜Lu (see § 2).

3.2.1 ZSL Classiﬁer Training with Generated Samples

In this second stage, we feed the trained conditional gen-
erator, fatt. with unseen class attributes (i.e., inputs from
˜Datt.). The idea here is to generate features that represent
unseen class instances, assuming that the learned condi-
tional generator, fatt. is able to generalize well to unseen
classes. Note that such a generalization assumption is ex-
tensively used in ZSL literature [7, 1, 22, 30]. Thereafter,
we use the generated features together with real seen class
features (i.e., outputs from fs for real seen class instances)
to train a new feature classiﬁer, h∗ : Rd → R|C|+| ˜C|3. For
evaluation, we use the model h∗ ◦ fs to classify test in-
stances.

4. Related Work

In this section, we ﬁrst discuss related UDA and ZSL
solutions. Thereafter, we discuss deep algorithms that are
based on the min-max optimization framework.

Unsupervised Domain Adaptation: Our proposal can be
employed to address UDA by statistical alignment. Statis-
tical alignment of domains is a fundamental solution for
UDA [25, 14, 26]. Focusing on UDA methods, the clos-
est work to ours is the Deep Correlation Alignment solution
(D-CORAL) of Sun et al. [26]. Apart from the fundamen-
tal difference in the formulation, i.e., min-max in our case
in comparison to min in D-CORAL, the statistical disparity
measure is different between the two solutions. Here, we

3Note that we evaluate our ZSL on the Generalized ZSL protocol pro-

posed in [31]

use a symmetric KL-divergence while D-CORAL measures
the disparity using the Frobenius norm.

Domain adversarial learning [9, 28, 24] uses GAN [11]
principles for learning domain invariant features. Here, a
feature extractor acts as the generator network of the GAN.
Its objective is to outperform the ability of the domain dis-
criminator to distinguish the domain of a given instance.
As explained, our confusion network is somewhat similar
in spirit to the discriminator network of domain adversarial
solutions. However, the purpose of the confusion network
is to maximize the statistical disparity.

Zero-Shot Learning: Learning a relationship between
semantic descriptors and instance features is the core con-
cept behind ZSL solutions. For instance, [7, 1, 22] learn
a bilinear relationship between semantic attributes and in-
stance features. Furthermore, Deep Auto-Encoders [17,
16], synthesizing classiﬁers [4], Kernel methods [32] are
also among the machine learning tools that have been re-
cently proposed for learning complex relationships between
semantic descriptors and instance features.

In a different direction, Xian et al. [30] propose feature
generation GANs for ZSL. Their objective is to ﬁrst train
a model that can generate features for seen classes given
attribute vectors as inputs. Thereafter, it is assumed that
this generator is generalizable for generating features for
unseen classes. Our two-stage ZSL framework is inspired
by this solution. However, in contrast we propose to use
statistical alignment to learn the generative model. This is
an unexplored path for ZSL. Furthermore, we explore the
capacity of min-max alignment in this context.

Min-Max Learning: The Maximum-Mean Discrep-
ancy [12] has been widely used to learn from distributions.
Naturally, minimization of MMD will create a min-max
problem. As such, Dziugaite et al. [6] propose to train a
generative model by minimizing an MMD loss. However,
the kernel used in MMD enabled the authors to avoid an ex-

9292

Accum. momentsAccum. momentsAccum. momentsAccum. moments(b)(a)plicit maximization step. The MMD-GAN formulation of
Li et al. [20] takes the idea further by learning the kernel
for MMD along the way. Our proposal is different from the
aforementioned MMD solutions in the sense that the con-
fusion network by itself is a feature mapping. Furthermore
and in contrast to MMD, our maximization is not a compo-
nent of the statistical disparity computations.

We conclude this part by acknowledging the recent work
of Shalev-Shwartz and Wexler [23]. There, the authors
study the min-max framework in optimizing various forms
of loss functions with a stress on classiﬁcation problems.
For example, the authors show that the min-max solution
for binary classiﬁcation problems with 0-1 loss enjoys a
strong form of guarantee while the min counterpart does
not. We believe that the theoretical insights provided in [23]
strengthen our idea of developing the min-max alignment.

5. Experiments

In this section, we empirically contrast our min-max
solution against various baselines on UDA and ZSL. Our
Deep Neural Network (DNN) models are trained end-to-end
with RMSProps optimizer with a batch size of 256. Ran-
domly initialized models are trained with a learning rate of
0.001 and pre-trained AlexNet [18] models with a learning
rate of 0.0001. To obtain stable covariance matrices, we use
an additional dimensionality reduction layer between f c7
and f c8 layers of the AlexNet where the dimensionality is
reduced to 256. Similar dimensionality reduction layers are
used in prior work [9]. We ﬁx the value of λu to 0.001 (see
Eq. (8)) unless stated otherwise. Furthermore, we use an
accumulation momentum of 0.5 (i.e., m = 0.5 in Eq. (6)).
Our confusion model consists of a single convolution (if the
input is a 2D-feature map) or fully connected layer with a
residual skip connection. We also use a leaky-ReLU acti-
vation layer at the output of confusion network. More de-
tails of our DNN structures, training hyper-parameters, and
impact of various confusion structures can be found in the
supplementary material.

5.1. Experiments on UDA

We evaluate and assess our min-max solution on UDA
with two sets of experiments. The ﬁrst experiment is
done with Ofﬁce31 dataset using pre-trained AlexNet ar-
chitecture. The second set of experiments is performed
on MNIST, SVHN, SYN. DIGITS, GTSRB, SYN. SIGNS,
STL and CIFAR datasets , where the CNN model is trained
from scratch. We share model parameters between source
and target domain networks during training (see Fig. 3(a)).
Focusing on the baselines, we denote the model trained
from the source data (i.e., no adaptation is considered)
as CNN. Other baselines include several state-of-the-art
UDA methods such as D-CORAL [26], DANN [9] and

VADA [24]4. These baselines are the most relevant ones,
idea-wise to our work. We also report results for the model
that only minimizes the KL divergence between source and
target domains (denoted by Min). We denote the proposed
min-max solution by Min-Max when λt = 0.0 in Eq. (8).
We also denote our min-max solution as Min-Max+ when
λt = 0.1.

In addition to Ofﬁce31, we

also experimented
namely,
with six more domain adaptation tasks,
SVHN ←→ MNIST, SYN. DIGITS −→ SVHN, SYN.
SIGNS −→ GTSRB and STL ←→ CIFAR5, where we
used the same protocol, data setup and network architecture
as in [24] (see supplemantary of this paper for the details).
For the two experiment sets STL ←→ CIFAR, we used
λu = 0.0001. The value of λu is 0.01 for all the remaining
experiments (i.e., experiments with MNIST, SVHN, SYN.
DIGITS, SYN. SIGNS, GTSRB).

In Table 1, we report the performance of both Min-
Max and Min.. We observe that in all cases, the Min-
Max method outperforms the Min. method. For instance,
in MNIST→SVHN, the Min-Max outperforms the Min.
alignment by 36.1%. Interestingly, in some cases the Min.
alignment is not able to improve upon the CNN baseline
that does not beneﬁt from any adaptations (e.g., D → W
of Ofﬁce31 dataset). However, our Min-Max method im-
proves the results in all cases. Our method obtains an av-
erage improvement of 12.2% over baseline CNN and 5.4%
over the baseline Min.. The improvement is a clear indica-
tion of a better statistical alignment, reinforcing our claim
that the min-max solution (Min-Max) is a better alternative
compared to aligning by minimizing the statistical dispari-
ties.

In Table 2, we compare our min-max solution with D-
CORAL [26] and the adversarial methods DANN [9] and
VADA [24]). For the Ofﬁce31 experiments, we use reported
results in [9], [10] and [26]. Results for remaining domain
sets (i.e., MNIST, SVHN, SYN. DIGITS, SYN. SIGNS,
GTSRB, STL, CIFAR) are obtained from Shu et al. [24] for
DANN and VADA. For Ofﬁce31 dataset, we do not observe
a signiﬁcant performance difference between Min-Max and
Min-Max+. Hence, we use only Min-Max (i.e., λt = 0.0).
However, for the remaining domain adaptation tasks, the
discriminative loss on the target domain is helpful and Min-
Max+ method outperforms Min-Max.

In Ofﬁce31 dataset, our solution is ranked among the top
two performers in four instances out of six and the top per-
former in two instances. Furthermore, our solution outper-

4We acknowledge that Shu et al. [24] also propose a more involved
algorithm, dirt-t as an improved version of VADA. Since our goal is to
mainly contrast min-max alignment against the min solution, we did not
beneﬁt from advanced learning techniques for UDA. Hence, we believe
VADA is a more appropriate baseline here.

5For the CIFAR and STL data, we consider the 9 shared classes (omit-

ing “monkey” and “frog”) as in [24].

9293

Sol.

s
t

CNN
Min
Min-Max

A
D

60.8
66.1
69.1

A
W
58.5
70.5
71.7

D
A

42.6
47.2
51.3

D
W
94.1
93.5
95.0

W
A

38.6
47.6
52.1

W MNIST
D

SVHN MNIST

SVHN DIGITS
SVHN

98.1
98.6
99.3

37.5
49.8
67.8

63.1
70.6
72.0

84.0
85.4
88.5

SIGNS
GTSRB CIFAR

STL

77.8
78.7
83.2

59.1
57.7
60.6

CIFAR

STL
75.9
74.4
76.1

Table 1. Comparison of the Min-Max UDA solution with CNN and Min baselines. For Ofﬁce31 we use the “fully transductive protocol”
as in [9, 26]. We use the acronyms A:Amazon, W:Webcam, and D: DSLR. For the remain domain sets ( MNIST, SVHN, SYN. DIGTS,
GTSRB, SYN. SIGNS, CIFAR, STL ) we follow the training protocol and network models used in [24].The best performance is in Bold.

Sol.

s
t

DANN [9]
VADA [24]
D-CORAL [26]
Min-Max+

A
D

67.1

-

66.8
69.1

A
W
73.0

-

66.4
71.7

D
A

54.5

-

52.8
51.3

D
W
96.4

-

95.7
95.0

W W MNIST
A

D

SVHN DIGITS

SIGNS

STL

CIFAR

SVHN MNIST

SVHN GTSRB CIFAR

52.7

99.2

-

51.5
52.1

-

99.2
99.3

60.6
73.3
72.7
79.3

68.3
94.5
87.8
97.0

90.1
94.9
71.8
94.6

97.5
99.2
59.9
97.3

62.7
71.4
60.5
67.7

STL
78.1
78.3
76.2
79.9

Table 2. Comparison of the Min-Max+ UDA solution with related UDA solutions. For Ofﬁce31 we use the “fully transductive protocol”
as in [9, 26]. We use the acronyms A:Amazon, W:Webcam, and D: DSLR. For the remain domain sets ( MNIST, SVHN, SYN. DIGTS,
GTSRB, SYN. SIGNS, CIFAR, STL ) we follow the training protocol and network models used in [24]. The best performance is in Bold
and second best is in Blue.

forms D-CORAL [26] in four instances on Ofﬁce31 dataset.
On the remaining domain adaptation tasks, our method out-
performs D-CORAL by a considerable margin. Our Min-
Max+ method performs better than state-of-the-art adver-
sarial methods such as DANN and VADA in three instances
out of six (i.e., MNIST↔SVHN and CIFAR→ STL).
the domain transformation tasks,

the
MNIST→SVHN task is the most difﬁcult one to adapt. This
is evident by the low performance in our baseline evalua-
tions. However, our proposed solution shows a signiﬁcant
improvement for this particular UDA task.

Out of all

5.2. Experiments on Zero Shot Learning

We compare our method with recent ZSL methods
on two ﬁne-grained image classiﬁcation datasets, namely
Caltech-UCSD-Birds [29] (CUB) and SUN dataset [21] and
two coarse grained datasets (Awa1 and Awa2 [19]) follow-
ing the Generalized ZSL (GZSL) protocol of [31]. We com-
pute average per-class accuracy for the seen and unseen
classes on the test instances which are denoted by S and U ,
respectively. The model performance is obtained through
harmonic mean (denoted by HM ) between U and S (i.e.
HM = 2 × (S × U )/(S + U )). The GZSL protocol evalu-
ates the performance on both seen and unseen samples with
the same classiﬁer (i.e., the search space includes both seen
and unseen classes). However, low performance either in
seen classes or the unseen classes will eventually tend to
give a low value for HM . We use the Resnet-101 [13] net-
work, pre-trained on ImageNet dataset [5], to extract fea-
tures. We use the train-test splits provided by [31] for all
these datasets. These splits are suitable for this experiment
as all unseen classes do not contain any overlap with the
ImageNet classes.

We implement our ZSL model components using fully-
in → f c(n) → out,
connected neural networks, fs :
fatt.
: in → f c(n) → noise → f c(512) → noise →
f c(n) → noise → f c(n) → out. The confusion network,
g is a single layer network, f c(n) with a residual skip con-
nection from the input to the output. Here, f c(n) represents
a fully-connected layer with n outputs and “noise” repre-
sents a dropout layer followed by an additive Gaussian noise
layer. We use n = 1024 for the Sun dataset experiments and
n = 512 for the remaining sets6. We set the value of λu and
m to 0.1. Furthermore, we start training the models fs and
h earlier than fatt.. This is to make sure that fatt. receives
an informative gradient from the classiﬁer, h.

Mini-batch creation for GZSL. We trained the classiﬁer
(see section 3.2.1) with mini-batches containing a mixture
of real seen classes and generated unseen classes. To im-
prove our classiﬁer’s robustness to unseen classes, every
mini-batch used 2× more generated samples per-class as
that of the real instances except for the case Awa1 for which
we report on 20×. For Awa1 we observe a signiﬁcant im-
provement can be achieved by using higher generated sam-
ple proportions. Further analysis on this can be found in our
supplementary.

Results for zero-shot-learning using our method in
shown in Table. 3. As a baseline, we also report results for
statistical alignment by minimization (Min.) All the base-
line methods use Resnet-101 features provided in [31]. We
observe that our proposed min-max alignment outperforms
the Min. baseline in all four experiments. For complete-
ness, we also performed an experiment where a correla-

6More details about model structure can be found in supplementary

material

9294

Data.
Sol.
SAE [17]
ZKL [32]
Cls. Prot. [15]
CLSW [30]
Min
Min-Max

Awa1

S

77.1
79.3
73.5
61.4
83.3
84.2

U
1.8
18.3
28.1
57.9
46.0
46.6

HM
3.5
29.7
40.6
59.6
59.3
60.0

Awa2

S

82.2
82.7

-
-

HM
2.2
30.8

-
-

U
1.1
18.9

-
-

32.9
37.8

89.7
88.8

48.1
53.0

Cubs

S

54.0
63.9
55.2
57.7
50.8
53.8

U
7.8
24.2
23.5
43.7
46.1
47.1

HM
13.6
35.1
32.9
49.7
48.3
50.2

U
8.8
21.0
21.5
42.6
38.8
37.9

Sun

S

18.0
31.0
34.7
36.6
35.0
36.5

HM
11.8
25.1
26.5
39.4
36.8
37.2

Table 3. Comparison of the proposed ZSL solution (Min-Max) on GZSL protocol [31]. We report the average per-class accuracy on
seen class test instance as “S”. The unseen class performance is reported as “U”. The harmonic mean of “U” and “S” are reported as “HM”.
The best performance is in Bold and second best is in Blue.

tion loss [26] is used instead of the KL divergence in Min.
However, this model did not show competitive performance
(e.g., the HM results for Awa1:26.1%, Awa2:19.6%).

We also compare our solution with the reported results
on the recent ZSL solutions. The proposed min-max align-
ment outperforms the CLSW [30], which uses a power-
ful Wasserstein GAN [2]) in the Cubs dataset by a large
margin. Overall, the proposed min-max alignment method
reaches competitive performances with state-of-the-art ZSL
methods, yet again indicating the effectiveness of proposed
alignment method.

Further Improvement by End-to-end Fine-tuning. We
followed the two-staged framework of CLSW [30] closely
but our model can be ﬁne-tuned in an end-to-end manner.
With end-to-end ﬁne-tuning, we observed a consistent im-
provement < 1% over the results reported in Table 3. How-
ever and interestingly for Awa1 we observe our min-max
solution achieves a HM of 61.3% through this.

5.3. Effect of Moment Accumulation

Lastly, we discuss the effect of momentum accumulation
(see § 2.2) for our solution. In Fig. 4, we report the per-
formance of the proposed min-max (denoted as Min-Max)
and minimization (Min) methods for various values of the
momentum, m (see Eq. (6)). Here, we consider one UDA
(Webcam → Amazon) dataset and one ZSL dataset (Cub).
Studying Fig. 4 shows that the accumulation helps in both
cases. Overall and inline with previous results, we observe
that the min-max solution performs better than the min one.
For the ZSL experiment, we ﬁnd out that the accumulation
is essential. We conjecture that this is due to the stability,
accumulation can bring in to the min-max learning.

6. Conclusion

In this paper, we proposed min-max statistical alignment
for learning domain invariant features. To realize our min-
max solution as an end-to-end trainable deep model, we
proposed a novel structure, “the confusion network”. Our
confusion network behaves similarly, in spirit, to the dis-

criminator of GANs. However, the proposed confusion net-
work attempts to learn a function that maximizes the statisti-
cal disparity between the two domains. We showed that the
performance of the proposed min-max statistical alignment
can be improved by accumulation of mini-batch statistics.
Furthermore, an important theoretical property of the min-
max solution is established in Theorem 1.

We evaluated our proposed min-max solution on two
transfer learning case- studies, namely, Unsupervised Do-
main Adaptation (UDA) and Zero-Shot Learning (ZSL).
Our UDA model used statistical alignment to train an in-
variant feature extractor for source and target domains. For
ZSL, we used the statistical alignment to train a feature gen-
erator for unseen classes. In our evaluations, the min-max
solution consistently outperformed statistical alignment by
minimization. Interestingly, we also showed that with the
proposed min-max solution we could even reach compara-
ble results with the state-of-the-art solutions using GAN’s
principles.

Extending the proposed min-max learning to other statis-
tical disparities (e.g., Wasserstein alignment) is our future
plan. Furthermore, we intend to explore various forms of
confusion networks to design generative models for com-
plex data (e.g., images) and present a dedicated theoretical
study about confusion network properties in future.

Figure 4. Effect of moment accumulation (see § 2.2) for the pro-
posed statistical alignment.

9295

References

[1] Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and
Cordelia Schmid. Label-embedding for image classiﬁca-
tion. IEEE Trans. Pattern Analysis and Machine Intelligence,
38(7):1425–1438, 2016. 5

[2] Martin Arjovsky, Soumith Chintala, and L´eon Bottou.
Wasserstein gan. arXiv preprint arXiv:1701.07875, 2017.
8

[3] Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N. Vap-
nik. A training algorithm for optimal margin classiﬁers. In
Proceedings of the Fifth Annual Workshop on Computational
Learning Theory, pages 144–152, 1992. 1

[4] Soravit Changpinyo, Wei-Lun Chao, Boqing Gong, and Fei
Sha. Synthesized classiﬁers for zero-shot learning. In Proc.
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), pages 5327–5336, 2016. 5

[5] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In Proc. IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pages 248–255, 2009. 7

[6] GK Dziugaite, DM Roy, and Z Ghahramani. Training
generative neural networks via maximum mean discrep-
ancy optimization. In Uncertainty in Artiﬁcial Intelligence-
Proceedings of the 31st Conference, UAI 2015, pages 258–
267, 2015. 5

[7] Andrea Frome, Greg S Corrado, Jon Shlens, Samy Bengio,
Jeff Dean, Tomas Mikolov, et al. Devise: A deep visual-
semantic embedding model.
In Proc. Advances in Neural
Information Processing Systems (NIPS), pages 2121–2129,
2013. 5

[8] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain
adaptation by backpropagation. In International Conference
on Machine Learning, pages 1180–1189, 2015. 1, 3, 4

[9] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-
cal Germain, Hugo Larochelle, Franc¸ois Laviolette, Mario
Marchand, and Victor Lempitsky. Domain-adversarial train-
ing of neural networks. Journal of Machine Learning Re-
search, 17(1):2096–2030, 2016. 1, 5, 6, 7

[10] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang,
Deep reconstruction-
David Balduzzi, and Wen Li.
classiﬁcation networks for unsupervised domain adaptation.
In European Conference on Computer Vision, pages 597–
613. Springer, 2016. 6

[11] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets. In Proc. Ad-
vances in Neural Information Processing Systems (NIPS),
pages 2672–2680, 2014. 3, 5

[12] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bern-
hard Sch¨olkopf, and Alexander Smola. A kernel two-sample
test. Journal of Machine Learning Research, 13(Mar):723–
773, 2012. 5

[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016. 7

[14] Samitha Herath, Mehrtash Harandi, and Fatih Porikli. Learn-
ing an invariant hilbert space for domain adaptation. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), July 2017. 1, 5

[15] Huajie Jiang, Ruiping Wang, Shiguang Shan, and Xilin
Chen. Learning class prototypes via structure alignment for
zero-shot recognition.
In Proc. European Conference on
Computer Vision (ECCV), 2018. 8

[16] Elyor Kodirov. Cross-class Transfer Learning for Visual
Data. PhD thesis, Queen Mary University of London, 2017.
5

[17] Elyor Kodirov, Tao Xiang, and Shaogang Gong. Semantic
autoencoder for zero-shot learning. In Proc. IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
pages 3174–3183, 2017. 5, 8

[18] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classiﬁcation with deep convolutional neural net-
works. In Proc. Advances in Neural Information Processing
Systems (NIPS), pages 1097–1105, 2012. 6

[19] Christoph H Lampert, Hannes Nickisch, and Stefan Harmel-
ing. Attribute-based classiﬁcation for zero-shot visual object
categorization. IEEE Trans. Pattern Analysis and Machine
Intelligence, 36(3):453–465, 2014. 7

[20] Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang,
and Barnab´as P´oczos. Mmd gan: Towards deeper under-
standing of moment matching network. In Proc. Advances in
Neural Information Processing Systems (NIPS), pages 2203–
2213, 2017. 1, 6

[21] Genevieve Patterson and James Hays. Sun attribute database:
Discovering, annotating, and recognizing scene attributes.
In Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 2751–2758. IEEE, 2012. 7

[22] Bernardino Romera-Paredes and Philip Torr. An embar-
rassingly simple approach to zero-shot learning.
In Proc.
Int. Conference on Machine Learning (ICML), pages 2152–
2161, 2015. 5

[23] Shai Shalev-Shwartz and Yonatan Wexler. Minimizing the
In Proc. Int. Conference on

maximal loss: how and why.
Machine Learning (ICML), pages 793–801, 2016. 1, 6

[24] Rui Shu, Hung Bui, Hirokazu Narui, and Stefano Ermon. A
DIRT-t approach to unsupervised domain adaptation. In In-
ternational Conference on Learning Representations, 2018.
1, 4, 5, 6, 7

[25] Baochen Sun, Jiashi Feng, and Kate Saenko. Return of frus-
tratingly easy domain adaptation. In Thirtieth AAAI Confer-
ence on Artiﬁcial Intelligence, 2016. 1, 5

[26] Baochen Sun, Jiashi Feng, and Kate Saenko. Correlation
alignment for unsupervised domain adaptation. In Domain
Adaptation in Computer Vision Applications, pages 153–
171. Springer, 2017. 1, 5, 6, 7, 8

[27] Baochen Sun and Kate Saenko. Deep coral: Correlation
alignment for deep domain adaptation. In Computer Vision–
ECCV 2016 Workshops, pages 443–450. Springer, 2016. 1,
2, 4

[28] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Dar-
rell. Adversarial discriminative domain adaptation. In Proc.
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), pages 2962–2971. IEEE, 2017. 5

9296

[29] Catherine Wah, Steve Branson, Peter Welinder, Pietro Per-
ona, and Serge Belongie. The caltech-ucsd birds-200-2011
dataset. 2011. 7

[30] Yongqin Xian, Tobias Lorenz, Bernt Schiele, and Zeynep
Akata. Feature generating networks for zero-shot learn-
ing. Proc. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), 2018. 1, 4, 5, 8

[31] Yongqin Xian, Bernt Schiele, and Zeynep Akata. Zero-shot
learning-the good, the bad and the ugly.
In Proc. IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 3077–3086, 2017. 1, 4, 5, 7, 8

[32] Hongguang Zhang and Piotr Koniusz. Zero-shot kernel
learning. Proc. IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), 2018. 5, 8

9297

