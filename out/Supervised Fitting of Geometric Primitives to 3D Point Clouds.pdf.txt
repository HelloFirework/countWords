Supervised Fitting of Geometric Primitives to 3D Point Clouds

Anastasia Dubrovina1

Li Yi1
2Facebook AI Research

Leonidas Guibas1,2

Lingxiao Li*1 Minhyuk Sung*1

1Stanford University

Abstract

Fitting geometric primitives to 3D point cloud data
bridges a gap between low-level digitized 3D data and high-
level structural information on the underlying 3D shapes.
As such, it enables many downstream applications in 3D
data processing. For a long time, RANSAC-based methods
have been the gold standard for such primitive ﬁtting prob-
lems, but they require careful per-input parameter tuning
and thus do not scale well for large datasets with diverse
shapes.
In this work, we introduce Supervised Primitive
Fitting Network (SPFN), an end-to-end neural network that
can robustly detect a varying number of primitives at differ-
ent scales without any user control. The network is super-
vised using ground truth primitive surfaces and primitive
membership for the input points. Instead of directly predict-
ing the primitives, our architecture ﬁrst predicts per-point
properties and then uses a differential model estimation
module to compute the primitive type and parameters. We
evaluate our approach on a novel benchmark of ANSI 3D
mechanical component models and demonstrate a signiﬁ-
cant improvement over both the state-of-the-art RANSAC-
based methods and the direct neural prediction.

1. Introduction

Recent 3D scanning techniques and large-scale 3D
repositories have widened opportunities for 3D geometric
data processing. However, most of the scanned data and
the models in these repositories are represented as digitized
point clouds or meshes. Such low-level representations of
3D data limit our ability to geometrically manipulate them
due to the lack of structural information aligned with the
shape semantics. For example, when editing a shape built
from geometric primitives, the knowledge of the type and
parameters of each primitive can greatly aid the manipula-
tion in producing a plausible result (Figure 1). To address
the absence of such structural information in digitized data,
in this work we consider the conversion problem of map-
ping a 3D point cloud to a number of geometric primitives
that best ﬁt the underlying shape.

*equal contribution

SPFN

Editing

Figure 1: Our network SPFN generates a collection of geo-
metric primitives that ﬁt precisely to the input point cloud,
even for tiny segments. The predicted primitives can then
be used for structure understanding or shape editing.

Representing an object with a set of simple geometric
components is a long-standing problem in computer vision.
Since the 1970s [3, 19], the fundamental ideas for tackling
the problem have been revised by many researchers, even
until recently [31, 34, 9]. However, most of these previous
work aimed at solving perceptual learning tasks; the main
focus was on parsing shapes, or generating a rough abstrac-
tion of the geometry with bounding primitives. In contrast,
our goal is set at precisely ﬁtting geometric primitives to the
shape surface, even with the presence of noise in the input.

For

this primitive ﬁtting problem, RANSAC-based
methods [28] remain the standard. The main drawback of
these approaches is the difﬁculty of ﬁnding suitable algo-
rithm parameters. For example, if the threshold of ﬁtting
residual for accepting a candidate primitive is smaller than
the noise level, over-segmentation may occur, whereas a too
large threshold will cause the algorithm to miss small pieces
primitives. This problem happens not only when process-
ing noisy scanned data, but also when parsing meshes in 3D
repositories because the discretization of the original shape
into the mesh obscures the accurate local geometry of the
shape surface. The demand for careful user control prevents
RANSAC-based methods to scale up to a large number of
categories of diverse shapes.

Such drawback motivates us to consider a supervised
deep learning framework. The primitive ﬁtting problem can

2652

be viewed as a model prediction problem, and the simplest
approach would be directly regressing the parameters in the
parameter space using a neural network. However, the re-
gression loss based on direct measurement of the parameter
difference does not reﬂect the actual ﬁtting error – the dis-
tances between input points and the primitives. Such mis-
informed loss function can signiﬁcantly limit prediction ac-
curacy. To overcome this, Brachmann et al. [4] integrated
the RANSAC pipeline into an end-to-end neural network
by replacing the hypothesis selection step with a differen-
tiable procedure. However, their framework predicts only
a single model, and it is not straightforward to extend it to
predict multiple models (primitives in our case). Ranftl et
al. [26] also introduced a deep learning framework to per-
form model ﬁtting via inlier weight prediction. We extend
this idea to predict weights representing per-point member-
ship for multiple primitive models in our setting.

In this work, we propose Supervised Primitive Fitting
Network (SPFN) that takes point clouds as input and pre-
dicts a varying number of primitives of different types with
accurate parameters. For robust estimation, SPFN does not
directly output primitive parameters, but instead predicts
three kinds of per-point properties: point-to-primitive mem-
bership, surface normal, and the type of the primitive the
point belongs to. Our framework supports four types of
primitives: plane, sphere, cylinder, and cones. These types
form the most major components in CAD models. Given
these per-point properties, our differentiable model estima-
tor computes the primitive parameters in an algebraic way,
making the ﬁtting loss fully backpropable. The advantage
of our approach is that the network can leverage the read-
ily available supervisions of per-point properties in train-
ing. It has been shown that per-point classiﬁcation prob-
lems (membership, type) are suitable to address using a
neural network that directly consumes a point cloud as in-
put [24, 25]. Normal prediction can also be handled effec-
tively with a similar neural network [2, 10].

We train and evaluate the proposed method using our
novel dataset, ANSI 3D mechanical component models
with 17k CAD models. The supervision in training is
provided by parsing the CAD models and extracting the
primitive information. In our comparison experiments, we
demonstrate that our supervised approach outperforms the
widely used RANSAC-based approach [28] with a big mar-
gin, despite using models from separate categories in train-
ing and testing. Our method shows better ﬁtting accuracy
compared to [28] even when we provide the latter with
much higher-resolution point clouds as input.

Key contributions

• Our differentiable primitive model estimator solves a
series of linear least-square problems, thus making the
whole pipeline end-to-end trainable.

• We demonstrate the performance of our network us-
ing a novel CAD model dataset of mechanical compo-
nents.

2. Related Work

Among a large body of previous work on ﬁtting prim-
itives to 3D data, we review only methods that ﬁt primi-
tives to objects instead of scenes, as our target use cases are
scanned point clouds of individual mechanical parts. For a
more comprehensive review, see survey [13].

RANSAC-based Primitive Fitting. RANSAC [8] and its
variants [30, 20, 6, 14] are the most widely used methods for
primitive detection in computer vision. A signiﬁcant recent
paper by Schnabel et al. [28] introduced a robust RANSAC-
based framework for detecting multiple primitives of differ-
ent types in a dense point cloud. Li et al. [17] extended
[28] by introducing a follow-up optimization that reﬁnes
the extracted primitives based on the relations among them.
As a downstream application of the RANSAC-based meth-
ods, Wu et al. [32] and Du et al. [7] proposed a proce-
dure to reverse-engineer the Constructive Solid Geometry
(CSG) model from an input point cloud or mesh. While
these RANSAC variants showed state-of-the-art results in
their respective ﬁelds, their performance typically depends
on careful and laborious parameter tuning for each category
of shapes. In addition, point normals are required, which are
not readily available from 3D scans. In contrast, our super-
vised deep learning architecture requires only point cloud
data as input and does not need any user control at test time.

Network-based Primitive Fitting. Neural networks have
been used in recent approaches to solve the primitive ﬁtting
problem in both supervised [34] and unsupervised [31, 29]
settings. However, these methods are limited in accuracy
with a restricted number of supported types. In the work
of Zou et al. [34] and Tulsiani et al. [31], only cuboids are
predicted and therefore can only serve as a rough abstrac-
tion of the input shape or image. CSGNet [29] is capable
of predicting more variety of primitives but with low ac-
curacy, as the parameter extraction is done by performing
classiﬁcation on a discretized parameter space. In addition,
their reinforcement learning step requires rendering a CSG
model to generate visual feedback for every training itera-
tion, making the computation demanding. Our framework
can be trained end-to-end and thus does not need expensive
external procedures.

• We propose SPFN, an end-to-end supervised neural
network that takes a point cloud as input and detects
a varying number of primitives with different scales.

3. Supervised Primitive Fitting Network

We propose Supervised Primitive Fitting Network
(SPFN) that takes an input shape represented by a point

2653

C : Number of points 
D : Number of primitives
E : Number of primitive types

Input

Point Cloud

P ∈ ℝ$×&

Softmax

PointNet++

22-normalize

Inputs

Network

Supervision

Variables

Softmax

Differentiable
module

External
solver

Memberships
'W ∈ [0,1]$×.

Normals
'N ∈ ℝ$×&

Types

'T ∈ [0,1]$×1

Primitives 
Reordering

(Sec. 3.1)

Supervision

Memberships W

Losses

(Sec. 3.3)

Normals N

Types T

GT Surfaces S

Primitives A

ℒseg

ℒnor

ℒtype

ℒ

ℒres

ℒaxis

P

'W 'N

Model 

Estimation
(Sec. 3.2)

'A

Figure 2: Network architecture. PointNet++ [25] takes input point cloud P and outputs three per-point properties: point-to-
primitive membership ˆW, normals ˆN, and associated primitive type ˆT. The order of ground truth primitives are matched
with the output in the primitive reordering step (Section 3.1). Then, the output primitive parameters are estimated from the
point properties in the model estimations step (Section 3.2). The loss is deﬁned as the sum of ﬁve loss terms (Section 3.3).

cloud P ∈ RN ×3, where N is number of points, and pre-
dicts a set of geometric primitives that best ﬁt the input. The
output of SPFN contains the type and parameters for every
primitive, plus a list of input points assigned to it. Our net-
work supports L = 4 types of primitives: plane, sphere,
cylinder, and cone (Figure 3), and we index these types by
0, 1, 2, 3 accordingly. Throughout the paper, we will use no-
tations {·}i,: and {·}:,k to denote i-th row and k-th column
of a matrix, respectively.

so thatPK

During training, for each input shape with K primitives,
SPFN leverages the following ground truth information as
supervision: point-to-primitive membership matrix W ∈
{0, 1}N ×K , unoriented point normals N ∈ RN ×3, and
bounded primitive surfaces {Sk}k=1,...,K . For the member-
ship matrix, Wi,k indicates if point i belongs to primitive k
k=1 Wi,k ≤ 1. Notice that W:,k, the k-th column
of W, indicates the point segment assigned to primitive k.
We allow K to vary for each shape, and W can have zero
rows indicating unassigned points (points not belonging to
any of the K primitives; e.g.
it belongs to a primitive of
unknown type). Each Sk contains information about the
type, parameters, and boundary of the k-th primitive sur-
face, and we denote its type by tk ∈ {0, 1, . . . , L − 1} and
its type-speciﬁc parameters by Ak. We include the bound-
ary of Sk in the supervision besides P because P can be
noisy, and we do not discriminate against small surfaces in
evaluating per-primitive losses (see Equation 17). For con-
venience, we deﬁne per-point type matrix T ∈ {0, 1}N ×L
1(Wi,k = 1)1(tk = l), where 1(·) is the

by Ti,l = PK

indicator function.

k=1

The pipeline of SPFN at training time is illustrated in
Figure 2. We use PointNet++ [25] segmentation architec-
ture to consume the input point cloud P. A slight modiﬁ-
cation is that we add three separate fully-connected layers
to the end of the PointNet++ pipeline in order to predict

the following per-point properties: point-to-primitive mem-
bership matrix ˆW ∈ [0, 1]N ×K 1, unoriented point normals
ˆN ∈ RN ×3, and per-point primitive types ˆT ∈ [0, 1]N ×L.
We use softmax activation to obtain membership probabil-
ities in the rows of ˆW and ˆT, and we normalize the rows
of the ˆN to constrain normals to have l2-norm 1. We then
feed these per-point quantities to our differentiable model
estimator (Section 3.2) that computes primitive parameters
{ ˆAk} based on the per-point information. Since this last
step is differentiable, we are able to backpropagate any kind
of per-primitive loss through the PointNet++, and thus the
training can be done end-to-end.

Notice that we do not assume a consistent ordering of
ground truth primitives, so we do not assume any order-
ing of the columns of our predicted ˆW. In Section 3.1, we
describe the primitive reordering step used to handle such
mismatch of orderings. In Section 3.2, we present our dif-
ferential model estimator for predicting primitive parame-
ters { ˆAk}. In Section 3.3, we deﬁne each term in our loss
function. Lastly, in Section 3.4, we describe implementa-
tion details.

3.1. Primitives Reordering

Inspired by Yi et al. [33], we compute Relaxed Intersec-
tion over Union (RIoU) [15] for all pairs of columns from
the membership matrices W and ˆW. The RIoU for two
indicator vectors w and ˆw is deﬁned as follows:

RIoU(w, ˆw) =

wT ˆw

kwk1 + k ˆwk1 − wT ˆw

.

(1)

The best one-to-one correspondence (determined by RIoU)
between columns of the two matrices is then given by Hun-
garian matching [16]. We reorder the ground truth primi-

1For notational clarity, for now we assume the number of predicted
primitives equals K, the number of ground truth primitives. See Section
3.4 for how to predict ˆW without prior knowledge of K.

2654

"

!

#

"

!

#

!

"

"

#

!

given as the right singular vector v corresponding to the
smallest singular value of matrix diag (w) X. As shown by
Ionescu et al. [11, 12], the gradient with respect to v can be
backpropagated through the SVD computation.

Figure 3: Primitive types and parameters. The boundary in-
formation in each Sk, together with parameters Ak, deﬁnes
the (bounded) region of the primitive k. On the other hand,
the point segment W:,k provides an approximation to this
bounded region.

tives according to this correspondence, so that ground truth
primitive k is matched with the predicted primitive k. Since
the set of inputs where a small perturbation will lead to a
change of the matching result has measure zero, the overall
pipeline remains differentiable almost everywhere. Hence
we use an external Hungarian matching solver to obtain
optimal matching indices, and then inject these back into
our network to allow further loss computation and gradient
propagation.

3.2. Primitive Model Estimation

In the model estimation module, primitive parameters
{Ak} are obtained from the predicted per-point properties
in a differentiable manner. As the parameter estimation for
each primitive is independent, in this section we will assume
k is a ﬁxed index of a primitive. The input to the model es-
timation module consists of P, the input point cloud, ˆN,
the predicted unoriented point normals, and ˆW:,k, the k-th
column of the predicted membership matrix ˆW. For sim-
plicity, we write w = ˆW:,k ∈ [0, 1]N and ˆA = ˆAk. For
p ∈ R3, let Dl(p, A) denote the distance from p to the
primitive of type l and parameters A. The differentiable
module for computing ˆA, given the primitive type, is illus-
trated below.

Plane. A plane is represented by A = (a, d) where a is
the normal of the plane, with kak = 1, and the points on the
plane are {p ∈ R3 : aTp = d}. Then

D2

plane(p, A) = (aTp − d)2.

(2)

We can then deﬁne ˆA as the minimizer to the weighted sum
of squared distances as a function of A:

Eplane(A; P, w) =

N

Xi=1

wi(aTPi,: − d)2.

(3)

∂Eplane

By solving
ging this into Equation 3 gives:

∂d = 0, we obtain d = PN

i=1 wiaTPi,:
PN

i=1 wi

. Plug-

Eplane(a; P, w) = kdiag (w) Xak2 ,

(4)

where Xi,: = Pi,: − PN
i=1 wiPi,:
PN
ing Eplane(A; P, w) over a becomes a homogeneous least
square problem subject to kak = 1, and its solution is

. Hence minimiz-

i=1 wi

Sphere. A sphere is parameterized by A = (c, r), where
c ∈ R3 is the center and r ∈ R is the radius. Hence

D2

sphere(p, A) = (kp − ck − r)2.

(5)

In the sphere case (also in the cases of cylinder and cone),
the squared distance is not quadratic. Hence minimizing
the weighted sum of squared distances over parameters as
done in the plane is only available via nonlinear iterative
solvers [18].
Instead, we consider minimizing over the
weighted sum of a different notion of distance:

Esphere(A; P, w) =

N

Xi=1

wi(kPi,: − ck2 − r2)2.

(6)

∂Esphere
∂r2 = 0 gives r2 =

j=1 wjkPj −
Solving
ck2. Putting this back in Equation 6, we end up with a
quadratic expression in c as a least square:

i=1 wi PN

1
PN

Esphere(c; P, w, a) = kdiag (w) (Xc − y)k2 ,

(7)

where Xi,: = 2(cid:18)−Pi,: +

PN

j=1 wj Pj,:
PN

j=1 wj (cid:19) and yi =

PT

i,:Pi,: −

PN

j=1 wj PT
j=1 wj

PN

j,:Pj,:

. This least square can be solved

via Cholesky factorization in a differentiable way [21].

Cylinder. A cylinder is parameterized by A = (a, c, r)
where a ∈ R3 is a unit vector of the axis, c ∈ R3 is the
center, and r ∈ R is the radius. We have

D2

cylinder(p, A) = (cid:18)qvTv − (aTv)2 − r(cid:19)2

,

(8)

where v = p−c. As in the sphere case, directly minimizing
over squared true distance is challenging. Instead, inspired
by Nurunnabi et. al. [22], we ﬁrst estimate the axis a and
then solve a circle ﬁtting to obtain the rest of the parameters.
Observe that the normals of points on the cylinder must be
perpendicular to a, so we choose a to minimize:

Ecylinder(a; ˆN, w) = (cid:13)(cid:13)(cid:13)

diag (w) ˆNa(cid:13)(cid:13)(cid:13)

which is a homogeneous least square problem same as
Equation 4, and can be solved in the same way.

2

,

(9)

Once obtaining the axis a, we consider a plane P with
normal a that passes through the origin, and notice the pro-
jection of the cylinder onto P should form a circle. Thus
we can choose c and r to be the circle that best ﬁts the pro-
jected points {Proja(Pi,:)}N
i=1, where Proja(·) denotes the
projection onto P. This is exactly the same formulation
as in the sphere case (Equation 6), and can thus be solved
similarly.

2655

Cone. A cone is parameterized by A = (a, c, θ) where
c ∈ R3 is the apex, a ∈ R3 is a unit vector of the axis from
the apex into the cone, and θ ∈ (0, π
2 ) is the half angle.
Then

D2

cone(p, A)2 = (cid:16)kvk sin(cid:16)min(cid:16)|α − θ| ,

π

2(cid:17)(cid:17)(cid:17)2

,

(10)

where v = p − c, α = arccos(cid:16) aTv

kvk(cid:17). Similarly with the

cylinder case, we use a multi-stage algorithm: ﬁrst we esti-
mate a and c separately, and then we estimate the half-angle
θ.

We utilize the fact that the apex c must be the intersec-
tion point of all tangent planes on the cone surface. Using
the predicted point normals ˆN, the multi-plane intersection
problem is formulated as a least square similar with Equa-
tion 7 by minimizing

2

,

(11)

Econe(c; ˆN) = (cid:13)(cid:13)(cid:13)

diag (w)(cid:16) ˆNc − y(cid:17)(cid:13)(cid:13)(cid:13)

where yi = ˆNT
i,:Pi,:. To get the axis direction a, observe
that a should be the normal of the plane passing through
all Ni if point i belongs to the cone. This is just a plane
ﬁtting problem, and we can compute a as the unit normal
that minimizes Equation 3, where we replace Pi,: by ˆNi,:.
We ﬂip the sign of a if it is not going from c into the cone.
Finally, using the apex c and the axis a, the half-angle θ is
simply computed as a weighted average:

θ =

1
PN

i=1 wi PN

i=1 wi arccos(cid:12)(cid:12)(cid:12)

.

aT Pi,:−c

kPi,:−ck(cid:12)(cid:12)(cid:12)

(12)

3.3. Loss Function

We deﬁne our loss function L as the sum of the following

ﬁve terms without weights:

L = Lseg + Lnorm + Ltype + Lres + Laxis.

(13)

Each loss term is described below for a single input shape.

Segmentation Loss. The primitive parameters can be
more accurately estimated when the segmentation of the in-
put point cloud is close to the ground truth. Thus, we min-
imize (1 − RIoU) for each pair of a ground truth primitive
and its correspondence in the prediction:

Lseg =

1
K

K

Xk=1(cid:16)1 − RIoU(W:,k, ˆW:,k)(cid:17) .

(14)

Point Normal Angle Loss. For predicting the point nor-
mals ˆN accurately, we minimize the absolute cosine angle
between ground truth and predicted normals:

Lnorm =

1
N

N

Xi=1 (cid:16)1 − |NT

i,:

ˆNi,:|(cid:17) .

(15)

The absolute value is taken since our predicted normals are
unoriented.

Per-point Primitive Type Loss. We minimize cross en-
tropy H for the per-point primitive types ˆT (unassigned
points are ignored):

Ltype =

1
N

N

Xi=1

1(Wi,: 6= 0)H(Ti,:, ˆTi,:),

(16)

where 1(·) is the indicator function.

Fitting Residual Loss. Most importantly, we minimize
the expected squared distance between Sk and the predicted
primitive k parameterized by ˆAk across all k = 1, . . . , K:

Lres =

1
K

K

Xk=1

E

p∼U (Sk)D2

tk (p, ˆAk),

(17)

where p ∼ U (S) means p is sampled uniformly on
the bounded surface S when taking the expectation, and
l (p, ˆA) is the squared distance from p to a primitive of
D2
type l with parameter ˆA, as deﬁned in Section 3.2. Note that
every Sk is weighted equally in Equation 17 regardless of
its scale, the surface area relative to the entire shape. This
allows us to detect small primitives that can be missed by
other unsupervised methods.

Note that in Equation 17, we use the ground truth type
tk instead of inferring the predicted type based on ˆT and
then properly weighted by ˆW. We do this because coupling
multiple predictions can make loss functions more compli-
cated, resulting in unstable training. At test time, however,
the type of primitive k is predicted as

ˆtk = argmax

l

N

Xi=1

ˆTi,l

ˆWi,k.

(18)

Axis Angle Loss. Estimating plane normal and cylin-
der/cone axis using SVD can become numerically unstable
when the predicted ˆW leads to degenerate cases, such as
when the number of points with a nonzero weight is too
small, or when the points with substantial weights form a
narrow plane close to a line during plane normal estimation
(Equation 4). Thus, we regularize the axis parameters with
a cosine angle loss:

Laxis =

1
K

K

Xk=1(cid:16)1 − Θtk (Ak, ˆAk)(cid:17) ,

(19)

where Θt(A, ˆA) denotes |aTˆa| for plane (normal), cylin-
der (axis), and cone (axis), and 1 for sphere (so the loss
becomes zero).

3.4. Implementation Details

In our implementation, we assume a ﬁxed number N of
input points for all shapes. While the number of ground
truth primitives varies across the input shapes, we choose
an integer Kmax in prediction to ﬁx the size the output mem-
bership matrix ˆW ∈ RN ×Kmax so that Kmax is no less than

2656

the maximum primitive numbers in input shapes. After the
Hungarian matching in Section 3.1, unmatched columns in
ˆW are ignored in the loss computation. At test time, we dis-

card a predicted primitive k if
> ǫdiscard, where
ǫdiscard = 0.005N for all experiments. This is just a rather
arbitrary small threshold to weed out unused segments.

i=1
N

PN

ˆWi,k

When evaluating the expectation E

p∼U (Sk)(·) in Equa-
tion 17, on-the-ﬂy point sampling takes very long time in
training. Hence the expectation is approximated as the av-
erage for M points on Sk that are sampled uniformly when
preprocessing the data.

4. Experiments

4.1. ANSI Mechanical Component Dataset

For training and evaluating the proposed network, we
use CAD models from American National Standards Insti-
tute (ANSI) [1] mechanical components provided by Tra-
ceParts [27]. Since there is no existing scanned 3D dataset
for this type of objects, we train and test our network by
generating noisy samples on these models. From 504 cat-
egories, we randomly select up to 100 models in each cat-
egory for balance and diversity, and split training/test sets
by categories so that training and test models are from dis-
joint categories, resulting in 13,831/3,366 models in train-
ing/test sets. We remark that the four types of primitives we
consider (plane, sphere, cylinder, cone) cover 94.0% per-
centage of area per-model on average in our dataset. When
generating the point samples from models, we still include
surfaces that are not one of the four types. The maximum
number of primitives per shape does not exceed 20 in all our
models. We set Kmax = 24 where we add 4 extra columns
in ˆW to allow the neural net to assign a small number of
points to the extra columns, effectively marking those points
unassigned because of the threshold ǫdiscard.

From the CAD models, we extract primitives informa-
tion including their boundaries. We then merge adjacent
pieces of primitive surfaces sharing exactly the same pa-
rameters; this happens because of the difﬁculty of repre-
senting boundaries in CAD models, so for instance a com-
plete cylinder will be split into a disjoint union of two mir-
rored half cylinders. We discard tiny pieces of primitives
(less than 2% of the entire area). Each shape is normal-
ized so that its center of mass is at the origin, and the axis-
aligned bounding box for the shape is included in [−1, 1]
range along every axis. In experiments, we ﬁrst uniformly
sample 8192 points over the entire surface of each shape as
the input point cloud (N = 8192). This is done by ﬁrst
sampling on the discretized mesh of the shape and then pro-
jecting all points onto its geometric surface. Then we ran-
domly apply noise to the point cloud along the surface nor-
mal direction in [−0.01, 0.01] range. To evaluate the ﬁtting
residual loss Lres, we also uniformly sample 512 points per

primitive surface for approximating Sk (M = 512).

4.2. Evaluation Metrics

We design our evaluation metrics as below. Each quan-
tity is described for a single shape, and the numbers are
reported as the average of these quantities across all test
shapes. For per-primitive metrics, we ﬁrst perform primi-
tive reordering as in Section 3.1 so the indices for predicted
and ground truth primitives are matched.

• Segmentation Mean IoU:

k=1 IoU(W:,k, I( ˆW:,k)), where I(·) is the one-

1

K PK

hot conversion.

• Mean primitive type accuracy:

1(tk = ˆtk), where ˆtk is in Equation 18.

k=1

1

K PK
N PN

1

• Mean point normal difference:

• Mean primitive axis difference:

i,:

i=1 arccos(cid:16)|NT
1(tk=ˆtk) PK

k=1

1

ˆNi,:|(cid:17).
1(tk = ˆtk) arccos(cid:16)Θtk (Ak, ˆAk)(cid:17).

k=1

PK
It is measured only when the predicted type is correct.

• Mean/Std. {Sk} residual:

1

E

k=1

K PK

p∼U (Sk)qD2

(p, ˆAk). In contrast to the
expression for loss Lres, predicted type ˆtk is used. The
{Sk} residual standard deviation is deﬁned accord-
ingly.

ˆtk

• {Sk} coverage:

E

1

K PK

k=1

is a threshold.

p∼U (Sk)1(cid:16)qD2

ˆtk

(p, ˆAk) < ǫ(cid:17), where ǫ

• P coverage:

1

N PN

i=1

ǫ is a threshold.

1(cid:16)minK

k=1(cid:16)qD2

ˆtk

(Pi,:, ˆAk)(cid:17) < ǫ(cid:17), where

When the predicted primitive numbers is less than K, there
will be less than K matched pairs in the output of the Hun-
garian matching.
In this case, we modify the metrics of
primitive type accuracy, axis difference, and {Sk} residual
mean/std. to average only over matched pairs.

4.3. Comparison to Efﬁcient RANSAC [28]

We compare the performance of SPFN with Efﬁcient
RANSAC [28] and also hybrid versions where we bring in
predictions from neural networks as RANSAC input. We
use the CGAL [23] implementation of Efﬁcient RANSAC
with its default adaptive algorithm parameters. Following
common practice, we run the algorithm multiple times (3 in
our all experiments), and pick the result with highest input
coverage. Different from our pipeline, Efﬁcient RANSAC
requires point normals as input. We use the standard jet-
ﬁtting algorithm [5] to estimate the point normals from the
input point cloud before feeding to RANSAC.

2657

Ind Method

1
2
3
4
5
6

Eff. RANSAC [28]+J
Eff. RANSAC [28]*+J*
Eff. RANSAC [28]+J*
Eff. RANSAC [28]+J*+ ˆW
Eff. RANSAC [28]+J*+ ˆW+ˆt
Eff. RANSAC [28]+ ˆN+ ˆW+ˆt

7 DPPN (Sec. 4.4)

SPFN-Lseg
SPFN-Lnorm+J*

8
9
10 SPFN-Lres
11 SPFN-Laxis
12 SPFN (ˆt → Est.)
13 SPFN

Seg.

(Mean IoU)

Primitive
Type (%)

Point

Normal (◦)

Primitive
Axis (◦)

{Sk} Residual
Mean ± Std.

{Sk} Coverage

P Coverage

ǫ = 0.01

ǫ = 0.02

ǫ = 0.01

ǫ = 0.02

43.68
56.07
45.90
69.91
60.68
60.56

44.05

41.61
71.18
72.70
77.31
75.71
77.14

52.92
43.90
46.99
60.56
92.76
93.13

51.33

92.40
95.44
96.66
96.47
95.95
96.93

11.42
6.92
6.87
6.87
6.87
8.15

-

8.25
6.87
8.74
8.28
8.54
8.66

7.54
2.42
5.85
2.90
6.21
7.02

3.68

1.70
4.20
1.87
6.27
1.71
1.51

0.072 ± 0.361
0.067 ± 0.352
0.080 ± 0.390
0.029 ± 0.234
0.036 ± 0.251
0.054 ± 0.307

0.021 ± 0.158

0.029 ± 0.178
0.022 ± 0.188
0.017 ± 0.162
0.019 ± 0.188
0.013 ± 0.140
0.011 ± 0.131

43.42
56.95
51.59
74.32
65.31
61.94

46.99

50.04
76.47
79.81
80.80
85.25
86.63

63.16
72.74
67.12
83.27
73.69
70.38

71.02

62.74
81.49
85.57
86.11
90.13
91.64

65.74
68.58
72.11
78.79
77.01
74.80

59.74

62.23
83.21
81.32
86.46
86.67
88.31

88.63
92.41
92.58
94.58
92.57
90.83

84.37

77.74
91.73
91.52
94.43
94.91
96.30

Table 1: Results of all experiments. +J indicates using point normals computed by jet ﬁtting [5] from the input point clouds.
The asterisk * indicates using high resolution (64k) point clouds. See Section 4.2 for the details of evaluation metrics, and
Sections 4.3 to 4.5 for the description of each experiment. Lower is better in 3-5th metrics, and higher is better in the rest.

Ground
Truth

Eff.RAN.

+J

Eff.RAN.*

+J*

Eff.RAN+
ˆN+ ˆW+ˆt

DPPN

SPFN
-Lseg

SPFN

-Lnorm+J*

SPFN
-Lres

SPFN
-Laxis

SPFN

Figure 4: Primitive ﬁtting results with different methods. The results are rendered with meshes generated by projecting point
segments to output primitives and then triangulating them. Refer to Sections 4.3 to 4.5 for the details of each method.

We report the results of SPFN and Efﬁcient RANSAC in
Table 1. Since Efﬁcient RANSAC can afford point clouds
of higher resolution, we test it both with the identical 8k in-
put point cloud as in SPFN (row 1), and with another 64k
input point cloud sampled and perturbed in the same way
(row 2). Even compared to results from high-resolution
point clouds, SPFN outperforms Efﬁcient RANSAC in all
metrics. Speciﬁcally, both {Sk} and P coverage numbers
with threshold ǫ = 0.01 show big margins, demonstrating
that our SPFN ﬁts primitives more precisely.

We also test Efﬁcient RANSAC by bringing in per-point

properties predicted by SPFN. We ﬁrst train SPFN with only
Lseg loss, and then for each segment in the predicted mem-
bership matrix ˆW we use Efﬁcient RANSAC to predict a
single primitive (Table 1, row 4). We further add Ltype
and Lnorm losses in training sequentially, and use the pre-
dicted primitive types ˆt and point normals ˆN in Efﬁcient
RANSAC (row 5-6). When the input point cloud is ﬁrst
segmented with a neural network, both {Sk} and P cover-
age numbers for Efﬁcient RANSAC increase signiﬁcantly,
yet still lower than SPFN. Notice that the point normals and
primitive types predicted by a neural network do not im-

2658

Figure 5: {Sk} coverage against scales of primitives.

prove the {Sk} and P coverage in RANSAC.

Figure 5 illustrates {Sk} coverage with ǫ = 0.01
for varying scales of ground truth primitives. Efﬁcient
RANSAC coverage improves when leveraging the segmen-
tation results of the network, but still remains low when the
scale is small. In contrast, SPFN exhibits consistent high
coverage for all scales.

4.4. Comparison to Direct Parameter Prediction

Network (DPPN)

We also consider a simple neural network named Direct
Parameter Prediction Network (DPPN) that directly pre-
dicts primitive parameters without predicting point proper-
ties as an intermediate step. DPPN uses the same Point-
Net++ [25] architecture that consumes P, but different from
SPFN, it outputs Kmax primitive parameters for every prim-
itive type (so it gives 4Kmax sets of parameters). In training,
the Hungarian matching to the ground truth primitives (Sec-
tion 3.1) is performed with ﬁtting residuals as in Equation
17 instead of RIoU. Since point properties are not predicted
and the matching is based solely on ﬁtting residuals (so the
primitive type might mismatch), only Lres is used as the loss
function. At test time, we assign each input point to the
closest predicted primitive to form ˆW.

The results are reported in row 7 of Table 1. Compared
to SPFN, both {Sk} and P coverage numbers are far lower,
particularly when the threshold is small (ǫ = 0.01). This
implies that supervising a network not only with ground
truth primitives but also with point-to-primitive associations
is crucial for more accurate predictions.

4.5. Ablation Study

We conduct ablation study to verify the effect of each
loss term. In Table 1 rows 8-11, we report the results when
we exclude Lseg, Lnorm (use jet-ﬁtting normals computed
from 64k points), Lres, and Laxis, respectively. The cover-
age numbers drop the most when the segmentation loss Lseg
is not used (-Lseg). When using point normals computed
from 64k input point clouds instead of predicting them (-
Lnorm+J*), the coverage also drops despite more accurate
point normals. This implies that SPFN predicts point nor-
mals in a way to better ﬁt primitives rather than to just ac-
curately predict the normals. Without including the ﬁtting
residual loss (-Lres), we see a drop in coverage and segmen-
tation accuracy. Excluding the primitive axis loss Laxis not

Figure 6: Results with real scans. Left are the 3D-printed
CAD models from the test set.

only hurts the axis accuracy, but also gives lower coverage
numbers (especially {Sk} coverage). Row 12 (ˆt → Est.)
shows results when using predicted types ˆt in the ﬁtting
residual loss (Equation 17) instead of the ground truth types
t. The results are compatible but slightly worse than SPFN
where we decouple type and other predictions in training.

4.6. Results with Real Scans

For testing with real noise patterns, we 3D-printed some
test models and scanned the outputs using a DAVID SLS-
2 3D Scanner. Notice that SPFN trained on synthesized
noises successfully reconstructed all primitives including
the small segments (Figure 6).

5. Conclusion

We have presented Supervised Primitive Fitting Network
(SPFN), a fully differentiable network architecture that pre-
dicts a varying number of geometric primitives from a 3D
point cloud, potentially with noise. In contrast to directly
predicting primitive parameters, SPFN predicts per-point
properties and then derive the primitive parameters using
a novel differentiable model estimator. The strong super-
vision we provide allows SPFN to accurately predict prim-
itives of different scales that closely abstract the underly-
ing geometric shape surface, without any user control. We
demonstrated in experiments that this approach gives sig-
niﬁcant better results compared to both the RANSAC-based
method [28] and direct parameters prediction. We also in-
troduced a new CAD model dataset, ANSI mechanical com-
ponent dataset, along with a set of comprehensive evalua-
tion metrics, based on which we performed our comparison
and ablation studies.

Acknowledgments. The authors wish to thank Chengtao
Wen and Mohsen Rezayat for valuable discussions and for
making relevant data available to the project. Also, the
authors thank TraceParts for providing ANSI Mechanical
Component CAD models. This project is supported by
a grant from the Siemens Corporation, NSF grant CHS-
1528025 a Vannevar Bush Faculty Fellowship, and gifts
from and Adobe and Autodesk. A. Dubrovina acknowl-
edges the support in part by The Eric and Wendy Schmidt
Postdoctoral Grant for Women in Mathematical and Com-
puting Sciences.

2659

References

[1] American National Standards Institute (ANSI). 6

[2] Aayush Bansal, Bryan Russell, and Abhinav Gupta. Marr
revisited: 2D-3D alignment via surface normal prediction.
CVPR, 2016. 2

[19] D. Marr and H. K. Nishihara. Representation and recogni-
tion of the spatial organization of three-dimensional shapes.
Proceedings of the Royal Society of London B: Biological
Sciences, 1978. 1

[20] J. Matas and O. Chum. Randomized RANSAC with T(d,d)

test. Image and Vision Computing, 2004. 2

[3] Thomas O. Binford. Visual perception by computer. In IEEE

[21] Iain Murray. Differentiation of the Cholesky decomposition,

Conference on Systems and Control, 1971. 1

2016. arXiv:1602.07527. 4

[22] A. Nurunnabi, Y. Sadahiro, and R. Lindenbergh. Robust
cylinder ﬁtting in three-dimensional point cloud data. In Int.
Arch. Photogramm. Remote Sens. Spatial Inf. Sci., 2017. 4

[23] Sven Oesau, Yannick Verdie, Cl´ement Jamin, Pierre Alliez,
Florent Lafarge, and Simon Giraudot. Point set shape detec-
tion. In CGAL User and Reference Manual. CGAL Editorial
Board, 4.13 edition, 2018. 6

[24] Charles Ruizhongtai Qi, Hao Su, Kaichun Mo, and
Leonidas J. Guibas. Pointnet: Deep learning on point sets
for 3D classiﬁcation and segmentation. In CVPR, 2017. 2

[25] Charles Ruizhongtai Qi, Ly Yi, Hao Su, and Leonidas J.
Guibas. Pointnet++: Deep hierarchical feature learning on
point sets in a metric space. In NIPS, 2017. 2, 3, 8

[26] Ren`e Ranftl and Vladlen Koltun. Deep fundamental matrix

estimation. In ECCV, 2018. 2

[27] TraceParts S.A.S. Traceparts. 6
[28] Ruwen Schnabel, Roland Wahl, , and Reinhard Klein. Efﬁ-
cient RANSAC for point-cloud shape detection. Computer
graphics forum, 2007. 1, 2, 6, 7, 8

[29] Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos
Kalogerakis, and Subhransu Maji. Csgnet: Neural shape
parser for constructive solid geometry. In CVPR, 2018. 2

[30] P. H. S. Torr and A. Zisserman. MLESAC: A new robust esti-
mator with application to estimating image geometry. CVIU,
2000. 2

[31] Shubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A.
Efros, and Jitendra Malik. Learning shape abstractions by
assembling volumetric primitives. In CVPR, 2017. 1, 2

[32] Qiaoyun Wu, Kai Xu, and Jun Wang. Constructing 3D CSG
models from 3D raw point clouds. Symposium on Geometry
Processing (SGP), 2018. 2

[33] Li Yi, Haibin Huang, Difan Liu, Evangelos Kalogerakis, Hao
Su, and Leonidas Guibas. Deep part induction from articu-
lated object pairs. SIGGRAPH Asia, 2018. 3

[34] Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan, and
Derek Hoiem. 3D-PRNN: Generating shape primitives with
recurrent neural networks. In ICCV, 2017. 1, 2

[4] Eric Brachmann, Alexander Krull, Sebastian Nowozin,
Jamie Shotton, Frank Michel, Stefan Gumhold, and Carsten
Rother. DSAC - Differentiable RANSAC for camera local-
ization. In CVPR, 2017. 2

[5] F. Cazals and M. Pouget. Estimating differential quantities
using polynomial ﬁtting of osculating jets. Symposium on
Geometry Processing (SGP), 2003. 6, 7

[6] Ondrej Chum and Jiri Matas. Matching with PROSAC - Pro-

gressive sample consensus. In CVPR, 2005. 2

[7] Tao Du, Jeevana Priya Inala, Yewen Pu, Andrew Spielberg,
Adriana Schulz, Daniela Rus, Armando Solar-Lezama, and
Wojciech Matusik.
InverseCSG: Automatic conversion of
3D models to CSG trees. SIGGRAPH Asia, 2018. 2

[8] Martin A. Fischler and Robert C. Bolles. Random sample
consensus: A paradigm for model ﬁtting with applications to
image analysis and automated cartography. Communications
of the ACM, 1981. 2

[9] Vignesh Ganapathi-Subramanian, Olga Diamanti, Soeren
Pirk, Chengcheng Tang, Matthias Niessner, and Leonidas J.
Guibas. Parsing geometry using structure-aware shape tem-
plates. In 3DV, 2018. 1

[10] Paul Guerrero, Yanir Kleiman, Maks Ovsjanikov, and
Niloy J. Mitra. PCPNET: Learning local shape properties
from raw point cloud. Eurographics, 2018. 2

[11] Catalin Ionescu, Orestis Vantzos, and Cristian Sminchisescu.
Matrix backpropagation for deep networks with structured
layers. 2015. 4

[12] Catalin Ionescu, Orestis Vantzos, and Cristian Sminchis-
escu. Training deep networks with structured layers by ma-
trix backpropagation. CoRR, abs/1509.07838, 2015. 4

[13] Adrien Kaiser, Jose Alonso Ybanez Zepeda, and Tamy
Boubekeur. A survey of simple geometric primitives de-
tection methods for captured 3D data. Computer Graphics
Forum, 2018. 2

[14] Zhizhong Kang and Zhen Li. Primitive ﬁtting based on the

efﬁcient multiBaySAC algorithm. PloS one, 2015. 2

[15] Philipp Kr¨ahenb¨uhl and Vladlen Koltun. Parameter learning
and convergent inference for dense random ﬁelds. In ICML,
2013. 3

[16] H. W. Kuhn. The hungarian method for the assignment prob-

lem. Naval Research Logistics Quarterly, 1955. 3

[17] Yangyan Li, Xiaokun Wu, Yiorgos Chrysanthou, Andrei
Sharf, Daniel Cohen-Or, and Niloy J. Mitra. Globﬁt: Consis-
tently ﬁtting primitives by discovering global relations. SIG-
GRAPH, 2011. 2

[18] Gabor Luk´acs, Ralph Martin, and Dave Marshall. Faithful
least-squares ﬁtting of spheres, cylinders, cones and tori for
reliable segmentation. In ECCV, 1998. 4

2660

