Deep Global Generalized Gaussian Networks

Qilong Wang1, Peihua Li2, Qinghua Hu1

,

∗, Pengfei Zhu1, Wangmeng Zuo3

1Tianjin University, 2Dalian University of Technology, 3 Harbin Institute of Technology
{qlwang,huqinghua,zhupengfei}@tju.edu.cn, peihuali@dlut.edu.cn, wmzuo@hit.edu.cn

Abstract

Recently, global covariance pooling (GCP) has shown
great advance in improving classiﬁcation performance of
deep convolutional neural networks (CNNs). However, ex-
isting deep GCP networks compute covariance pooling of
convolutional activations with assumption that activations
are sampled from Gaussian distributions, which may not
hold in practice and fails to fully characterize the statistics
of activations. To handle this issue, this paper proposes a
novel deep global generalized Gaussian network (3G-Net),
whose core is to estimate a global covariance of generalized
Gaussian for modeling the last convolutional activations.
Compared with GCP in Gaussian setting, our 3G-Net as-
sumes the distribution of activations follows a generalized
Gaussian, which can capture more precise characteristics
of activations. However, there exists no analytic solution for
parameter estimation of generalized Gaussian, making our
3G-Net challenging. To this end, we ﬁrst present a novel
regularized maximum likelihood estimator for robust esti-
mating covariance of generalized Gaussian, which can be
optimized by a modiﬁed iterative re-weighted method. Then,
to efﬁciently estimate the covariance of generaized Gaus-
sian under deep CNN architectures, we approximate this
re-weighted method by developing an unrolling re-weighted
module and a square root covariance layer. In this way, 3G-
Net can be ﬂexibly trained in an end-to-end manner. The
experiments are conducted on large-scale ImageNet-1K and
Places365 datasets, and the results demonstrate our 3G-Net
outperforms its counterparts while achieving very competi-
tive performance to state-of-the-arts.

1. Introduction

Deep convolutional neural networks (CNNs) have at-
tracted a great amount of attention in computer vision com-
munity, and demonstrated enormous advantages in many
tasks, especially in large-scale visual classiﬁcation [26, 34,
35, 17, 21, 20]. However, most deep CNN architectures

∗Qinghua Hu is the corresponding author. We thank NVIDIA corpora-

tion for donating GPU.

ResNet50 + Covariance (Gaussian)
ResNet50 + GAP

0

0.2

0.4

0.6

0.8

(b) 6-th Channel

ResNet50 + Covariance (Gaussian)
ResNet50 + GAP

1

0.8

0.6

0.4

0.2

0

1

0.8

0.6

0.4

0.2

0

(a) Input Image

ResNet50 + Covariance (Gaussian)
ResNet50 + GAP

1

0.8

0.6

0.4

0.2

0

0

0.2

0.4

0.6

0.8

0

0.2

0.4

0.6

0.8

(c) 67-th Channel

(d) 125-th Channel

Figure 1. Illustration of histograms or distributions of the last con-
volutional activations given an input image (a). We show, in some
channels, histograms and ﬁtting distributions of the last convolu-
tion activations in CNN models trained with global average pool-
ing (GAP) [17] (black bar) and covariance pooling [28] (red line),
respectively. Obviously, both of them have long tails and do not
obey strictly Gaussian distributions.

summarize the last convolutional activations only using
simple global ﬁrst-order pooling methods, severely limit-
ing the representation ability of deep CNNs. To handle this
issue, researchers integrate some global covariance pooling
(GCP) methods with deep CNNs in an end-to-end manner,
which show great effectiveness to improve the classiﬁcation
performance of deep CNNs [23, 32, 37, 28, 31, 27].

Among these GCP networks, Ionescu et al. [23] ﬁrst in-
tegrate a second-order pooling (O2P) [4] layer into deep
CNNs, namely DeepO2P, and develop a matrix backprop-
agation theory for end-to-end training. A parallel work
is bilinear CNN (B-CNN) [32], which concerns the outer
product of the last convolutional activations extracted from
two CNN models, followed by element-wise power normal-
ization and ℓ2-normalization. When two CNN models are
identical, B-CNN reduces to a global second-order pool-
ing of convolutional activations. Wang et al. [37] and Li
et al. [28] insert respectively a global Gaussian distribution

5080

and matrix power normalized covariance pooling after the
last convolution layer of deep CNNs, which obtain better
performance by considering geometry of Gaussian distribu-
tion and robust estimation of covariance. Subsequently, im-
proved B-CNN [31] shows empirically matrix square root
normalization can improve B-CNN, and uses the modiﬁed
Denman-Beavers iteration [19] to speed up inference of
the networks. Li et al. [27] develop forward and back-
ward propagation methods based on Newton-Schulz itera-
tion [19] to accelerate both training and inference of matrix
square root normalized covariance pooling networks [28].

Although previous deep GCP networks [23, 32, 37, 28,
31, 27] have proven to improve the representation ability
of deep CNNs, these methods compute covariance pooling
with invariably assuming that convolutional activations fol-
low a Gaussian distribution. Such an assumption does not
always hold true in real scenarios. To verify it, we randomly
choose some images from ImageNet-1K [9], and compute
histograms of the last convolutional activations extracted
from pre-trained CNN model with global average pooling
(GAP) [17], as well as ﬁtting distributions of ones extracted
from pre-trained GCP network [27]. Figure 1 plots the his-
tograms and distributions of activations for one example
(remaining others share similarity) in some channels. We
observe that either histograms of activations extracted from
GAP-based CNN or distributions of the ones extracted from
GCP network are long tailed, not strictly obeying Gaussian
distributions. Since Gaussian models fail to characterize
long-tailed distributions, covariance of Gaussian has lim-
ited capability to capture characteristics of activations.

Compared with Gaussian models, multivariate general-
ized Gaussian models can better characterize complex dis-
tributions, especially long-tailed ones [2]. In terms of the
considerations above, this paper proposes a deep global
generalized Gaussian networks (3G-Net). The core of 3G-
Net is to summarize the statistics of the last convolutional
activations by computing a global covariance of generalized
Gaussian, which can capture more precise characteristics of
convolutional activations. However, different from covari-
ance estimation in Gaussian setting, there exists no analytic
solution for covariance estimation of generalized Gaussian,
making our 3G-Net challenging. To circumvent this difﬁ-
culty, inspired by [38], we ﬁrst present a regularized max-
imum likelihood estimator, which allows us to robustly es-
timate covariance of generalized Gaussian distribution with
a modiﬁed iterative re-weighted method. According to this
estimator, we propose an unrolling re-weighted module and
a square root covariance layer for computing the covariance
of generalized Gaussian. The unrolling re-weighted module
is designed to iteratively estimate weight of each activation
in an approximative yet efﬁcient manner. The square root
covariance layer is used to compute matrix square root of
the estimated covariance, which is resulted by our modiﬁed

iterative re-weighted method. In this way, our 3G-Net can
be ﬂexibly trained in an end-to-end learning manner.

The overview of our proposed 3G-Net is illustrated in
Figure 2. The experiments are conducted on two large-scale
image benchmarks, i.e., ImageNet-1K [9] and Places365
[44]. The contributions of this paper can be concluded as
follows. (1) We propose a novel deep global generalized
Gaussian network (3G-Net) by estimating a global covari-
ance of generalized Gaussian to summarize the statistics of
the last convolutional activations, aiming at capturing pre-
cise characteristics of activations and further improving rep-
resentation ability of deep CNNs. (2) To our best knowl-
edge, we make the ﬁrst attempt to robustly estimate covari-
ance of generalized Gaussian distribution under deep CNN
architectures. From a point of implementation view, we in-
troduce an unrolling re-weighted module and a square root
covariance layer based on the proposed robust estimator.
(3) The experimental results on large-scale ImageNet-1K
and Places365 demonstrate the proposed 3G-Net outper-
forms its counterparts under ResNet architectures [17], and
achieves state-of-the-art performance.

2. Related Work

Recently, integration of preferable pooling or encoding
methods into deep CNNs has shown effectiveness in im-
proving classiﬁcation performance.
In contrary to afore-
mentioned deep GCP networks [23, 32, 37, 28, 31, 27],
some researchers study to approximate covariance pooling
for obtaining lower-dimensional representations. Among
them, Gao et al. [13] and Kong et al. [25] propose compact
B-CNN and low-rank B-CNN methods, respectively. Dai
et al. [8] fuse additional ﬁrst-order (mean) information into
the compact B-CNN [13] by simply concatenating them.
Gou et al. [15] approximate [37] by introducing homoge-
neous mapping and sub-matrix square-root layers followed
by compact B-CNN. Kernel pooling [7] extends the idea of
[13] to higher-order (number of order > 2) pooling for ﬁne-
grained visual recognition. Cai et al. [3] suggest a com-
pact higher-order pooling based on polynomial kernel ap-
proximation and rank-1 tensor decomposition [24]. Mean-
while, some works [40, 30] incorporate local approximated
second-order statistics into convolution or fully-connected
layers of deep CNNs to increase the nonlinearity of net-
works. Additionally, the classical Bag-of-Words models
are also embedded into deep CNNs [1, 29]. Different from
above methods, our 3G-Net incorporates a global covari-
ance of generalized Gaussian into deep CNNs, obtaining
better representations and higher classiﬁcation accuracy.

Our covariance of generalized Gaussian layer involves
an unrolling re-weighted module for computing iteratively
weights of activations. It shares the similarity with the re-
cently proposed self-attention mechanisms in deep CNNs
[20, 39, 11, 41, 12], among which Hu et al. [20] introduce

5081

Re-weighted 

Re-weighted 

Block 1

Block 2

……

Re-weighted 

Block T

X

X

X

Unrolling Re-weighted Module

Xˆ

⊗

X

ˆˆ=

ΤXXΣ

1/2ΣΣ =ˆ

Square Root Covariance

Image

Backbone Model

Global Covariance of Generalized Gaussian Layer

Loss

Figure 2. Overview of the proposed deep global generalized Gaussian networks (3G-Net), where a global covariance of generalized Gaus-
sian is inserted after the last convolution block to summarize the statistics of activations. Based on the proposed robust covariance estimator,
our global covariance of generalized Gaussian layer consists of an unrolling re-weighted module and a square root covariance layer.

a Squeeze-and-Excitation module into convolution blocks,
performing channel-wise weighting on outputs of each con-
volution block. Going a step further, CBAM [41] extends
[20] by introducing an additional spatial attention module.
Wang et al. [39] and Du et al. [11] propose non-local blocks
and interaction-aware attention module to obtain better at-
tention maps, respectively. Fu et al. [12] propose an at-
tention proposal sub-network to iteratively generates multi-
scale region attention for obtaining representations. Many
recent works are concerned with integration of attention
modules into deep CNNs, and a comprehensive review on
these methods is beyond the scope of this paper. Differ-
ent from these methods, our unrolling re-weighted mod-
ule is proposed, based on a modiﬁed iterative re-weighted
method, for estimating covariance of generalized Gaussian.

3. Proposed Method

In this section, we will introduce our proposed 3G-Net.
Firstly, we brieﬂy recall deﬁnition of multivariate gener-
alized Gaussian distribution and its parameter estimation.
Then, we construct the trainable covariance of generalized
Gaussian layer. Finally, we describe implementation of 3G-
Net based on the covariance of generalized Gaussian layer.

3.1. Multivariate Generalized Gaussian Distribu 

tion

Note that Eqn. (1) will reduce respectively to the Gaus-
sian and Laplacian distributions when β = 1 and β = 0.5.
Clearly, MGGD is able to characterize more complex dis-
tributions, in comparison to Gaussian models. Moreover,
MGGD has the ability to model long-tailed distributions,
more suitable for convolutional activations (as shown in
Figure 1). However, there is no closed-form solution for pa-
rameter estimation of MGGD. As shown in [43], maximum
likelihood estimation (MLE) for Σ of MGGD is deﬁned by

arg min

Σ

NXn=1

(xT

n Σ−1xn)β + N log |Σ|.

(2)

Based on above MLE (2), covariance Σ of MGGD can be
estimated by a ﬁxed point algorithm (or iterative reweighed
method) [33, 43]. Correspondingly, estimation of Σ in t-
iteration is described as:

Σt =

1
N

NXn=1

where yt

n = xT

n Σ−1

yt
n + (yt

N d

n)1−βPj6=n(yt

t−1xn, δ = (cid:18) β

dNPj6=n(yt

j)β · xnxT
n ,
j)β(cid:19) 1

β

(3)

and β

can be estimated by Newton-Raphson procedure [33], i.e.,

βt = βt−1 − f (βt−1)/f

′

(βt−1).

(4)

To summarize the statistics of the last convolutional acti-
vations X ∈ Rd×N = {x1, . . . , xN } with N samples of d-
dimension, we propose to employ a multivariate generalized
Gaussian distribution (MGGD) with zero mean [33] (i.e.,
covariance of MGGD), which takes the following form:

′

Here f
(βt−1) is the partial derivative of f (βt−1), and
f (βt−1) is a function associated with yt, βt−1 and a
digamma function (refer to [33, Eqn. (13)] for details). As
proven in [33], parameter estimation of MGGD based on
Eqns. (3) and (4) can converge to a stationary point.

p(xi; Σ; β; δ) =

Γ(d/2)

β

πd/2Γ(d/2β)2d/2β

δd/2|Σ|1/2

exp(cid:18)−

1
2δβ (xiΣ−1xT

i )β(cid:19) ,

where β and δ are shape and scale parameters of MGGD,
respectively; Σ is covariance matrix of MGGD, and Γ is a
Gamma function.

(1)

3.2. Trainable Covariance of Generalized Gaussian

Layer

To construct our trainable covariance of generalized
Gaussian layer, we ﬁrst introduce a regularized MLE for
robustly estimating covariance of generalized Gaussian.
Then, we achieve this estimator by developing an unrolling
re-weighted module and a square root covariance layer.

5082

3.2.1 Robust Covariance Estimation of Generalized

X

Gaussian

Recent works [38, 28] show classical MLE for covariance
of Gaussian is not robust under deep architectures, while ro-
bust estimator helps to improve performance. So we extend
similar idea to estimate covariance of generalized Gaussian.
As suggested in [38], we introduce the von Neumann diver-
gence [10] between Σ and identity matrix I as a regularizer
into the MLE (2). After some manipulations, we have

ˆ
t −X

1

ˆ
t −X

1

⋅

⊕

⋅

c

⊕

1x1 Conv

⋅

Element-wise 
Multiplication

⊕ Element-wise 

Addition

Sigmoid

Figure 3. Diagram of a re-weighted block in our unrolling re-
weighted module.

(yn)β + log |Σ| + λtr(Σ − log(Σ)),

(5)

iteration can be computed as

arg min

Σ

1
N

NXn=1

n Σ−1xn and λ is a regularizing constant.
where yn = xT
Analogous to [38], Eqn. (5) allows a robust estimator for co-
variance of generalized Gaussian under deep architectures.
However, the objective function in Eqn. (5) has no an-
alytic solution. For its optimization, we develop a modi-
ﬁed iterative re-weighted method so that we can obtain the
analytic expression of unique optimal solution for each it-
eration. Let Σt be 1
n , where
w(xn, Σt−1) indicate weights of xn in Eqn. (3) and Σt−1
is estimated covariance in (t-1)-th iteration. The solution of
Eqn. (5) can be concluded in the following theorem.

n=1 w(xn, Σt−1) · xnxT

NPN

Theorem 1 Let Σt = UDiag(σd)UT be the singular
value decomposition (SVD) of Σt, where Diag(σd) and U
are diagonal and orthogonal matrices consisting of singu-
lar values σd and eigenvectors, respectively. Then, objec-
tive function (5) can be optimized iteratively as

w(xn, Σt−1) · xnxT
n ,

(6)

Σt =

1
N

NXn=1

bΣt = UDiag(cid:18)s(cid:18) 1 − λ
λ (cid:19)2

+

σd
λ

−

1 − λ

λ (cid:19)UT ,

which is the unique optimal solution in t-th iteration.

Note that we set λ to 1 throughout all the experiments, as
λ = 0.5 ∼ 1 achieve the similar performance, and λ = 1
is easier to be implemented. According to Theorem 1,
our regularized iterative re-weighted method robustly esti-
mates covariance of generalized Gaussian with iteratively
re-weighting activations and computing matrix square root
of covariance. Due to page limit, complete proof of Theo-
rem 1 is given in the supplementary material.

3.2.2 Unrolling Re-weighted Module

N d

yt
n + (yt

w(xn, Σt−1) =

n)1−βPj6=n(yt
j)β ,
t−1, and bXt−1
t−1xn, Σt−1 = bXt−1bXT

where yt
indicates the weighted activations in (t-1)-th iteration. Since
j)β is independent of xn, we can rewrite Eqn. (7)

n = xT

n Σ−1

(7)

Pj6=n(yt

as

w(xn, Σt−1) =

N d
yt
n + cn(yt

n)1−β .

(8)

Here cn is a postive constant [33, Remark II.3]. Given a set
of activations X = {x1, · · · , xN }, we can compute weights
of X as:

wt = N d/(cid:0)(cid:2)Λ(Yt−1)(cid:3) + c ⊙(cid:2)Λ(Yt−1)(cid:3)1−β(cid:1),

where Yt−1 = XT Σ−1
t−1X, c = [c1, . . . , cN ], and
Λ(Yt−1) extracts the diagonal elements of matrix Yt−1.
⊙ and / indicate element-wise multiplication and division,
respectively.

(9)

However, Eqn. (9) involves matrix inversion, which
is not suitable for GPU parallel implementation, slowing
down the training of network. To handle this issue, we em-
ploy Newton-Schulz Iteration [19] and the idea of tensor
approximation [24] to develop a re-weighted block, as il-
lustrated in Figure 3, which can approximate Eqn. (9) in
an efﬁcient manner. Firstly, to avoid computing inversion
of Σt−1, we decompose Σ−1
t−1 . Then

t−1 into Σ−1/2

t−1 Σ−1/2

Yt−1 can be computed by(cid:0)Σ−1/2

Q0 = Σt−1 and P0 = I, Σ−1/2
following Newton-Schulz iteration method [19]:

t−1 X(cid:1)T(cid:0)Σ−1/2

t−1 X(cid:1). Given

t−1 can be computed with the

Qk =

Pk =

1
2
1
2

Qk−1(3I − Pk−1Qk−1),

(3I − Pk−1Qk−1)Pk−1.

(10)

According to Eqn. (6), our robust estimator needs to com-
pute the weights of activations in each iteration. Speciﬁ-
cally, the weight associated with each activation xn in t-th

After K iterations, QK and PK will converge to Σ1/2
t−1 and
Σ−1/2
t−1 , respectively. Previous works [31, 27] have demon-
strated Eqn. (10) can achieve satisfying performance with

5083

only one iteration. It motivates us to approximate Σ−1/2
t−1
t−1 ≈
with one-step Newton-Schulz iteration,

i.e., Σ−1/2

P1 =

(3I − Σt−1). So Yt−1 is approximated as

1
2

t−1 + 3I)X.

(11)

Yt−1 ≈

1
4

ZT Z, Z = (−bXt−1bXT

So far, we compute Λ(Yt−1) in Eqn. (9) requiring
t−1, both of which are second-order
tensors. Following the idea of tensor approximation [30,
3, 40], we approximate them using learnable 1 × 1 convolu-
tions followed by element-wise product. Given a W ×H ×d

Λ(ZT Z) and bXt−1bXT
tensor bXt−1, which can be reshaped to bXt−1 with N =
Λ(Yt−1) ≈ [conv1×(cid:0)conv1×(Zt−1) ⊙ conv1×(Zt−1)(cid:1),
Zt−1 ≈ [conv1×(bXt−1) ⊙ conv1×(bXt−1)] ⊕ conv1×(X ),

W × H, we can efﬁciently implement Λ(Yt−1) as follows:

(12)

Given Λ(Yt−1),

where conv1× and [conv1× denotes one and a group of 1×1
convolutions, respectively; ⊕ means element-wise addition.
the weights wt are computed with

N d/(cid:0)Λ(Yt−1) + c ⊙ Λ(Yt−1)1−β(cid:1). Here, N d/(·) can

be regarded as a normalization on estimated weights and
c ⊙ Λ(Yt−1) is a Hadamard product, where we use a
Sigmoid function and one 1 × 1 convolution for imple-
mentation, respectively. Finally, we compute wt using the
following formulation:

wt−1 ≈ φ(cid:0)Λ(Yt−1) ⊕ conv1×1((Λ(Yt−1))1−β)(cid:1),

where φ is a Sigmoid function. In terms of Eqns. (12) and
(13), we can implement our re-weighted block using basic
1 × 1 convolutions, element-wise operations and Sigmoid
function, endowing its efﬁciency and straightforward back-
propagation. To estimate covariance of generalized Gaus-
sian, we need to compute Eqn. (9) repeatedly. To this
end, as illustrated in Figure 2, we propose an unrolling
re-weighted module.
It consists of multiple consecutive
re-weighted blocks, each of which aims at implementing
Eqn. (9). By stacking multiple re-weighted blocks, we can
ﬂexibly construct our unrolling re-weighted module.

where Σ = bUbΛbUT is SVD of Σ. bΛ and bU are the eigen-
values and eigenvectors of Σ, respectively. bΛ

2 indicates
element-wise square root of the eigenvalues. It is easy to
see that computation of Eqn. (14) heavily dependents on
SVD or eigenvalues decomposition (EIG).

1

However, SVD or EIG is limitedly supported on GPU,
slowing down the training speed of square root covariance
layer [27]. Eqn.(10) gives the form of Newton-Schulz It-

eration [19], which shows bΣ can be approximated by QK

with K iterations and initialization of Q0 = Σ and P0 = I.
Compared with matrix square root via SVD (14), Eqn. (10)
only involves matrix multiplication, suitable for GPU im-
plementation. Here we employ the recently proposed train-
able iterative method [27] based on Eqn. (10) to make better
use of multi-GPU and accelerate the training of network. As
suggested in [27], additional pre-normalization (i.e., Q0 =

are employed. Thus, the partial derivative of loss function l

tr(Σ) Σ) and post-compensation (i.e., bΣ = ptr(Σ)QK )
with respect to bX can be derived based on matrix backprop-
QK(cid:17)

compensation takes the following form:

backpropagation

agation [23].

Speciﬁcally,

formula

post-

∂l

=

of

I.

1

∂QK

=ptr(Σ)

(15)

;

1

∂l

∂l

∂bΣ

∂Σ(cid:12)(cid:12)(cid:12)p

tr(cid:16)(cid:16)∂l/∂bΣ(cid:17)T
2ptr(Σ)
2(cid:16) ∂l
∂Qk(cid:16)3I − Qk−1Pk−1(cid:17) − Pk−1
∂Qk(cid:17),
2(cid:16)(cid:16)3I − Qk−1Pk−1(cid:17) ∂l
Pk−1Qk−1(cid:17),
2(cid:16) ∂l
∂Q1(cid:16)3I − Q0(cid:17) −

− Pk−1Qk−1

∂l
∂Pk

∂l
∂P1

− Qk−1

− Q0

∂Pk

∂l

∂l

−

1

1

∂Q1(cid:17).

∂l
∂Pk

∂l
∂Qk

Pk−1

Qk−1

(16)

∂l

∂Pk−1

=

∂l
∂Q0

=

According to Eqn. (10), the gradients of k-th iteration are

Considering Eqn. (15), the gradient of l with respect to Σ
can be computed as

(13)

∂l

∂Qk−1

=

3.2.3 Square Root Covariance Layer

As shown in Eqn. (6), for optimizing the regularized MLE
(5), we need to compute matrix square root of covariance
once the weights are estimated. Here we construct a square
root covariance layer to achieve it. Let weighted activations

be bX, we can compute square root covariance of bX as

1

bΣ = (bXbXT )1/2 = Σ1/2 = bUbΛ

2bUT ,

(14)

=

Σ(cid:17)

tr(cid:16)(cid:16)∂l/∂Q0(cid:17)T

∂l
∂Σ

−(tr(Σ))2

∂Σ(cid:12)(cid:12)(cid:12)p
Finally, the partial derivative of l with respect to bX is

∂l/∂Q0
tr(Σ)

I +

∂l

∂l

+

.

= bX(cid:18) ∂l

∂Σ

+(cid:18) ∂l

∂Σ(cid:19)T(cid:19),

Given ∂l/∂bX in Eqn. (18), we can complete backpropaga-

tion of square root covariance layer.

(17)

(18)

∂bX

5084

3.3. Deep Global Generalized Gaussian Networks

As suggested in previous methods [23, 32, 37, 28], we
construct our deep global generalized Gaussian networks
(3G-Net) by inserting the proposed covariance of general-
ized Gaussian layer after the last convolution block. In this
paper, we employ ResNet-50 and ResNet-101 [17] as back-
bone models. Following the settings in [28], we add one
1 × 1 convolution with 256 ﬁlters between the last con-
volution block and the proposed covariance of generalized
Gaussian layer, and remove downsampling in the last stage.
As such, dimension of last convolutional activations is re-
duced from 2048 to 256, while their size increases from
7 × 7 to 14 × 14, balancing efﬁciency and effectiveness.

To accomplish our unrolling re-weighted module, chan-
nel numbers of input and output of conv1× in the Eqn. (12)
both are set to 256. [conv1× is composed of two consecutive
1 × 1 convolutions, where the channel numbers of input and
output in the ﬁrst convolution are respectively set to 256 and
64, while ones of the second convolution are set to 64 and
1, respectively. We discard the element-wise power oper-
ation of Eqn. (13) in the re-weighted block, as the experi-
mental results show it has little effect on performance. For
guaranteeing efﬁciency of our 3G-Net, we run respectively
the Newton-Schulz Iteration (10) within one iteration and
ﬁve iterations in unrolling re-weighted module and the ﬁ-
nal square root covariance layer, albeit more iterations may
bring further improvement. By performing matrix triangu-
lation, our covariance of generalized Gaussian layer outputs
a 256(256 + 1)/2-dimensional vector for ﬁnal prediction.
Note that, our 3G-Net will bring about additional 0.34 × T
M parameters (T indicates number of iterations), compar-
ing with existing deep global covariance pooling networks
in Gaussian setting [23, 32, 28, 27].

4. Experiments

To evaluate the effectiveness of our proposed 3G-Net, we
conduct experiments on widely used ImageNet-1K [9] and
Places365 [44] datasets. We ﬁrst describe training details of
our 3G-Net, and make ablation study to analyze effects of
key components using ImageNet-1K. Finally, we compare
with state-of-the-arts on both ImageNet-1K and Places365.

4.1. Training Details

To train our 3G-Net, we adopt the same data augmen-
tation strategy with [34, 17, 28]. Speciﬁcally, all training
images with mean subtraction and standard color augmenta-
tion are resized with their shorter side randomly sampled on
[256, 512], and a 224×224 patch is randomly cropped from
each resized image. The random horizontal ﬂip is used. Fol-
lowing the settings in [17], we optimize the network param-
eters using SGD with a mini-batch size of 256, a momentum
of 0.9 and a weight decay of 0.0001. The learning rate is

ResNet-50 (GAP)
iSQRT-COV (Re-implement)
3G-Net (Ours)

24

23.5

23

22.5

22

21.5

)

%

(
 
r
o
r
r
E
1
-
p
o
T

 

21

0

1

2
T

3

4

Figure 4. Effect of number of iterations (T ) on the proposed 3G-
Net with ResNet-50 architecture on ImageNet-1K.

initialized to 0.1, and is divided by 10 every 30 epochs. We
adopt respectively single center crop and 10-crop predic-
tions on ImageNet-1K and Places365, and report top-1 and
top-5 error rates on validation sets for comparison. All pro-
grams are implemented using PyTorch package1, and run
on a PC equipped with four Titan Xp GPUs and 64G RAM.

4.2. Ablation Study on ImageNet 1K

Impact of Iteration Number Number of iterations (T )
of our modiﬁed iterative re-weighted method (i.e., number
of blocks in unrolling re-weighted module) plays a key role
in covariance estimation of generalized Gaussian. To as-
sess the effect of parameter T on our 3G-Net, we employ
ResNet-50 as a backbone model and conduct experiments
on ImageNet-1K dataset. It contains about 1.28M training
images and 50K validation images, collected from 1,000
object categories. Top-1 errors of our 3G-Net with differ-
ent numbers of iterations are shown in Figure 4, where we
also compare with baseline methods, i.e., ResNet-50 with
GAP [17] and iSQRT-COV [27]. Note that ResNet-50 with
iSQRT-COV [27] can be regarded as a special case of our
3G-Net without re-weighting activations, i.e., estimating
covariance in Gaussian setting. Increasing number of itera-
tions can achieve lower classiﬁcation errors, and the perfor-
mance of our 3G-Net saturates with T = 3 (21.31% in Top-
1 error). The larger number of iterations brings negligible
gain but more computational and memory costs. Compared
with baseline methods, our 3G-Net outperforms ResNet-50
based on GAP and iSQRT-COV over 2.6% and 0.64% in
Top-1 error, respectively. Based on the above results, we
set T to 3 throughout the following experiments for balanc-
ing effectiveness and efﬁciency.

Effectiveness of Re-weighted Module To verify the ef-
fectiveness of our unrolling re-weighted module, we com-
pare with its two variants. The ﬁrst one only employs
[conv1× in Eq. (12) (i.e., two consecutive 1 × 1 convolu-

1The source code and network models will be available at https:

//github.com/csqlwang/3G-Net

5085

⋅

(a) URM-v1

(b) URM-v2

1x1 Conv

⋅

Element-wise 
Multiplication

Sigmoid

Figure 5. Illustration of two variants of our unrolling re-weighted
module, i.e., (a) URM-v1 and (b) URM-v2.

Method

Top-1 error

Top-5 error

None
URM-v1
URM-v2
3G-Net with T = 1 (Ours)
3G-Net with T = 3 (Ours)

21.95
21.97
21.89
21.64
21.31

6.17
6.17
6.14
5.81
5.61

Table 1. Results (in %) of 3G-Net with different re-weighted mod-
ules on ImageNet-1K.

Method

Top-1 err.

Top-5 err.

GAP [17]
GAP (Re-implement)
Plain COV
B-CNN [32]
G2DeNet [37]
MPN-COV [28]
iSQRT-COV [27]
iSQRT-COV (Re-implement)
3G-Net w/o Estimator (5)
3G-Net (Ours)

24.6
23.91
26.41
23.18
22.77
22.73
22.14
21.95
25.17
21.31

7.7
7.15
9.09
6.96
6.55
6.54
6.22
6.17
8.14
5.61

Table 2. Results (in %) of different global pooling methods under
ResNet-50 architecture on ImageNet-1K.

tions), which is a commonly used method to generate spa-
tial attention maps [41]. The second one introduces an addi-

tional conv1×(bXt−1) ⊙ conv1×(bXt−1) into the ﬁrst variant

of module. These two variants can be seen as two subdivi-
sions of our unrolling re-weighted module, namely URM-
v1 and URM-v2, respectively. The illustrations of URM-v1
and URM-v2 are shown in Figure 5. Table 1 lists the results
of our method with different re-weighted modules, from it
we can see that both URM-v1 and URM-v2 achieve no or
negligible gain, while our single re-weighted block outper-
forms URM-v1 and URM-v2 by 0.36% and 0.33% in Top-5
error, respectively. The unrolling re-weighted module con-
sisting of 3 blocks achieves further improvement, showing
the effectiveness of our unrolling re-weighted module.

Robust Estimator We evaluate effect of robust estima-
tion (5) on our 3G-Net. It brings no extra parameters, and
is on par with non-robust one in space/time complexity. As
compared in Tables 2 and 3, 3G-Net without (w/o) robust
estimation (5) is superior to Plain COV, but is clearly in-
ferior to the one with robust estimator. Additionally, 3G-
Net under ResNet-50 with or w/o robust estimation obtain
43.07/13.34 vs. 45.47/15.00 on Places365. Above results
clearly show the signiﬁcance of our robust estimation.

Comparison of Various Global Pooling We compare

Method

Backbone Models

Top-1

Top-5

ResNet-50

ResNet-101

FBN [30]
SORT [40]
ResNeXt [42]
SE [20]
CBAM [41]
A2-Nets [6]
DropBlock [14]
iSQRT-COV [27]
3G-Net (Ours)
GAP [17]
ResNeXt [42]
SE [20]
CBAM [41]
iSQRT-COV [27]
3G-Net w/o Estimator (5)
3G-Net (Ours)
ResNet-152 [17]
ResNet-152 + SE [20]
ResNet-200 [18]>
PyramidNet-200 [16]>
DenseNet-264 [21]

24.0
23.82
22.11
23.29
22.66
23.0
21.87
22.14
21.31
23.6
21.2
22.38
21.51
21.21
24.23
20.37
23.0
21.57
21.7
20.1
22.15

7.1
6.27
5.90
6.62
6.31
6.5
5.98
6.22
5.61
7.1
5.6
6.07
5.69
5.68
7.58
5.17
6.7
5.73
5.8
5.4
6.12

Table 3. Comparison of errors (in %) with state-of-the-art methods
on ImageNet-1K. All methods employ single 224 × 224 crop pre-
diction, and the competing results are duplicated from the original
papers. >The results are copied from [20].

our 3G-Net with several existing global pooling methods
using ResNet-50, including the original GAP [17], Plain co-
variance (COV) pooling (i.e., XXT ), B-CNN [32], MPN-
COV [28], G2DeNet [37] and iSQRT-COV [27]. The re-
sults of GAP, MPN-COV and iSQRT-COV are copied from
the original papers. We implement Plain COV, B-CNN and
G2DeNet by ourselves, and we also re-implement GAP and
iSQRT-COV. For fair comparison, we adopt the same set-
tings of network and hyperparameters for all competitors.
Note that we insert a BN layer [22] after B-CNN model
for stable and rapid convergence. The results of different
methods on ImageNet-1K are given in Table 2. All second-
order pooling methods except Plain COV outperform the
original GAP. Plain COV achieves unsatisfactory result in
this case. G2DeNet and MPN-COV obtain similar results,
which are superior to B-CNN. Our 3G-Net achieves the
best performance, demonstrating covariance of generalized
Gaussian is more effective than the ones based on Gaussian
[32, 28, 27, 37]. Our 3G-Net outperforms iSQRT-COV by
0.56% in Top-5 error, which is a non-trivial improvement,
since iSQRT-COV is a very strong baseline while iSQRT-
COV under ResNet-101 with much more parameters just
achieves 0.54% gain over iSQRT-COV with ResNet-50.

4.3. Comparison on ImageNet 1K

Here we compare our 3G-Net, under both ResNet-50
and ResNet-101 architectures, with several state-of-the-art
methods on ImageNet-1K. The top-1 and top-5 errors of
different methods are listed in Table 3, where the results
of ResNet-200 [18], PyramidNet-200 [16] and remaining
competing methods are duplicated from [20] and the origi-
nal papers, respectively. As shown in Table 3, our 3G-Net

5086

Method
Top-1 err.
Top-5 err.

Method
Top-1 err.
Top-5 err.

ResNet-50 [17] △

44.82
14.71

ResNet-50+B-CNN [32]

ResNet-50+iSQRT-COV [27]

ResNet-50+3G-Net (Ours)

ResNet-101+3G-Net (Ours)

44.24
14.27

43.68
13.73

43.07
13.34

42.77
13.12

GoogLeNet [35]△

ResNet-152 [17] △

ResNet-101 [17]

ResNeXt-101 [42]♣

CRU-Net-116 [5]♣

46.37
16.12

45.26
14.92

44.09
13.93

43.79
13.75

43.40
13.45

Table 4. Results (in %) of different methods with 10-crop prediction on Places365. △The results are duplicated from https://github.
com/CSAILVision/places365. ♣The results are copied from [5].

obtains the best performance among all competing meth-
ods under ResNet-50 architecture. Compared with deep
local second-order statistics networks, i.e., FBN [30] and
SORT [40], our 3G-Net achieves a clear improvement.
Meanwhile, 3G-Net is superior to ResNeXt [42], which
employs much wider convolution ﬁlters. Compared with
deep CNNs based on various advanced self-attention meth-
ods [20, 41, 6], 3G-Net obtains 1.98%, 1.35%, 1.69% and
1.01%, 0.7%, 0.89% gains in top-1 and top-5, respectively.
Our 3G-Net obtains 0.83% in top-1 (0.61% in top-5) gains
over the top deep covariance pooling network [27].

When ResNet-101 is used as a backbone model, the pro-
posed 3G-Net improves the original ResNet-101 with GAP
by a large margin.
In like manner, our 3G-Net is supe-
rior to ResNeXt-101 over 0.89% in top-1 (0.43% in top-5).
Meanwhile, it outperforms respectively SE-Net and CBAM
[20, 41] about 2.01% and 1.14% in top-1 (0.9% and 0.52%
in top-5). The proposed 3G-Net improves iSQRT-COV over
0.84% and 0.51% in top-1 and top-5, respectively. Note
that our 3G-Net based on ResNet-50 is slightly superior to
iSQRT-COV with ResNet-101 in top-5 error, while our 50-
layer 3G-Net outperforms 152-layer ResNet [17] and 152-
layer ResNet with SE module [20]. Furthermore, 50-layer
3G-Net performs better than 200-layer ResNet [18] while
101-layer 3G-Net is slightly superior to 200-layer pyrami-
dal ResNet [16] in top-5 error. Our 50-layer 3G-Net also
outperforms DenseNet [21] of 264 layers. Above results
clearly suggest the competitiveness of our 3G-Net.

4.4. Comparison on Places365

Finally, we evaluate our 3G-Net on standard Places365
dataset, which includes about 1.8M and 36.5K images
of 365 scene classes for training and validation, respec-
tively. Compared with ImageNet-1K, each sample image
in Places365 involves of more objects, leading more ambi-
guity. Using ResNet-50 and ResNet-101 as backbone mod-
els, we compare with three global pooling methods (i.e.,
GAP [17], B-CNN [32] and iSQRT-COV [27]) and four
deep CNN architectures (i.e., GoogLeNet [35], ResNet-152
[17], ResNeXt-101 [42] and CRU-Net-116 [5]). We adopt
10-crop prediction in comparison to the existing results.

The results of different methods are given in Table 4,
where we implement B-CNN by ourselves, and implement
iSQRT-COV using the source code released by the authors.

We adopt exactly the same parameter settings for fair com-
parison. Compared with other three global pooling meth-
ods under ResNet-50 architectures, our 3G-Net obtains the
lower classiﬁcation error. The proposed 3G-Net is signif-
icantly better than the original GAP, and outperforms B-
CNN and iSQRT-COV by 1.17% and 0.61% in top-1 er-
ror, respectively. Our 3G-Net can achieve further improve-
ment using ResNet-101, and obtains the best results.
It
demonstrates the effectiveness of our global covariance of
generalized Gaussian layer. Compared with the advanced
deep CNN architectures, our 3G-Net clearly outperforms
GoogLeNet and ResNet-152, while achieving better results
than CRU-Net-116 and ResNeXt-101, although they are
much deeper and wider.

5. Conclusion

In this paper, we proposed a novel 3G-Net, which ro-
bustly estimates a global covariance of generalized Gaus-
sian distribution to summarize the last convolutional acti-
vations, since distributions of convolutional activations are
complex and have long tails, which can not be fully charac-
terized by Gaussian models. Our 3G-Net assumes distribu-
tion of convolutional activations obey a generalized Gaus-
sian model, capturing characteristic of activations more pre-
cisely. The experimental results on large-scale ImageNet-
1K and Places365 datasets demonstrated our 3G-Net can
achieve higher classiﬁcation accuracy than deep CNNs with
either GAP or global covariance of Gaussian. The effective-
ness of 3G-Net suggests more precise characterization of
convolutional activations is helpful to improve performance
of deep CNNs. In future, we will apply the proposed 3G-
Net to action or video classiﬁcation, and investigate integra-
tion of more diverse distributions (e.g., exponential families
[36]) into deep CNNs for further improvements.

Acknowledgments

The work was supported by the National Natural Sci-
ence Foundation of China (Grant No. 61806140, 61471082,
61671182, 61876127, 61732011), Natural Science Founda-
tion of Tianjin Under Grants 17JCZDJC30800, and Young
Elite Scientists Sponsorship Program by Tianjin. Qilong
Wang was supported by China Post-doctoral Programme
Foundation for Innovative Talent.

5087

References

[1] R. Arandjelovic, P. Gronat, A. Torii, T. Pajdla, and J. Sivic.
NetVLAD: CNN architecture for weakly supervised place
recognition. In CVPR, 2016.

[2] G. E. P. Box and G. C. Tiao. Bayesian Inference in Statistical

Analysis. Wiley, New York, USA, 1992.

[3] S. Cai, W. Zuo, and L. Zhang. Higher-order integration of
hierarchical convolutional activations for ﬁne-grained visual
categorization. In ICCV, 2017.

[4] J. Carreira, R. Caseiro, J. Batista, and C. Sminchisescu. Free-
IEEE

form region description with second-order pooling.
TPAMI, 37(6):1177–1189, 2015.

[5] Y. Chen, X. Jin, B. Kang, J. Feng, and S. Yan. Sharing resid-
ual units through collective tensor factorization to improve
deep neural networks. In IJCAI, 2018.

[6] Y. Chen, Y. Kalantidis, J. Li, S. Yan, and J. Feng. A2-Nets:

Double attention networks. In NIPS, 2018.

[7] Y. Cui, F. Zhou, J. Wang, X. Liu, Y. Lin, and S. Belongie.
Kernel pooling for convolutional neural networks. In CVPR,
2017.

[8] X. Dai, J. Yue-Hei Ng, and L. S. Davis. FASON: First and
second order information fusion network for texture recog-
nition. In CVPR, 2017.

[9] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. ImageNet: A large-scale hierarchical image database.
In CVPR, 2009.

[10] I. S. Dhillon and J. A. Tropp. Matrix nearness problems
with Bregman divergences. SIAM J. MAP, 29(4):1120–1146,
2008.

[11] Y. Du, C. Yuan, B. Li, L. Zhao, Y. Li, and W. Hu. Interaction-
aware spatio-temporal pyramid attention networks for action
classiﬁcation. In ECCV, 2018.

[12] J. Fu, H. Zheng, and T. Mei. Look closer to see better: Recur-
rent attention convolutional neural network for ﬁne-grained
image recognition. In CVPR, 2017.

[13] Y. Gao, O. Beijbom, N. Zhang, and T. Darrell. Compact

bilinear pooling. In CVPR, 2016.

[14] G. Ghiasi, T.-Y. Lin, and Q. V. Le. DropBlock: A regular-

ization method for convolutional networks. In NIPS, 2018.

[15] M. Gou, F. Xiong, O. Camps, and M. Sznaier. MoNet: Mo-

ments embedding network. In CVPR, 2018.

[23] C. Ionescu, O. Vantzos, and C. Sminchisescu. Matrix back-
In

propagation for deep networks with structured layers.
ICCV, 2015.

[24] T. G. Kolda and B. W. Bader. Tensor decompositions and

applications. SIAM Review, 51(3):455–500, 2009.

[25] S. Kong and C. Fowlkes. Low-rank bilinear pooling for ﬁne-

ImageNet
In

grained classiﬁcation. In CVPR, 2017.

[26] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

classiﬁcation with deep convolutional neural networks.
NIPS, 2012.

[27] P. Li, J. Xie, Q. Wang, and Z. Gao. Towards faster train-
ing of global covariance pooling networks by iterative matrix
square root normalization. In CVPR, 2018.

[28] P. Li, J. Xie, Q. Wang, and W. Zuo. Is second-order infor-
mation helpful for large-scale visual recognition? In ICCV,
2017.

[29] Y. Li, M. Dixit, and N. Vasconcelos. Deep scene image clas-

siﬁcation with the MFAFVNet. In ICCV, 2017.

[30] Y. Li, N. Wang, J. Liu, and X. Hou. Factorized bilinear mod-

els for image recognition. In ICCV, 2017.

[31] T.-Y. Lin and S. Maji. Improved bilinear pooling with CNNs.

In BMVC, 2017.

[32] T.-Y. Lin, A. RoyChowdhury, and S. Maji. Bilinear CNN

models for ﬁne-grained visual recognition. In ICCV, 2015.

[33] F. Pascal, L. Bombrun, J. Tourneret, and Y. Berthoumieu.
Parameter estimation for multivariate generalized Gaussian
distributions. IEEE TSP, 61(23):5960–5971, 2013.

[34] K. Simonyan and A. Zisserman. Very deep convolutional
networks for large-scale image recognition. In ICLR, 2015.
[35] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed,
D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions. In CVPR, 2015.

[36] M. J. Wainwright and M. I. Jordan. Graphical models, expo-
nential families, and variational inference. Foundations and
Trends in Machine Learning, 1(1-2):1–305, 2008.

[37] Q. Wang, P. Li, and L. Zhang. G2DeNet: Global Gaussian
distribution embedding network and its application to visual
recognition. In CVPR, 2017.

[38] Q. Wang, P. Li, W. Zuo, and L. Zhang. RAID-G: Robust es-
timation of approximate inﬁnite dimensional Gaussian with
application to material recognition. In CVPR, 2016.

[39] X. Wang, R. Girshick, A. Gupta, and K. He. Non-local neural

[16] D. Han, J. Kim, and J. Kim. Deep pyramidal residual net-

networks. In CVPR, 2018.

works. In CVPR, 2017.

[17] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning

for image recognition. In CVPR, 2016.

[18] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in

deep residual networks. In ECCV, 2016.

[19] N. J. Higham. Functions of Matrices: Theory and Computa-

tion. SIAM, Philadelphia, PA, USA, 2008.

[20] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation net-

works. In CVPR, 2018.

[21] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger.
Densely connected convolutional networks. In CVPR, 2017.
[22] S. Ioffe and C. Szegedy. Batch Normalization: Accelerating
deep network training by reducing internal covariate shift. In
ICML, 2015.

[40] Y. Wang, L. Xie, C. Liu, S. Qiao, Y. Zhang, W. Zhang,
Q. Tian, and A. Yuille. SORT: Second-order response trans-
form for visual recognition. In ICCV, 2017.

[41] C. Woo, J. Park, J.-Y. Lee, and I. S. Kweon. BAM: Convo-

lutional block attention module. In ECCV, 2018.

[42] S. Xie, R. B. Girshick, P. Doll´ar, Z. Tu, and K. He. Aggre-
gated residual transformations for deep neural networks. In
CVPR, 2017.

[43] T. Zhang, A. Wiesel, and M. S. Greco. Multivariate general-
ized Gaussian distribution: Convexity and graphical models.
IEEE TSP, 61(16):4141–4148, 2013.

[44] B. Zhou, `A. Lapedriza, A. Khosla, A. Oliva, and A. Torralba.
Places: A 10 million image database for scene recognition.
IEEE TPAMI, 40(6):1452–1464, 2018.

5088

