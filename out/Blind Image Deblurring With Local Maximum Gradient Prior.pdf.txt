Blind Image Deblurring with Local Maximum Gradient Prior

Liang Chen

Faming Fang∗

Tingting Wang

Guixu Zhang

Shanghai Key Laboratory of Multidimensional Information Processing, and

Department of Computer Science and Technology, East China Normal University, Shanghai, China

Abstract

Blind image deblurring aims to recover sharp image
from a blurred one while the blur kernel is unknown. To
solve this ill-posed problem, plenty of image priors have
been explored and used in this area.
In this paper, we
present a blind deblurring method based on Local Maxi-
mum Gradient (LM G) prior. Our work is inspired by the
simple and intuitive observation that the maximum value of
a local patch gradient will diminish after blurring process,
which is proved to be true both mathematically and empiri-
cally. This inherent property of the blurring process allows
us to establish a new energy function. By introducing a lin-
ear operator to compute the Local Maximum Gradient, to-
gether with an effective optimization scheme, our method
can handle various speciﬁc scenarios. Extensive experi-
mental results illustrate that our method is able to achieve
favorable performance against state-of-the-art algorithms
on both synthetic and real-world images.

1. Introduction

Single image blind deblurring has drawn considerable
attention in recent years. Photography equipments, from
surveillance camera to personal hand-held smart phone, are
often suffered from blurring when capturing images. The
blurring process is characterized by the relative rotation or
translation between cameras and objects within camera lens
exposure time.

If the blur kernel is space-invariant, we consider it as
uniform blur. The blurring process is modelled as a convo-
lution operation, i.e.,

B = I ⊗ K + ǫ,

(1)

where B, I, K and ǫ represent blurry input, latent image,

∗Corresponding Author. Email address: fmfang@cs.ecnu.edu.cn. This
work was sponsored by the Key Project of the National Natural Science
Foundation of China under Grant 61731009 and the National Natural Sci-
ence Foundation of China under Grant 61871185, and ”Chenguang Pro-
gram” supported by Shanghai Education Development Foundation and
Shanghai Municipal Education Commission under Grant 17CG25.

blur kernel and the inevitable noise, respectively, and ⊗ de-
notes the convolution symbol. Latent image I and blur ker-
nel K are what we intend to acquire out of this equation.
This is a highly ill-posed problem, because different pairs
of I and K can bring about the same B.

Recent works, either optimization-based [4, 23, 2, 27,
20] or learning-based [24, 22, 17, 30, 25], have brought
signiﬁcant improvements in blind deconvolution. We give
a detailed introduction to the highly related optimization-
based methods in this section.

Fergus et al. [4] introduce heavy-tailed distribution of
natural images gradient histogram and sparse characteristic
of blur kernel. Shan et al. [23] exploit a new representa-
tion by concatenating two piece-wise continuous functions
to ﬁt the heavy-tailed distribution of logarithmic gradient,
and incorporate it with a local prior for blind deblurring.
To accelerate the iteration process, Cho and Lee [2] adopt
a multi-scale framework, and utilize image gradient for the
deblurring process rather than pixel values. Xu et al. [26]
ﬁnd that strong edges could not improve kernel estimation
when object scale is relatively smaller than the kernel, and
they introduce a two-phase method to reﬁne the kernel es-
timation step. Moreover, Levin et al.
[14] derive an ef-
fective method to optimize the popular maximum a poste-
riori (M AP ) framework. Krishnan et al.
[10] utilize an
L1/L2 regularization which inhenrently favors clear image
over blurred ones. Hu et al. [7] adopt conditional random
ﬁeld framework to learn good regions for deblurring. Xu
et al. [27] develop an unnatural L0 sparse expression and
greatly reduce the running time.
Instead of utilizing the
salient edges for kernel estimation directly, Gong et al. [5]
use a gradient activation method to automatically select a
subset of gradients of the latent image for the task. These
methods perform well on natural blurry images. However,
when it comes to special occasions, such as human face
[18], low-light [6] and text [19] blurred images, some of
them will encounter setbacks.

A number of image priors have also been utilized to solve
this ill-posed problem [16, 11, 21, 20, 28, 15]. To name a
few, natural image patches across different scales are previ-
ously used by Michaeli and Ironi [16], as the patches recur-

11742

(a) Blurred image

(b) Our result

(c) LMG map of (a)

(d) LMG map of (b)

Figure 1. Deblurring result of a blurred image. The blurring process diminishes the LMG value of a clear image. Maximizing LMG value
helps to recover blurry images.

rence will decrease in blurred images. Lai et al. [11] uti-
lizes the normalized color-line prior to restore sharp edges.
Ren et al. [21] make use of low rank characteristic of simi-
lar local patch groups. However, the low-rank property has
their limitations when the blurred image contains rich tex-
tures. Pan et al. [20] utilize dark channel prior (most of the
smallest pixels value in a patch are likely to be zero) and
outperform various existing methods. Nevertheless, when
the images are bright pixels dominant, dark channel prior
based method is less likely to help estimate the kernel. To
remedy this problem, Yan et al. [28] introduce an extreme
channel prior based on dark channel and the opposite bright
channel. To incorporate with the deep learning approach,
Li et al. [15] adopt a CNN network structure to learn a dis-
criminative prior for the task.

In this paper, we propose a new blind deblurring frame-
work based on Local Maximum Gradient (LM G) prior. We
ﬁnd that after the blurring process, the maximum gradi-
ent value of a local patch will diminish. We incorporate
this property into a conventional sparse-based energy func-
tion. Empirically, we enforce an L1 norm to the LM G in-
volved term which favours clear images over blurred images
during the iteration steps. With a non-linear optimization
scheme, our algorithm performs well on both synthetic and
real datasets.

Our contributions of this work can be summarized as fol-
lows: (1) we present a new image prior termed as LM G
and mathematically prove why it works during deblurring
process; (2) we adopt L1 norm on the LM G involved term,
and provide an effective optimization scheme for the energy
function; (3) our method performs well on both synthetic
benchmark datasets [13, 9, 12] and real images against
state-of-the-art algorithms.

2. Local Maximum Gradient Prior

We now introduce the new prior, and then prove why
it works mathematically. The prior is based on a proposi-
tion that, in a local image patch, the maximum value of the
LM G will diminish after the blurring process (as shown in
Fig. 1). To better illustrate this observation, we formally

deﬁne LM G as follows,

LM G(I)(x) = max

c∈{r,g,b}

( max
y∈P (x)

(|∇I c(y)|)),

(2)

where both x and y denote pixel locations in the image,
P (x) is the image patch centered at x, c is the color channel
which belongs to set {r, g, b}, ∇ denotes gradient operator
in two dimensions. Here we use length accumulation of
two dimensions. Note that from Eq. (2), if the input image
is gray-scale, only one max operation is needed.

We take the one-dimension signal as an example. As
shown in Fig. 2(a), we can observe that in a certain do-
main area △h, the gradient of the blurred signal (red curve)
is smaller than the corresponding clear one (dark straight).
This observation conforms to our proposition. The same
situation can be extended to two-dimension signal such as
an image.

Additionally, we validate our theory on a dataset of
4, 000 images from PASCAL 2012 dataset [1]. We blur the
images to obtain 4, 000 corresponding blurry images, and
then calculate the LM G value of these images. As shown
in Fig. 2(b) and (c). Most LMG values of blurred images
are below 0.4, while the LMG values of corresponding clear
images are distributed ranging from 0 to 2. Therefore, this
statistical law demonstrates that the blurring process will
diminish the LM G value. The phenomenon is not surpris-
ing. To conﬁrm the above observation, we conduct follow-
ing veriﬁcation,

max
y∈P (x)

|∇B(y)| = max
y∈P (x)

|∇(I(y) ⊗ K) |

= max
y∈P (x)

≤ max
y∈P (x)

= max
y∈P (x)

|∇I(y) ⊗ K |

|∇I(y)| ∗ |K|

|∇I(y)|,

(3)

the second to third step in Eq. (3) can be proved by Young’s
convolution inequality [29]. Considering that color channel
is not an inﬂuential factor of the proposition, we extend Eq.

21743

1

0.8

0.6

0.4

0.2

0

50

Blur
Clear

150

△v

△v

△h
100

(a)

3

2

l

3.5

2.5

s ×104
t
n
e
m
e
e
 
G
M
L
 
f
o
 
r
e
b
m
u
n
 
e
g
a
r
e
v
A

0.5

1.5

1

0

Blur
Clear

y
t
i
l
i

b
a
b
o
r
p
e
v
i
t

 

l

l

a
u
m
u
c
 
s
t
n
e
m
e
e
G
M
L
e
g
a
r
e
v
A

 

 

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

Blur
Clear

0.5

1

Gradient

1.5

2

(c)

0

0.5

1.5

2

1

Gradient

(b)

Figure 2. (a) The maximum gradients of clear signal (black) and corresponding blurry signal (red). △h and △v denote range and gra-
dient. (b) Average intensity histograms of LM G elements of both clear image and blurry image in PASCAL 2012 dataset [1]. (c) The
corresponding cumulative distribution of (b).

(3) to,

max

c∈{r,g,b}

( max
y∈P (x)

(|∇Bc(y)|)) ≤

max

c∈{r,g,b}

( max
y∈P (x)

(|∇I c(y)|)).

(4)

This notion of LM G holds for all the patches in the image.
We can also derive from the deﬁnition of LMG (Eq. (2))
that the theoretical maximum value of LM G at a pixel is
2. Based on these properties, we have the following inequa-
tion,

LM G(B)(x) ≤LM G(I)(x),

which implies,

2 − LM G(B)(x) ≥2 − LM G(I)(x).

(5)

(6)

(5) demonstrates that LM G values of latent images
Eq.
are tending to be larger than those of blurred image. We
adopted the convex L1 norm to accumulate all LM G in-
volved term throughout the image, and the reason for choos-
ing the L1 norm will be demonstrated in section 5.3. Thus,
we have the inequations,

k2 − LM G(B)k1 ≥ k2 − LM G(I)k1.

(7)

We incorporate the LM G term to our energy function to
form a new model. From Eq. (7) we know that minimizing
the term k2−LM G(·)k1 will obtain a solution favours clear
image. One may argue the reason for choosing the exact
number 2 in Eq. (6) and (7). Certainly, any number above
2 is feasible. However, it will result in greater energy value
in our function. Thus, selecting the doable minimum value
is our best choice.

3. Proposed Model

In this section, we put forward a concrete deblurring
model and an effective optimization scheme. With a con-
ventional deblurring framework, our energy function is de-
ﬁned as,

where β, γ and τ are corresponding weight parameters for
the following regularization terms. The ﬁrst ﬁdelity term
enforces similarity between convolution result I ⊗ K and
the observed blurred image B. The second term is the new
LM G involved term aforementioned. The third term en-
sures that only salient edges affect the function by remov-
ing tiny ones which is ﬁrst introduced in [27], and previ-
ously used in a hybrid manner in [19, 20, 28, 15]. As for the
last regularization term, some methods use L1 norm [23, 8],
we adopt the conventional L2 norm for calculation conve-
nience, and it works to constrain the kernel to be smooth.

Before presenting our algorithm to solve the above
model. We ﬁrst tackle the tricky problem of LM G oper-
ation.

We know that both the operations max and | · | can be
regarded as mapping matrices. The | · | can be seen as
a matrix A applied to the vectorized image gradient ∇I.
Each value of A belongs to the set {1, −1}, and is depen-
dent on the polarity of the element in ∇I. Note that there
are two dimensions involved in the gradient operator, i.e.,
∇ = (∇h, ∇v)T . Therefore, the absolute operator is also
two-dimensional, i.e., A = (Ah, Av), which is given by,

Ah(x, y) = (cid:26) 1, ∇Ih(x, y) ≥ 0

−1, ∇Ih(x, y) < 0

.

Similar for Av, we have

|∇I| = A ⊙ ∇I,

where we use ⊙ to denote hadamard product. Note that in
vector form of I, both the operators A and ∇ should be
sparse, and in this case,

|∇I| = A∇I1.

Drawing a lesson from [20], max operator can be substi-
tuted with a sparse matrix M applied to the vectorized form

kI ⊗ K − Bk2 + βk2 − LM G(I)k1

min
I,K

+γk∇Ik0 + τ kKk2,

(8)

1Here we use A to denote the diagnoal form of A, and I to denote the
vectorized form of I for consistence. The matrix form of ∇ is toeplitz
manner.

31744

of image |∇I|, which satisﬁes,

M(x, z) = (cid:26) 1, z = arg maxy∈P (x) |∇I|(y)

0, otherwise

.

All the matrices could be acquired during the deblurring
process, and are computed with intermediate latent image.
Let G = M ∗ A ∗ ∇, the LM G operation can be written as,

LM G(I) = GI.

(9)

3.1. Proposed Algorithm

Instead of solving Eq. (8) directly, we split the energy
function into two sub problems, and alternatively optimize
them. Two sub problems can be written as follows,

where α3 is a positive penalty parameter. We can solve Eq.
(14) by updating I and q in an alternative manner, which is
given by,

kKI − Bk2 + α2k∇I − gk2 + α3kI − qk2,

α1k2 − Gq − uk2 + α3kI − qk2.

(15)

(16)

min

I

min

q




Both the Eq. (15) and (16) have a closed-form solution.
We can solve Eq. (15) with FFT (Fast Fourier Transform)
directly, and the solution can be obtained according to [27,
28]. The solution of Eq. (16) is given by,

q =

α1GT (2 − u) + α3I

α1GT G + α3

.

Given I, we can compute u and g separately by following

kI ⊗ K − Bk2 + βk2 − LM G(I)k1 + γk∇Ik0,

(10)

two sub-equations,

min

I

min
K




kI ⊗ K − Bk2 + τ kKk2.

(11)

We further provide an effective optimization scheme to
solve the above sub problems.

3.1.1 Estimate Latent Image

Owing to the non-convex L0 norm, optimizing Eq.
(10)
directly becomes computationally formidable. Considering
this, we adopt the half-quadratic splitting method [27]. With
new substitution variable u → 2 − LM G(I) and g → ∇I,
Eq. (10) can be rewritten as,

kI ⊗ K − Bk2 + βkuk1 + γkgk0+

min
I,u,g

α1k2 − LM G(I) − uk2 + α2k∇I − gk2,

(12)

where α1 and α2 are the penalty parameters. We can solve
Eq. (12) by optimizing I, u, g alternatively while ﬁxing oth-
ers.

Given the LM G matrix G, we can solve I in following

manner,

min

I

kKI − Bk2 + α1k2 − GI − uk2 + α2k∇I − gk2,

(13)

here we use K to denote toeplitz form of blur kernel K,
B, u, g to denote vector form of B, u, g, respectively.

Eq. (13) is a quadric problem referring to I. We can solve
it with the conjugate gradient method. However, because of
the large size of G, conjugate gradient method will require
tremendous time to convergence (Details are demonstrated
in supplementary material.). Therefore, we introduce an-
other auxiliary variable q for I in the second term of Eq.
(13) as a trade off between speed and accuracy. Thus, Eq.
(13) can be represented by following approach,

min

u

βkuk1 + α1k2 − GI − uk2,

min

g

λkgk0 + α2k∇I − gk2.

(17)

(18)

Eq. (17) is a one-dimension shrinkage, and the solution can
be written as,

u = sign(2 − GI) · max(|2 − GI| −

β
2α1

, 0).

Eq. (18) is a pixel-wise optimization problem according to
[27]. The answer is given by,

g = (cid:26) ∇I,

0,

|∇I|2 ≥ λ
α2
otherwise

.

3.1.2 Estimate Blur Kernel

With I given, optimizing K becomes a least squares prob-
lem. To accelerate the convergence rate, we adopt the kernel
estimation method from [2]. Thus, Eq. (11) can be rede-
ﬁned as

k∇I ⊗ K − ∇Bk2 + τ kKk2.

(19)

min
K

The optimal solution of K can be acquired with a FFT
method directly. We know K is subject to the constraints

that Ki > 0 andPi Ki = 1. After acquiring the kernel, we

will set negative elements of K to zero, and regularize K.
Empirically, we adopt the coarse-to-ﬁne deblurring scheme
with an image pyramid [2]. Main steps from one pyramid
level are shown in Alg. 1. More details about the algorithm
are provided in the supplementary material.

kKI − Bk2 + α1k2 − Gq − uk2+

min
I,q

α2k∇I − gk2 + α3kI − qk2,

4. Experimental Results

(14)

We implement our model in MATLAB. First, we carry
out experiments on natural image datasets [13, 9, 12]and

41745

Algorithm 1: Blur kernel estimation with LM G
prior algorithm

Input: Blurry image B
Initialize K from the coarser level.
while iter = 1:maxiter do

Update I with Eq. (10).
Update K with Eq. (11).

end
Output: Blur kernel K. Intermediate latent image

I.

100

80

60

40

20

t

n
e
c
r
e
p

 
s
s
e
c
c
u
S

0

1

80

t

n
e
c
r
e
p

 
s
s
e
c
c
u
S

60

40

20

0

1

Yan et al
Pan et al
Cho et al
Krishnan et al
Fergus et al
Xu et al
Ours

2

3

4

5

Error ratios

(a)

Yan et al
Xu et al
Pan et al (text)
Zhong et al
Cho et al
Fergus et al
Levin et al
ours

2

3

4

5

Error ratios

(b)

Figure 3. (a), (b) are quantitative evaluations on the benchmark
datasets by [13] and [12], respectively. Our model performs well
among state-of-the-art algorithms.

real images, and compare it with other state-of-the-art al-
gorithms. Furthermore, we evaluate our method on text
[19], face[18], saturated [6] images, and compare it with the
method tailored to these speciﬁc scenarios. We use the same
non-blind deconvolution method from [19] unless otherwise
mentioned. We use Peak-Signal-to-Noise Ratios (PSNR) on
benchmark dataset [9] as the performance evaluation, and
evaluate outputs on datasets [12, 13] in terms of error ratio,
which is measured by the ratio between deconvolution error
with the estimated kernel and deconvolution with the truth
kernel [13]. In all experiments, we use following parame-
ters: β = γ = 0.004, τ = 2. The patch size for computing
LM G value is ﬁxed as 35 × 35. All the results from other
methods are either provided or generated by the code from
authors’ website using default settings. Please refer to the
supplementary material for more examples.

4.1. Nature images

To better illustrate the effectiveness of our model, we use

three mainstream benchmark datasets mentioned above.

We ﬁrst test our model on the dataset from Levin et
al.[13], and compare with several other methods [4, 2, 10,
20, 28]. There are total 4 × 8 images in the dataset.
It
was generated from 4 original images ﬁltered with 8 differ-
ent kernels. Due to the relative translation between ground
truth and deconvolution result, calculating PSNR directly
will cause inaccuracy of the result. Thus, we use error ratio
as performance evaluation on this dataset instead. Fig. 3
(a) shows that our LM G based method outperforms state-

 

R
N
S
P
e
g
a
r
e
v
A

35

30

25

20

Cho and Lee
Krishnan et al
Shan et al
Xu and Jia
Pan et al
Yan et al
Li et al
Ours

im1

im2

im3

im4

Average

Figure 4. Average PSNR value of the dataset [9]. Our method
achieves 30.37 on average, leading among state-of-the-art meth-
ods.

of-the-art algorithms with 100% of our results under error
ratio 1.8, and the corresponding proportion for the second
best [20] is 93.75%.

Next, We evaluate our method on the uniform dataset
from [12] which contains 100 images including face, text
and low-illumination images. We run a thorough test of all
the images and computed the cumulative error ratio. A to-
tal of seven other algorithms [4, 2, 27, 14, 31, 19, 28] are
taken as comparison objects. For fair comparison, we use
the non-blind algorithm from [3] to generate ﬁnal results af-
ter acquiring blur kernels. The overall comparison result is
shown in Fig. 3 (b). Our model takes lead with 45% of the
output under error ratio 2.

Moreover, we test our method on the benchmark dataset
[9] against other latest algorithms [2, 10, 26, 20, 28, 15].
The dataset is constituted of 4 original images corrupted
with 12 kernels. We calculate the PSNR value by com-
paring each of our results with 199 original images cap-
tured along the blur trajectory and mark the ﬁnest value.
The comparison result is shown in Fig. 4, our method
achieves higher average PSNR value (30.37) than the sec-
ond best [15] (30.15). Demonstrating with one image from
this dataset, the corresponding results are shown in Fig.
5. Our method generates a more visually pleasing result
against [27, 28], and contain less ringing artifacts than dark
channel based method[20].

We further test our method on real-world blurred images.
As shown in Fig. 6, we use the same non-blind deconvolu-
tion method from [6] to generate ﬁnal results for each com-
parison methods [10, 20, 19, 6]. While other state-of-the-art
methods produce varying degrees of ringing artifacts, our
method generates sharper edges and contain fewer artifacts.

4.2. Domain speciﬁc images

Deblurring Low-illumination blurred images are rather
challenging for most methods. Fig. 7 shows an example
from [6]. Natural image deblurring method [27] fails to
generate clear images mainly due to the large region of sat-
urated pixels. Meanwhile, our method yields even sharper
edges than the state-of-the-art low-illumination deblurring

51746

Input

Xu et al. [27]

Yan et al. [28]

Pan et al. [20]

Ours

Figure 5. Qualitative comparison with other state-of-the-art methods on image from dataset [9]. The image estimated by LM G based
method is visually more pleasing and has less ringing artifact.

(a) Input

(b) Krishnan et al. [10]

(c) Pan et al. [20]

(a) Input

(b) Yan et al. [28]

(d) Pan et al. [19]

(e) Hu et al. [6]

(f) Ours

Figure 6. Comparison with other state-of-the-art methods on real-
world blurred image. Results are produced by the same non-blind
deconvolution method[6]. Our method generates ﬁner edges and
clearer details as are shown in red boxes (Best viewed on high
resolution display with zoom-in).

(c) Pan et al. [19]

(d) Ours

Figure 8. Results on text blurred image. Here we use the same
non-blind deconvolution method from [19]. Our method yields a
result comparable to the model speciﬁc on text [19].

(a) Input

(b) Xu et al. [27]

(c) Hu et al. [6]

(d) Ours

Figure 7. Results on low-illumination blurred image. Results
are generated by the same non-blind deconvolution method from
[6]. Red boxes contain varying degrees of ringing artifacts (Best
viewed on high-resolution display with zoom-in).

(a) Input

(b) Xu et al. [27] (c) Pan et al. [20]

(d) Ours

Figure 9. Results on face blurred image. Here we use the same
non-blind deconvolution method [3]. Our method produces more
visually pleasing result.

Text images are yet another herculean task for most
methods, because the contents of interest are mainly two-
toned (black and white) which do not follow the heavy-
tailed statistics of natural images [19]. As shown in Fig.
8. Kernel estimated by extreme channel prior[28] result in
large residual blur, and the result generated by our model
compares favorably with the method tailored to text [19].

model [6] as shown in the red boxes.

Face images often contain few edges or texture [18]

61747

100

t

n
e
c
r
e
p

 
s
s
e
c
c
u
S

80

60

40

20

0

1

100

80

60

40

20

t

n
e
c
r
e
p

 
s
s
e
c
c
u
S

0

1

With LMG
Without LMG
With only LMG

2

3

4

5

Error ratios

(a)

Without LMG
Constraint with L0 norm
Constraint with L2 norm
Constraint with L1 norm

1.5

2

2.5

Error ratios
(b)

Figure 10. Quantitative evaluations on the benchmark dataset from
[13]. (a) Effectiveness of the proposed LM G prior. (b) Ablation
study referring to the norm constraint on LM G related term. The
model with k2 − LM G(·)k1 generate better results.

which is vital for kernel estimation. Fig. 9 demonstrates
deblurring result on an face image. Our method generate
ﬁner result with less ringing artifacts than nature image de-
blurring method [27, 20].

(a) Input

(b) Pan et al. [20](c) Yan et al. [28]

(d) Ours

(e) Intermediate result of Pan et al. [20].

(f) Intermediate result of Yan et al. [28].

5. Analysis and Discussion

(g) Intermediate result of Our model without LM G prior.

In this section, we further evaluate the effectiveness of
LM G prior, discuss its relation with L0 regularized meth-
ods, norm constrains on LM G related term, effect of the
patch size used for computing LM G map, and analyse its
convergence property and the limitations.

5.1. Effectiveness of LMG prior

Our model adopts two regularized terms including sparse
constraint on the image gradient and the LM G related term.
Fig. 11 (g) and (h) show an example of our model with and
without LM G prior. The kernel estimated with LM G prior
yields sharper images over iterations, while the kernel esti-
mated without LM G looks like a delta kernel. The com-
parison demonstrates the effectiveness of the LM G related
term. To better evaluate the effectiveness of LM G prior, we
further conduct ablation study on benchmark dataset [13]
with, without and with only the LM G prior. We disable
the LM G prior in our implementation to ensure a fair com-
parison. As shown in Fig. 10 (a), our model with LM G
term (red line) generates better results than the one without
it (green line). However, we found if only with the LM G
term, our model performs poorly with majority of the ssd
error above 2. This indicates that LM G prior is not able to
handle deblurring task alone.

5.2. Comparison with other L0 regularized priors

Several methods adopt L0-regularized priors in deblur-
ring task [27, 19] because of the strong sparsity of the L0
norm. Recent approaches enforce sparsity on the dark chan-
nel [20] and the bright channel [28] of latent images. As
shown in Fig. 11 (b) and (c). They fail to estimate the
blur kernel when there are not enough extreme (dark and
bright) pixels. Although our method yields the same kernel
at the early stages of the deblurring process, but the change

(h) Intermediate result of Our model with LM G prior.

(i) Intermediate result of LM G map.

Figure 11. Deblurred results and its corresponding intermediate
results. The results of several methods [20, 28] are shown in (b) -
(d), corresponding intermediate results over iterations (from left to
right) are shown in (e) - (h). Our model with LM G prior generates
sharper edges and contains fewer artifacts. The LM G map of
the intermediate latent image gets brighter over iterations which
complies with our observation (Here we regularize the range of
LM G to 0 − 1 by dividing its value by 2).

of LM G helps to restore shaper edges than the extream
channel based approaches in the following stages. Our ex-
perimental results on three different datasets also indicate
the superiority of our model as illustrated in the previous
section.

5.3. Norm constraint on the LM G term

As demonstrated in Eq. (7), we adopt the L1 norm to
constrain the LM G related term. However, we know that
L2 norm is also reasonable since the LM G related term
(2−LM G) is positive. Also, the sparsity of LM G term en-
courages us to explore the effectiveness of L0 norm applied
in the term. To better evaluate the effect of k2−LM G(·)k0,
k2 − LM G(·)k1 and k2 − LM G(·)k2, we conduct experi-
ments using these three different constrains on dataset from
Levin et al.
[13]. As shown in Fig. 10 (b), our model

71748

100

 

y
g
r
e
n
e
e
g
a
r
e
v
A

90

80

70

60

50

40

30

0

10

20

Iterations

30

0.86

0.85

0.84

0.83

0.82

0.81

0.8

y
t
i
r
a

l
i

i

m
s
 
l

e
n
r
e
k
 

e
g
a
r
e
v
A

40

50

0.79

0

10

20

Iterations

30

40

50

(a) Objective function value
Figure 12. Convergence analysis of the proposed algorithm. We
evaluate the energy value of Eq. (10), and the kernel similarity [7]
at the ﬁnest scale.

(b) Kernel similarity

with any constraint forms is better than without using LM G
prior, which indicates that LM G is an inherent property and
can help the deblurring process. Also, we found constraint
with L1 norm generates the best results, i.e., our model with
k2 − LM G(·)k1 can achieve the best performance.

Table 1. Evaluations on datasets [13] with different patch size.

Patch size

15 × 15

25 × 25

35 × 35

45 × 45

Avg. PSNR

33.05

33.12

33.29

33.12

5.4. Effect of patch size for computing LM G map

The patch size is an critical factor for computing LM G
map. We conduct experiments with different patch sizes on
dataset [13]. As shown in Tab. 1, we compute the average
PSNR value of the results generated by different patch sizes.
The dataset contains images of size 255 × 255. Thus, the
maximum patch size we consider is 45×45. Overall, PSNR
differences between each patch size are rather small, which
indicates that our model is insensitive to the patch size once
it is in a reasonable range.

5.5. Convergence analysis

Our method adopt half-quadratic scheme to optimize the
non-convex L0 norm and the non-linear LM G operation.
Since it involves several auxiliary variables during estimat-
ing latent image, one may question the overall convergence
property. We analyse its convergence by empirically con-
ducting experiments on the dataset [13] to see the change
of energy refering to Eq. (10), and the kernel similarity [7]
referring to Eq. (11) over iterations. The experiments are
carried out at the ﬁnest image scale. As shown in Fig. 12,
our algorithm converges less than 50 iterations, which vali-
dates the effectiveness of our optimization scheme.

5.6. Limitation

One of the limitations of our method is its ineffectiveness
when dealing with image contains signiﬁcant non-gaussian
noise. Fig. 13 shows an example of our method dealing

(a)

(b)

(c)

Figure 13. Limitation of the proposed model. Our method cannot
handle blurred image with non-gaussian noise. (a) Input blurred
image. (b) Deblurring result of our method. (c) Deblurring result
of our method with applying gaussian ﬁlter to the blurred image
ﬁrst.

with images degraded by salt and pepper noise. As shown
in Fig. 13 (b), it will not work if we apply the proposed
method to the blurred image directly. In this case, we settle
the problem by enforcing gaussian ﬁlter on the noisy blurred
image ﬁrst, and the result is more pleasing as shown in Fig.
13 (c).

Another drawback of the proposed method is that it re-
quires plenty of time to iteratively update variables. Tab. 2
demonstrates the time comparison of several methods on a
computer with 12 GB RAM and Intel Core i5 − 7400 CPU.

Table 2. Running time comparison. The code is implemented in
MATLAB unless mentioned.

Method

225 × 225

600 × 600

800 × 800

Xu et al. (C++) [27]
Krishnan et al. [10]

Yan et al. [28]
Pan et al. [20]

Ours

1.22
6.04
22.33
137.43
65.20

3.61
50.02
178.31
945.91
376.94

6.90
90.94
367.70
1992.44
755.43

6. Conclusions

In this paper, we introduce a new Local Maximum Gra-
dient prior for blind deblurring. Our work is motivated by
the fact that the maximum gradient value of a local patch
will diminish after the blurring process. Therefore, max-
imizing LM G value will help restore clearer images.
In
order to recover the latent image restricted by the LM G
prior, we present an effective optimization scheme based on
half-quadratic splitting strategy. With a coarse-to-ﬁne MAP
framework, our model works well in most cases. Exper-
imental results depict that our method performs favorably
against state-of-the-art algorithms on natural images, and
generate solid outputs on given occasions including face,
text, and low-illumination images. Furthermore, we believe
our proposed prior has the potential to be extended to other
image reconstruction areas in future work.

81749

References

[1] Pablo Andr´es Arbel´aez, Jordi Pont-Tuset, Jonathan T. Bar-
ron, Ferran Marqu´es, and Jitendra Malik. Multiscale combi-
natorial grouping. In IEEE Conference on Computer Vision
and Pattern Recognition, 2014.

[2] Sunghyun Cho and Seungyong Lee. Fast motion deblurring.

ACM Transactions on Graphics, 28(5):145, 2009.

[3] S. Cho, Jue Wang, and S. Lee. Handling outliers in non-blind
image deconvolution. In IEEE International Conference on
Computer Vision, 2011.

[4] Robert Fergus, Barun Singh, Aaron Hertzmann, Sam T.
Roweis, and William T. Freeman. Removing camera shake
from a single photograph. ACM Transactions on Graphics,
25(3):787–794, 2006.

[5] Dong Gong, Mingkui Tan, Yanning Zhang, Anton van den
Hengel, and Qinfeng Shi. Blind image deconvolution by au-
tomatic gradient activation.
In IEEE Conference on Com-
puter Vision and Pattern Recognition, 2016.

[6] Zhe Hu, Sunghyun Cho, Jue Wang, and Ming-Hsuan Yang.
Deblurring low-light images with light streaks. In IEEE Con-
ference on Computer Vision and Pattern Recognition, 2014.
[7] Zhe Hu and Ming-Hsuan Yang. Good regions to deblur. In

European Conference on Computer Vision, 2012.

[8] Jiaya Jia.

Single image motion deblurring using trans-
parency. In IEEE Conference on Computer Vision and Pat-
tern Recognition, 2007.

[9] Rolf K¨ohler, Michael Hirsch, Betty Mohler, Bernhard
Sch¨olkopf, and Stefan Harmeling. Recording and playback
of camera shake: Benchmarking blind deconvolution with a
real-world database. In European Conference on Computer
Vision, 2012.

[10] Dilip Krishnan, Terence Tay, and Rob Fergus. Blind decon-
volution using a normalized sparsity measure. In IEEE Con-
ference on Computer Vision and Pattern Recognition, 2011.
[11] Wei-Sheng Lai, Jian-Jiun Ding, Yen-Yu Lin, and Yung-Yu
Chuang. Blur kernel estimation using normalized color-line
priors. In IEEE Conference on Computer Vision and Pattern
Recognition, 2015.

[12] Wei-Sheng Lai, Jia-Bin Huang, Zhe Hu, Narendra Ahuja,
and Ming-Hsuan Yang. A comparative study for single im-
age blind deblurring. In IEEE Conference on Computer Vi-
sion and Pattern Recognition, 2016.

[13] Anat Levin, Yair Weiss, Fredo Durand, and William T Free-
man. Understanding and evaluating blind deconvolution al-
gorithms. In IEEE Conference on Computer Vision and Pat-
tern Recognition, 2009.

[14] Anat Levin, Yair Weiss, Fredo Durand, and William T Free-
man. Efﬁcient marginal likelihood optimization in blind de-
convolution. In IEEE Conference on Computer Vision and
Pattern Recognition, 2011.

[15] Lerenhan Li, Jinshan Pan, Wei-Sheng Lai, Changxin Gao,
Nong Sang, and Ming-Hsuan Yang. Learning a discrimina-
tive prior for blind image deblurring. In IEEE Conference on
Computer Vision and Pattern Recognition, 2018.

[16] Tomer Michaeli and Michal Irani. Blind deblurring using
internal patch recurrence. In European Conference on Com-
puter Vision, 2014.

[17] Seungjun Nah, Tae Hyun Kim, and Kyoung Mu Lee. Deep
multi-scale convolutional neural network for dynamic scene
deblurring.
In IEEE Conference on Computer Vision and
Pattern Recognition, 2017.

[18] Jinshan Pan, Zhe Hu, Zhixun Su, and Ming-Hsuan Yang. De-
blurring face images with exemplars. In European Confer-
ence on Computer Vision, 2014.

[19] Jinshan Pan, Zhe Hu, Zhixun Su, and Ming-Hsuan Yang. l0-
regularized intensity and gradient prior for deblurring text
images and beyond. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 39(2):342–355, 2017.

[20] Jinshan Pan, Deqing Sun, Hanspeter Pﬁster, and Ming-
Hsuan Yang. Blind image deblurring using dark channel
prior. In IEEE Conference on Computer Vision and Pattern
Recognition, 2016.

[21] Wenqi Ren, Xiaochun Cao, Jinshan Pan, Xiaojie Guo, Wang-
meng Zuo, and Ming-Hsuan Yang. Image deblurring via en-
hanced low-rank prior.
IEEE Transactions on Image Pro-
cessing, 25(7):3426–3437, 2016.

[22] Christian J. Schuler, Michael Hirsch, Stefan Harmeling, and
Bernhard Sch¨olkopf. Learning to deblur. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 38(7):1439–
1451, 2016.

[23] Qi Shan, Jiaya Jia, and Aseem Agarwala. High-quality mo-
tion deblurring from a single image. ACM Transactions on
Graphics, 27(3):73, 2008.

[24] Jian Sun, Wenfei Cao, Zongben Xu, and Jean Ponce. Learn-
ing a convolutional neural network for non-uniform motion
blur removal. In IEEE Conference on Computer Vision and
Pattern Recognition, 2015.

[25] Xin Tao, Hongyun Gao, Xiaoyong Shen, Jue Wang, and Ji-
aya Jia. Scale-recurrent network for deep image deblurring.
In IEEE Conference on Computer Vision and Pattern Recog-
nition, 2018.

[26] Li Xu and Jiaya Jia. Two-phase kernel estimation for robust
In European Conference on Computer

motion deblurring.
Vision, 2010.

[27] Li Xu, Shicheng Zheng, and Jiaya Jia. Unnatural l0 sparse
representation for natural image deblurring. In IEEE Con-
ference on Computer Vision and Pattern Recognition, 2013.
[28] Yanyang Yan, Wenqi Ren, Yuanfang Guo, Rui Wang, and
Xiaochun Cao. Image deblurring via extreme channels prior.
In IEEE Conference on Computer Vision and Pattern Recog-
nition, 2017.

[29] W. H. Young. On the multiplication of successions of fourier
constants. Proceedings of the Royal Society of London. Se-
ries A, Containing Papers of a Mathematical and Physical
Character, 87(596):331–339, 1912.

[30] Jiawei Zhang, Jinshan Pan, Jimmy S. J. Ren, Yibing Song,
Linchao Bao, Rynson W. H. Lau, and Ming-Hsuan Yang.
Dynamic scene deblurring using spatially variant recurrent
neural networks. In IEEE Conference on Computer Vision
and Pattern Recognition, 2018.

[31] Lin Zhong, Sunghyun Cho, Dimitris Metaxas, Sylvain Paris,
and Jue Wang. Handling noise in single image deblurring
using directional ﬁlters. In IEEE Conference on Computer
Vision and Pattern Recognition, 2013.

91750

