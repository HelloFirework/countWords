End-to-End Learned Random Walker

for Seeded Image Segmentation

Lorenzo Cerrone, Alexander Zeilmann, Fred A. Hamprecht

Heidelberg Collaboratory for Image Processing

IWR, Heidelberg University, Germany

{lorenzo.cerrone, alexander.zeilmann, fred.hamprecht}@iwr.uni-heidelberg.de

Abstract

We present an end-to-end learned algorithm for seeded
segmentation. Our method is based on the Random Walker
algorithm, where we predict the edge weights of the under-
lying graph using a convolutional neural network. This can
be interpreted as learning context-dependent diffusivities
for a linear diffusion process. Besides calculating the exact
gradient for optimizing these diffusivities, we also propose
simpliﬁcations that sparsely sample the gradient and still
yield competitive results. The proposed method achieves
the currently best results on a seeded version of the CREMI
neuron segmentation challenge.

1. Introduction

Image segmentation is the task of partitioning an image
into regions that are meaningful for a given task. Seeded
segmentation is a popular semi-supervised variant, where
an oracle annotates one or more pixels per region with an
instance label, such that all seeds in a region share the same
label.

Most seeded segmentation pipelines involve two parts: a
ﬁrst step that predicts, for each pair of adjacent pixels, if or
not they are likely part of the same region; and a second step
that ingests these predictions as well as the seed locations
and then infers the precise extent of each region. The second
step is often cast as inference in an undirected probabilistic
graphical model, either discrete [6] or continuous [13].

If no prior information on the nature of the images to be
segmented is available, the ﬁrst step – boundary estimation
– is of necessity generic. It is then possible to use or train
some state of the art edge detection method (e.g. [19]) and
choose the parameters of the second step – inference – by
hand.

But since dense ground truth is required for the training
of a powerful edge detection method in any case, one may
also go further and train the two steps jointly. Such a struc-

tured learning is more general than the naive approach of
training a CNN to predict good boundary indicators, obliv-
ious to what these will be used for; and to subsequently
and independently optimize the parameters of the inference
step.

For the second, inference, step, we choose a Condi-
tional Gaussian Markov Random Field with only seed ﬁ-
delity as the unary term – also known as Random Walker
algorithm [13] – and here show how to train that inference
scheme jointly with a deep convolutional neural network
(CNN).

Our choice of a Gaussian Markov Random Field is mo-

tivated by the following features:

• Less sensitive to noisy edge weights than the Water-
shed [11] which is fast and hence popular in seeded
segmentation, but also susceptible to outliers based on
its use of the (max, min)-semiring [4].

• More amenable to differentiation than the purely com-

binatorial graph cuts problem [6].

• More computationally efﬁcient than more expressive
generalizations involving higher-order potentials [22].

More speciﬁcally, we make the following contributions:

1. We demonstrate end-to-end structured learning of a
pipeline consisting of a deep neural network that pre-
dicts edge weights, which are subsequently used in a
seeded segmentation by linear diffusion, i.e., with the
Random Walker algorithm.

2. We calculate the exact gradient of our objective func-
tion and propose a sparse sampling strategy of the gra-
dient to reduce computation time.

3. We evaluate the algorithm on a seeded version of the
MICCAI Challenge on Circuit Reconstruction from
Electron Microscopy Images (CREMI) [10]. Here, the
proposed method outperforms unstructured training of

12559

a CNN combined with the Random Walker algorithm,
and deﬁnes a new state of the art.

4. We provide the source code as PyTorch pack-
age on https://github.com/hci-unihd/
pytorch-LearnedRandomWalker,
allowing
general use of the proposed Learned Random Walker.

2. Related Work

Diffusion processes are attractive because they engender
nontrivial global behavior as a consequence of trivial local
interactions. As such, they have a rich history in machine
learning and computer vision.

Seeded segmentation could be seen as an instance of
semi-supervised segmentation, which has been explored
in conjunction with Gaussian Markov Random Fields
(GMRF) on arbitrary graphs in [31], though without the su-
pervised learning of edge weights as discussed here.

In computer vision, linear diffusion has been proposed
for seeded segmentation in the seminal work of Grady [13].
In semantic segmentation and image-valued regression
tasks, Tappen et al. [23] have shown how to learn context-
dependent potentials for GMRFs. These authors did not
explore seeded segmentation, and the number of parame-
ters learned was in the hundreds, not hundreds of thousands
as in our case. Jancsary et al. [14] have pioneered the use
of ﬂexible nonparametric classiﬁers to determine the poten-
tials in a Conditional GMRF. However, they opted for en-
sembles of decision trees and had to estimate the impact of
each possible split on the loss function, making a number of
approximations necessary.

In recent work, Vernaza and Chandraker [27] have pro-
posed a ﬁrst-order approximation of the derivative for back-
propagation. We show in section 4.5 that this approximation
is not well-behaved for the kind of sparse seeds considered
here.

Our algorithm can also be seen from the viewpoint of
coupling a deep network with an undirected probabilistic
graphical model. In contrast to [7, 30] we use a GMRF that
makes inference easier. End-to-end learning of a GMRF
was also proposed in [5], though these authors do not solve
the inference problem exactly as we do; instead, they unroll
a few steps of gradient descent into extra layers of their neu-
ral network. Our inference problem can be seen as convex
quadratic program. Recent work proposes quadratic pro-
gramming as a generic neural network layer [2]. However,
the paper and implementation do not account for the kind
of sparsity that characterizes our formulation, and scales
only to a few hundred random variables, where we use
tens of thousands. Indeed, the solution of huge sparse sys-
tems of the kind discussed here is possible in almost linear
time [25].

Other important seeded segmentation strategies are
based on discrete Markov Random Fields [6] that do how-
ever not admit the differentiability we crucially need; or on
shortest paths similarities that can be computed even more
efﬁciently than the diffusions we use [3]. However, the use
of (single) shortest paths to measure the dissimilarity from
each pixel to every seed is not as robust as the averaging
over many paths that diffusion processes implicitly accom-
plish [28].

Such fragility is especially pronounced for watershed-
type methods that base dissimilarities on a minimax crite-
rion [9]. Even so, such methods have been used successfully
in biomedical [18] and other applications. Recent work
has sought to mitigate this limitation by learning the edge
weights for watershed seeded segmentation in a structured
fashion, just as we do, and moreover making the algorithm
adaptive [29], the cost for the latter being a somewhat in-
volved recurrent neural net formulation. The experiments
in section 4.3 show that we can supersede the learned wa-
tershed in spite of our simpler architecture.

Remarkably, all of the above inference schemes for
seeded segmentation – graph cuts, random walker / linear
diffusion and geodesic distances – emerge as special cases
of a unifying optimization problem [8].

3. Methods

3.1. Mathematical Background

To make this paper self-contained, we derive the linear
system (1) which is solved in the Random Walker algo-
rithm. While Grady [13] deduced the system by minimizing
a discretized Dirichlet energy, we derive it directly from the
discretized Laplace equation.

The Random Walker algorithm models seeded segmen-
tation with |L| distinct categories of seeds as follows: each
category or label a ∈ L is associated with an inﬁnitely large
reservoir. This reservoir is coupled to the pixels that have
been marked with label a. From this reservoir, the label a
can diffuse across the image. The pixels associated with all
other labels a′ ∈ L \ {a} act as sinks for label a. That is,
the concentration of a label a is one at the pixels that have
been marked with this label; it is zero at the locations of
all other seeds; and its “concentration” in-between is given
by the stationary state of the linear diffusion equation. Im-
portantly, local diffusivities are informed by local image ap-
pearance: Random Walker assumes high diffusivity within
ground truth segments and low diffusivity across segments.
In the continuous setting, diffusion is usually formulated

as

12560

u = f on ∂Ω,

∆u = 0 in Ω,

Figure 1. Illustration of the Learned Random Walker pipeline at training and test time. Top: forward pass, the input image is mapped
by a CNN to an undirected edge-weighted graph. A probability map is computed for each object using the Random Walker algorithm.
At test time, a segmentation and an uncertainty map are computed from the probabilities. Bottom: backward pass of the training. The
dense derivative of the Random Walker algorithm is too expensive to compute, instead, a sampling scheme is used and only a very sparse
Jacobian is passed to the CNN.

where we prescribe the value of a function u on the bound-
ary of the domain Ω and require that the Laplace operator
vanishes in the interior of the domain.

To carry these ideas over to the domain of discrete im-
ages, we consider an image as a connected undirected edge-
weighted graph G = (V, E) with adjacency relation i ∼
j ⇐⇒ (i, j) ∈ E and edge weights we ∈ R+ for every
edge e ∈ E. The set of vertices V is partitioned into un-
marked vertices U and marked vertices M , the seed pixels.
By L we denote the graph Laplacian which is deﬁned as

−wi,j

Pk∼i wi,k

0

if i ∼ j
if i = j
else,

Li,j = 


i.e. L = D − A with the degree matrix D and the adjacency
matrix A of G. We consider the vertices ordered in such
a way that the marked pixels appear above and left of the
unmarked pixels in L:

L = (cid:18)LM B

BT LU(cid:19) .

We deﬁne a row stochastic matrix Z ∈ [0, 1]|V |×|L| by

Zi,a = probability of vertex i having label a ∈ L.

This matrix Z is called assignment matrix in recent litera-
ture [1]. We assume that the rows in Z are sorted in the
same way as in L, i.e. the marked rows are above the un-
marked rows. Thus, we can partition the matrix into a
marked (known) part ZM and an unmarked (wanted) part
ZU . With these notions, the continuous diffusion equation
can be extended to the discrete setting in the following way:

(cid:18)LM B
BT LU(cid:19)(cid:18)ZM

ZU(cid:19) = (cid:18)∗
0(cid:19) ,

i.e. the Laplace matrix multiplied by the assignment ma-
trix is 0 on the unmarked vertices and not prescribed on the
marked ones — indicated by the ∗ on the right-hand side.
This is similar to ∆u not being required to have a certain
value on ∂Ω. ZM is set to user-speciﬁed values. Multiply-
ing out yields the following extremely sparse linear system,
which is at the heart of the Random Walker algorithm:

LU ZU = −BT ZM .

(1)

Since LU is invertible, the solution ZU of the linear system
exists and is unique.

In summary, solving the above linear system gives the
probability, for each pixel, to be associated with a given
seed. These probabilities are typically fractional, which

12561

turns out to be a great advantage: It allows the deﬁnition
of meaningful spatially resolved uncertainty measures such
as the entropy at each pixel,

Hv = −Xa∈L

Zv,a log (Zv,a)

(2)

See Figure 2 for an illustration.

The same kind of measure would not be meaningful for
graph cut type approaches, whose unimodularity guarantees
integral all-or-nothing solutions. For graph cut results, the
entropy would be constant across the entire image.

In the Random Walker, the ﬁnal labeling is obtained from
the resulting assignment matrix by a winner-take-all selec-
tion of the the label with maximal probability for each ver-
tex v 7−→ arg maxa∈L Zv,a.

3.2. Structured Learning of a CNN to Predict Edge

Weights for the Random Walker

To ﬁnd appropriate edge weights, early work [13] used
simple parametric estimators of local image contrast, such
as exponentiated intensity differences. Later work has used
ﬂexible nonlinear estimators, such as random forests, to es-
timate edge weights [14]. We want to use gradient descent
to train weight estimators in a structured fashion in the sense
of [26], only for seeded segmentation and for a more ﬂexi-
ble and powerful class of estimators.

When solving equation (1) exactly, structured learning
amounts to the following optimization problem: the mini-
mization of loss l with respect to the neural network param-
eters Θ

arg min

Θ

l(cid:0)Z ∗

U , −LU (I; Θ)−1 · B(I; Θ)T · ZM(cid:1)

(3)

based on ground truth Z ∗
U . Here, we have made explicit the
dependence of LU and BT on the edge weights w, which in
turn depend on image I and network parameters Θ.

To solve the optimization problem we use gradient de-

scent, for which we compute the gradient

∂l (Z ∗
U , ZU )
∂Θ

=

∂l (Z ∗

U , ZU )

∂ZU

∂ZU
∂w

∂w
∂Θ

.

(4)

The ﬁrst and third term on the right hand side are stan-
dard:
the partial derivative of the loss function with re-
spect to a candidate solution, and of the neural network
with respect to its parameters, respectively. The remain-
ing tensor is cumbersome due to its extremely large di-
mensions: the partial derivative of the probability of (typ-
ically:) dozens of seeds |L| in millions of pixels |U | with
respect to millions of edges |E| make for a formidable ob-
ject ∂ZU /∂w ∈ R|U |×|L|×|E|. One way to evaluate this
expression is to take the derivative with respect to w of the
linear system (1):

∂LU ZU

∂w

= −

∂BT ZM

∂w

Since the probabilities at the marked pixels do not depend
on the edge weights we have ∂ZM /∂w = 0 and obtain with
the product rule the following tensor-valued linear system,
whose solution is ∂ZU /∂w:

LU

∂ZU
∂w

= −

∂LU
∂w

ZU −

∂BT
∂w

ZM

(5)

This equation is a combined representation of |L||E| usual
linear systems with matrix LU and changing right hand
sides. These right hand sides are easy to calculate as
∂LU /∂w and ∂BT /∂w are very sparse and constant with
respect to w, i.e. they do not change during the gradient de-
scent.

3.3. Simpliﬁcations for Calculating the Gradient

On the other hand, computing the huge rank 3 tensor
∂ZU /∂w requires, in each gradient descent step, solving
the tensor-valued linear system (5), which is computation-
ally expensive. As the tensor is only used in the tensor mul-
tiplication

∂l(Z ∗

U , ZU )
∂w

=

∂l(Z ∗

U , ZU )
∂ZU

∂ZU
∂w

∈ R|L|

we can make a few simplifying approximations:

Instead of calculating the entire gradi-
Sparse Gradient
ent tensor ∂l(Z ∗
U , ZU )/∂w we randomly select n ≪ |E|
edges for which we solve the corresponding linear systems
and set the entries corresponding to other edges to zero.
This approach can be seen as a stochastic gradient descent
algorithm.

We have tried more sophisticated strategies, including
ones based on the label entropy or ones that concentrate
on misclassiﬁed pixels. However, none of them performed
signiﬁcantly better than the simple and parameter-free uni-
form sampling of edges, so this was used in all experiments
shown.

In equation (4), the entries in the huge
Gradient Pruning
3-tensor are multiplied, and hence modulated, with entries
from ∂l(Z ∗
U , ZU )/∂ZU . Inspired by [16], for a given edge
(ij) we only compute the contributions from label

arg max

a

(cid:18) ∂l(Z ∗

U , ZU )
∂ZU

(cid:19)i,a

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

.

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Taken together, these two approximations reduce the size of
the tensor from |U | × |L| × |E| to |U | × 1 × n, i.e instead
of solving |L||E| linear systems of size |U | we only solve
n linear systems of size |U |. As an example, we choose a
4-connected graph with 128 × 128 vertices and 10 labels.
Fig 3 shows average backpropagation run-times. We found
n = 1024 to be the best compromise between (≈ 15-fold)
speed-up and accuracy.

12562

Seeds and Predicted Segmentation

Error Map

Uncertainty

Figure 2. The assignment matrix produced by the Random Walker algorithm can be converted to a segmentation (left picture, including the
seeds we used in the Random Walker algorithm). The center image illustrates the wrongly labeled pixels (marked red). The uncertainty of
the labeling is illustrated via the entropy (white indicates high, black indicates small uncertainty).
We found that wrongly segmented regions usually have high uncertainty. However the converse is not true in general: High uncertainty
does not necessarily indicate a wrong segmentation.

)
s
(

e
m
T

i

# of Sampled Gradients

Figure 3. Run time comparison for different number of gradients
sampled. For comparison, a complete backpropagation step (n =
16384) takes 37s. All results reported are for a (i7-6700, 3.4 GHz)
CPU machine.

before computing the loss.

As loss function we choose the Cross Entropy loss (CE)

on the assignment matrix, deﬁned as

CE(Z ∗, Z) = −

1

|V | Xi∈V Xa∈L

Z ∗

i,a log (Zi,a)

(6)

where Z is our calculated assignment matrix and Z ∗ the
ground truth. We also tried employing the Mean Squared
Loss and the Dice Loss. While results are comparable, CE
performed slightly better. In addition, we used an unstruc-
tured CE loss on the weights and for regularization an ℓ2
weight decay on the network parameters Θ. In summary,
the loss reads

l (Z ∗, Z(Θ)) = CE(Z ∗, Z(Θ)) + αCE (w∗, w(Θ))
kΘk2
2 .

+

γ
2

(7)

4. Experiments and Results

4.1. Pipeline Overview

The proposed method is agnostic to CNN architecture;
we employ a Convolutional-Deconvolutional network in-
spired by [17]. The segmentation is conducted in 2D, but
the network accepts a 3D volume as input (3 slices along z)
and predicts edge weights for the central slice only. In our
implementation we used the 4-connected graph, so on aver-
age we only need two edge weights per pixel, one horizontal
and one vertical. The network details are shown in the sup-
plementary material. The network outputs edge weight im-
ages at half the original resolution. This speeds up both in-
ference and backpropagation and reduces the memory foot-
print without impacting the ﬁnal result. The assignments are
then scaled to the original size using bilinear interpolation

where w∗ are the ground truth edges obtained from Z ∗, α =
10−2 and γ = 10−5.

The network is trained on patches of size 256 × 256. We
use mini-batches of size 10 and train for a total of 10 epochs.
Before the structured training, the CNN is pre-trained using
only the side loss on the same data, with mini-batches of
size 10 and for 2 epochs. As optimizer we use Adam [15].

4.2. Seeded CREMI 2D Segmentation

In our experiments we work on the data from the MIC-
CAI Challenge on Circuit Reconstruction from Electron
Microscopy Images (CREMI) [10]. The challenge has been
designed to measure automated segmentation accuracy in
connectomics. There, the aim is to trace a myriad neural
processes in serial section electron microscopy images to
ultimately produce a wiring diagram of the brain. While

12563

the accuracy of automated methods is improving continu-
ously [12], they do not yet reach a precision that would al-
low immediate downstream processing. Also, automated
methods need much training data, and so seeded segmenta-
tion of connectomics data is of interest both for ground truth
generation and for proofreading of automated predictions.

The CREMI dataset is composed of three volumes from
adult Drosophila melanogaster (common fruit ﬂy) brain tis-
sue, each of size 1250 × 1250 × 125 pixels. The three vol-
umes are very different in appearence: While the neurites in
CREMI A are mostly homogeneous in size and shape, the
two other volumes (CREMI B and C) are more challenging,
with cells that have jagged boundaries and large variations
in size and shape. We use the ﬁrst 50 slices in z for testing
and the last 75 for training.

For our seeded segmentation, we assume that an oracle
provides precisely one seed per segment. Here we imple-
ment an oracle by automatically computing the seeds from
the ground truth. For each segment we place one seed at
a random location, but with a reasonable distance to any
boundary. Because using seeds from an oracle is a strong
assumption we cannot directly compare our approach to the
unseeded algorithms competing in the CREMI challenge.
Therefore, we evaluate the performance of our end-to-end
algorithm by comparing it to the following pipelines, which
are also seeded approaches:

Standard Random Walker: We slightly modiﬁed our
network to directly predict boundary probability maps. For
this, we trained the CNN on the same dataset for a total of
10 epochs, while using the Dice loss and mini-batches of
size 10. Subsequently, we compute the segmentation using
the standard Random Walker algorithm given in [13]. The
algorithm has a single hyperparameter β, which we tune
optimally. As for the Learned Random Walker we down-
sampled the graph by a factor of 2 to reduce computational
footprint.

Watershed: For the Watershed algorithm, we used the
same methodology as for the standard Random Walker al-
gorithm to predict boundary probability maps. The only
difference is in the output size. Indeed, the Watershed algo-
rithm is very efﬁcient to compute and thus we do not down-
sample.

Learned Watershed: Lastly, we compared our results
with the numbers published in [29].

All segmentations are evaluated using the ofﬁcial
CREMI metrics: Variation of Information (VOI) and
Adapted Rand Error (ARAND). VOI [20] is the conditional
entropy of the predicted and the ground truth segmentation:
VOI = VOIsplit + VOImerge = H(Z|Z ∗) + H(Z ∗|Z) where
H is the conditional entropy. ARAND is the complement of

Seeds and Predicted Segmentation

Vertical Diffusivities

Horizontal Diffusivities

Figure 4. Learned Random Walker qualitative behavior in narrow
corridors. Top: seeds and the resulting Learned Random Walker
segmentation. Middle and bottom: The learned horizontal and
vertical diffusivities are much stronger inside a corridor than near
its perimeter. The horizontal diffusivity (bottom image) is a little
larger because the corridor itself is horizontal.

the Adjusted Rand Index [21]: ARAND = 1 − AdjRAND.
According to the challenge, we used a tolerance of two pix-
els around the boundary.

4.3. Seeded CREMI 2D Segmentation Results

We show all results in Table 1. Quantitatively,

the
Learned Random Walker with its structured training out-
performed the Random Walker algorithm with unstructured
training in every experiment. Furthermore, the Learned
Random Walker gave the best results in two of the three
volumes, CREMI A and B, whereas Watershed obtained the

12564

VOI

WS

Cremi A 0.075 ± 0.024
Cremi B 0.211 ± 0.080
Cremi C 0.209 ± 0.074
0.165 ± 0.091

Total

WS

ARAND
Cremi A 0.016 ± 0.010
Cremi B 0.049 ± 0.044
Cremi C 0.053 ± 0.045
0.039 ± 0.037

Total

LWS

—
—
—

0.376 ± 0.034

LWS

—
—
—

0.082 ± 0.001

RW

LRW

0.177 ± 0.015
0.362 ± 0.086
0.421 ± 0.091
0.320 ± 0.127

0.062 ± 0.021
0.193 ± 0.089
0.232 ± 0.081
0.162 ± 0.102

RW

LRW

0.042 ± 0.008
0.153 ± 0.078
0.163 ± 0.066
0.239 ± 0.146

0.011 ± 0.009
0.045 ± 0.044
0.061 ± 0.038
0.039 ± 0.040

Table 1. Quantitative comparison of Seeded Watershed on a good boundary probability map, Learned Watershed [29], Random Walker on
a good boundary probability map and Learned Random Walker on the seeded CREMI challenge. Lower is better.

Seeds and Predicted Segmentation

Error Map

Vertical Diffusivities

Figure 5. Typical Learned Random Walker fail on CREMI C. The red circle in the right image indicates a false positive boundary detection.
In this part of the data, the Learned Random Walker tends to hallucinate boundaries.

best results on CREMI C.

4.4. Qualitative Experiments on Arabidopsis

Indeed, volumes B and C are less well suited for the Ran-
dom Walker algorithm, which has intrinsic shrinkage bias,
whereas watershed does not [24]. We observe that the struc-
tured learning seems to overcome this handicap: While the
standard Random Walker algorithm tends to suffer in nar-
row corridors or near narrow funnels, the structured training
helped the network predict stronger diffusivities inside this
kind of regions, see Figure 4. We can assume the network
learns a strong shape prior on how these kind of regions
look like.

On the other hand, we observed a tendency to false posi-
tive boundary hallucination with the pure structured train-
ing of the network. An example is shown in Figure 5.
Moreover, in our experiments, we observed that a CNN
trained directly on a boundary detection task generally per-
forms better on more semantic tasks, like distinguishing in-
ner structures or mitochondria from true cell boundaries.

Thaliana Ovules

In Figure 6 we show a qualitative comparison between
LRW and Watershed in a different imaging domain. The 3D
dataset (courtesy of Schneitz Lab, TU Munich, Germany)
consists of several Arabidopsis thaliana ovules, acquired
using confocal laser scanning microscopy. The ovules are
the major female reproductive organ of the plant. The Ara-
bidopsis ovule serves as a prominent model for quantitative
morphogenetic studies which require highly accurate seg-
mentation of cells. The experimental setup used is identical
to sec. 4. As shown in Figure 6, the results agree qualita-
tively with our experiments on CREMI.

4.5. Sampling Strategy vs. Approximate Back 

Propagation

Different approaches have been proposed for backprop-
agating gradient in Laplacian systems. Very recently, a ﬁrst
order approximation of the true derivative has been used

12565

Seeds and Raw Input

Error Map

Figure 6. Qualitative comparison between Learned Random
Walker and Watershed applied on confocal microscopy data. Blue
and yellow areas represent the regions where the Learned Random
Walker outperformed Watershed and vice versa, respectively.

in [27] for semantic segmentation. Their approach has the
conspicuous advantage that it requires solving only one sys-
tem of linear equations. We set up a simple experiment to
show the differences between the Learned Random Walker
backpropagation and the one presented in [27].

We tried to perfectly regress a single image labelling in
two different scenarios: Extended seeding, where we use
large brush strokes on the image as seeds; and sparse seeds,
where each region was seeded in a single pixel only. Instead
of using a neural network to predict edge weights, we over-
parametrize the system by using one parameter per edge;
and we use gradient descent to update all these parameters
until convergence.

For this example we used a sample image from the
CREMI dataset [10] and the same methodology as in sec-
tion 4. The quantitative results are presented in Table 2.

We ﬁnd that the Learned Random Walker can ﬁt the
ground truth both under extended and sparse seeds; whereas
the ﬁrst-order approximation to backpropagation gives sat-
isfactory results only with extended but not with sparse
seeds. Qualitatively, we observed that the ﬁrst-order ap-

ARAND

Extended
Seeding

Sparse
Seeding

First order approx. [27]
LRW, 250 samples (ours)

LRW, no sampling

0.04
0.01
0.01

0.32
0.03
0.01

Table 2. Quantitative comparison between Learned Random
Walker presented here and ﬁrst order approximation from [27].
The ARAND metric is deﬁned in Section 4.2, and lower is better.

Seeds and Segmentation

Vertical Diffusivities

Horizontal Diffusivities

First order approx.

[27]

LRW

250 samples

LRW

no sampling

First order approx.

[27]

LRW

250 samples

LRW

no sampling

Figure 7. Qualitative comparison between Learned Random
Walker presented here and ﬁrst order approximation from [27]. We
can observe that neither the sparse seeding nor our sampling strat-
egy (sec. 3.3) affect the reconstruction capability of the Learned
Random Walker.

proximation breaks down far from any given seeds Figure 7.
Moreover, we ﬁnd that the sampling strategy introduced in
sec. 3.3 has little effect on the reconstruction accuracy.

5. Acknowledgments

We are grateful to Kay Schneitz, Rachele Tofanelli and
Athul Vijayan for sharing data and helpful discussions. This
work was supported by the Deutsche Forschungsgemein-
schaft (DFG) research unit FOR2581 Quantitative Plant
Morphodynamics.

6. Conclusion

We have proposed an end-to-end learned pipeline for
seeded segmentation. We successfully trained a CNN
jointly with the Random Walker algorithm obtaining very
competitive results and outperforming the standard Ran-
dom Walker algorithm. Furthermore, we propose and im-
plemented an efﬁcient sparse-backpropagation training and
experimentally proved that our method is able to train a net-
work with very sparse seeds. In our experiments we always
used a dense ground truth, but the proposed approach also
allows for training a network from sparse ground truth. We
plan to further explore this regime in future work.

12566

References

[1] Freddie ˚Astr¨om, Stefania Petra, Bernhard Schmitzer, and
Christoph Schn¨orr. A Geometric Approach to Image Label-
ing. In Proc. ECCV, 2016.

[2] Brandon Amos and J. Zico Kolter. OptNet: Differentiable
optimization as a layer in neural networks.
In Doina Pre-
cup and Yee Whye Teh, editors, Proceedings of the 34th In-
ternational Conference on Machine Learning, volume 70 of
Proceedings of Machine Learning Research, pages 136–145,
International Convention Centre, Sydney, Australia, 06–11
Aug 2017. PMLR.

[3] Xue Bai and Guillermo Sapiro. A geodesic framework for
fast interactive image and video segmentation and matting.
In 2007 IEEE 11th International Conference on Computer
Vision, pages 1–8, Oct 2007.

[4] John Baras and George Theodorakopoulos. Path Problems in
Networks. Synthesis Lectures on Communication Networks.
Morgan & Claypool Publishers, 2010.

[5] Gedas Bertasius, Lorenzo Torresani, Stella X. Yu, and Jianbo
Shi. Convolutional random walk networks for semantic im-
age segmentation. In CVPR, pages 6137–6145. IEEE Com-
puter Society, 2017.

[6] Yuri Y. Boykov and Marie-Pierre Jolly.

Interactive graph
cuts for optimal boundary & region segmentation of objects
in n-d images.
In Proceedings Eighth IEEE International
Conference on Computer Vision, volume 1, pages 105–112,
2001.

[7] Liang-Chieh Chen, Alexander Schwing, Alan Yuille, and
Raquel Urtasun. Learning deep structured models.
In In-
ternational Conference on Machine Learning, pages 1785–
1794, 2015.

[8] Camille Couprie, Leo Grady, Laurent Najman, and Hugues
Talbot. Power watershed: A unifying graph-based optimiza-
tion framework. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 33(7):1384–1399, July 2011.

[9] Jean Cousty, Gilles Bertrand, Laurent Najman, and Michel
Couprie. Watershed cuts: Thinnings, shortest path forests,
and topological watersheds. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 32(5):925–939, May
2010.

[10] CREMI. Miccai challenge on circuit reconstruction from
electron microscopy images, 2017. https://cremi.
org.

[11] A. X. Falcao, J. Stolﬁ, and R. de Alencar Lotufo. The image
foresting transform:
theory, algorithms, and applications.
IEEE Transactions on Pattern Analysis and Machine Intel-
ligence, 26(1):19–29, Jan 2004.

[12] Jan Funke, Fabian David Tschopp, William Grisaitis, Arlo
Sheridan, Chandan Singh, Stephan Saalfeld, and Srinivas C
Turaga. Large scale image segmentation with structured loss
based deep learning for connectome reconstruction.
IEEE
Transactions on Pattern Analysis and Machine Intelligence,
2018.

[13] Leo Grady. Random walks for image segmentation. IEEE
Trans. Pattern Anal. Mach. Intell., 28(11):1768–1783, 2006.
[14] Jeremy Jancsary, Sebastian Nowozin, and Carsten Rother.
Loss-speciﬁc training of non-parametric image restoration

models: A new state of the art. In Proceedings of the 12th
European Conference on Computer Vision - Volume Part
VII, ECCV’12, pages 112–125, Berlin, Heidelberg, 2012.
Springer-Verlag.

[15] Diederik P. Kingma and Jimmy Ba. Adam: A method for

stochastic optimization. CoRR, abs/1412.6980, 2014.

[16] Nikos Komodakis and Georgios Tziritas. Image completion
using efﬁcient belief propagation via priority scheduling and
dynamic pruning. IEEE Transactions on Image Processing,
16(11):2649–2661, Nov 2007.

[17] Kisuk Lee, Jonathan Zung, Peter Li, Viren Jain, and H. Se-
bastian Seung. Superhuman accuracy on the snemi3d con-
nectomics challenge. CoRR, abs/1706.00120, 2017.

[18] Filip Malmberg, Robin Strand, Joel Kullberg, Richard Nor-
denskj¨old, and Ewert Bengtsson. Smart paint - a new inter-
active segmentation method applied to mr prostate segmen-
tation. MICCAI workshop, 2012.

[19] Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Pablo Arbel´aez,
and L. Van Gool. Convolutional oriented boundaries: From
image segmentation to high-level tasks. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 40(4):819–
833, April 2018.

[20] Marina Meil˘a. Comparing clusterings: an axiomatic view. In
In ICML 2005: Proceedings of the 22nd international con-
ference on Machine learning, pages 577–584. ACM Press,
2005.

[21] William M. Rand. Objective criteria for the evaluation of
clustering methods. Journal of the American Statistical As-
sociation, 66(336):846–850, 1971.

[22] Stefan Roth and Michael J. Black. Fields of experts: a frame-
work for learning image priors. In 2005 IEEE Computer So-
ciety Conference on Computer Vision and Pattern Recogni-
tion (CVPR’05), volume 2, pages 860–867 vol. 2, June 2005.
[23] Kegan G. G. Samuel and Marshall F. Tappen. Learning op-
timized map estimates in continuously-valued mrf models.
In 2009 IEEE Conference on Computer Vision and Pattern
Recognition, pages 477–484, June 2009.

[24] Ali Kemal Sinop and Leo Grady. A seeded image segmen-
tation framework unifying graph cuts and random walker
which yields a new algorithm. In 2007 IEEE 11th Interna-
tional Conference on Computer Vision, pages 1–8, Oct 2007.
[25] Daniel A. Spielman and Shang-Hua Teng. Nearly-linear time
algorithms for graph partitioning, graph sparsiﬁcation, and
solving linear systems.
In Proceedings of the Thirty-sixth
Annual ACM Symposium on Theory of Computing, STOC
’04, pages 81–90, New York, NY, USA, 2004. ACM.

[26] Marshall F. Tappen, Ce Liu, Edward H. Adelson, and
William T. Freeman. Learning gaussian conditional random
ﬁelds for low-level vision.
In 2007 IEEE Conference on
Computer Vision and Pattern Recognition, pages 1–8, June
2007.

[27] Paul Vernaza and Manmohan Chandraker. Learning random-
walk label propagation for weakly-supervised semantic seg-
mentation.
In 2017 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), volume 00, pages 2953–
2961, July 2017.

[28] Ulrike von Luxburg. A tutorial on spectral clustering. Statis-

tics and Computing, 17(4):395–416, Dec 2007.

12567

[29] Steffen Wolf, Lukas Schott, Ullrich K¨othe, and Fred A.
Hamprecht. Learned watershed: End-to-end learning of
seeded segmentation. ICCV, pages 2030–2038, 2017.

[30] Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-
Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang
Huang, and Philip HS Torr. Conditional random ﬁelds as
recurrent neural networks. In Proceedings of the IEEE Inter-
national Conference on Computer Vision, pages 1529–1537,
2015.

[31] Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. Semi-
supervised learning using gaussian ﬁelds and harmonic func-
tions.
In Proceedings of the Twentieth International Con-
ference on International Conference on Machine Learning,
ICML’03, pages 912–919. AAAI Press, 2003.

12568

