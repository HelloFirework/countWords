OCGAN: One-class Novelty Detection Using GANs with Constrained Latent

Representations

Pramuditha Perera∗

Ramesh Nallapati

Johns Hopkins University

AWS AI

Bing Xiang

AWS AI

pperera3@jhu.edu

rnallapa@amazon.com

bxiang@amazon.com

Abstract

We present a novel model called OCGAN for the classi-
cal problem of one-class novelty detection, where, given a
set of examples from a particular class, the goal is to deter-
mine if a query example is from the same class. Our solution
is based on learning latent representations of in-class exam-
ples using a denoising auto-encoder network. The key con-
tribution of our work is our proposal to explicitly constrain
the latent space to exclusively represent the given class. In
order to accomplish this goal, ﬁrstly, we force the latent
space to have bounded support by introducing a tanh ac-
tivation in the encoder’s output layer. Secondly, using a
discriminator in the latent space that is trained adversari-
ally, we ensure that encoded representations of in-class ex-
amples resemble uniform random samples drawn from the
same bounded space. Thirdly, using a second adversarial
discriminator in the input space, we ensure all randomly
drawn latent samples generate examples that look real. Fi-
nally, we introduce a gradient-descent based sampling tech-
nique that explores points in the latent space that gener-
ate potential out-of-class examples, which are fed back to
the network to further train it to generate in-class examples
from those points. The effectiveness of the proposed method
is measured across four publicly available datasets using
two one-class novelty detection protocols where we achieve
state-of-the-art results.

1. Introduction

One-class novelty detection tackles the problem of quan-
tifying the probability that a test example belongs to the dis-
tribution deﬁned by training examples [21]. Different from
other machine learning tasks [12],[15], in one-class novelty
detection, examples of only a single class are observed at
training time. During inference, the trained model is ex-
pected to accept in-class examples and reject out-of-class

∗This work was conducted as part of the ﬁrst author’s internship at AWS

AI.

Figure 1. Limitations of in-class representation based novelty de-
tection. Top: Input images; Middle: Output of an auto-encoder
network trained on digit 8. Bottom: Output produced by OC-
GAN, the proposed method. Even though auto-encoder network
is trained only on digits of 8, it provides good reconstruction for
digits from classes 1,5,6 and 9. In contrast, OCGAN forces the
latent representation of any example to reconstruct a digit 8. As a
result, all out-of-class examples produce high Mean Squared Er-
ror (MSE). The intensity of red color in the bottom two rows is
proportional to the MSE.

examples. Since the problem formulation assumes unavail-
ability of any negative training data, it is a difﬁcult problem
to solve in practice. Nevertheless, it has a number of appli-
cations including abnormality detection [24],[14] intruder
detection [17],[13],[16], bio-medical data processing [20]
and imbalance learning [10].

With the advent of deep learning, one-class novelty de-
tection has received considerable amount of attention in the
literature. Contemporary works in one-class novelty detec-
tion focus on learning a representative latent space for the
given class [23, 18]. Once such a space is learned, novelty
detection is performed based on the projection of a query
image onto the learned latent space. Two distinct strategies
are commonly used for this purpose in the literature. In the
ﬁrst strategy, the difference between the query image and
its inverse image (reconstruction) is used as a novelty detec-
tor. Various distance measures ranging from mean squared
error [23] to discriminator output [22] have been used in
the literature for this purpose. In comparison, the second
strategy explicitly models the learned latent space using a
distribution [1, 18, 21, 16]. In this work, we consider the
former strategy for novelty detection. We investigate lim-
itations of existing representation learning techniques and
propose learning a latent space that exclusively generates

12898

only in-class examples, to improve performance in novelty
detection.

Existing work focuses on generating a latent representa-
tion that preserves details of the given class. In doing so,
it is assumed that when an out-of-class object is presented
to the network, it will do a poor job of describing the ob-
ject, thereby reporting a relatively higher reconstruction er-
ror. However, this assumption does not hold at all times.
For an example, experiments done on digits in the literature
[18, 1] suggest that networks such as auto-encoders trained
on digits with a simple shape such as 0 and 1 have high
novelty detection accuracy. In contrast, digits with complex
shapes, such as digit 8, have relatively weaker novelty de-
tection accuracy. This is because a latent space learned for
a class with complex shapes inherently learns to represent
some of out-of-class objects as well. As an example, the
latent space learned on digit 8 is also able to represent other
digits such as 1,3,6,7 reasonably well – thereby producing
very low distance error values for out-of-class examples as
shown in Figure 1 (middle).

We note that the requirement in novelty detection is not
only to ensure that in-class samples are well represented; it
is also to ensure that out-of-class samples are poorly repre-
sented. To the best of our knowledge, none of the previous
work has addressed the latter requirement. In this work, we
propose One-Class GAN (OCGAN), a two-fold latent space
learning process that considers both these requirements.

At a high-level, we learn a latent space that represents
objects of a given class well. Secondly, we ensure that any
example generated from the learned latent space is indeed
from the known class.
In other words, if the network is
trained on a digits of 8, we ensure that any sample drawn
from the latent space, when used to generate an image, cor-
responds to an image of digit 8. This ensures that out-
of-class samples are not well represented by the network.
Shown in Figure 1(bottom) are the outputs generated by
the proposed method for the inputs shown in Figure 1(top).
Since the entire latent space corresponds to images from
digit 8, all projections into the latent space in return pro-
duce images of digit 8.

2. Related Work

One-class Novelty Detection. One-class novelty detection
is a well-deﬁned research problem with standard evaluation
metrics that has received considerable attention in the recent
past. It has been traditionally treated as a representation-
learning problem. The earliest methods in one-class nov-
elty detection used Principal Component Analysis (PCA)
[2] and its kernel extension [5] to ﬁnd a subspace that best
describes the given concept. With the advent of neural net-
works and deep learning, a similar mapping was sought us-
ing auto-encoder networks [4].

As discussed in the preceding section, once such a map-

ping is learned, one-class novelty detection is carried out
either based on reconstruction error or by explicitly model-
ing the normal behaviour of the known class in the latent
space. In [5] and [23] the former strategy has been used to
perform novelty detection using mean squared error as the
novelty function. In [22], a Generative Adversarial Network
(GAN) [3] is trained to de-noise noisy samples of the given
class. There, the discriminator’s prediction in the image
space is used to quantify reconstruction error. Following
a slightly different strategy, [25] proposes to learn a map-
ping between a random distribution and the image manifold
of the given class. In [25], the closest image to a query is
sought through back-propagation, where novelty detection
is performed based on the difference between the two im-
ages.

The latter strategy, where the behavior of the known class
in the latent space is modeled, has also received consider-
able attention in recent works. Earlier work of this nature
used one-class modeling tools such as One-class SVM [26]
and Support Vector Data Descriptor (SVDD) [27] on top of
an obtained latent representation. In [18], ﬁrst, a GAN is
used to obtain a latent representation. Then, the probabil-
ity distribution of the latent space is modeled as a product
of two marginal distributions where marginal distributions
are learned empirically. In contrast, in [1] the latent distri-
bution is modeled using an auto-regressive network that is
learned along with the parameters of the auto-encoder. Us-
ing a different approach, deep-SVDD [21] tries to learn a
latent space where intra-class variance is low. The method
proposed by [21] is conceptually similar to [17] but does
not use any external data in ﬁnding the solution as done in
the latter work.

Anomaly Detection and One-class Classiﬁcation. Both
anomaly detection [30] and one-class classiﬁcation [26] are
problems related to one-class novelty detection. Both have
similar objectives – to detect out-of-class samples given a
set of in-class samples. A hard label is expected to be as-
signed to a given image in one-class classiﬁcation; therefore
its performance is measured using detection accuracy and
F1 score. In contrast, novelty detection is only expected to
associate a novelty score to a given image; therefore per-
formance of novelty detection is measured using a Receiver
Operating Characteristic (ROC) curve. However, boundary-
based one-class classiﬁcation methods such as One-class
SVM, and SVDD can be adopted as novelty detection meth-
ods by considering distance to the decision boundary as the
novelty score. In contrast, anomaly detection (also known
as outlier detection) is an unsupervised learning task [30].
Given a mixture of unlabeled in-class and out-of-class ex-
amples, goal of anomaly detection is to separate in-class
examples from out-of class examples. Since anomaly de-
tection and novelty detection follow different protocols, we
note that these two tasks are not comparable. Therefore,

2899

tools designed for anomaly detection and novelty detection
cannot be used interchangeably.
Adversarial Learning. Given a set of images, Generative
Adversarial Networks introduced in [3] play a two-player
game between a generator network and a discriminator net-
work. Here, the generator network tries to produce realis-
tic images (fake images) from the given image distribution
whereas the discriminator network tries to distinguish fake
images from real images. At equilibrium, the generator net-
work learns the distribution of the given image set. In order
to achieve this state, GAN theory dictates that there should
be a balance between the capacities of the two networks. In
[9], GAN was extended to the conditional setting. Based
on this extension, GANs have been used in many image-to-
image translation applications since. It was shown in [19]
that GANs can be used to learn stable representations even
with deep convolutional networks, provided that certain de-
sign choices are made. Inspired by the network architecture
of [22], and following principles outlined in [19], we pro-
pose a deep convolutional GAN architecture as the back-
bone of our solution.

3. Proposed Method: OCGAN

3.1. Motivation

In the introduction, we presented an example where a
network trained to represent a given class has ended up
providing good representation for images of other classes.
When images of a given class are sufﬁciently diverse,
smoothly transitioning between the projection of one in-
class image in the latent space to that of another can be
done along inﬁnitely many different paths – this is partic-
ularly the case for latent spaces with high dimensionality.
In training auto-encoders, we model projections of only ob-
served examples into the latent space - not all possible paths
between the corresponding latent points.

In Figure 2 we visualize a path traced in the latent space
between two points corresponding to two different images
of the given class (class 8). This visualization reveals that as
we transition from one point to the other in the latent space
along the speciﬁed path, certain intermediate latent samples
resemble the likeness of digit 1. When the network observes
an instance of digit 1, it gets projected onto such samples.
Since digit 1 is well represented by the network, its recon-
struction error will be low, although it is out of class. The
core idea of our proposal is based on this observation. We
argue that if the entire latent space is constrained to rep-
resent images of the given class, the representation of out-
of-class samples will be minimal – thereby producing high
reconstruction errors for them.

With this strategy in mind, we explicitly force the en-
tirety of the latent space to represent only the given class.
When applied to the example in Fig. 2, all latent samples

Figure 2. This ﬁgure illustrates the latent space learned for digit
8 using a denoising-autoencoder network (left) and the proposed
method (right). Visualization of a chosen path between two digit
images in the latent space are shown in the ﬁgure. In the denoising
auto-encoder, digit 1 is well represented in this path. Therefore, for
a digit 1 image, the reconstruction error will be low. On the other
hand, the proposed method produces in-class examples through-
out the chosen path in the latent space between the two images.
Therefore, when a digit 1 image that gets projected into this path
is considered, we ﬁnd that reconstruction error is high.

along any path between the two 8’s will reconstruct into a
set of digit 8 images. Visualization of the path as shown
in Figure 2(b) validates this claim. As a result, when an
out-of-class digit 1 is presented to the model, there will be
a high difference between the digit and the reconstruction
of the digit (which will now look more like a digit 8). As
a result, the proposed method is able to produce superior
novelty detection performance.

3.2. Proposed Strategy

The proposed solution, OCGAN, consists of four com-
ponents: a denoising auto-encoder, two discriminators (la-
tent and visual discriminator) and a classiﬁer. The proposed
network is trained using adversarial principles. We describe
each of these components in detail below.
Denoising auto-encoder: Following previous work, we use
a denoising auto-encoder network to learn a representation
for the given concept. The auto-encoder is an encoder (En)
- decoder (De) structure that is trained with the objective of
minimizing the distance between the input and the output
of the network. It is the usual practice to have a bottleneck
latent-space in between with a dimension smaller than the
input. Due to this bottleneck, auto-encoder retains only es-
sential information in the latent space that is required for re-
construction. In a denoising auto-encoder, noise is added to
the input image and the network is expected to reconstruct
the denoised version of the image. It is shown in the lit-
erature that denoising auto-encoders reduce over-ﬁtting and
improve generalizabilty of the network compared to regular
auto-encoders. As a result, denoising auto-encoders open

2900

up the possibility of having a latent dimension larger than
the input image dimension [29].

Further, our strategy revolves around densely sampling
from the latent space. To facilitate this operation, with the
intention of having a bounded support for the latent space,
we introduce a tanh activation in the output layer of the en-
coder. Therefore, support of the latent space is (−1, 1)d,
where d is the dimension of the latent space. In our imple-
mentation, we add zero mean Gaussian white noise with a
variance of 0.2 to input images and train the auto-encoder
using mean squared error loss as shown below:

lMSE = ||x − De(En(x + n))||2
2,

where x is an input image and n ∼ N (0, 0.2). In addition,
adversarial loss terms introduced in the following sections
are also used to learn parameters of the auto-encoder. Since
the decoder part of the auto-encoder also acts as the gener-
ator of images from latent space, we use the words decoder
and generator interchangeably in the remainder of the text.
Latent Discriminator: The motivation of our method is to
obtain a latent space where each and every instance from
the latent space represents an image from the given class.
If representations of the given class are only conﬁned to a
sub-region of the latent space, this goal is not possible to
achieve. Therefore, we explicitly force latent representa-
tions of in-class examples to be distributed uniformly across
the latent space. We achieve this using a discriminator oper-
ating in the latent space that we call latent discriminator Dl
. The latent discriminator is trained to differentiate between
latent representations of real images of the given class and
samples drawn from a U(−1, 1)d distribution. We consider
a loss of the form:

llatent

= −(Es∼U(−1,1)[log Dl(s)] +
Ex∼px [log(1 − Dl(En(x + n)))])

where, px is the distribution of in-class examples. We train
the latent discriminator along with the auto-encoder net-
work using maxEn minDl llatent. Since the latent space is a
hyper-cube with support (−1, 1)d, at equilibrium, the latent
projections of examples from the given class are expected
to be distributed evenly following a U(−1, 1)d distribution.
Visual Discriminator: In order for the network not to rep-
resent any out-of-class objects, we propose to sample ex-
haustively from the latent space and ensure corresponding
images are not from out-of class. Since there are no nega-
tive classes present during training, this condition is difﬁcult
to enforce. Instead, we make sure that all images generated
from latent samples are from the same image space distri-
bution as the given class. In order to enforce this constraint,
we use a second discriminator that we call visual discrimi-
nator (Dv).

(a)

(b)

Figure 3. Visualization of generated images from random latent
samples when the network is trained (a) without informative-
negative mining (b) with informative-negative mining, for digit
9. In the former case, obtained digits are of a different shape in
certain instances. For example, the highlighted generated-image
looks like a 0. In the latter case, all generated digits consistently
look like a 9.

Visual discriminator is trained to differentiate between
images of the given class and images generated from ran-
dom latent samples using the decoder De(s), where s is a
random latent sample. We refer to latter images as fake im-
ages for the remainder of the paper. When the visual dis-
criminator is fooled, fake images chosen at random in gen-
eral will look similar to examples from the given class. We
evaluate adversarial loss lvisual as follows.

lvisual = −(Es∼U(−1,1)[log Dv(De(s))] +

Ex∼pl [log(1 − Dv(x))])

We learn visual discriminator together with the auto-

encoder network using maxDe minDv lvisual.
Informative-negative Mining: The components described
thus far account for the core of the proposed network.
Shown in Figure 3(a) is a visualization of fake images ob-
tained by jointly training these three sub-networks using
digit 9. Figure 3(a) suggests that the proposed network is
able to generate plausible images of the given class for ma-
jority of the random latent samples. However, as indicated
in the ﬁgure there are few cases where the produced out-
put looks different from the given class. For example, the
highlighted digit in Figure 3(a) looks more like a zero than
a nine.

This result suggests that despite the proposed training
procedure, there are latent space regions that do not produce
images of the given class. This is because sampling from all
regions in the latent space is impossible during training –
particularly when the latent dimension is large. A naive so-
lution to this problem is to reduce the dimensionality of the
latent space. However, with a lower dimension, the amount
of detail the network preserves goes down. As a result, al-
though all latent samples produce an in-class image, a very
low dimensionality would diminish performance in novelty
detection.

As an alternative, we propose to actively seek regions
in the latent space that produce images of poor quality.

2901

For the remainder of the paper we refer to these images as
informative-negative samples. We use informative-negative
samples to train the generator so that it learns to produce
good quality in-class images even for these latent sam-
ples. However, we continue to use samples chosen at ran-
dom to train two discriminators, as feeding weaker sam-
ples would hinder training of discriminators.
In order to
ﬁnd informative-negative samples, ﬁrst we start with ran-
dom latent-space samples and use a classiﬁer to assess the
quality of the image generated from the sample. The loss
of the classiﬁer is used to back-propagate and compute gra-
dients in the latent space. We then take a small step in the
direction of the gradient to move to a new point in the la-
tent space where the classiﬁer is conﬁdent that the generated
image is out-of-class.
Classiﬁer: The role of the classiﬁer is to determine how
well the given image resembles content of the given class.
Ideally such a classiﬁer can be trained using positive and
negative examples of a given class. However, since there are
no negative training samples available, we train a weaker
classiﬁer instead. In the proposed mechanism, if the con-
tent belongs to the given class, the classiﬁer deems it posi-
tive, and if the content bears no resemblances to the positive
class, the classiﬁer deems it negative.

We train the classiﬁer using reconstructions of in-class
samples as positives and fake images, those that are gener-
ated from random samples in the latent space, as negatives.
This classiﬁer is trained independent of other network ele-
ments using binary cross entropy loss lclassiﬁer. In other
words, the classiﬁer loss is not considered while learning
generator and discriminator parameters. Initially, since the
quality of fake samples is poor, the classiﬁer is able to ob-
tain very low loss value. As the quality of fake images im-
proves with training, differentiation becomes harder and it
forces the classiﬁer to become smarter.

It should be noted that the classiﬁer’s prediction of a
given image as a negative may or may not mean that the
given image always corresponds to an informative-negative
latent sample. Even if it does not, such images do not hinder
the training process at all, and training proceeds as usual.

Since the informative-negative classiﬁer does not partic-
ipate in the GAN game, there is no requirement to balance
the capacity of the classiﬁer with the generator (whereas,
this is the case for both other discriminators). Therefore, it
is possible to make the classiﬁer very strong to increase its
conﬁdence in in-class reconstructions.

Figure 4 shows the impact of the informative-negative
mining procedure using a few illustrative examples. In the
ﬁgure, image pairs before and after negative mining are dis-
played. We have shown cases where the original images
are not largely changed in the bottom row. In the top row
we have shown a few examples where the input images have
been substantially altered as a result of informative-negative

Figure 4. Informative-negative mining. Shown in the image are
image pairs before and after mining process for different digits. In
the top row, original images are subjected to substantial changes
where they have been converted into a different digits altogether.
These are the informative-negatives we are looking for. In the bot-
tom row, the change is not substantial, which means the samples
we mined are not informative. However, it still does not hurt our
training process.

mining. For example, the top left sample of digit 2 appears
to be a digit 7 after the process. In Figure 3(b), we show the
impact of this procedure by visualizing a few fake images
generated from random latent samples for digit 9. It is ev-
ident from the ﬁgure that informative-negative mining has
helped in generating digits of the desired class more consis-
tently across the whole latent space.

Full OCGAN Model: The full network of OCGAN and the
breakdown of each individual component of the proposed
network is shown in Figure 5. The network is trained in
two iterative steps. In the ﬁrst step, all other sub-networks
except the classiﬁer network are frozen. The classiﬁer net-
work is trained with reconstructed in-class examples and
generated fake examples. Then, it is frozen and the auto-
encoder and two discriminators are trained adversarially.
The latent discriminator is trained based on latent projec-
tions of in-class images and random samples drawn from
U(−1, 1) distribution. The visual discriminator is trained
using fake images generated from random latent samples
and real images from the given class. Discriminators are
trained by minimizing the loss llatent + lvisual.

Prior to each generator step, informative-negative sam-
ples are sought in the latent space using a batch of random
samples drawn from the U(−1, 1) distribution, and using
gradient descent steps from the classiﬁer’s loss in the la-
tent space. The auto-encoder is trained using informative-
negative samples and latent projections of (noise-injected)
real examples of the given class using 10×lMSE+lvisual+
llatent. A larger weight is given to the lMSE term to obtain
good reconstructions. The coefﬁcient was chosen empiri-
cally based on the quality of reconstruction. In our imple-
mentation, we started mining for informative-negative sam-
ples only after the network started producing fake images of
reasonable quality. Steps of the training procedure is sum-
marized in Algorithm 1.

2902

Input

: Set of training data x, iteration size N ,

parameter λ

Output: Models: En, De, C, Dl , Dv

for iteration 1 to → N do

Classiﬁer update: keep Dl, Dv, En, De ﬁxed.
n ←− N (0, I)
l1 ←− En(x + n)
l2 ←− U(−1, 1)
lclassiﬁer ←− C(De(l2), 0) + C(De(l1), 1)
Back-propagatelclassiﬁer to change C

Discriminator update:
llatent ←− Dl(l1, 0) + Dl(l2, 1)
lvisual ←− Dv(De(l2), 0) + Dv(x, 1)
Back-propagatellatent +
lvisual and change Dl, Dv

Informative-negative mining : Keep all

networks ﬁxed.
for sub-iteration 1 to → 5 do
lclassiﬁer ←− C(De(l2), 1)
Back-propagate lclassiﬁer to change l2

end

Generator update: keep Dl, Dv,C ﬁxed.
llatent ←− Dl(l1, 1) + Dl(l2, 0)
lvisual ←− Dv(De(l2), 1) + Dv(x, 0)
lmse ←− ||x − De(l1)||2
Back-propagate
llatent + lvisual + λlmse to change En, De

end

Algorithm 1: Training methodology of the OCGAN
model: Dl, Dv and C represent the outputs of the la-
tent discriminator, visual discriminator and the classi-
ﬁer respectively. En and De are the encoder and the de-
coder/generator respectively. Real label and fake label
are denoted by 1 and 0 respectively.

Network Architecture and Hyper-parameter Selection:
The auto-encoder is a symmetric network with three 5 x 5
convolutions with stride 2 followed by three transposed con-
volutions. All convolutions and transposed-convolutions
are followed by batch normalization and leaky ReLU (with
slope 0.2) operations. A tanh activation was placed imme-
diately after the last convolution layer to restrict support of
the latent dimension. We used a base channel size of 64
for the auto-encoder and increased number of channels by a
factor of 2 with every layer1.

The visual discriminator and classiﬁer are networks with
three 5 x 5 convolutions with stride 2. Base channel size of
two networks were chosen to be 12 and 64 respectively. La-
tent discriminator is a fully connected network with layers

1Source

code

in MXNet

is

made

available

at

https://github.com/PramuPerera/OCGAN.

of sizes 128, 64, 32 and 16 respectively. Batch normaliza-
tion and ReLu activations were used after each layer in all
networks.

At the end of training, we selected the model that re-
sulted in minimum MSE on the validation set for evaluation.
Model hyper-parameters such as learning rate, latent space
size were chosen based on the MSE of validation set. The
number of base channels in each network and coefﬁcient of
loss terms were decided based on the plot of training loss of
each network component.

4. Experimental Results

4.1. Evaluation Methodology

We test the effectiveness of the proposed method us-
ing four publicly available multi-class object recognition
datasets. In order to simulate a one-class setting, each class
at a time is considered as the known class, as proposed in
[1], [18] and [21]. The network is trained using only sam-
ples of the known class. During testing, we treat the union
of remaining classes as out-of-class samples. Following
previous work, we compare the performance of our method
using Area Under the Curve (AUC) of Receiver Operating
Characteristics (ROC) curve. Here, we note that there exist
two protocols in the literature for one-class novelty detec-
tion.
Protocol 1 : Training is carried out using 80% of in-class
samples. The remaining 20% of in-class data is used for
testing. Negative test samples are randomly selected so that
they constitute half of the test set.
Protocol 2 : Use the training-testing splits of the given
dataset to conduct training. Training split of the known
class is used for training / validation. Testing data of all
classes are used for testing.

The work of [18] used the 2nd protocol to evaluate their
performance in MNIST[8], FMNIST[31] and COIL100[11]
datasets, whereas the authors of [1] and [21] chose the 1st
protocol on MNIST and CIFAR10[7] datasets. We compare
our method on these baselines using the relevant protocol
for fair comparison.

4.2. Datasets and Experimental Results

In this section we brieﬂy introduce each dataset used for
evaluation and present experimental results for the proposed
method. In Figure 6, a few representative examples from
the considered datasets are shown. We tabulate results cor-
responding to Protocol 1 in Table 1 and results of protocol
2 in Tables 2 and 3.
COIL100 : COIL100 is a multi-class dataset where each
object class is captured using multiple different poses.
There are 100 image classes in the dataset with a few im-
ages per class (typically less than hundred). Figure 6 sug-
gests that the intra-class difference is very small for this

2903

Figure 5. Illustration of OCGAN architecture: the network consists of four sub-networks : an auto-encoder, two discriminators and a
classiﬁer.

Figure 6. Representative images from the datasets used for evaluation. Images in each column belong to the same class.

dataset. As a result, all considered method produces high
AUC values for protocol 1 as shown in Table 1. Our pro-
posed method of OCGAN records 0.995 AUC, surpassing
[18] which reported AUC of 0.968.

fMNIST : fMNIST is intended to be a replacement for
MNIST, where the dataset comprises of 28×28 images of
fashion apparels/accessories. As evident from Figure 6,
fMNIST is a more challenging dataset compared to both
COIL100 and MNIST, since there is considerable amount of
intra-class variances. The proposed method improves nov-
elty detection performance by over 2% compared to [18] for
this dataset, using protocol 1.

MNIST : MNIST dataset contains hand-written digits from
0-9 with a 28 × 28 resolution. This dataset has been widely
used to benchmark one-class novelty detection results. In
terms of complexity, it is an easier dataset compared to
fMNIST, but more challenging than COIL100. We report
performances of the proposed method on this dataset using
both protocols.

When protocol 1 was used, our OCGAN model yielded
an improvement of about 3% compared to state-of-the-art
[18] method. As shown in Table 2, when protocol 2 is used,
our method has not only registered a better average AUC
value, it has reported best AUC for individual classes in 9
out of 10 classes.

CIFAR10 : CIFAR10 is an object recognition dataset that
consists of images from 10 classes. Out of the considered
datasets, CIFAR10 is the most challenging dataset due to it

Table 1. Mean One-class novelty detection using Protocol 1.
MNIST COIL fMNIST
0.88
0.82
0.899
0.932
0.977

ALOCC DR [22]
ALOCC D [22]
DCAE [23]
GPND [18]
OCGAN

0.809
0.686
0.949
0.968
0.995

0.753
0.601
0.908
0.901
0.924

diverse content and complexity. Speciﬁcally, it should be
noted that all other datasets are very well aligned, without
a background. In comparison, CIFAR10 is not an aligned
dataset and it contains objects of the given class across
very different settings. As a result, one-class novelty detec-
tion results for this dataset are comparatively weaker for all
methods. Out of the baseline methods, [21] has done con-
siderably better than other methods. Following their work,
we carried out the same pre-processing in our experiments.
In addition, we subtracted the class-mean image from all
training and testing images. We obtained comparable re-
sults to deep-SVDD with the proposed method where we
recorded average AUC of 0.6566.

4.3. Ablation Study

In order to investigate the effectiveness of each addi-
tional component of the proposed work, we carried an ab-
lation study using the MNIST dataset. Speciﬁcally, we
consider four scenarios. In the ﬁrst scenario we consider
only the auto-encoder. In the second and third scenarios,

2904

CIFAR10COILFMNISTMNISTTable 2. One-class novelty detection results for MNIST dataset using Protocol 2.

OCSVM [26]
KDE [2]
DAE [4]
VAE [6]
Pix CNN [28]
GAN [25]
AND [1]
AnoGAN [25]
DSVDD [21]
OCGAN

0
0.988
0.885
0.894
0.997
0.531
0.926
0.984
0.966
0.980
0.998

1
0.999
0.996
0.999
0.999
0.995
0.995
0.995
0.992
0.997
0.999

2
0.902
0.710
0.792
0.936
0.476
0.805
0.947
0.850
0.917
0.942

3
0.950
0.693
0.851
0.959
0.517
0.818
0.952
0.887
0.919
0.963

4
0.955
0.844
0.888
0.973
0.739
0.823
0.960
0.894
0.949
0.975

5
0.968
0.776
0.819
0.964
0.542
0.803
0.971
0.883
0.885
0.980

6
0.978
0.861
0.944
0.993
0.592
0.890
0.991
0.947
0.983
0.991

7
0.965
0.884
0.922
0.976
0.789
0.898
0.970
0.935
0.946
0.981

8
0.853
0.669
0.740
0.923
0.340
0.817
0.922
0.849
0.939
0.939

9
0.955
0.825
0.917
0.976
0.662
0.887
0.979
0.924
0.965
0.981

MEAN
0.9513
0.8143
0.8766
0.9696
0.6183
0.8662
0.9671
0.9127
0.9480
0.9750

Table 3. One-class novelty detection results for CIFAR10 dataset using Protocol 2. Plane and Car classes are annotated as Airplane and
Automobile in CIFAR10.

PLANE CAR BIRD CAT DEER DOG FROG HORSE

SHIP

TRUCK MEAN

OCSVM [26]

KDE [2]
DAE [4]
VAE [6]

Pix CNN [28]

GAN [25]
AND [1]

AnoGAN [25]
DSVDD [21]

OCGAN

0.630
0.658
0.411
0.700
0.788
0.708
0.717
0.671
0.617
0.757

0.440
0.520
0.478
0.386
0.428
0.458
0.494
0.547
0.659
0.531

0.649
0.657
0.616
0.679
0.617
0.664
0.662
0.529
0.508
0.640

0.487
0.497
0.562
0.535
0.574
0.510
0.527
0.545
0.591
0.620

0.735
0.727
0.728
0.748
0.511
0.722
0.736
0.651
0.609
0.723

0.500
0.496
0.513
0.523
0.571
0.505
0.504
0.603
0.657
0.620

0.725
0.758
0.688
0.687
0.422
0.707
0.726
0.585
0.677
0.723

0.533
0.564
0.497
0.493
0.454
0.471
0.560
0.625
0.673
0.575

0.649
0.680
0.487
0.696
0.715
0.713
0.680
0.758
0.759
0.820

0.508
0.540
0.378
0.386
0.426
0.458
0.566
0.665
0.731
0.554

0.5856
0.6097
0.5358
0.5833
0.5506
0.5916
0.6172
0.6179
0.6481
0.6566

we use auto-encoder with the visual and latent discrimi-
nators respectively. In the ﬁnal scenario, we consider the
full proposed model, OCGAN. Mean AUC for each class of
MNIST dataset is tabulated in Table 4.

We note that the AUC value obtained for the auto-
encoder is already high at 0.957. Therefore even slightest
of improvement from this point is signiﬁcant. When a la-
tent discriminator is introduced, performance of the system
improves marginally by 0.2%. When a visual discriminator
is added on top, the performance improves further by 1%.
When informative-negative mining as added, performance
is further improved by a 0.4%.

Table 4. Ablation study for OCGAN performed on MNIST.

Without any Discriminators
With latent Discriminator
With two Discriminators
Two Discriminators + Classiﬁer

0.957
0.959
0.971
0.975

5. Conclusion

In this work we dived deep into mechanics of
reconstruction-error based novelty detection. We showed
that a network trained on a single class is capable of rep-

resenting some out-of-class examples, given that in-class
objects are sufﬁciently diverse. In order to combat this is-
sue we introduce a latent-space-sampling-based network-
learning procedure. First we restricted the latent space to
be bounded and forced latent projections of in-class popu-
lation to be distributed evenly in the latent space using a la-
tent discriminator. Then, we sampled from the latent space
and ensured using a visual discriminator that any random
latent sample generates an image from the same class. Fi-
nally, in an attempt to reduce false positives we introduced
an informative-negative mining procedure. We showed that
our OCGAN model outperforms many recently proposed
one-class novelty detection methods on four publicly avail-
able datasets. Further, by performing an ablation study we
showed that each component of the proposed method is im-
portant for the functionality of the system.

Experimental results suggest that the proposed method
is effective especially when a single concept is present in
images as is the case with COIL, MNIST and fMNIST
datasets. In future work we aim to generalize OCGANs to
natural image datasets with more complex structure. Fur-
ther, we wish to investigate their applicability to video nov-
elty detection.

2905

References

[1] D. Abati, A. Porrello, S. Calderara, and R. Cucchiara. AND:
Autoregressive Novelty Detectors. In 2019 IEEE Conference
on Computer Vision and Pattern Recognition, 2019. 1, 2, 6,
8

[2] Christopher M. Bishop. Pattern Recognition and Machine

Learning (Information Science and Statistics). 2006. 2, 8

[3] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets.
In Advances
in neural information processing systems, pages 2672–2680,
2014. 2, 3

[4] Raia Hadsell, Sumit Chopra, and Yann Lecun. Dimension-
ality reduction by learning an invariant mapping.
In In
Proc. Computer Vision and Pattern Recognition Conference
(CVPR’06. IEEE Press, 2006. 2, 8

[5] Heiko Hoffmann. Kernel pca for novelty detection. Pattern

Recognition, 40(3):863 – 874, 2007. 2

[6] Diederik P Kingma and Max Welling. Auto-encoding varia-
tional bayes. In International Conference on Learning Rep-
resentations. 8

[7] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar. 6

[8] Yann LeCun and Corinna Cortes. MNIST handwritten digit

database. 6

[9] Mehdi Mirza and Simon Osindero. Conditional generative

adversarial nets. arXiv preprint arXiv:1411.1784, 2014. 3

[10] Krystyna Napierala and Jerzy Stefanowski. Types of minor-
ity class examples and their inﬂuence on learning classiﬁers
from imbalanced data. Journal of Intelligent Information
Systems, 46(3):563–597, Jun 2016. 1

[11] Sameer A. Nene, Shree K. Nayar, and Hiroshi Murase.
Columbia object image library (coil-20. Technical report,
1996. 6

[12] Poojan Oza and Vishal Patel. C2ae: Class conditioned auto-
encoder for open-set recognition. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), June
2019. 1

[13] Poojan Oza and Vishal M Patel. Active authentication us-
ing an autoencoder regularized cnn-based one-class classi-
ﬁer. In 2019 14th IEEE International Conference on Auto-
matic Face & Gesture Recognition (FG 2019). IEEE, 2019.
1

[14] Poojan Oza and Vishal M Patel. One-class convolutional
neural network. IEEE Signal Processing Letters, 26(2):277–
281, 2019. 1

[15] Pramuditha Perera and Vishal Patel. Deep transfer learning
for multiple class novelty detection. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), June
2019. 1

[16] Pramuditha Perera and Vishal M Patel. Dual-minimax prob-
ability machines for one-class mobile active authentication.
In IEEE Conference on Biometrics: Theory, Applications,
and Systems (BTAS). IEEE, 2018. 1

[17] P. Perera and V. M. Patel. Learning Deep Features for One-

Class Classiﬁcation. ArXiv e-prints, Jan. 2018. 1, 2

[18] S. Pidhorskyi, R. Almohsen, D. A Adjeroh, and G. Doretto.
Generative Probabilistic Novelty Detection with Adversarial
Autoencoders. In Advances in Neural Information Process-
ing Systems, 2018. 1, 2, 6, 7

[19] Alec Radford, Luke Metz, and Soumith Chintala. Unsuper-
vised representation learning with deep convolutional gen-
erative adversarial networks. CoRR, abs/1511.06434, 2015.
3

[20] Stephen J Roberts. Novelty detection using extreme value
IEE Proceedings-Vision, Image and Signal Pro-

statistics.
cessing, 146(3):124–129, 1999. 1

[21] Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas
Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Em-
manuel M¨uller, and Marius Kloft. Deep one-class classiﬁ-
cation. In Proceedings of the 35th International Conference
on Machine Learning, pages 4393–4402, 2018. 1, 2, 6, 7, 8
[22] Mohammad Sabokrou, Mohammad Khalooei, Mahmood
Fathy, and Ehsan Adeli. Adversarially learned one-class
classiﬁer for novelty detection. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pages 3379–3388, 2018. 1, 2, 3, 7

[23] Mayu Sakurada and Takehisa Yairi. Anomaly detection us-
ing autoencoders with nonlinear dimensionality reduction. In
Proceedings of the MLSDA 2014 2Nd Workshop on Machine
Learning for Sensory Data Analysis, 2014. 1, 2, 7

[24] Babak Saleh, Ali Farhadi, and Ahmed Elgammal. Object-
centric anomaly detection by attribute-based reasoning.
In
Proceedings of the 2013 IEEE Conference on Computer Vi-
sion and Pattern Recognition, pages 787–794, 2013. 1

[25] Thomas Schlegl, Philipp Seeb¨ock, Sebastian M. Waldstein,
Ursula Schmidt-Erfurth, and Georg Langs. Unsupervised
anomaly detection with generative adversarial networks to
guide marker discovery. In IPMI, 2017. 2, 8

[26] Bernhard Sch¨olkopf, John C. Platt, John C. Shawe-Taylor,
Alex J. Smola, and Robert C. Williamson. Estimating the
support of a high-dimensional distribution. Neural Comput.,
13(7):1443–1471, 2001. 2, 8

[27] David M. J. Tax and Robert P. W. Duin. Support vector data

description. Mach. Learn., 54(1):45–66, 2004. 2

[28] Aaron van den Oord, Nal Kalchbrenner, Lasse Espeholt, ko-
ray kavukcuoglu, Oriol Vinyals, and Alex Graves. Condi-
tional image generation with pixelcnn decoders.
In D. D.
Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett,
editors, Advances in Neural Information Processing Systems
29, pages 4790–4798. 2016. 8

[29] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. Extracting and composing robust
features with denoising autoencoders. In Proceedings of the
25th International Conference on Machine Learning, pages
1096–1103, 2008. 4

[30] Yan Xia, Xudong Cao, Fang Wen, Gang Hua, and Jian
Sun. Learning discriminative reconstructions for unsuper-
vised outlier removal. In 2015 IEEE International Confer-
ence on Computer Vision, ICCV 2015, Santiago, Chile, De-
cember 7-13, 2015, pages 1511–1519, 2015. 2

[31] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-
mnist: a novel image dataset for benchmarking machine
learning algorithms. 2017. 6

2906

