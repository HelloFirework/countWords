Fast Single Image Reﬂection Suppression via Convex Optimization

Yang Yang1, Wenye Ma2, Yin Zheng3, Jian-Feng Cai4, Weiyu Xu1

1University of Iowa, 2Tencent, 3WeChat Search Application Department, Tencent,

4Hong Kong University of Science and Technology

yy.hz76@gmail.com, wenyema@tencent.com, yinzheng@tencent.com,

jfcai@ust.hk, weiyu-xu@uiowa.edu

Abstract

Removing undesired reﬂections from images taken
through the glass is of great importance in computer vision.
It serves as a means to enhance the image quality for aes-
thetic purposes as well as to preprocess images in machine
learning and pattern recognition applications. We propose
a convex model to suppress the reﬂection from a single in-
put image. Our model implies a partial differential equa-
tion with gradient thresholding, which is solved efﬁciently
using Discrete Cosine Transform. Extensive experiments
on synthetic and real-world images demonstrate that our
approach achieves desirable reﬂection suppression results
and dramatically reduces the execution time.

1. Introduction

Images taken through glass usually contain unpleasant
It is highly desirable if such reﬂections can
reﬂections.
be removed.
In particular, with the advent of the popu-
larity of portable digital devices such as smartphones and
tablets, a lot of such images are taken in everyday life. A
fast-response and user-friendly image reﬂection suppres-
sion technology is of great practical signiﬁcance so that
such images can be processed on portable devices in sec-
onds with the best dereﬂected results produced in real-time
according to a user’s visual perception.

Given an input reﬂection-contaminated image Y, tradi-
tional approaches that attempt to remove the reﬂection fo-
cus on separating the image into the transmission layer T
(the true background) and the reﬂection layer R [3], i.e.,
the following assumption is made

Y = T + R,

(1)

where T and R are unknowns. This problem is highly ill-
posed since the number of unknowns is twice the number of
conditions. Multiple ways of separation are possible. Dif-
ferent priors and assumptions have been introduced to nar-

The work of W. Xu was supported in part by Simons Foundation

318608 and in part by NSF DMS-1418737.

(1a) Original Image

(1b) Dereﬂected Image

Figure 1: (1a): A real-world image taken through the window
on a train. Notice the reﬂection of the seat and the lights in the
train. (1b): The result after the reﬂection suppression by our pro-
posed method. Image size: 1080 × 1440. Execution time: 1.15s.
https://github.com/yyhz76/reflectSuppress

row down the range of valid solutions, despite speciﬁc lim-
itations therein. Instead of separating the image into two
layers, suppressing the reﬂection in a single input image,
as proposed in Arvanitopoulos et al. [2], is more practical.
In most cases, people are more interested in the transmis-
sion layer of an image. Also, perfect layer separation of
a single image is in general difﬁcult. The separated layers
using existing approaches more or less contain misclassi-
ﬁed information, especially when the reﬂection is sharp and
strong, which might yield dark dereﬂected outputs. This is
caused by the removal of a large portion of the energy which
concentrates in the reﬂection layer (See Sec. 3).

Most image reﬂection removal approaches so far empha-
size the performance in the aspects of the quality of the
dereﬂection.
In addition, they can only handle relatively
small-sized images and are often computationally inefﬁ-
cient. With the rapid development of portable device tech-
nologies, megapixel smartphone images are very common
nowadays. Therefore, the efﬁciency of such methods also
needs to be improved to handle large images. We propose
an image reﬂection suppression approach that is highly ef-
ﬁcient, which is able to process large smartphone images
in seconds, yet can achieve competitive dereﬂection quality
compared to state-of-the-art approaches. Fig. 1 is an exam-
ple of our approach applying on a smartphone image.

18141

1.1. Related Work

Prior research in image reﬂection removal can be catego-
rized by the number of input images. One branch relies on
multiple input images that are closely related to each other.
The other branch only has one image as input.

1.1.1 Multiple Image Reﬂection Removal

The multiple images used for reﬂection removal are usu-
ally related to each other in certain aspects. For example,
Schechner et al. [16], Farid and Adelson [5], Kong et al. [9]
separate transmission and reﬂection layers by taking images
of objects at different angles through polarizers. Agrawal
et al. [1] use images taken with and without ﬂash to re-
duce reﬂection. Approaches based on different character-
istics of ﬁelds in transmission and reﬂection layers are also
proposed [6–8, 11, 18, 23]. Xue et al. [23] utilize the differ-
ence of motion ﬁelds to separate layers. Li and Brown [11]
use SIFT-ﬂow to align multiple images and separate lay-
ers according to the variation of gradient ﬁelds across im-
ages. Similarly, Han and Sim [8] extend this idea and com-
pute gradient reliability at each pixel and recover the trans-
mission gradients by solving a low-rank matrix completion
problem. Reﬂection removal using multiple images gener-
ally achieves better performance than that using a single im-
age since information across images can be exploited to im-
prove layer separation results. However, these approaches
usually requires special settings such as images taken from
certain angles and locations, or special devices such as po-
larizers and ﬂashes, which signiﬁcantly limit their practical-
ity.

convex and a large number of iterations is needed to achieve
desirable result. Other latest methods include deep learning
strategies (Fan et al. [4]), and nonlocal similar patch search
(Wan et al. [20]). However, either extra network training
time or external image datasets are required.

1.2. Our Contribution

In this paper, we propose an approach for single image
reﬂection suppression that achieves desirable performance
in terms of both efﬁciency and dereﬂection quality. Our
contribution is summarized as follows, which contribute to
the high efﬁciency of our approach:

• Our proposed model is convex. The solution is guar-

anteed to be the global optimal of the model.

• The optimal solution is in closed form and doesn’t rely
on iterative algorithms. It is obtained through solving
a partial differential equation, which can be done efﬁ-
ciently using Discrete Cosine Transform.

• Our method doesn’t require any external dataset or
training time as in the aforementioned neural network
approaches.

2. Our Proposed Model

2.1. Notations

Throughout the paper, we use bold letters such as T, Y,
K, f to denote matrices. Plain letters with subscripts Tm,n
denotes the element of T at the intersection of the m-th row
and the n-th column. Elementwise multiplication between
matrices is denoted by ◦ and convolution is denoted by ∗.

1.1.2 Single Image Reﬂection Removal

2.2. Model Formulation

On the other hand, several approaches have also been at-
tempted to remove reﬂection from a single input image. Al-
though a single input image is more likely to be encountered
in everyday life, it is in fact more challenging than multiple
image cases due to the lack of additional inter-image infor-
mation. Existing approaches rely on different prior assump-
tions on transmission and reﬂection layers. Levin and Weiss
[10] employ the gradient sparsity prior with user assisted
labels to distinguish between layers. Li and Brown [12] ex-
ploit the relative smoothness of different layers to separate
them using a probabilistic framework. Shih et al. [17] ex-
plore the removal of reﬂection from double-pane glass with
ghosting artifacts. Wan et al. [19] utilize multi-scale depth
of ﬁeld to classify edges into different layers.

Instead of separating layers, Arvanitopoulos et al. [2]
propose to suppress the reﬂection in a single input image us-
ing Laplacian-based data ﬁdelity term and gradient sparsity
prior, which achieves desirable quality of dereﬂection but
is not quite efﬁcient due to the fact that their model is non-

Our proposed model relies on the assumption that the
camera focuses on the transmission layer (i.e., the objects
behind the glass) so that sharp edges appear mostly in this
layer. On the other hand, the reﬂection layer (i.e., the reﬂec-
tion off the surface of the glass) is less in focus so that edges
in this layer are mostly weaker than those in the transmis-
sion layer. This is often true in real world scenarios since the
distance from the camera to the object in focus is different
from that to the glass. We formally express our assumption
using the following equation, as mentioned in [2]:

Y = wT + (1 − w)(κ ∗ R),

(2)

where Y is the input camera image, T is the transmission
layer and R is the reﬂection layer. w is a parameter that
measures the weight between the two layers. κ is a Gaussian
blurring kernel.

Our proposed model is inspired from [2], where the
original model minimizes the data ﬁdelity term kL(T) −
L(Y)k2
2 which is the difference on the edges between the

8142

(2a) Transmission layer

(2b) Reﬂection layer

a

a

(2c) Synthetic blend,
w = 0.7, σ = 2

(2d) [2], λ = 0.05.
Execution time: 382s

(2e) Proposed, h = 0.11.
Execution time: 0.63s

Figure 2: Comparison of the proposed model with [2] on a 2D synthetic toy example. The proposed model removes the reﬂection layer
content (i.e., the letter ‘R’) more thoroughly. It also retains more transmission layer texture content. The execution time (averaged over 20
repeated runs) of the proposed model is about 600 times faster than [2]. Image size 800 × 800. Texture images from [21].

output and input images (See Eq.(6) in [2]). The edge infor-
mation of an image is obtained by applying the Laplacian
operator L(·) . In addition, an l0 prior of the image gradient
k∇Tk0 is added to the objective function.
It encourages
smoothing of the image while maintaining the continuity
of large structures. The Laplacian-based data ﬁdelity term
better enforces consistency in structures of ﬁne details in
the transmission layer compared to a more straightforward
data ﬁdelity term1 kT − Yk2
2. The model in [2] removes
more gradients as the regularization parameter λ increases,
which is the consequence of using the l0 prior. Essentially,
it sets a threshold on the gradients of the input image and
removes the gradients whose magnitudes are larger than the
given threshold. The gradient-thresholding step appears as
a closed-form solution in each iteration of their algorithm
(See Eq.(12) in [2]). Similarly, we fuse this idea into our
model formulation, but in a different way. Rather than
solving the minimization problem and threshold the gradi-
ent from the solution, we adopt the idea from [13, 14] and
put the gradient-thresholding step directly into the objective
function. We hence propose the following model:

kL(T) − div(δh(∇Y))k2

2 +

ε
2

kT − Yk2
2,

(3)

min

T

1
2

where

L(Y) = ∇xx(Y) + ∇yy(Y),

Xi,j ,

if kXi,jk2 ≥ h

0,

otherwise

(4)

(5)

.

δh(Xi,j) =


The data ﬁdelity term kL(T)−div(δh(∇Y))k2
2 imposes the
gradient-thresholding step on the input image Y before tak-
ing the divergence of ∇Y. The gradients whose magnitudes
are less than h will become zero. Since the data ﬁdelity term

1The data ﬁdelity term kT − Yk2

2 combined with the l0 prior is used

in image smoothing. A detailed discussion can be found in [22].

2 kT − Yk2

only contains a second order term of the variable T, the sec-
ond term ε
2 is added to guarantee the uniqueness
of the solution (see Sec. 2.3 for details), where ε is taken to
be a very small value so as not to affect the performance of
the data ﬁdelity term.

Fig. 2 is a toy example demonstrating the effect of our
proposed model on synthetic images. We created the trans-
mission layer (Fig. 2a) consisting of a letter ‘T’ and back-
ground wooden grain texture. The reﬂection layer (Fig. 2b)
consists of a letter ‘R’ and the background sand beach tex-
ture. These two layers are then blended (Fig. 2c) accord-
ing to Eq.(2) with blending weight w = 0.7 and the stan-
dard deviation of the Gaussian blurring kernel κ is set to
σ = 2. We compare the result of [2] (Fig. 2d) with our
proposed model (Fig. 2e). As can be seen, our proposed
model outperforms [2] both in the quality of dereﬂection
and the execution time. Our proposed method removes the
letter ‘R’ in the reﬂection layer while largely preserves the
wooden grains in the transmission layer. In contrast, the ap-
proach in [2] doesn’t remove the letter ‘R’ as thoroughly as
ours and a lot more wooden grains are lost. Further increas-
ing the parameter λ in [2] will remove more of the letter
‘R’ but at the same time even more wooden grains will be
lost as well. In addition, the execution time of our proposed
model is much faster than the approach in [2].

2.3. Solving the Model

Unlike the model proposed in [2] which is non-convex
due to the presence of the k·k0 term, our proposed model (3)
is convex with respect to the target variable T. Therefore,
the optimal solution can be obtained by solving a system of
equations, which guarantees the optimality of the solution
and contributes to the fast execution time compared to iter-
ative methods that are common among existing approaches
(See Sec. 3 for details).

The gradient of the objective function (3) is given by

∇T = L(cid:16)L(T) − div(cid:0)δh(∇Y)(cid:1)(cid:17) + ε(T − Y).

(6)

8143

Let the gradient be zero, we obtain the following equation

3. Experiments

(cid:16)L2 + ε(cid:17)T = L(cid:16)div(δh(∇Y))(cid:17) + εY.

(7)

This equation is a variation of 2D Poisson’s equation. We
associate it with Neumann boundary condition since we
assume a mirror extension at the boundary of the image,
which implies zero gradient on the boundary. This bound-
ary value problem can hence be solved via Discrete Cosine
Transform (DCT). Let Fc, F −1
denote the two dimensional
DCT and its inverse. We introduce the following result

c

Theorem 2.1. The discretization of 2D Poisson’s equation

L(T) = f

(8)

with Neumann boundary condition on an M × N grid is
solved by

Tm,n = F −1

Km,n !,
c   [Fc(f )]m,n

(9)

where T, f , K ∈ RM ×N . Km,n = 2(cid:18) cos(cid:16) mπ
N (cid:17) − 2(cid:19). 0 ≤ m ≤ M − 1, 0 ≤ n ≤ N − 1.
cos(cid:16) nπ

M (cid:17) +

See [15] for a proof of this conclusion. Essentially it
says that after taking DCT, the left side of Eq.(8) becomes
elementwise multiplication, i.e., Fc(L(T)) = K ◦ Fc(T)
so the above conclusion follows.
It is worth mentioning
that the solution (9) has a singularity at (m, n) = (0, 0). To
guarantee a unique solution, extra condition (for example,
the value at T0,0) must be speciﬁed beforehand.

We apply Theorem 2.1 to solve Eq.(7). Notice that after

All experiments are implemented using MATLAB 2017a
on a PC with 8-core Intel i7-8550U 1.80GHz CPU and 16
GB memory. We compare our method with state-of-the-art
approaches Arvanitopoulos et al. [2], Li and Brown [12]
and Wan et al. [19]. These approaches are implemented
using the original MATLAB source code provided from
the authors. These approaches are selected for comparison
since only a single image is required as the input. Other
single image reﬂection removal approaches mentioned in
Sec. 1.1.2 either require external image datasets [4, 20] or
additional conditions (user labels [10], double-pane glass
and ghosting cues [17]). We use PSNR and SSIM (adopted
in [2]) together with execution time as metrics to evaluate
the performance of the selected approaches. The execution
times reported throughout this paper are all averaged over
20 repeated runs.

The parameter h in (3) represents the level of the gradi-
ent thresholding. The gradients whose magnitudes are less
than h will be smoothed out. Fig. 3 shows the effect of in-
creasing h. The larger h is, the more reﬂection components
and transmission layer details are removed. Similar to the
regularization parameter λ in [2]’s approach, the value of h
that produces the best visual result depends on the strength
of the reﬂection in each input image since the best visual
result is a balance between the preservation of transmission
details and the suppression of reﬂection. Typically, h val-
ues within the interval [0.01, 0.1] yield desirable results. As
will be demonstrated below, ﬁnding the best parameter h
for each image is almost instantaneous.

taking DCT on both sides, the equation becomes

3.1. Synthetic Images

(K ◦ K + εE) ◦ Fc(T) = Fc(P),

(10)

where P ∈ RM ×N denotes the right hand side of Eq.(7) and
E ∈ RM ×N is a matrix of all 1’s. Therefore, the solution to
Eq.(7) is

Tm,n = F −1

c   [Fc(P)]m,n
m,n + ε !,

K 2

(11)

where Km,n is the same as in Theorem 2.1. The unique-
ness of the solution is automatically guaranteed because of
the presence of ε in the denominator, which is the conse-
quence of adding the ε
2 term in Eq.(3). Our algorithm is
summarized as follows:

Algorithm 1 Image Reﬂection Suppression via Gradient
Thresholding and Solving PDE

Input: Y, h, ε

return Tm,n = F −1

m,n + ε !.
c   [Fc(P)]m,n

K 2

Output: T

We blend two pairs of images of size 512 × 512 pixels
in Fig. 4 according to the assumption (2), where Ti and
Ri, i = 1, 2 represent transmission and reﬂection layers,
respectively. The variance of the Gaussian blurring kernel
κ is ﬁxed to σ = 4 and two blending weights w = 0.7, 0.5
are used. For parameters in other models, we use the default
values as reported in their papers (λ = 100 in [12], λ = 0.4
in [19], λ = 0.002 in [2]). In our proposed model, we ﬁx
h = 0.03 and ε = 10−6.

The images before and after the reﬂection suppression
are demonstrated in Fig. 5. The method of Li and Brown
[12] tends to produce dark images with false colors. This
is partially due to the fact that the energy from the reﬂec-
tion layer accounts for a large portion in our synthetic im-
ages. Removing the reﬂection ends up with signiﬁcant en-
ergy loss and hence produces dark outputs. The method
of Wan et al. [19] removes most of the reﬂection but over-
smoothes transmission layer details (For example, top edge
of Lena’s hat in the mirror, bottom edge of the green pep-
per, especially in w = 0.5 cases (See Fig. 5h and Fig. 5r)).
Arvanitopoulos et al.’s approach [2] produces outputs that

8144

(3a) Input

(3b) h = 0.01

(3c) h = 0.02

(3d) h = 0.03

Figure 3: The effect of increasing the threshold parameter h in the proposed reﬂection suppression model.
removes more reﬂection as well as some details from the transmission layer. Best viewed on screen.

Increasing the parameter

rameter h is tuned for each input image for the same reason.
However, parameter tuning in our model is almost instanta-
neous, which will be demonstrated below. The parameter ε
is empirically ﬁxed to 10−8.

Table 3 demonstrates the advantage of the proposed
model in terms of the execution time. It is much faster com-
pared to other state-of-the-art algorithms.2 Typically it only
takes less than 1.5 seconds to output the dereﬂected images.
Moreover, the dereﬂection quality also outperforms other
methods as demonstrated in Fig. 6 (Notice the difference
in the zoomed-in boxes). Our proposed method not only
suppresses the reﬂection satisfactorily but also maintains as
much transmission details as possible. Being fast and ef-
fective, our proposed method has the potential of being im-
plemented directly on portable devices such as smartphones
and tablets. The high efﬁciency makes it possible for a mo-
bile device user to adjust the parameter h easily (for ex-
ample, via moving a slider on the phone screen) to get an
immediate response and select the best dereﬂected image
according to the user’s visual perception (See Fig. 7).

However, our model also has limitation when the model
assumption (2) is violated. If the reﬂection layer contains
sharp edges, the corresponding gradients at the edge pixels
will be large. Therefore, increasing the threshold param-
eter h won’t removed these reﬂection edges before losing
some gentle transmission layer details. Failure cases are
shown in Fig. 8, where none of the methods in compari-
son completely removes the reﬂection. That being said, our
proposed method still retains more details even if edges in
the transmission layer are not sharp enough, for example, in
dark images like Fig. 8e.

4. Conclusion and Future Work

We proposed an efﬁcient approach for single image re-
ﬂection suppression. It is formulated as a convex problem,
which is solved via gradient thresholding and solving a vari-
ation of 2D Poisson’s equation using DCT. We validated
the effectiveness and efﬁciency of our approach through ex-

2At such picture size, the approach in Wan et al. [19] reports out-of-

memory error, indicating that it is not suitable for large-sized images.

8145

(4a) T1

(4b) R1

(4c) T2

(4d) R2

Figure 4: Images used as transmission layers (T1, T2) and reﬂec-
tion layers (R1, R2) for the synthetic experiments. T1 is blended
with R1. T2 is blended with R2.

are the closest to our proposed method. However, as shown
in Table 1 and 2, our outputs achieve better performance
in terms of PSNR, SSIM and execution time in all cases.
Particularly, notice that the execution time of our method
outperforms all the others by a signiﬁcant margin.

3.2. Real World Images

The size of the real-world images used here are 1080 ×
1440 pixels. We captured these images directly using smart-
phone. Default parameter settings are used in the method of
Li and Brown [12]. As for the method of Arvanitopoulos
et al. [2], we tune the regularization parameter λ for each
input image to get the best visual result since the outcome
is much more sensitive to parameter tuning compared to Li
and Brown’s approach. In our proposed model (3), the pa-

(5a) T1 + R1, w = 0.7

(5b) [12]

(5c) [19]

(5d) [2]

(5e) Proposed

(5f) T1 + R1, w = 0.5

(5g) [12]

(5h) [19]

(5i) [2]

(5j) Proposed

(5k) T2 + R2, w = 0.7

(5l) [12]

(5m) [19]

(5n) [2]

(5o) Proposed

(5p) T2 + R2, w = 0.5

(5q) [12]

(5r) [19]

(5s) [2]

(5t) Proposed

Figure 5: Comparison of reﬂection suppression on synthetic images. Column 1: Blended images. Column 2: Li and Brown [12]’s results.
Column 3: Wan et al. [19]’s results. Column 4: Arvanitopoulos [2]’s results. Column 5: our proposed results. Best viewed on screen.

Table 1: Comparison of PSNR and SSIM of reﬂection suppression methods on synthetic images in Fig. 5. Image size: 512 × 512 pixels

Image

Fig. 5a
Fig. 5f
Fig. 5k
Fig. 5p

Li and Brown [12]
PSNR
16.08
13.46
16.64
13.55

SSIM
0.549
0.344
0.762
0.574

Wan et al. [19]
SSIM
PSNR
0.874
19.81
16.65
0.700
0.840
17.10
14.54
0.751

Arvanitopoulos et al. [2]

Proposed

PSNR
20.87
16.80
19.42
15.10

SSIM
0.896
0.716
0.896
0.787

PSNR
20.99
16.93
19.44
15.14

SSIM
0.903
0.736
0.897
0.789

periments on synthetic and real-world images.
It is able
to output desirable dereﬂected smartphone images in sec-
onds. However, single image reﬂection suppression remains
a challenging problem as there are still cases where current

approaches fail to completely remove the reﬂection. Future
work includes designing effective and efﬁcient algorithms
to handle sharp and strong reﬂections for large images.

8146

(6a) Input 1

(6b) [12]

(6c) [2],
λ = 0.01

(6d) Proposed,

h = 0.04

(6e) Input 2

(6f) [12]

(6g) [2],
λ = 0.005

(6h) Proposed,

h = 0.033

(6i) Input 3

(6j) [12]

(6k) [2],
λ = 0.01

(6l) Proposed,

h = 0.1

(6m) Input 4

(6n) [12]

(6o) [2],
λ = 0.002

(6p) Proposed,

h = 0.03

Figure 6: Comparison of reﬂection suppression methods on real-world images taken at various scenes. The method of Li and Brown [12]
yields images that appear darker than the original input. Some reﬂection edges are not completely removed (e.g. upper left corner in Fig.
6f and Fig. 6j). The method of Arvanitopoulos et al. [2] achieves better color reproduction but suffers from some loss of details in the
transmission layer (e.g. the top corner of the building in Fig. 7c, the vegetation in Fig. 6g, the disk on the glass in Fig. 6o). Our Proposed
method retains the most transmission layer details with superior reﬂection layer suppression among these methods. Best viewed on screen.

8147

Table 2: Execution times (sec) of reﬂection suppression meth-
ods on synthetic images in Fig. 5. Image size: 512 × 512 pixels

Table 3: Execution times (sec) of reﬂection suppression methods
on real-world images in Fig. 6. Image size: 1080 × 1440 pixels

Image
Fig. 5a
Fig. 5f
Fig. 5k
Fig. 5p

[12]
12.06
11.68
7.25
7.69

[19]
49.31
49.24
48.74
47.86

[2]

Proposed

185.32
185.82
185.51
185.83

0.19
0.18
0.19
0.19

Image
Input 1
Input 2
Input 3
Input 4

[12]
39.06
52.60
17.90
10.75

[2]

1044.28
1086.05
1032.28
1100.73

Proposed

1.46
1.36
1.40
1.15

(7a) h = 0.01

(7b) h = 0.03

(7c) h = 0.05

Figure 7: A slider demo simulated in MATLAB. As we move the slider to the right, the h value increases and the reﬂection is gradually
suppressed. The response time is less than 1.5 seconds for smartphone images of size 1080 × 1440. Best viewed on screen.

(8a) Input 1

(8b) [12]

(8c) [2],
λ = 0.002

(8d) Proposed,

h = 0.03

(8e) Input 2

(8f) [12]

(8g) [2],
λ = 0.002

(8h) Proposed,

h = 0.03

Figure 8: Failure cases of our proposed method. Failure is likely to occur when edges in the reﬂection layer are sharp and strong. This
limitation is also observed in the other two methods. In Row 1, the reﬂection of the ﬂuorescent lamps outside the room is almost as sharp
as the real ones inside, which makes it hard to distinguish between them. In Row 2, although our proposed method fails to completely
remove the reﬂection (the inside of a bus), it retains more transmission details than [2] as shown in the zoomed-in regions. The method
in [12] again produces dark outputs. Best viewed on screen.

8148

References

[1] A. Agrawal, R. Raskar, S. K. Nayar, and Y. Li. Remov-
ing photography artifacts using gradient projection and ﬂash-
exposure sampling. ACM Transactions on Graphics (TOG),
24(3):828–835, 2005. 2

[2] N. Arvanitopoulos Darginis, R. Achanta, and S. S¨usstrunk.
Single image reﬂection suppression.
In IEEE Conference
on Computer Vision and Pattern Recognition (CVPR 2017),
number EPFL-CONF-227363, 2017. 1, 2, 3, 4, 5, 7, 8, 9

[3] H. Barrow and J. Tenenbaum. Recovering intrinsic scene

characteristics. Comput. Vis. Syst, 2, 1978. 1

[4] Q. Fan, J. Yang, G. Hua, B. Chen, and D. Wipf. A generic
deep architecture for single image reﬂection removal and im-
age smoothing.
In Proceedings of the IEEE International
Conference on Computer Vision (ICCV), 2017. 2, 4

[5] H. Farid and E. H. Adelson. Separating reﬂections and light-
ing using independent components analysis.
In Computer
Vision and Pattern Recognition, 1999. IEEE Computer Soci-
ety Conference on., volume 1, pages 262–267. IEEE, 1999.
2

[6] K. Gai, Z. Shi, and C. Zhang. Blindly separating mixtures of
multiple layers with spatial shifts. In Computer Vision and
Pattern Recognition, 2008. CVPR 2008. IEEE Conference
on, pages 1–8. IEEE, 2008. 2

[7] X. Guo, X. Cao, and Y. Ma. Robust separation of reﬂec-
tion from multiple images. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
2187–2194, 2014. 2

[8] B.-J. Han and J.-Y. Sim. Reﬂection removal using low-rank
matrix completion. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), 2017.
2

[9] N. Kong, Y.-W. Tai, and J. S. Shin. A physically-based
approach to reﬂection separation: from physical modeling
to constrained optimization.
IEEE transactions on pattern
analysis and machine intelligence, 36(2):209–221, 2014. 2

[10] A. Levin and Y. Weiss. User assisted separation of reﬂec-
tions from a single image using a sparsity prior. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence, 29(9),
2007. 2, 4

[11] Y. Li and M. S. Brown. Exploiting reﬂection change for auto-
matic reﬂection removal. In Computer Vision (ICCV), 2013
IEEE International Conference on, pages 2432–2439. IEEE,
2013. 2

[12] Y. Li and M. S. Brown. Single image layer separation using
relative smoothness. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 2752–
2759, 2014. 2, 4, 5, 7, 8, 9

[13] W. Ma, J. M. Morel, S. Osher, and A. Chien. An l1-based
variational model for retinex theory and its applications to
medical images. In CVPR, 2011. 3

[14] W. Ma and S. Osher. A tv bregman iterative model of retinex
theory. Inverse Problem and Imaging, 6(4):697–708, 2012.
3

[15] W. H. Press. Numerical recipes 3rd edition: The art of sci-

entiﬁc computing. Cambridge university press, 2007. 4

[16] Y. Y. Schechner, J. Shamir, and N. Kiryati. Polarization-
based decorrelation of transparent layers: The inclination an-
gle of an invisible surface. In Computer Vision, 1999. The
Proceedings of the Seventh IEEE International Conference
on, volume 2, pages 814–819. IEEE, 1999. 2

[17] Y. Shih, D. Krishnan, F. Durand, and W. T. Freeman. Re-
ﬂection removal using ghosting cues. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 3193–3201, 2015. 2, 4

[18] C. Sun, S. Liu, T. Yang, B. Zeng, Z. Wang, and G. Liu. Auto-
matic reﬂection removal using gradient intensity and motion
cues. In Proceedings of the 2016 ACM on Multimedia Con-
ference, pages 466–470. ACM, 2016. 2

[19] R. Wan, B. Shi, T. A. Hwee, and A. C. Kot. Depth of
ﬁeld guided reﬂection removal. In Image Processing (ICIP),
2016 IEEE International Conference on, pages 21–25. IEEE,
2016. 2, 4, 5, 7, 9

[20] R. Wan, B. Shi, A.-H. Tan, and A. C. Kot. Sparsity based re-
ﬂection removal using external patch search. In Multimedia
and Expo (ICME), 2017 IEEE International Conference on,
pages 1500–1505. IEEE, 2017. 2, 4

[21] A. G. Weber. The usc-sipi image database version 5. USC-

SIPI Report, 315:1–24, 1997. 3

[22] L. Xu, C. Lu, Y. Xu, and J. Jia.

Image smoothing via l0
In ACM Transactions on Graphics

gradient minimization.
(TOG), volume 30, page 174. ACM, 2011. 3

[23] T. Xue, M. Rubinstein, C. Liu, and W. T. Freeman. A com-
putational approach for obstruction-free photography. ACM
Transactions on Graphics (TOG), 34(4):79, 2015. 2

8149

