GeoNet: Deep Geodesic Networks for Point Cloud Analysis

Tong He1, Haibin Huang2

,†, Li Yi3, Yuqian Zhou4, Chihao Wu2, Jue Wang2, Stefano Soatto1

1UCLA 2Megvii (Face++)

3Stanford 4UIUC †Corresponding Author

Abstract

Surface-based geodesic topology provides strong cues
for object semantic analysis and geometric modeling. How-
ever, such connectivity information is lost in point clouds.
Thus we introduce GeoNet, the ﬁrst deep learning archi-
tecture trained to model the intrinsic structure of surfaces
represented as point clouds. To demonstrate the applica-
bility of learned geodesic-aware representations, we pro-
pose fusion schemes which use GeoNet in conjunction with
other baseline or backbone networks, such as PU-Net and
PointNet++, for down-stream point cloud analysis. Our
method improves the state-of-the-art on multiple represen-
tative tasks that can beneﬁt from understandings of the un-
derlying surface topology, including point upsampling, nor-
mal estimation, mesh reconstruction and non-rigid shape
classiﬁcation.

1. Introduction

Determining neighborhood relationship among points in a
point cloud, known as topology estimation, is an important
problem since it indicates the underlying point cloud struc-
ture, which could further reveal the point cloud semantics
and functionality. Consider the red inset in Fig. 1: the two
clusters of points, though seemingly disconnected, should
indeed be connected to form a chair leg, which supports the
whole chair. On the other hand, the points on opposite sides
of a chair seat, though spatially very close to each other,
should not be connected to avoid confusing the sittable up-
per surface with the unsittable lower side. Determining such
topology appears to be a very low-level endeavor but in real-
ity it requires global, high-level knowledge, making it a very
challenging task. Still, from the red inset in Fig. 1, we could
draw the conclusion that the two stumps are connected only
after we learn statistical regularities from a large number
of point clouds and observe many objects of this type with
connected elongated vertical elements extending from the
body to the ground. This motivates us to adopt a learning
approach to capture the topological structure within point
clouds.

Figure 1. Our method takes a point cloud as input, and outputs rep-
resentations used for multiple tasks including upsampling, normal
estimation, mesh reconstruction, and shape classiﬁcation.

lying surface topology as well as object geometry, and pro-
pose methods that leverage the learned topological features
for geodesic-aware point cloud analysis. The representa-
tion should capture various topological patterns of a point
cloud and the method of leveraging these geodesic features
should not alter the data stream, so our representation can
be learned jointly and used in conjunction with the state-of-
the-art baseline or backbone models (e.g. PU-Net, Point-
Net++ [45, 32, 33, 7]) that feed the raw data through, with
no information loss to further stages of processing.

For the ﬁrst goal, we propose a geodesic neighborhood
estimation network (GeoNet) to learn deep geodesic repre-
sentations using the ground truth geodesic distance as su-
pervision signals. As illustrated in Fig. 2, GeoNet consists
of two modules: an autoencoder that extracts a feature vec-
tor for each point and a geodesic matching (GM) layer that
acts as a learned kernel function for estimating geodesic
neighborhoods using the latent features. Due to the super-
vised geodesic training process, intermediates features of
the GM layer contain rich information of the point cloud
topology and intrinsic surface attributes. We note that the
representation, while trained on geodesic distances, does
not by construction produce geodesics (e.g. symmetry, tri-
angle inequality, etc.). The goal of the representation is to
inform subsequent stages of processing of the global geom-
etry and topology, and is not to conduct metric computa-
tions directly.

Our primary goals in this paper are to develop represen-
tations of point cloud data that are informed by the under-

For the second task, as shown in Fig. 3, we propose
geodesic fusion schemes to integrate GeoNet into the state-

16888

of-the-art network architectures designed for different tasks.
Speciﬁcally, we present PU-Net fusion (PUF) for point
cloud upsampling, and PointNet++ fusion (POF) for normal
estimation, mesh reconstruction as well as non-rigid shape
classiﬁcation. Through experiments, we demonstrate that
the learned geodesic representations from GeoNet are bene-
ﬁcial for both geometric and semantic point cloud analyses.
In summary, in this paper we propose an approach for
learning deep geodesic-aware representations from point
clouds and leverage the results for various point set anal-
yses. Our contributions are:

• We present, to the best of our knowledge, the ﬁrst deep
learning method, GeoNet, that ingests point clouds and
learns representations which are informed by the in-
trinsic structure of the underlying point set surfaces.

• To demonstrate the applicability of learned geodesic
representations, we develop network fusion architec-
tures that incorporate GeoNet with baseline or back-
bone networks for geodesic-aware point set analysis.

• Our geodesic fusion methods are benchmarked on
multiple geometric and semantic point set tasks using
standard datasets and outperform the state-of-the-art
methods.

2. Related work

We assume our input is a point cloud, which can be ob-
tained by multiple-view geometry, single image depth esti-
mation [29, 20, 15, 38, 12] or collected from various sensors
(e.g. depth camera, Lidar, etc.). We mainly review tradi-
tional graph-based methods for geodesic distance compu-
tation, as well as general works on point cloud upsampling,
normal estimation, and non-rigid shape classiﬁcation, as we
are unaware of other prior works on point cloud-based deep
geodesic representation learning.

Geodesic distance computation. There are two types
of methods: some allow the path to traverse mesh faces [35,
31, 6, 14, 37, 41, 8] for accurate geodesic distance compu-
tation, while others ﬁnd approximate solutions via shortest
path algorithms constrained on graph edges [11, 13, 23].
For the ﬁrst type, an early method [35] suggests a polyno-
mial algorithm of time O(n3logn) where n is the number
of edges, but their method is restricted to a convex poly-
tope. Based on Dijkstra’s algorithm [11], [31] improves
the time complexity to O(n2logn) and extends the method
to an arbitrary polyhedral surface. Later, [6] proposes an
O(n2) approach using a set of windows on the polyhedron
edges to encode the structure of the shortest path set. By
ﬁltering out useless windows, [41] further speeds up the al-
gorithm. Then [8] introduces a heat method via solving a
pair of standard linear elliptic problems. As for graph edge-
based methods, typical solutions include Dijkstra’s [11],

Floyd-Warshall [13] and Johnson’s algorithms [23], which
have much lower time complexity than the surface travers-
ing methods. For a 20000-vertex mesh, computing its all-
pair geodesic distances can take several days using [41]
while [23] only uses about 1 minute on CPU. When a mesh
is dense, the edge-constrained shortest path methods gen-
erate low-error geodesic estimates. Thus in our work, we
apply [23] to compute the ground truth geodesic distance.

Point upsampling. Previous methods can be summa-
rized into two categories.
i) Optimization based meth-
ods [1, 27, 22], championed by [1], which interpolates a
dense point set from vertices of a Voronoi diagram in the
local tangent space. Then [27] proposes a locally opti-
mal projection (LOP) operator for point cloud resampling
and mesh reconstruction leveraging an L1 median. For im-
proving robustness to point cloud density variations, [22]
presents a weighted LOP. These methods all make strong
assumptions, such as surface smoothness, and are not data-
driven, and therefore have limited applications in practice.
ii) Deep learning based methods. To apply the (graph) con-
volution operation, many of those methods ﬁrst voxelize
a point cloud into regular volumetric grids [40, 39, 19, 9]
or instead use a mesh [10, 44]. While voxelization intro-
duces discretization artifacts and generates low resolution
voxels for computational efﬁciency, mesh data can not be
trivially reconstructed from a sparse and noisy point cloud.
In [43, 42] a sparse point cloud is reprojected onto a range
map and modeled as a 2.5D inpanting problem. To directly
upsample a 3D point cloud, PU-Net [45] learns multilevel
features for each point and expands the point set via a multi-
branch convolution unit implicitly in feature space. But PU-
Net is based on Euclidean space and thus does not leverage
the underlying point cloud surface attributes in geodesic
space, which we show in this paper are important for up-
sampling.

Normal estimation. A widely used method for point
cloud normal estimation is to analyze the variance in a tan-
gential plane of a point and ﬁnd the minimal variance direc-
tion by Principal Component Analysis (PCA) [21, 24]. But
this method is sensitive to the choice of the neighborhood
size, namely, large regions can cause over-smoothed sur-
faces and small ones are sensitive to noises. To improve ro-
bustness, [16, 4, 2] propose to ﬁt higher-order shapes. How-
ever, methods described above all require careful parameter
tuning at the inference time and only estimate normal orien-
tation up to sign. Thus, so far robust estimation for oriented
normal vectors using traditional methods is still challeng-
ing, especially across different noise levels and shape struc-
tures. There are only few data-driven methods that are able
to integrate normal estimation and orientation alignment
into a uniﬁed pipeline [17, 33]. They take a point cloud as
input and directly regress oriented normal vectors, but these
methods are not designed to learn geodesic topology-based

6889

Figure 2. GeoNet: geodesic neighborhood estimation network.

representations that capture the intrinsic surface features for
better normal estimation.

Non-rigid shape classiﬁcation. Classifying the point
cloud of non-rigid objects often consists of two steps: ex-
tracting intrinsic features in geodesic space and applying a
classiﬁer (e.g. SVM, MLP, etc.). Some commonly used
features include wave kernel signatures [3], heat kernel sig-
natures [36], spectral graph wavelet signatures [30], Shape-
DNA [34], etc. For example, DeepGM [28] uses geodesic
moments and stacked sparse autoencoders to classify non-
rigid shapes, such as cat, horse, spider, etc. The geodesic
moments are feature vectors derived from the integral of
the geodesic distance on a shape, while stacked sparse au-
toencoders are deep neural networks consisting of multiple
layers of sparse autoencoders. However, the above methods
all require knowing graph-based data, which is not avail-
able from widely used sensors (e.g. depth camera, Lidar,
etc.) for 3D data acquisition. Though PointNet++ [33] is
able to directly ingest a point cloud and conduct classiﬁca-
tion, it is not designed to model the geodesic topology of
non-rigid shapes and thus its performance is inferior to tra-
ditional two-step methods which heavily reply on the ofﬂine
computed intrinsic surface features.

3. Method

3.1. Problem Statement

χ = {xi} denotes a point set with xi ∈ Rd and
i = 1, . . . , N . Although the problem and the method de-
veloped are general, we focus on the case d = 3 using
only Euclidean coordinates as input. A neighborhood sub-
set within radius r from a point xi is denoted Br(xi) =
{xj|dE(xi, xj) ≤ r} where dE(xi, xj) ∈ R is the Eu-
clidean (embedding) distance between xi and xj . The cardi-
nality of Br(xi) is K. The corresponding geodesic distance
set around xi is called Gr(xi) = {gij = dG(xi, xj)|xj ∈
Br(xi)} where dG ∈ R means the geodesic distance. Our
goal is to learn a function f : xi
7→ Gr(xi) that maps
each point to (an approximation of) the geodesic distance
set Gr(xi) around it.

3.2. Method

We introduce GeoNet, a network trained to learn the
function f deﬁned above.
It consists of an autoencoder
with skip connections, followed by a multi-scale Geodesic

Matching (GM) layer,
leveraging latent space features
{ψ(xi)} ⊆ R3+C of the point set. GeoNet is trained
in a supervised manner using ground truth geodesic dis-
tances between points in the set χ. To demonstrate the ap-
plicability of learned deep geodesic-aware representations
from GeoNet, we test our approach on typical tasks that
require understandings of the underlying surface topology,
including point cloud upsampling, surface normal estima-
tion, mesh reconstruction, and non-rigid shape classiﬁca-
tion. To this end, we leverage the existing state-of-the-
art network architectures designed for the aforementioned
problems. Speciﬁcally, we choose PU-Net as the base-
line network for point upsampling and PointNet++ for other
tasks. The proposed geodesic fusion methods, called PU-
Net fusion (PUF) and PointNet++ fusion (POF), integrate
GeoNet with the baseline or backbone models to conduct
geodesic-aware point set analysis.

3.3. Geodesic Neighborhood Estimation

As illustrated in Fig. 2, GeoNet consists of two modules:
an autoencoder that extracts a feature vector ψ(xi) for each
point xi ∈ χ and a GM layer that acts as a learned geodesic
kernel function for estimating Gr(xi) using the latent fea-
tures.

Feature Extraction. We use a variant of PointNet++,
which is a point set based hierarchical and multi-scale func-
It maps an input point set χ
tion, for feature extraction.

to a feature set {ϕ(xi)|xi ∈ eχ} where ϕ(xi) ∈ R3+ eC is
a concatenation of the xyz coordinates and the eC dimen-
sional embedding of xi, and eχ is a sampled subset of χ by
farthest-point sampling. To recover features {ψ(xi)} for the
point cloud χ, we use a decoder with skip connections. The
decoder consists of recursively applied tri-linear feature in-
terpolators, shared fully connected (FC) layers, ReLU and
Batch Normalization. The resulting (N, 3 + C) tensor is
then fed into the GM layer for geodesic neighborhood esti-
mation.

Geodesic Matching. We group the latent features ψ(xi)
into neighborhood feature sets Frl (xi) = {ψ(xj)|xj ∈
Brl (xi)}, under multiple radius scales rl. At each scale
rl we set a maximum number of neighborhood points Kl,
and thus produce a tensor of dimension (N, Kl, 3+C). The
grouped features, together with the latent features, are sent
to a geodesic matching module, where ψ(xi) is concate-
nated with ψ(xj) for every xj ∈ Brl (xi). The resulting

6890

Figure 3. PU-Net (top) and PointNet++ (bottom) geodesic fusion architectures.

feature ξij ∈ R3+2C becomes the input to a set of shared
FC layers with ReLU, Batch Normalization and Dropout.
As demonstrated in [18], the multilayer perceptron (MLP)
acts as a kernel function that maps ξij to an approxima-
tion of the geodesic distance, ˆgij . Finally, the GM layer
yields Grl (xi) for each point of the input point cloud χ. We
use a multi-scale L1 loss Lgeo = Pl Lgeol to compare the

ground truth geodesic distances to their estimates:

Lgeol = X

X

xi∈χ

xj ∈Brl (xi)

|gij − ˆg(xi, xj)|

N Kl

(1)

3.4. Geodesic Fusion

To demonstrate how the learned geodesic representations
can be used for point set analysis, we propose fusion meth-
ods based on the state-of-the-art (SOTA) network archi-
tectures for different tasks. For example, PU-Net is the
SOTA upsampling method and thus we propose PUF that
uses PU-Net as the baseline network to conduct geodesic
fusion for point cloud upsampling. With connectivity infor-
mation provided by the estimated geodesic neighborhoods,
our geodesic-fused upsampling network can better recover
topological details, such as curves and sharp structures, than
PU-Net. We also present POF leveraging PointNet++ as the
fusion backbone, and demonstrate its effectiveness on both
geometric and semantic tasks where PointNet++ shows the
state-of-the-art performance.

PU-Net Geodesic Fusion. A PUF layer, as illustrated
in Fig. 3 (top), takes a (N, d) point set as input and sends
it into two branches: one is a multi-scale Euclidean group-
ing layer, and the other is GeoNet. At each neighborhood
scale rl, the grouped point set Brl (xi) is fused with the es-
timated geodesic neighborhood Grl (xi) to yield Srl (xi) =

{(xj, gij)|xj ∈ Brl (xi)} with (xj, gij) ∈ Rd+1. Then the
(N, Kl, d + 1) fused tensor is fed to a PointNet to generate
a (N, Cl) feature tensor which will be stacked with features
from other neighborhood scales. The remaining layers are
from PU-Net. As indicated by the red rectangles in Fig. 3,
the total loss has two weighted terms:

L = Lgeo + λLtask

(2)

where Lgeo is for GeoNet training (1), λ is a weight and
Ltask, in general, is the loss for the current task that we are
targeting. In this case, the goal is point cloud upsampling:
Ltask = Lup(θ) where θ indicates network parameters.
PUF upsampling takes a randomly distributed sparse point
set χ as input and generates a uniformly distributed dense
point cloud ˆP ⊆ R3. The upsampling factor is α = |P |
|χ| :

Lup(θ) = LEM D(P, ˆP ) + λ1Lrep( ˆP ) + λ2 kθk2

(3)

in which the ﬁrst term is the Earth Mover Distance (EMD)
between the upsampled point set ˆP and the ground truth
dense point cloud P :

LEM D(P, ˆP ) = min
φ: ˆP →P

X

pi∈ ˆP

kpi − φ(pi)k2

(4)

where φ : ˆP → P indicates a bijection mapping.

The second term in (3) is a repulsion loss which pro-
motes a uniform spatial distribution for ˆP by penalizing
close point pairs:

Lrep( ˆP ) = X

X

pi∈ ˆP

pj ∈ ePi

η(kpi − pjk)ω(kpi − pjk)

(5)

6891

Figure 4. Representative results of geodesic neighborhood estimation. Red dots indicate the reference point and stars represent target points
selected for the purpose of illustration. Points in dark-purple are closer to the reference point than those in bright-yellow. Shortest paths
between the reference point and the target point in euclidean space are colored in sky-blue. Topology-based geodesic paths are in pink.

where ePi is a set of k-nearest neighbors of pi, η(r) = −r
penalizes close pairs (pi, pj), and ω(r) = e−r2/h2
decaying weight function with some constant h [22, 27].

is a fast-

PointNet++ Geodesic Fusion. Fig. 3 (bottom) illus-
trates the PointNet++ based fusion pipeline. Due to task
as well as architecture differences between PU-Net and
PointNet++, we make following changes to PUF to de-
sign a suitable fusion strategy that leverages PointNet++.
First, for multi-scale grouping, we use the learned geodesic
neighborhoods ˆGr(xi) instead of Euclidean ones. Geodesic
grouping brings attention to the underlying surfaces as well
as structures of the point cloud. Second, while the PUF
layer fuses estimated ˆGr(xi) = {ˆgij = ˆdG(xi, xj)|xj ∈
Br(xi)}, where ˆgij ∈ R, of each neighborhood point set
Br(xi) into the backbone network, the POF layer uses the
eC extracted from the
latent geodesic-aware features eξij ∈ R
second-to-last FC layer in GeoNet. Namely, eξij is an inter-
mediate high-dimensional feature vector from ξij to ˆgij via
FC layers, and therefore it is better informed of the intrin-
sic point cloud topology. Third, in PointNet++ fusion we
apply the POF layer in a hierarchical manner, leveraging
farthest-point sampling. Thus, the learned features encode
both local and global structural information of the point set.
The total loss for POF also has two parts: One is for GeoNet
training and the other is for the task-at-hand. We experiment
on representative tasks that can beneﬁt from understandings
of the topological surface attributes. We use the L1 error for
point cloud normal estimation:

Lnormal = X

3X

xi∈χ

j=1

i − ˆn(xi)(j)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)n(j)

3N

(6)

v1

v2

v3

r 6 0.1
r 6 0.2
r 6 0.4
r 6 0.1
r 6 0.2
r 6 0.4
r 6 0.1
r 6 0.2
r 6 0.4

K-3
8.75
16.22
15.15

11.71
19.22
21.03

13.28
14.85
13.48

K-6
8.97
17.33
16.80

11.49
17.76
17.19

14.23
17.27
16.10

K-12
9.04
17.90
17.88

11.55
18.28
18.20

14.62
18.54
17.72

Euc
9.06
18.16
18.95

11.57
18.56
19.44

14.78
19.49
19.68

GeoNet

5.67
9.25
9.75

7.06
9.74
10.04

10.86
13.61
14.73

Table 1. Neighborhood geodesic distance estimation MSE (x100)
on the heldout ShapeNet training-category samples. We com-
pare with KNN-Graph based shortest path methods under different
choices of K values. Euc represents the difference between Eu-
clidean distance and geodesic distance. MSE(s) are reported under
multiple radius ranges r. v1 takes uniformly distributed point sets
with 512 points as input, and v2 uses randomly distributed point
clouds. v3 is tested using point clouds that have 2048 uniformly
distributed points.

v1

v2

v3

r 6 0.1
r 6 0.2
r 6 0.1
r 6 0.2
r 6 0.1
r 6 0.2

K-3
8.81
11.84

10.52
15.02

11.82
11.80

K-6
9.01
12.88

10.21
12.99

12.39
12.84

K-12
9.05
13.49

10.25
13.59

12.65
13.55

Euc
9.06
13.75

10.26
13.86

12.75
14.50

GeoNet

7.52
11.44

8.94
11.69

10.88
12.26

Table 2. Geodesic neighborhood estimation MSE (x100) on the
leftout ShapeNet categories. v1 takes uniformly distributed point
sets with 512 points as input, and v2 uses randomly distributed
point clouds. v3 is tested using point clouds that have 2048 uni-
formly distributed points.

reconstruction [25]. To classify point clouds of non-rigid
objects, we use cross-entropy loss:

in which ni ∈ R3 is the ground truth unit normal vector of
xi, and ˆn(xi) ∈ R3 is the estimated normal. We then use
the normal estimation to generate mesh via Poisson surface

Lcls = −

SX

c=1

yclog(pc(χ))

(7)

6892

Figure 5. Point cloud upsampling comparisons with PU-Net. The input point clouds have 512 points with random distributions and the
upsampled point clouds have 2048 points. Red insets show details of the corresponding dashed region in the reconstruction.

where S is the number of non-rigid object categories, and c
is class label; yc ∈ {0, 1} is a binary indicator, which takes
value 1 if class label c is ground truth for the input point set.
pc(χ) ∈ R is the predicted probability w.r.t. class c of the
input point set.

3.5. Implementation

For GeoNet training, the multiscale loss Lgeol is en-
forced at three radius ranges: 0.1, 0.2 and 0.4. We use
Adam [26] with learning rate 0.001 and batchsize 3 for 8
epochs. To train the geodesic fusion networks, we set the
task term weight λ as 1, and use Adam with learning rate
0.0001 and batchsize 2 for around 300 to 1500 epochs de-
pending on the task and the dataset. Source code in Tensor-
ﬂow will be made available upon completion of the anony-
mous review process.

4. Experiments

We put GeoNet to the test by estimating point cloud
geodesic neighborhoods. To demonstrate the applicabil-
ity of learned deep geodesic-aware representations, we also
conduct experiments on down-stream point cloud tasks such
as point upsampling, normal estimation, mesh reconstruc-
tion and non-rigid shape classiﬁcation.

4.1. Geodesic Neighborhood Estimation

In Tab. 1 (v1) we show geodesic distance set, Gr(xi),
estimation results on the ShapeNet dataset [5] using point
clouds with 512 uniformly distributed points. Mean-
squared errors (MSE) are reported under multiple radius
scales r w.r.t. xi ∈ χ. GeoNet demonstrates consistent
improvement over the baselines. Representative results are
visualized in Fig. 4. Our method captures various topologi-
cal patterns, such as curved surfaces, layered structures, in-
ner/outer parts, etc.

Figure 6. Top-k mean square error (MSE) of upsampled points that
have large errors, for both the heldout training-category samples
(red) and the leftout ShapeNet categories (green).

Training

Leftout

PU-Net

PUF

PU-Net

PUF

MSE
7.14
6.23

12.38
9.55

EMD CD
2.72
8.06
7.62
2.46

11.43
8.90

3.98
3.27

Table 3. Point cloud upsampling results on both the heldout
training-category samples and the unseen ShapeNet categories.
MSE(s) (x10000) are scaled for better visualization.

Generality. We test GeoNet’s robustness under different
point set distributions and sizes. In Tab. 1 (v2) we use point
clouds with 512 randomly distributed points as input. We
also test on dense point sets that contain 2048 uniformly
distributed points in Tab. 1 (v3). Our results are robust to
different point set distributions as well as sizes. To show the
generalization performance, in Tab. 2 we report results on
the leftout ShapeNet categories. Our method performs bet-
ter on unseen categories, while KNN-Graph based shortest
path approaches suffer from point set distribution random-
ness, density changes and unsuitable choices of K values.

6893

Figure 7. Mesh reconstruction results on the Shrec15 (left) and the ShapeNet (right) datasets using the estimated normal by PointNet++
and our method POF. GT presents mesh reconstructed via the ground truth normal. We also visualize POF normal estimation in the fourth
and the last columns.

Figure 8. Point set normal estimation errors. Blue indicates small
errors and red is for large ones.

PCA

PointNet++

POF

6 2.5◦
6.16±0.01
12.81±0.18
16.26±0.30

6 5◦

14.85±0.02
33.37±0.92
39.02±1.09

6 10◦

27.16±0.17
61.58±2.02
66.98±1.46

6 15◦

34.17±0.28
75.49±1.95
79.66±1.21

Table 4. Point cloud normal estimation accuracy (%) on the
Shrec15 dataset under multiple angle thresholds.

PCA

Training

PointNet++

POF

PCA

Leftout

PointNet++

POF

6 2.5◦ 6 5◦ 6 10◦ 6 15◦
24.82
62.30
63.62

5.33
30.68
32.04

10.11
43.19
45.02

18.52
55.91
57.52

5.24
17.35
19.13

10.59
28.82
31.83

18.99
43.26
46.22

25.17
51.17
53.78

Table 5. Point cloud normal estimation accuracy (%) on the
ShapeNet dataset for both heldout training-category samples and
leftout categories.

4.2. Point Cloud Upsampling

We test PUF on point cloud upsampling and present re-
sults in Tab. 3. We compare against the state-of-the-art point
set upsampling method PU-Net on three metrics: MSE,
EMD as well as the Chamfer Distance (CD). Our method
outperforms the baseline under all metrics by 9.25% av-

erage improvement on the heldout training-category sam-
ples. Since geodesic neighborhoods are better informed of
the underlying point set topology than Euclidean ones, PUF
upsampling produces less outliers and recovers more details
in Fig. 5, such as curves and sharp structures.

Generality. To analyze outlier robustness (i.e. points
with large reconstruction errors), we plot top-k MSE in
Fig. 6. Our method generates fewer outliers on both the
heldout training-category samples and the unseen cate-
gories. We also report quantitative results on the leftout
categories in Tab. 3. Again, PUF signiﬁcantly surpasses the
state-of-the-art upsampling method PU-Net under three dif-
ferent evaluation metrics.

4.3. Normal Estimation and Mesh Reconstruction

For normal estimation we apply PointNet++ geodesic fu-
sion, POF, then we conduct Poisson mesh reconstruction
leveraging the estimated normals. Quantitative results for
normal estimation on the Shrec15 dataset and the ShapeNet
dataset are given in Tab. 4 and Tab. 5, respectively. We com-
pare our method with the traditional PCA algorithm as well
as the state-of-the-art deep learning method PointNet++.
Our results outperform the baselines by around 10% rela-
tive improvement. In Fig. 8, we visualize typical normal
estimation errors, showing that PointNet++ usually fails at
high-curvature and complex-surface regions. For further ev-
idence, we visualize Poisson mesh reconstruction in Fig. 7
using the estimated normals.

Generality. In Tab. 5 we evaluate normal estimation per-
formance on the leftout ShapeNet categories. Our method
has higher accuracy over competing methods under multi-
ple angle thresholds. Though trained with point clouds of
2048 points, POF is also tested on denser input. In Fig. 9
we take point clouds with 8192 points as input, and visual-
ize the normal estimation and mesh reconstruction results,
which shows that our method generalizes to dense point

6894

Figure 9. Normal estimation and Poisson mesh reconstruction re-
sults by POF using dense point clouds with 8192 points.

Input feature

Accuracy (%)

PointNet++

POF

XYZ
XYZ

DeepGM Intrinsic features

73.56
94.67

93.03

Table 6. Point cloud classiﬁcation of non-rigid shapes on the
Shrec15 dataset.

Gaussian Noise Level

PointNet++

POF

0.8% 0.9% 1.0% 1.1% 1.2%
62.38
70.54
91.89
84.98

69.27
90.93

67.83
89.40

65.66
87.72

Table 7. Noisy point clouds classiﬁcation accuracy (%). We add
Gaussian noise of 0.8% to 1.2% of unit ball radius.

clouds without re-training and produces ﬁne-scaled mesh.

4.4. Non rigid Shape Classiﬁcation

Results of non-rigid shape classiﬁcation are reported in
Tab. 6. While POF and PointNet++ only take point cloud-
based xyz Euclidean coordinates as input, DeepGM re-
quires ofﬂine computed intrinsic features from mesh data in
the ground truth geodesic metric space. Though using less
informative data, our method has higher classiﬁcation ac-
curacy than other methods, which further demonstrates that
the proposed geodesic fusion architecture, POF, is suitable
for solving tasks that require understandings of the underly-
ing point cloud surface attributes.

Generality. We add Gaussian noise of different lev-
els to the input and conduct noisy point clouds classiﬁca-
tion. Comparisons are shown in Tab. 7. POF outperforms
PointNet++ under several noise levels. Our method also
demonstrates better noise robustness.
It shows a 10.24%
decrease in relative accuracy at the maximum noise level,
while PointNet++ decreases by up to 15.20%.

4.5. Failure Modes

Failure cases of geodesic neighborhood estimation are
shown in Fig. 10. Due to large ratios between length and
width/height, after normalizing a stick-shaped object (e.g.

Figure 10. Failure cases of geodesic neighborhood estimation for
stick-shaped objects (e.g.
rocket, knife, etc.) which have large
ratios between length and width/height. Red dots indicate the ref-
erence point. Points in dark-purple are closer to the reference point
than those in bright-yellow.

rocket, knife, etc.)
into a unit ball we need high preci-
sion small values to represent its point-pair geodesic dis-
tance along the width/height sides. Since stick-shaped ob-
jects like rocket and knife only take up a small portion of
the training data, GeoNet tends to make mistakes for held-
out samples from these categories at inference time. Us-
ing an anistropic normalization might alleviate this issue but
is challenging in practice as the principal directions would
have to be estimated. We have not found additional failure
cases, and quantitative improvements continue to take effect
due to rich surface-based topological information learned
during the geodesic-supervised training process.

5. Conclusion

We have presented GeoNet, a novel deep learning archi-
tecture to learn the geodesic space-based topological struc-
ture of point clouds. The training process is supervised by
the ground truth geodesic distance and therefore the learned
representations reﬂect the intrinsic structure of the underly-
ing point set surfaces. To demonstrate the applicability of
such a topology estimation network, we also propose fusion
methods to incorporate GeoNet into computational schemes
that involve the standard backbone architectures for point
cloud analysis. Our method is tested on both geometric and
semantic tasks and outperforms the state-of-the-art meth-
ods, including point upsampling, normal estimation, mesh
reconstruction and non-rigid shape classiﬁcation. For future
works we will move on to complicated scenes where a mesh
might need to be approximated for supervision.

Acknowledgment

Research supported by ONR N00014-17-1-2072,

N00014-13-1-034 and ARO W911NF-17-1-0304.

6895

References

[1] M. Alexa, J. Behr, D. Cohen-Or, S. Fleishman, D. Levin,
and C. T. Silva. Computing and rendering point set surfaces.
IEEE Transactions on visualization and computer graphics,
9(1):3–15, 2003. 2

[2] N. Amenta and M. Bern. Surface reconstruction by voronoi
ﬁltering. Discrete & Computational Geometry, 22(4):481–
504, 1999. 2

[3] M. Aubry, U. Schlickewei, and D. Cremers. The wave kernel
signature: A quantum mechanical approach to shape analy-
sis. In Computer Vision Workshops (ICCV Workshops), 2011
IEEE International Conference on, pages 1626–1633. IEEE,
2011. 3

[4] F. Cazals and M. Pouget. Estimating differential quantities
using polynomial ﬁtting of osculating jets. Computer Aided
Geometric Design, 22(2):121–146, 2005. 2

[5] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan,
Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su,
et al. Shapenet: An information-rich 3d model repository.
arXiv preprint arXiv:1512.03012, 2015. 6

[6] J. Chen and Y. Han. Shortest paths on a polyhedron. In Pro-
ceedings of the sixth annual symposium on Computational
geometry, pages 360–369. ACM, 1990. 2

[7] W. Chen, X. Han, G. Li, C. Chen, J. Xing, Y. Zhao, and H. Li.
Deep rbfnet: Point cloud feature learning using radial basis
functions. arXiv preprint arXiv:1812.04302, 2018. 1

[8] K. Crane, C. Weischedel, and M. Wardetzky. Geodesics in
heat: A new approach to computing distance based on heat
ﬂow. ACM Transactions on Graphics (TOG), 32(5):152,
2013. 2

[9] A. Dai, C. R. Qi, and M. Nießner. Shape completion us-
ing 3d-encoder-predictor cnns and shape synthesis. In Proc.
IEEE Conf. on Computer Vision and Pattern Recognition
(CVPR), volume 3, 2017. 2

[10] M. Defferrard, X. Bresson, and P. Vandergheynst. Convolu-
tional neural networks on graphs with fast localized spectral
ﬁltering. In Advances in Neural Information Processing Sys-
tems, pages 3844–3852, 2016. 2

[11] E. W. Dijkstra. A note on two problems in connexion with

graphs. Numer. Math., 1(1):269–271, Dec. 1959. 2

[12] X. Fei, A. Wong, and S. Soatto. Geo-supervised visual
IEEE Robotics and Automation Letters,

depth prediction.
4(2):1661–1668, 2019. 2

[13] R. W. Floyd. Algorithm 97: shortest path. Communications

of the ACM, 5(6):345, 1962. 2

[14] M. Garland and P. S. Heckbert. Surface simpliﬁcation us-
ing quadric error metrics.
In Proceedings of the 24th an-
nual conference on Computer graphics and interactive tech-
niques, pages 209–216. ACM Press/Addison-Wesley Pub-
lishing Co., 1997. 2

[15] C. Godard, O. Mac Aodha, and G. J. Brostow. Unsuper-
vised monocular depth estimation with left-right consistency.
In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 270–279, 2017. 2

[16] G. Guennebaud and M. Gross. Algebraic point set sur-
faces. In ACM Transactions on Graphics (TOG), volume 26,
page 23. ACM, 2007. 2

[17] P. Guerrero, Y. Kleiman, M. Ovsjanikov, and N. J. Mitra.
Pcpnet learning local shape properties from raw point clouds.
In Computer Graphics Forum, volume 37, pages 75–85. Wi-
ley Online Library, 2018. 2

[18] X. Han, T. Leung, Y. Jia, R. Sukthankar, and A. C. Berg.
Matchnet: Unifying feature and metric learning for patch-
based matching.
In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 3279–
3286, 2015. 4

[19] X. Han, Z. Li, H. Huang, E. Kalogerakis, and Y. Yu. High-
resolution shape completion using deep neural networks for
global structure and local geometry inference. In Proceed-
ings of IEEE International Conference on Computer Vision
(ICCV), 2017. 2

[20] R. Hartley and A. Zisserman. Multiple view geometry in

computer vision. Cambridge university press, 2003. 2

[21] H. Hoppe, T. DeRose, T. Duchamp, J. McDonald, and
W. Stuetzle. Surface reconstruction from unorganized points,
volume 26. ACM, 1992. 2

[22] H. Huang, D. Li, H. Zhang, U. Ascher, and D. Cohen-Or.
Consolidation of unorganized point clouds for surface recon-
struction. ACM transactions on graphics (TOG), 28(5):176,
2009. 2, 5

[23] D. B. Johnson. Efﬁcient algorithms for shortest paths in
sparse networks. Journal of the ACM (JACM), 24(1):1–13,
1977. 2

[24] I. Jolliffe. Principal component analysis. In International en-
cyclopedia of statistical science, pages 1094–1096. Springer,
2011. 2

[25] M. Kazhdan and H. Hoppe. Screened poisson surface recon-
struction. ACM Transactions on Graphics (ToG), 32(3):29,
2013. 5

[26] D. P. Kingma and J. Ba. Adam: A method for stochastic

optimization. arXiv preprint arXiv:1412.6980, 2014. 6

[27] Y. Lipman, D. Cohen-Or, D. Levin, and H. Tal-Ezer.
Parameterization-free projection for geometry reconstruc-
tion. ACM Transactions on Graphics (TOG), 26(3):22, 2007.
2, 5

[28] L. Luciano and A. B. Hamza. Deep learning with geodesic
moments for 3d shape classiﬁcation. Pattern Recognition
Letters, 105:182–190, 2018. 3

[29] Y. Ma, S. Soatto, J. Kosecka, and S. S. Sastry. An invitation
to 3-d vision: from images to geometric models, volume 26.
Springer Science & Business Media, 2012. 2

[30] M. Masoumi, C. Li, and A. B. Hamza. A spectral graph
wavelet approach for nonrigid 3d shape retrieval. Pattern
Recognition Letters, 83:339–348, 2016. 3

[31] J. S. Mitchell, D. M. Mount, and C. H. Papadimitriou. The
discrete geodesic problem. SIAM Journal on Computing,
16(4):647–668, 1987. 2

[32] C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep
learning on point sets for 3d classiﬁcation and segmentation.
Proc. Computer Vision and Pattern Recognition (CVPR),
IEEE, 1(2):4, 2017. 1

[33] C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++: Deep hi-
erarchical feature learning on point sets in a metric space. In
Advances in Neural Information Processing Systems, pages
5099–5108, 2017. 1, 2, 3

6896

[34] M. Reuter, F.-E. Wolter, and N. Peinecke. Laplace–beltrami
spectra as shape-dnaof surfaces and solids. Computer-Aided
Design, 38(4):342–366, 2006. 3

[35] M. Sharir and A. Schorr. On shortest paths in polyhedral
spaces. SIAM Journal on Computing, 15(1):193–215, 1986.
2

[36] J. Sun, M. Ovsjanikov, and L. Guibas. A concise and prov-
ably informative multi-scale signature based on heat diffu-
sion. In Computer graphics forum, volume 28, pages 1383–
1392. Wiley Online Library, 2009. 3

[37] V. Surazhsky, T. Surazhsky, D. Kirsanov, S. J. Gortler, and
H. Hoppe. Fast exact and approximate geodesics on meshes.
In ACM transactions on graphics (TOG), volume 24, pages
553–560. Acm, 2005. 2

[38] A. Wong, B.-W. Hong, and S. Soatto. Bilateral cyclic con-
straint and adaptive regularization for unsupervised monocu-
lar depth prediction. arXiv preprint arXiv:1903.07309, 2019.
2

[39] J. Wu, C. Zhang, T. Xue, B. Freeman, and J. Tenenbaum.
Learning a probabilistic latent space of object shapes via 3d
generative-adversarial modeling. In Advances in Neural In-
formation Processing Systems, pages 82–90, 2016. 2

[40] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and
J. Xiao. 3d shapenets: A deep representation for volumetric
shapes. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 1912–1920, 2015. 2

[41] S.-Q. Xin and G.-J. Wang. Improving chen and han’s algo-
rithm on the discrete geodesic problem. ACM Transactions
on Graphics (TOG), 28(4):104, 2009. 2

[42] Y. Yang and S. Soatto. Conditional prior networks for op-
In Proceedings of the European Conference on

tical ﬂow.
Computer Vision (ECCV), pages 271–287, 2018. 2

[43] Y. Yang, A. Wong, and S. Soatto. Dense depth posterior
(ddp) from single image and sparse range. arXiv preprint
arXiv:1901.10034, 2019. 2

[44] L. Yi, H. Su, X. Guo, and L. J. Guibas. Syncspeccnn: Syn-
chronized spectral cnn for 3d shape segmentation. In CVPR,
pages 6584–6592, 2017. 2

[45] L. Yu, X. Li, C.-W. Fu, D. Cohen-Or, and P.-A. Heng. Pu-
net: Point cloud upsampling network. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 2790–2799, 2018. 1, 2

6897

