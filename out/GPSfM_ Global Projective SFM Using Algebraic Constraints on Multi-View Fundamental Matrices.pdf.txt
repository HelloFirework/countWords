GPSfM: Global Projective SFM Using Algebraic Constraints

on Multi-View Fundamental Matrices

Yoni Kasten*

Amnon Geifman*

Meirav Galun

Ronen Basri

Weizmann Institute of Science

{yoni.kasten,amnon.geifman,meirav.galun,ronen.basri}@weizmann.ac.il

Abstract

This paper addresses the problem of recovering projec-
tive camera matrices from collections of fundamental matri-
ces in multiview settings. We make two main contributions.

First, given (cid:0)n

2(cid:1) fundamental matrices computed for n im-

ages, we provide a complete algebraic characterization in
the form of conditions that are both necessary and sufﬁcient
to enabling the recovery of camera matrices. These con-
ditions are based on arranging the fundamental matrices
as blocks in a single matrix, called the n-view fundamen-
tal matrix, and characterizing this matrix in terms of the
signs of its eigenvalues and rank structures. Secondly, we
propose a concrete algorithm for projective structure-from-
motion that utilizes this characterization. Given a complete
or partial collection of measured fundamental matrices, our
method seeks camera matrices that minimize a global al-
gebraic error for the measured fundamental matrices. In
contrast to existing methods, our optimization, without any
initialization, produces a consistent set of fundamental ma-
trices that corresponds to a unique set of cameras (up to a
choice of projective frame). Our experiments indicate that
our method achieves state of the art performance in both
accuracy and running time.

1. Introduction

This paper considers the problem of recovering pro-
jective camera matrices from collections of fundamental
matrices. Many multiview structure from motion (SFM)
pipelines begin, given n images, I1, ..., In, by robustly es-
timating fundamental matrices between image pairs from
collections of point matches, e.g., using RANSAC. How-

ever, in typical settings, only a subset of the (cid:0)n

2(cid:1) pairwise

fundamental matrices can be estimated, and the estimated
matrices may be subject at times to signiﬁcant errors. More-
over, fundamental matrices are deﬁned through a homoge-
neous equation and can thus assume any scale factor, but

*Equal contributors

a consistent setting of these scales is important in multi-
view settings [20, 22] (in analogy to resolving the distance
between cameras in a calibrated setting). Consequently, ac-
curate recovery of camera matrices is interesting both from
theoretical and practical standpoints. Our paper makes con-
tributions to both of these aspects.

of (cid:0)n

An important theoretical question is, given a collection

2(cid:1) fundamental matrices, whether these fundamental

matrices are consistent, in the sense that there exist n cam-
era matrices that produce these fundamental matrices. Be-
low we address this question by providing a set of algebraic
constraints that form both necessary and sufﬁcient condi-
tions for the consistency of fundamental matrices. Our for-
mulation, which extends the partial list of necessary condi-
tions introduced in [22], considers the symmetric matrix F

of size 3n × 3n, formed by stacking all (cid:0)n

2(cid:1) fundamental

matrices. It provides a complete characterization of F in
terms of the signs of its eigenvalues and rank patterns.

An advantage of our algebraic characterization is that it
can readily be used to construct optimization algorithms to
recover camera matrices. In the second part of this paper we
introduce an efﬁcient algorithm to recover projective cam-
era matrices directly from measured fundamental matrices.
Our algorithm, which utilizes the consistency constraints
presented in this paper, uses global optimization for camera
recovery, overcoming noise and missing measurements. It
further avoids one of the main difﬁculties in a previous ap-
proach [22] – the need to accurately recover a scale factor
for each of the estimated fundamental matrix. This allows
us to obtain state-of-the-art results without any initializa-
tion. We demonstrate the utility of our method by applying
it to uncalibrated image collections of various sizes. Our
experiments indicate that our method outperforms previous
methods in both accuracy and runtime.

1.1. Previous work

The recovery of projective camera matrices was ad-

dressed in several lines of work.
Incremental algorithms [13, 15, 19] process the images
sequentially, interleaving camera and depth recovery for ev-

13264

ery new image. Such methods can be sensitive to the order
of processing and may suffer from drift, due to accumula-
tion of errors. The use of bundle adjustment for every new
image reduces such drift, but is computationally demand-
ing.

Factorization-based methods [5, 6, 12, 15, 16, 23, 25] fac-
tor a measurement matrix that includes all point matches
across views into an (unknown) product of camera matrices,
depth values, and 3D point locations. These methods typi-
cally yield very large optimization problems and are often
approached by splitting the problem into smaller subprob-
lems.

Global methods. A number of “global methods” were pro-
posed recently demonstrating both accurate and efﬁcient
recovery of camera matrices from pairwise measurements
(essential or fundamental matrices), mostly in a calibrated
setting [11, 27, 18, 7, 2]. Sweeney el al. [24] attempts to
improve the consistency of fundamental matrices by mini-
mizing the discrepancy of reprojected points in three views
(through an “epipolar point transfer”). They, however, can-
not achieve projective recovery since their method does not
guarantee the consistency of the improved fundamental ma-
trices. Sengupta et al. [22] attempt to enforce rank con-
straints on the measured fundamental matrices. Compli-
cated by the need to simultaneously recover suitable scale
factors, their method is sensitive to errors and requires
highly accurate initialization, which was achieved by ap-
plying the state-of-the-art, calibrated LUD algorithm [18],
defeating the purpose of projective camera recovery without
calibration.

Solvability of viewing graphs. A number of papers seek
to design algorithms that can identify “solvable viewing
graphs” [14, 18, 20, 24]. A viewing graph captures the pat-
tern of missing fundamental matrices. Let G = (V, E) be a
graph such that a node vi ∈ V represents image Ii and an
edge eij ∈ E exists if the fundamental matrix Fij relating Ii
and Ij is available. G is called solvable if the corresponding
n camera matrices can be determined uniquely (up to a 4×4
projective transformation) despite the missing fundamental
matrices. Identifying solvable graphs is equivalent to ask-
ing, given a partial set of fundamental matrices, if F can be
completed uniquely to satisfy our algebraic constraints.

Finally, both our paper and [22] explore algebraic prop-
erties of multiview fundamental matrices (MVFs) and pro-
pose optimization schemes for utilizing these properties to-
ward camera pose recovery. However, these two papers
differ in several signiﬁcant respects. First, [22] provides
a set of necessary algebraic constraints, for the consistency
of MVF F , while we provide a complete set of necessary
and sufﬁcient algebraic conditions. Moreover, our condi-
tions are speciﬁed directly in terms of the MVFs, in con-
trast to [22] which rely on the construction of an auxiliary,
unknown matrix. Our direct formulation further leads to

a signiﬁcantly simpler optimization algorithm, including a
new algorithm for recovering the projective camera matri-
ces, from a consistent MVF F , which is lacking in [22]

2. Algebraic constraints of n-view fundamental

matrices

Let I1, . . . , In denote a collection of n images of a
static scene captured respectively by projective cameras
P1, ..., Pn. Each camera Pi is represented by a 3× 4 matrix
Pi = KiRT
i [I,−ti], where Ki is a 3× 3 calibration matrix,
ti ∈ R3 and Ri ∈ SO(3) respectively denote the location
and orientation of Pi in some global coordinate system, and
I denotes the 3 × 3 identity matrix. Below we further de-
note Vi = K −T
[I,−ti]. Consequently,
let X = (X, Y, Z)T be a scene point in the global coordi-
nate system. Its projection onto Ii is given by xi = Xi/Zi,
where Xi = (Xi, Yi, Zi)T = KiRT

i , so Pi = V −T

i RT

i

We next denote the fundamental matrix between images
Ii and Ij by Fij. In [2, 22] it was shown that Fij can be
written as

i (X − ti).

Fij = K −T

i RT

i (Ti − Tj)RjK −1

j = Vi(Ti − Tj)V T

j , (1)

where Ti = [ti]×. It can be readily veriﬁed that this def-
inition of Fij is consistent with the standard properties of
fundamental matrices [8], including (a) P T
i FijPj is skew
symmetric, and (b) eT
ikFij ejk = 0, where eik denotes the
projection of the center of camera k onto camera i, i.e.,
eik = Pitk.

Note, however, that (1) attributes a scale to each Fij that
relates it to some global coordinate system.
In practice,
given two images, a fundamental matrix is determined only
up to a multiplicative factor. We will denote an estimated
fundamental matrix by ˆFij and assume, in case it is esti-
mated accurately, that ˆFij = λijFij with unknown λij 6= 0.
We next construct a matrix from all(cid:0)n
2(cid:1) fundamental ma-
Deﬁnition 1. A matrix F ∈ S3n, whose 3 × 3 blocks are
denoted by Fij , is called an n-view fundamental matrix if
rank(Fij) = 2 for all i 6= j and Fii = 0.
We use S3n to denote the space of all 3n × 3n symmetric
matrices. The symmetry of F implies that Fij = F T
ji .

trices.

Deﬁnition 2. An n-view fundamental matrix F is called
consistent if there exist camera matrices P1, ..., Pn of the
form Pi = V −T
[I, ti] such that Fij = Vi([ti]×−[tj]×)V T
j .

i

A consistent F , therefore, takes the form

F =




F12
0

0
F21
...
Fn1 Fn2

... F1n
... F2n
...
0

...




3265

and each Fij is scaled properly in accordance with the
global coordinate system. We further refer to the 3 × 3n
ith block row of F by Fi.
Our main theoretical result is summarized below in The-
orem 1, which speciﬁes a set of necessary and sufﬁcient
algebraic conditions for the consistency of F in terms of
its eigenvalue sign and rank patterns. These, in turn, will
be used in later sections to construct a new optimization al-
gorithm for global recovery of projective camera matrices
from noisy fundamental matrices.

Theorem 1. An n-view fundamental matrix F is consistent
with a set of n cameras whose centers are not all collinear
if, and only if, the following conditions hold:

1. Rank(F ) = 6 and F has exactly 3 positive and 3 neg-

ative eigenvalues.

2. Rank(Fi) = 3 for all i = 1, ..., n.

Below we provide a proof sketch. The full proof is deferred
to the supplementary material. To prove the theorem we
ﬁrst state that for a symmetric rank 6 matrix F the following
three conditions are equivalent:

(i) F has exactly 3 positive and 3 negative eigenvalues.

(ii) F = XX T − Y Y T with X, Y ∈ R3n×3 and

rank(X) = rank(Y ) = 3.

(iii) F = U V T + V U T with U, V ∈ R3n×3 and

rank(U ) = rank(V ) = 3.

In particular, using the eigen-decomposition of F ,
let
F xi = αixi and F yi = −βyi, αi, βi > 0, the columns
of X and Y respectively may include √αixi and √βiyi,
and U, V are related to X, Y through

U = (X − Y )/√2, V = (X + Y )/√2.

(2)

Next, to show the necessary condition, let F be a con-
sistent, n-view fundamental matrix, then clearly (1) can be
written in matrix form as F = U V T + V U T , where U, V ∈
R3n×3 whose 3 × 3 blocks respectively are Ui = ViTi and
Vi, implying condition 1. Condition 2 holds because not all
cameras are collinear, since if conversely rank(Fi) < 3
for some i then there exists a 3-vector e 6= 0 such that
F T
e = 0, and therefore ∀j Fjie = 0, implying, in con-
i
tradiction, that the camera centers are all collinear.
To establish the sufﬁcient condition, let F be an n-view
fundamental matrix that satisﬁes conditions 1 and 2. Con-
dition 1 (along with (iii)) implies that Fij = UiV T
j + ViU T
j .
Next, Fii = 0 implies that UiV T
is skew symmetric, and
i
so ∀i either rank(Ui) = 2 or rank(Vi) = 2. Next, as we
show in the supplementary material, rank(Fi) = 3 implies
WLOG that ∀i, rank(Vi) = 3 and rank(Ui) = 2. This and

imply that V −1

the skew-symmetry of UiV T
i Ui is skew-
i
symmetric. Denote this matrix by Ti = [ti]×, we obtain
Fij = Vi(Ti − Tj)V T
j , establishing that F is consistent. Fi-
nally, {ti}n
i=1 are not all collinear, since, otherwise ∃i and
∃e 6= 0 such that ∀j Fjie = 0, implying that F T
e = 0,
contradicting the full rank of Fi.

i

Theorem 1 also provides a practical tool for projective
reconstruction. Given a set of (possibly noisy) pairwise
fundamental matrices we can use constrained, low-rank op-
timization to recover a matrix that satisﬁes conditions 1-2.
Then, we can use the obtained n-view fundamental matrix
to recover the underlying camera matrices. This is summa-
rized in the following corollary.

Corollary 1. Projective reconstruction: Let F ∈ S3n be
a consistent n-view fundamental matrix, then it is possible
to explicitly determine camera matrices P1, ..., Pn that are
consistent with F .

Proof. The claim is justiﬁed by the following construction,
which relies on the proof of Theorem 1.

1. Since F satisﬁes condition 1 we can use its eigen-
decomposition to express it as F = XX T − Y Y T ,
and then construct U and V using (2).

2. Now, WLOG, rank(Vi) = 3 and rank(Ui) = 2 for all
i = 1, ..., n (or else U and V should be interchanged).

3. We next deﬁne Ti = V −1
and we denote Ti = [ti]×.

i Ui. Ti is skew symmetric,

4. By construction Fij = Vi(Ti − Tj)V T

j , implying that
ti] form a consistent set of camera

Pi = [V −T
i
matrices.

|− V −T

i

This construction is unique up to a 4 × 4 projective trans-
formation.

Let F be a consistent n-view fundamental matrix.
Clearly, if we scale differently any of its blocks, λijFij
with λij 6= 0, then in general F ceases to be consistent.
In particular, it maintains condition 2 of Theorem 1, but
its rank is no longer 6. Note, however, that we can scale
each block-row (and by symmetry column) of F differently
and maintain both the conditions of the theorem; i.e., let
S = diag(s1I, .., snI) with si 6= 0, then SF S is consistent
if and only if F is consistent. (Such scaling is equivalent to
scaling the projective camera matrices.) This, in fact, im-
plies that we need to determine only (cid:0)n
2(cid:1) − n of the scale
clude all (cid:0)n
2(cid:1) pairwise fundamental matrices. In real appli-

Up to this point we considered n-view matrices that in-

factors and set the rest of the n scales arbitrarily.

cations, however, often only a subset of the pairwise ma-
trices can be computed. Additionally, the estimated funda-
mental matrices are improperly scaled and may suffer from

3266

large inaccuracies. In these cases we may want to recon-
struct the cameras from partial subsets of fundamental ma-
trices. Indeed, our algorithm, presented later in Sec. 3, re-
covers a consistent set of camera matrices from triplets of
images, allowing us to handle missing fundamental matri-
ces and to remove outliers. The following theorem estab-
lishes that, with proper intersection, camera matrices are
determined uniquely (up to the usual 4× 4 projective ambi-
guity) from consistent sub-matrices. We ﬁrst need the fol-
lowing deﬁnition:

Deﬁnition 3. Let F ∈ R3n×3n and let F 1, ..., F k be block
sub-matrices of F, with F i ∈ R3mi×3mi , 3 ≤ mi ≤ n.
{F 1, ..., F k} is called a consistent cover of F if each
F i forms a consistent multi-view fundamental matrix and
each diagonal element of F is contained in at least one of
F 1, ..., F k.
Theorem 2. Let F ∈ R3n×3n and let F 1, ..., F k form a
consistent cover of F .
If for all 2 ≤ m ≤ k, there ex-
ists l < m such that F l, F m overlap in at least one funda-
mental matrix, then there exists a unique n-view consistent
fundamental matrix ¯F (up to n scale factors) whose blocks
¯Fij = λijFij with some λij 6= 0 for all Fij that belong to
any of F 1, ..., F k.

Proof. We prove this by induction on k. We begin with
k = 2. By Corollary 1, F 1, F 2 deﬁne two sets of camera
matrices P 1,P 2 that are consistent with respect to F 1, F 2,
respectively. Since F 1 and F 2 share a fundamental ma-
trix Fij , Fij corresponds to a pair of cameras in P 1 and a
second pair in P 2 so that the two pairs are equal up to a
projective homography ([8], p. 254). Consequently, P 2 can
be mapped to the projective frame of P 1 to form a set of n
camera matrices [20], that in turn determine a unique (up to
n global scale factors) consistent n-view matrix, ¯F . Now,
each fundamental matrix, in either F 1 or F 2, corresponds
to two cameras from this set of n cameras and hence has
exactly the same entries as in ¯F up to scale.

This argument can now be repeated inductively to prove

the theorem for all k > 2.

3. Method

Given images I1, ..., In, we assume a standard robust
method (e.g., RANSAC) is used to estimate the pairwise

set of estimated fundamental matrices. In general, only a

fundamental matrices, where we denote by Ω = { ˆFij} the
subset of the (cid:0)n
2(cid:1) pairwise fundamental matrices are esti-

mated, due to, e.g., occlusion, large motion, or changes in
brightness, and the available estimates are noisy. An addi-
tional complication is that to make these fundamental matri-
ces consistent they must each be scaled by an unknown fac-
tor to ﬁt the global coordinate frame. Our aim therefore is

to ﬁnd a consistent n-view matrix F ∈ S3n that is as similar

as possible to the measured fundamental matrices. Straight-
forward optimization of this problem is difﬁcult as it yields
a nonlinear optimization formulation with rank constraints,
as in [22], which required initialization by a high quality
method.

Below we introduce a novel method that utilizes global
optimization and yet circumvents the need to recover the
scale factors. Our method works by enforcing the consis-
tency constraints of Theorem 1 on 3-view fundamental ma-
trices and by maintaining their intersections, as is required
by Theorem 2, to obtain a global reconstruction. This yields
an optimization problem, with simple and efﬁcient formu-
lation, that directly uses the measured data without the need
to incorporate any initialization. We solve this optimiza-
tion using the alternating direction method of multipliers
(ADMM) [3], where each step in the ADMM has a closed
form solution.

We avoid recovering scale factors by enforcing consis-
tency for image triplets. As we explained in Sec. 2, we only

need to determine(cid:0)n

2(cid:1)−n of the scale factors, while the rest

can be set arbitrarily. A consequence of this is that there are
no scale factors for n = 3, as proved below.

Corollary 2. A consistent 3-view fundamental matrix is in-
variant to arbitrarily scaling its constituent fundamental
matrices.

Proof. Let F be a consistent 3-view fundamental matrix
whose blocks are deﬁned as Fij = Vi(Ti − Tj)V T
j , and
let eF be a 9 × 9 matrix whose blocks are deﬁned to be
eFij = sijFij where sij 6= 0 are arbitrary scale factors.

Without loss of generality we can assume that the number
of negative scale factors is even (otherwise we can multi-
ply the entire matrix by -1). Therefore, s1 = ( s12s13
2 ,
s23
s2 = ( s23s12
2 determine real values
s13
such that s1s2 = s12, s1s3 = s13, and s2s3 = s23. Let

2 , and s3 = ( s13s23
s12

)

)

)

1

1

1

eVi = siVi for i = 1 . . . 3, we get that

eFij = sijVi(Ti − Tj)V T

j = siVi(Ti − Tj)sjV T
= eVi(Ti − Tj)eV T

j

j

(3)

Therefore eF = SF S with S = diag(s1I, s2I, s3I), and

hence it is consistent.

This corollary implies that for 3-view fundamental ma-
trices consistency is invariant under any choice of scale fac-
tors. Our optimization formulation relies on this observa-
tion to avoid the need to estimate the scale factors during op-
timization. In particular, we introduce a global optimization
scheme that enforces the consistency of triplets of views,
while simultaneously enforcing the compatibility of the dif-
ferent triplets. In the rest of this section we ﬁrst formulate
our optimization problem and discuss how to solve it with
ADMM. Then we discuss how to select minimal subsets of

3267

triplets to speed up the optimization and ﬁnally show how
the results of our optimization can be used to reconstruct the
n cameras.

3.1. Optimization

Our input set of estimated fundamental matrices { ˆFij}
determines a viewing graph G = (V, E) with nodes
v1, ..., vn, corresponding to the n cameras, and eij ∈ E
if ˆFij belongs to the collection of the estimated fundamen-
tal matrices. Let τ denote a collection of m 3-cliques in G,
3(cid:1). The collection τ may include all the 3-cliques
m ≤ (cid:0)n

in G, or a subset, as we explain in Sec. 3.3. We index the
elements of τ by k = 1, ..., m, where τ (k) denotes the kth
triplet. The selection of τ induces a partial selection of es-
timated fundamental matrices, Ω, that participate in the op-
In our construction, if ˆFij ∈ Ω then
timization process.
ij = ˆFji ∈ Ω.
ˆF T
We deﬁne the measurement matrix ˆF ∈ S3n to include
all ˆFij ∈ Ω in their corresponding 3× 3 block while setting
the rest of the blocks to 03×3. In the optimization process,
we look for a matrix F ∈ S3n that is as close as possible
to ˆF under the constraint that its 9 × 9 blocks, induced by
{τ (k)}m
k=1, are consistent. In
general, such an F is inconsistent (since its scale factors are
incompatible across triplets) and incomplete, but, based on
Theorem 2, it uniquely determines the corresponding pro-
jective cameras.

k=1 and denoted as {Fτ (k)}m

We next introduce our constrained optimization problem

min

F

s.t.

mX

||Fτ (k) − ˆFτ (k)||2

F

k=1
F = F T
Fii = 03×3
rank(Fτ (k)) = 6

i = 1, . . . , n

k = 1, . . . , m.

Solving (4) is challenging due to the rank constraints. As
mentioned above, we approach this problem using ADMM.
To that end, 2m auxiliary matrix variables of size 9 × 9
are added: m variables duplicating {Fτ (k)}m
k=1, denoted
{Bk}m
k=1, and m Lagrange multipliers {Γk}m
k=1, yielding

the objective

min

L(Fτ (k), Bk, Γk)

(5)

mX

F,B1,...,Bm

k=1
s.t. F = F T

Fii = 03×3
rank(Bk) = 6

i = 1, ..., n

k = 1, ..., m,

max
Γk

where

L(Fτ (k), Bk, Γk) = α|| ˆFτ (k)−Fτ (k)||2

F +||Bk−Fτ (k)+Γk||2
F .

We initialize the auxiliary variables at t = 0 with

B(0)

k = ˆFτ (k), Γ(0)

k = 0

and then alternate between the following three steps, where
at each step we update the values of the variables at iteration
t given their values at t − 1.
(i) Solving for F .

argmin

F

s. t.

mX

k=1

α|| ˆFτ (k) − Fτ (k)||2

F

(6)

+ ||B(t−1)

k

− Fτ (k) + Γ(t−1)

k

||2

F

F = F T
Fii = 03×3

i = 1, ..., n.

In practice, we explicitly maintain the equality constraints
over F , i.e., F is symmetric with zero block diagonal.
Therefore, at each iteration t we can solve only for the tri-
angular upper part of F , i.e., {Fij| ˆFij ∈ Ω, i < j}. This

yields an unconstrained convex quadratic objective in these
variables, and hence it admits a closed form solution. Let
Nij be the number of 3-cliques in τ that include the edge
eij. Then, for each such triplet τ (k) we denote the vari-
ables corresponding to the i, j block as Bk(i, j), Γk(i, j),
and ˆFτ (k)(i, j). This yields the following update rule

F (t)
ij =

1

Nij(1 + α)

NijX

k=1

B(t−1)

k

(i, j) + Γ(t−1)

k

(i, j) (7)

+α ˆFτ (k)(i, j).

B(t)

k = argmin

Bk

||Bk − F (t)

τ (k) + Γ(t−1)

k

||2

F

(8)

s.t rank(Bk) = 6.

Here, the closed form solution is
k = SV P (F (t)

B(t)

τ (k) − Γ(t−1)

k

, 6)

(9)

where SV P (A, p) denotes the singular value projection of
the matrix A to rank p.

(iii) Updating Γk.

For all k = 1, . . . , m

Γ(t)
k = Γ(t−1)

k

+ B(t)

k − F (t)
τ (k).

(10)

Note that the constraints in (4) cover only a subset of the
constraints in Theorem 1, and in particular they do not re-
strict the sign pattern of the eigenvalues of Fτ (k), the rank
2 of Fij , or the rank 3 of Fi. Our experiments, however,
indicate that with the amounts of noise prevalent in existing
datasets, and by removing collinear triplets, our solutions
always satisfy these constraints to a good numerical preci-
sion.

(4)

(ii) Solving for Bk.

For all k = 1, . . . , m

3268

3.2. Camera recovery

We use the optimized matrix F to recover the corre-
sponding projective cameras. Since F is generally incon-
sistent we cannot use the eigen-decomposition method de-
scribed in Corollary 1. However, the 9 × 9 sub-matrices
Fτ (k) are consistent, and by construction they form a triplet
cover of G. It is therefore straightforward to traverse the
graph Gτ and, using Theorem 2, apply a homography to
each three cameras corresponding to Fτ (k), k = 1, ..., m, to
bring them all to a common projective frame. Note that this
process is exact, since all Fτ (k) are consistent.

3.3. Constructing triangle cover

Eq. (4) enforces the consistency of 3-view sub-matrices.
In principle, this formulation can be applied to all 3-cliques
of G (although outlier and collinear triplet removal may be
needed). It is however more efﬁcient (and sufﬁces for re-
construction) to apply this to a subset of the triplets, pro-
vided the triplets produce a solvable viewing graph.

Given a viewing graph G = (V, E), we consider further
a graph Gτ = (Vτ , Eτ ) whose nodes v′ ∈ Vτ represent
3-clique in G and an edge e′
kl ∈ Eτ exists if triangles v′
k
and v′
l share two images. We call Gτ a triplet cover of G if
every node vi ∈ V belongs to at least one vertex in Vτ .
Our objective is to ﬁnd a small and reliable triplet cover
of G. We do this heuristically as follows. We associate a
weight wij with each edge eij ∈ E, where wij counts the
number of inliers of pairwise correspondences, identiﬁed
for ˆFij . We then ﬁnd NG edge-disjoint maximal spanning
trees for G, and use this set to produce a triplet cover for
G, denoted Gτ , in a similar way to [13]. Next, we prune
Gτ greedily, removing triplets whose cameras are collinear
and triplets whose consistency scores are low. To measure
collinearity we divide the distance between the two epipoles
in each image by their average distance from the image cen-
ter and average these ratios over the three images. Denote
this measure by lk we remove triplets with lk < δ1. We fur-
ther measure consistency as ck = kFτ (k) − ˆFτ (k)kF , where
ˆFτ (k) is the measured 3-view fundamental matrix associ-
ated with the triplet v′
k and Fτ (k) is its closest consistent
triplet calculated using our ADMM optimization for only
this triplet. (This can be done very efﬁciently.) Finally, we
sort the remaining triplets by their stability scores, deﬁned
as sk = lδ2
k /ck, and greedily remove triplets of low score
while maintaining the connectivity of Gτ and its cover of
G, see an illustration in Fig. 1.

4. Experiments

4.1. Structure from motion pipeline

We used our method to construct a projective SFM
pipeline. The pipeline obtains pairwise fundamental ma-
trices computed with RANSAC. As described in Sec. 3, we

Algorithm 1: Projective SFM Pipeline

Input

: Fundamental matrices Ω = { ˆFij}
Viewing Graph: G = (V, E)
Tracks of point matches (for BA)

Output: Projective reconstruction of Cameras and

Points

Gτ ←Select a triplet cover for G (Sec. 3.3)
Form the n-view measurement matrix ˆF ← { ˆFij}
Solve (4) using ADMM:
Initialize B(0)
for t = 1, ..., Nit do

k = ˆFτ (k), Γ(0)

k = 0, t = 1

Update F (t) using (7)
For k = 1, ..., m, update B(t)
For k = 1, ..., m, update Γ(t)

k using (9)
k using (10)

end
For k = 1, ..., m, retrieve camera matrices for triplet
τ (k) (Corollary 1)
P ← Bring cameras to a global projective frame of
reference (Sec. 3.2)
X ← Triangulate points from points tracks
P,X ← Reﬁne solution using Bundle Adjustment
Return P,X

Figure 1: Building a triplet cover for the House dataset (10 cam-
eras). From left to right, the viewing graph, the ﬁnal viewing
graph, and the corresponding triplet cover.

ﬁrst construct a reliable triangle cover. We next use ADMM
to solve (4), obtaining consistent 3-view submatrices, and
use them to construct camera matrices. In postprocessing
we use projective bundle adjustment (BA) to improve our
camera recovery and 3D point reconstruction. Note that,
similar to global Euclidean SFM methods [2, 7, 11, 18, 27],
we only apply BA once at the end of the pipeline. For
this step we triangulate point tracks and apply projective
bundle adjustment to the camera matrices and the point
matches. Similar to [21], after convergence, 3D points are
re-triangulated and a few additional iterations of BA are ap-
plied for better convergence. Our pipeline is summarized in
Alg. 1.

4.2. Implementation details

matrices ˆFij, as in [9], by ˆF n

Before optimization we normalize the input fundamental
, where Ni ∈

ij = N −T

ˆFijN −1

j

i

3269

Table 1: Reprojection error and run time obtained in our experiments.

Dataset

#points

#Images

Dino 319
Dino 4983
Corridor
House
Gustav Vasa
Folke Filbyter
Park Gate
Nijo
Drinking Fountain
Golden Statue
Jonas Ahls
De Guerre
Dome
Alcatraz Courtyard
Alcatraz Water Tower
Cherub
Pumpkin
Sphinx
Toronto University
Sri Thendayuthapani
Porta san Donato
Buddah Tooth
Tsar Nikolai I
Smolny Cathedral
Skansen Kronan

319
4983
737
672
4249
21150
9099
7348
5302
39989
2021
13477
84792
23674
14828
72784
69335
32668
7087
88849
25490
27920
37857
51115
28371

36
36
11
10
18
40
34
19
14
18
40
35
85
133
172
65
195
70
77
98
141
162
98
131
131

Ours
0.4314
0.4205
0.2596
0.3399
0.1564
0.258
0.3109
0.3901
0.2806
0.223
0.1845
0.2609
0.2354
0.5162
0.4704
0.7408
0.5959
0.3366
0.5417
0.6113
0.3992
0.5957
0.2897
0.4639
0.4424

PPSFM
0.5042
0.4442
0.276
0.3687
0.1687
–
0.3447
0.4412
0.3125
0.24
0.2108
0.2891
0.2507
0.5592
0.5972
0.7921
–
0.3669
0.2588
0.3517
0.4352
0.8583
0.309
0.5079
0.4414

Error(pixels)
Sengupta
0.6134
0.5795
0.2765
0.5984
0.2591
–
0.3288
0.4173
0.2942
0.2368
0.1979
0.2728
1.8991
5.3641
0.5003
–
–
0.3508
0.2557
0.3204
4.5186
1.7853
0.3021
0.4773
0.4477

Var-Pro
0.6157
0.5961
0.2741
0.3719
0.1671
26.6054
0.5489
0.417
0.2942
0.2272
0.197
0.2715
0.2413
0.5366
3.0353
Out of memory (16GB)
Time Limit (12H)
0.3486
0.2556
Out of memory (16GB)
0.4155
0.6245
0.3013
Out of memory (16GB)
0.4291

Ours
3.07
4.80
1.12
0.95
3.18
6.07
11.33
5.70
2.85
7.07
5.29
13.79
109.83
65.04
87.11
34.87
130.74
23.36
25.65
248.72
78.22
62.17
62.71
197.72
102.75

PPSFM
3.24
15.19
1.31
0.70
7.06
–
25.85
10.33
5.80
20.45
15.22
27.92
171.83
113.17
68.31
81.42
–
49.05
100.27
418.21
87.84
84.44
95.68
264.04
165.77

Time(s)

Sengupta
46.40
50.35
21.05
18.10
32.93
–
62.6
32.22
26.35
86.8
46.64
103.70
970
537
539
–
–
191
779.5
1070
771
792
422
640.87
1000

Var-Pro
5.48
384.01
45.16
55.19
326.48
2.33E+04
1600
148.74
82.07
3890
90.81
282.87
3.78E+04
3210
1080
–
–
2.53E+04
335.9708
–
2060
5530
8700
–
2610

R3×3 normalizes the location of interest points in image Ii
to have zero mean and unit variance. In data sets where the
point matches distribute non-isotropically, we normalize the
variance separately in each axis. After the optimization Fij
is denormalized by N T

i FijNj.

For the optimization, we set α = 0.001 (in (6)) and per-
form Nit = 1000 iterations of ADMM updates. For the
triplet selection procedure (Sec. 3.3) we set NG = 5 and
δ1 = 0.03. We set δ2 by the following condition, if the aver-
age non-collinearity measure, lk, exceeds 0.5 we set δ2 = 0.
Otherwise, it means the data is highly collinear, and so we
set δ2 = 1.2.

To produce 3D points from multiview tracks we used the
Matlab linear triangulation code of [8]. We implemented
projective bundle adjustment using the Ceres [1] non lin-
ear least squares optimization package and used Huber loss
(with parameter 0.1) for robustness. We performed up to
100 iterations of bundle adjustment. Our code is imple-
mented in Matlab on an Intel processor i-7 7700 with 16GB
RAM.

4.3. Results

We tested the method on several projective datasets from
[17] and VGG [26] and compared the results to state-of-the-
art projective reconstruction pipelines, including:
P2SfM [15]. This recent method solves for projective struc-
ture incrementally by solving linear least squares systems
that incorporate constraints on the sought projective depths.
The paper demonstrated both superior re-projection accu-
racy and running time, compared to existing methods.
VarPro [10]. This method ﬁrst applies afﬁne bundle ad-
justment followed by projective BA. It further uses variable

projection to improve the solution of BA.
Sengupta et. al [22]. Similar to our method, this method
applies rank constraints to n-view matrices, but it explic-
itly recovers the scale factors. As the authors acknowledge,
their algorithm is sensitive, and so it was suggested as a re-
ﬁnement to a calibrated method [18]. To avoid calibration,
for a fair comparison, we initialized the method with P2SfM
[15]. Moreover, as the method does not suggest a way to
produce projective reconstruction, we used Corollary 1 to
obtain camera matrices from its output.

To compare all the methods, we ran them with the code
supplied by the authors. For [22] we counted only its run-
ning time (excluding the running time of the initialization
method). For [10] we set a time limit of 12 hours. We ran
all the methods on the same computer under the same con-
ditions.

Table 1 shows the mean reprojection error (in pix-
els) across all scene points and the total running time (in
seconds) obtained with our method compared to P2SfM,
VarPro, and Sengupta et al. It can be seen that our method
achieved superior accuracies to all the other methods in
22 of the 25 data sets tested. Moreover, for certain com-
plex scene structures (e.g., Pumpkin and Folk Filbyter) our
method managed to reconstruct the scene, whereas all the
other methods failed to obtain a reconstruction (we tried
with many different hyper-parameters). In almost all cases
our method was also faster, improving runtime in 22 out
of 25 data sets. The best compared method (separately for
each dataset) had a median of 4.8% reprojection error worse
than our method and required an additional median runtime
of 74% compared to our method. The quality of our recon-
struction can also be appreciated by the recovered 3D point

3270

10

5

0

-5

-10

-15
0

200

400
600
Iterations

800

1000

Figure 2: Enforcing rank constraints. The plot shows (in log10
scale) the ratio between the seventh and sixth singular value of
Fτ (k) averaged for all triplets.

clouds shown in Fig 3.

We believe the improved accuracy is partly explained by
the effective enforcement of the rank 6 constraint for all
triplets. We demonstrate this in Fig. 2, which shows the
ratio between the 7th and 6th singular values of Fτ (k) aver-
aged over all triplets for the House model. Our optimization
reduces this ratio to near machine precision, indicating that
indeed rank 6 is achieved in all runs.

4.4. Graph consistency simulations

Since our optimization (4) only enforces a subset of the
consistency constraints in Theorem 1 we next test the con-
sistency of our recovered fundamental matrices (with no
bundle adjustment) in synthetic experiments. We generated
10 camera matrices and 15,000 three dimensional points.
We then projected the points and perturbed them by Gaus-
sian noise. Finally, we selected 15 matching triplets at
random and used them to compute fundamental matrices,
which we gave to our algorithm.

The results are shown in Fig. 4. We evaluated consis-
tency using the symmetric epipolar distance associated with
the term eT
ikFij ejk, where eik denotes the projected loca-
tion of camera k onto camera i. Denote this distance by
Sijk, then Sijk + Sjki + Skij = 0 implies that cameras
i, j, k are consistent ([8], p. 384). Additionally, we show the
quality of recovering the ground truth fundamental matri-
ces (measured by average Frobenius norm), and the average
symmetric epipolar distance of the ground truth matches.
It can be seen that our method maintains consistency un-
der all error levels while achieving high quality recovery of

Figure 3: Visualization of the result of our projective structure
from motion pipeline after applying self-calibration of [4] . From
left to right: Tsar Nikolai I, Sphinx, Dome.

l

e
v
e
L
 
y
c
n
e
t
s
s
n
o
c
n

i

I

0.2

0.15

0.1

0.05

0

0

Our Results
Sweeney et. al

0.1

0.2
0.3
Noise Level

0.4

0.5

t

 

h
u
r
T
d
n
u
o
r
G
F
o

 

 

t
 

e
c
n
a
t
s
D

i

0.025

0.02

0.015

0.01

0.005

0

0

Our Results
Sweeney et. al

0.1

0.2

0.3
Noise Level

0.4

0.5

e
c
n
a
t
s
D

i

l

i

 
r
a
o
p
p
E
 
c
i
r
t
e
m
m
y
S

0.2

0.15

0.1

0.05

0

0

Our Results
Sweeney el. al

0.1

0.2
0.3
Noise Level

0.4

0.5

(a)

(b)

(c)

Figure 4: Synthetic experiments. Average symmetric epipo-
lar distance of corresponding epipoles (left), error in fundamen-
tal matrix recovery, compared to ground truth (average Frobenius
norm, middle), and symmetric epipolar distance for ground truth
matches. Our method (in blue) is compared against [24].

fundamental matrices compared to ground truth. We com-
pare our results with [24]’s consistency optimization (Sec.
3 therein).

5. Conclusion

We considered the problem of recovering projective
camera matrices from collections of fundamental matrices.
We derived a complete algebraic characterization of n-view
fundamental matrices in the form of conditions that are
both necessary and sufﬁcient to enable the recovery of cam-
era matrices. We further introduced an algorithm that uses
this characterization for global recovery of camera matrices
from measured fundamental matrices. Our algorithm is efﬁ-
cient and requires no initialization. We tested the algorithm
on a large number of datasets and compared it to existing,
state-of-the-art methods, showing both improved accuracy
and runtime.

In future work we plan to explore ways to relate our alge-
braic constraints with the question of solvability of viewing
graphs. In addition, we plan to similarly characterize col-
lections of essential matrices.
Acknowledgment This research was supported in part by the Min-
erva foundation with funding from the Federal German Ministry
for Education and Research.

References

[1] S. Agarwal, K. Mierle, and Others. Ceres solver. http:

//ceres-solver.org.

[2] M. Arie-Nachimson, S. Z. Kovalsky,

I. Kemelmacher-
Shlizerman, A. Singer, and R. Basri. Global motion esti-
mation from point matches. In 2012 Second Int. Conf. on 3D
Imaging, Modeling, Processing, Visualization & Transmis-
sion, pages 81–88. IEEE, 2012.

[3] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, et al.
Distributed optimization and statistical learning via the al-
ternating direction method of multipliers. Foundations and
Trends in Machine learning, 3(1):1–122, 2011.

[4] M. Chandraker, S. Agarwal, F. Kahl, D. Nist´er, and D. Krieg-
man. Autocalibration via rank-constrained estimation of the

3271

absolute quadric. In Computer Vision and Pattern Recogni-
tion, 2007. CVPR’07. IEEE Conference on, pages 1–8. IEEE,
2007.

[21] J. L. Schonberger and J.-M. Frahm. Structure-from-motion
In IEEE Conf. on Computer Vision and Pattern

revisited.
Recognition, pages 4104–4113, 2016.

[22] S. Sengupta, T. Amir, M. Galun, T. Goldstein, D. W. Jacobs,
A. Singer, and R. Basri. A new rank constraint on multi-
view fundamental matrices, and its application to camera
location recovery. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 4798–
4806, 2017.

[23] P. Sturm and B. Triggs. A factorization based algorithm for
In European

multi-image projective structure and motion.
Conf. on computer vision, pages 709–720. Springer, 1996.

[24] C. Sweeney, T. Sattler, T. Hollerer, M. Turk, and M. Polle-
feys. Optimizing the viewing graph for structure-from-
motion. In IEEE Int. Conf. on Computer Vision, pages 801–
809, 2015.

[25] T. Ueshiba and F. Tomita. A factorization method for projec-
tive and euclidean reconstruction from multiple perspective
views via iterative depth estimation. In European Conf. on
computer vision, pages 296–310. Springer, 1998.

[26] O. VGG. Multiview datasets. http://www.robots.

ox.ac.uk/˜vgg/data/.

[27] K. Wilson and N. Snavely. Robust global translations with
1dsfm. In European Conf. on Computer Vision, pages 61–75.
Springer, 2014.

[5] S. Christy and R. Horaud. Euclidean shape and motion from
multiple perspective views by afﬁne iterations. IEEE Trans.
on Pattern Analysis and Machine Intelligence, 18(11):1098–
1104, 1996.

[6] Y. Dai, H. Li, and M. He. Projective multiview structure
and motion from element-wise factorization.
IEEE Trans.
on Pattern Analysis and Machine Intelligence, 35(9):2238–
2251, 2013.

[7] T. Goldstein, P. Hand, C. Lee, V. Voroninski, and S. Soatto.
Shapeﬁt and shapekick for robust, scalable structure from
motion. In European Conf. on Computer Vision, pages 289–
304. Springer, 2016.

[8] R. Hartley and A. Zisserman. Multiple view geometry in

computer vision. Cambridge university press, 2003.

[9] R. I. Hartley.

In defence of the 8-point algorithm.

In Int.

Conf. on Computer Vision, pages 1064–1070. IEEE, 1995.

[10] J. H. Hong, C. Zach, A. Fitzgibbon, and R. Cipolla. Projec-
tive bundle adjustment from arbitrary initialization using the
variable projection method. In European Conf. on Computer
Vision, pages 477–493. Springer, 2016.

[11] N. Jiang, Z. Cui, and P. Tan. A global linear method for
camera pose registration. In IEEE Int. Conf. on Computer
Vision, pages 481–488, 2013.

[12] R. Kennedy, L. Balzano, S. J. Wright, and C. J. Taylor. On-
line algorithms for factorization-based structure from mo-
tion. Computer Vision and Image Understanding, 150:139–
152, 2016.

[13] M. Klopschitz, A. Irschara, G. Reitmayr, and D. Schmal-
stieg. Robust incremental structure from motion. In Proc.
3DPVT, volume 2, pages 1–8, 2010.

[14] N. Levi and M. Werman. The viewing graph. In Computer
Vision and Pattern Recognition, volume 1, pages I–I. IEEE,
2003.

[15] L. Magerand and A. Del Bue. Practical projective structure
from motion (p2sfm). In 2017 IEEE Int. Conf. on Computer
Vision (ICCV), pages 39–47. IEEE, 2017.

[16] J. Oliensis and R. Hartley.

Iterative extensions of the
sturm/triggs algorithm: Convergence and nonconvergence.
IEEE Trans. on Pattern Analysis and Machine Intelligence,
29(12):2217–2233, 2007.

[17] C. Olsson and O. Enqvist. Stable structure from motion for
unordered image collections. In Scandinavian Conf. on Im-
age Analysis, pages 524–535. Springer, 2011.

[18] O. Ozyesil and A. Singer. Robust camera location estimation
by convex programming. In IEEE Conf. on Computer Vision
and Pattern Recognition, pages 2674–2683, 2015.

[19] M. Pollefeys, L. Van Gool, M. Vergauwen, F. Verbiest,
K. Cornelis, J. Tops, and R. Koch. Visual modeling with
a hand-held camera.
Int. Journal of Computer Vision,
59(3):207–232, 2004.

[20] A. Rudi, M. Pizzoli, and F. Pirri. Linear solvability in the
viewing graph. In Asian Conf. on Computer Vision, pages
369–381. Springer, 2010.

3272

