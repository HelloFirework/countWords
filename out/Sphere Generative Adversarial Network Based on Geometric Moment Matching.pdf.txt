Sphere Generative Adversarial Network Based on Geometric Moment Matching

Sung Woo Park and Junseok Kwon

School of Computer Science and Engineering, Chung-Ang University, Seoul, Korea

pswkiki@gmail.com

jskwon@cau.ac.kr

Abstract

We propose sphere generative adversarial network
(GAN), a novel integral probability metric (IPM)-based
GAN. Sphere GAN uses the hypersphere to bound IPMs
in the objective function. Thus, it can be trained sta-
bly. On the hypersphere, sphere GAN exploits the in-
formation of higher-order statistics of data using geomet-
ric moment matching, thereby providing more accurate re-
sults.
In the paper, we mathematically prove the good
properties of sphere GAN. In experiments, sphere GAN
quantitatively and qualitatively surpasses recent state-of-
the-art GANs for unsupervised image generation problems
with the CIFAR-10, STL-10, and LSUN bedroom datasets.
Source code is available at https://github.com/
pswkiki/SphereGAN .

1. Introduction

Since the seminal work by Goodfellow et al. [8], gener-
ative adversarial networks (GANs) have attracted much re-
search interest, and they have been used to achieve outstand-
ing performance in a wide range of computer vision appli-
cations including in image generation [17, 26], super reso-
lution [14], video prediction [19], style transfer [5, 12, 34],
image inpainting [39], image editing [14], visual track-
ing [28], 3D reconstruction [1], segmentation [7], object
detection [35], reinforcement learning [10], and medical
imaging [40].

Conventional GANs try to minimize the distribution di-
vergence between fake and real data [8]. For this purpose,
the generator tries to produce desired samples that look like
real data, and the discriminator tries to differentiate them
from real data. Although GANs have been successfully ap-
plied to various tasks, it is very difﬁcult to train them, in
turn making it difﬁcult to use them to solve more complex
problems. For example, training dynamics frequently be-
come unstable, and the generated samples easily collapse to
a few modes.

While a lot of GANs and their applications have been
proposed recently, in this paper, we focus on GANs based

on integral probability metrics (IPMs) [2, 9, 24, 37] for
overcoming the aforementioned problems.
IPM-based
GANs insert a gradient penalty term or soft consistent term
into objective functions for achieving stable learning, re-
sulting in a remarkable improvement in performance. How-
ever, these additional terms inevitably introduce additional
hyper-parameters that need to be tuned, thereby incurring
higher computation cost.
In addition, many IPM-based
GANs suffer from the unstable behavior of the sample-
based constrain strategy, and WGAN uses only ﬁrst-order
statistics with a dual form of the 1-Wesserstein distance.

In this paper, we develop sphere GAN, a novel IPM-
based GAN. Sphere GAN uses geometric moment match-
ing and exploits the information of higher-order statistics
of data, thus obtaining accurate results. Because moment
matching is performed on the hypersphere, IPMs of sphere
GAN can be bounded. We show that the geometric con-
straint induced by the hypersphere makes GAN training
more stable. Sphere GAN affords these advantages without
relying on the heuristics of conventional IPM-based GAN,
namely, virtual sampling techniques and additional gradient
penalty terms.
Instead, sphere GAN utilizes Riemannian
manifolds (i.e., hypersphere) supported by the mathemati-
cal theory.

This paper makes three main contributions:
• We propose sphere GAN, a novel concept that afford
several advantages over IPM-based GANs. To the best
of our knowledge, our proposed sphere GAN is the
ﬁrst attempt to use Riemannian manifolds to deﬁne
IPMs in GAN objective functions.
In addition, it is
the ﬁrst IPM-based GAN that does not use the gradi-
ent penalty or virtual data sampling techniques.

• The good properties of sphere GAN are mathemati-
cally proven. In Section 4, we show that sphere GAN
is closely related to IPMs and that minimizing the pro-
posed distance amounts to minimizing the multiple
Wesserstein distances of probability measures on the
n-dimensional hypersphere Sn.

• Sphere GAN outperforms recent state-of-the-art meth-
ods including IPM-based GAN variants for unsu-

4292

pervised image generation problems with CIFAR-
10, STL-10, and LSUN bedroom datasets. Sphere
GAN signiﬁcantly improves the accuracy by efﬁ-
ciently matching higher order moments in feature
spaces.

2. Related Work

It is difﬁcult to measure the distance between two non-
overlapping probability distributions with low variances
when we utilize discrepancy measures based on Kullback-
Leibler (KL) divergence [2]. To overcome this problem,
IPM-based GAN variants [23] have been recently proposed
as alternatives for KL-divergence-based GANs. In IPMs,
the distance between two probability distributions is mea-
sured by the largest discrepancy in expectation over a cer-
tain class of functions, making it crucial to select a proper
class of functions in IPM-based GANs. In this section, we
discuss the advantages and disadvantages of several IPM-
based GAN variants.
Wesserstein distance: WGAN and its variants in [2, 9,
24, 37] use Wesserstein metrics to compare the probabil-
ity measures of real images with those of fake images. In
these methods, discriminators are modeled as a real-valued
1-Lipschitz function, which output a one-dimensional Eu-
clidean space. To enforce the Lipschitz condition, WGAN
clips the weights of discriminators such that they lie in a
compact interval [−c, c] [2]. However, weight clipping
leads to unstable learning and produces sub-optimal re-
sults [9]. To solve this problem, WGAN with a gradient
penalty (WGAN-GP) was proposed. However, the train-
ing time of WGAN-GP is almost two times that of other
methods because it needs to calculate the gradient norm in
every iteration. WGAN-CT [37] avoided this constraint by
combining the gradient penalty term with the soft consis-
tent term that penalizes violations of the 1-Lipschitz condi-
tion. WGAN-GP and WGAN-CT showed remarkable per-
formance; however, both methods need additional penalty
terms that can lead to sub-optimal solutions when penalty
weights are wrongly selected.

WGAN-CT trains networks with good heuristics; by
contrast sphere GAN does not sample virtual data points.
Unlike WGAN-GP [9], WGAN-CT [37], and WGAN-LP
[24], sphere GAN does not have an additional penalty term
[20], making its training time much shorter. We experimen-
tally demonstrate that sphere GAN achieves state-of-the-art
results without gradient constraints.
Maximum mean discrepancy (MMD) distance: WGAN
matches only ﬁrst-order moments in discriminator networks
[2]. By contrast, MMD GAN matches inﬁnite-order mo-
ments deﬁned on unit ball in Hilbert space [16]. MMD
GAN affords several advantages through the use of higher-
order statistics; however, it uses autoencoders to satisfy
the injectivity of networks and performs weight clipping to

bound the gradients for stable learning. Therefore, the ob-
jective functions in [16] considerably reduce the network
capacity. The MMD distance cannot handle complex natu-
ral images well because the pixel space is high dimensional.
In this case, the MMD distance produces low-quality sam-
ples and loses the diversity of representations.
Other IPMs:
Squared MMD with a speciﬁc kernel is
well known to be equivalent to the energy distance. The
Cram´er GAN used this energy distance to train GANs [3].
The critic function was parameterized by neural networks,
and then, the energy distance was maximized [30, 41]. Like
MMD GAN, Cram´er GAN imposed the Lipschitz constraint
on critic functions for achieving stable learning. By con-
trast, ﬁsher GAN [22] and Sobolev GAN [21] deﬁned func-
tion classes on the Lebesgue ball and the Sobolev space, re-
spectively, to avoid the Lipschitz constraint; however, they
need to solve an augmented Lagrangian to impose theoreti-
cal constraints on discriminators.

Like MMD GAN and Fisher GAN [22], sphere GAN
uses information of higher-order statistics in GAN objec-
tive functions. However, MMD GAN and Fisher GAN re-
quire expensive penalty terms to satisfy theoretical assump-
tions. By contrast, the objective function of sphere GAN
in (4) is simple and straightforward but also robust because
it is mathematically equivalent to using multiple Wesser-
stein distances deﬁned on a hypersphere. Section 4 provides
mathematical proofs of the fact that the objective function
(4) is closely related to IPMs.

3. Sphere GAN

This section introduces the novel sphere GAN and
shows that is has several advantages compared to state-of-
the-art IPM-based GANs.

3.1. Objective Function

The objective function based on the Wasserstein metric
directly matches the ﬁrst moment in the one-dimensional
feature space as follows.

min

G

max

D

Ex∼P [D(x)] − Ez∼N [D(G(z))],

(1)

where G and D denote the generator and discriminator, re-
spectively, and P and N represent real data and latent code
distributions, respectively. In (1), the discriminator D maps
data x to a real number R:

D : x ∈ X → R,

(2)

where D should satisfy the 1-Lipschitz condition D ∈
Lip1, and X ⊂ Rn is the n-dimensional Euclidean im-
age space. As in conventional IPM-based GANs, the ob-
jective function of our sphere GAN is based on (1). Un-
like in existing GANs that directly match the ﬁrst moment

4293

Figure 1. Pipeline of sphere GAN. Fake data is generated from noise inputs by a generator. Then, real and fake data are fed to a
discriminator, which maps the output to an n-dimensional Euclidean feature space (i.e., yellow plane). The green and purple circles on the
plane denote feature points of fake and real samples, respectively. By geometric transformation, these feature points are re-mapped into
the n-dimensional hypersphere (i.e., yellow sphere). By using theses mapped points, sphere GAN calculates geometric moments centered
at the north pole of the hypersphere. The discriminator of sphere GAN tries to maximize the moment differences of probability measures
between real and fake samples, while the generator tries to interfere with the discriminator by minimizing the moment differences. By
using the geometric moments deﬁned on the hypersphere, the generator and discriminator enhance their performance through a two-player
minmax game.

of one-dimensional feature spaces, sphere GAN matches
higher-order and multiple moments deﬁned on the hyper-
sphere. For this purpose, the discriminator outputs an n-
dimensional hypersphere Sn:

D : x ∈ X → Sn.

(3)

Then, the objective function of sphere GAN is deﬁned as

min

G

max

D Xr

Ex[dr

s(N, D(x)]−Xr

Ez[dr

s(cid:0)N, D(G(z))(cid:1)],

(4)
for r = 1,··· , R, where the function dr
s in (8) measures the
r-th moment distance between each sample and the north
pole of the hypersphere, N. Note that the subscript s indi-
cates that dr
s is deﬁned on Sn. Fig.1 shows the pipeline of
sphere GAN.

With the new objective function in (4), sphere GAN af-
fords advantages. First, by deﬁning IPMs on the hyper-
sphere, it can alleviate several constraints that should be
imposed on the discriminator. As mentioned above, con-
ventional discriminators based on the Wesserstein distance
require Lipschitz constraints, which forces the discrimina-
tors to be a member of 1-Lipschitz functions. However,
constraints with incorrect weight parameters λ consider-
ably reduce the network capacity and overly reﬂect sampled
points. For example, WGAN-GP, WGAN-CT, and WGAN-
LP in [9, 24, 37] require additional constraint terms in the
objective function for updating discriminators:

Ldisc = Ez[D(G∗(z))] − Ex[D(x)] + λC(x),

(5)

Table 1. Gradient penalty terms used in conventional GANs
based on the Wesserstein distance. GP, CT, and LP denote gradi-
ent penalty, soft consistency, and Lipschitz penalty terms, respec-
tively. ˆx denotes the feature points that are uniformly sampled
from straight lines from real to fake data points. x′, x′′ denote
virtual data points which are perturbed by dropout units.

Additional constraint term

GP

LP

Eˆxh(||∇ˆxD(ˆx)||2 − 1)2i

CT GP + Ex′,x′′ [max (0, d(D(x′), D(x′′))) − Const]

Eˆxhmax (0,||∇ˆxD(ˆx)||2 − 1)2i

where G∗ denotes the ﬁxed generator and C denotes addi-
tional constraint terms that are deﬁned in Table 1. In (5),
the gradient norm should be calculated at every iteration;
this increases the computational complexity. Unlike in con-
ventional approaches, sphere GAN does not need any ad-
ditional constraints that forces discriminators to lie in a de-
sired function space. By using geometric transformation,
sphere GAN ensures that distance functions lie in a desired
function space. Then, our new objective function for updat-
ing the weights of the discriminator is

Ldisc = Xr

Ez[dr

s(cid:0)N, D(G∗(z))(cid:1)]−Xr

Ex[dr

s(N, D(x)],

(6)
where there are no additional constraint terms. Algorithm 1
show the pseudo-code of sphere GAN.

4294

Algorithm 1 Sphere GAN
Input: Real data distribution P.
Output: Discriminator and generator parameters: w, θ
1: while θ has not converged do
2:

for r = 1 to R do

Sample real data x from P.
Sample random noise z from N (0, I).
L(r)
disc ← dr

s(cid:0)N, Dw(Gθ(z))(cid:1) − dr

s(cid:0)N, Dw(x)(cid:1)

end for
for r = 1 to R do

end for

Sample real data x from P.
Sample random noise z from N (0, I).
L(r)
gen ← −dr
w ← Adam(∇wPR
θ ← Adam(∇θPR

s(cid:0)N, Dw(Gθ(z))(cid:1)

r=1 L(r)
r=1 L(r)

disc, w)
gen, θ)

13:
14: end while

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

3.2. Hypersphere

As in (4), sphere GAN matches multiple moments over
the feature space deﬁned on the hypersphere Sn. Sphere
GAN uses the hypersphere instead of arbitrary Riemannian
manifolds M because doing so affords the following three
advantages.

1. The distance function dr

s of the hypersphere is bounded

and becomes very easy to implement.

2. The gradient norm behaves well with this distance

function, which is crucial for stable learning.

3. The Riemannian structure of the hypersphere is suit-

able for deﬁning GAN objectives.

Conventional GANs typically consider the Euclidean
space Rn with the Euclidean distance. These GANs can
be extended by modeling arbitrary Riemannian manifolds.
These manifolds are not compact and the distance function
is not bounded, which may cause gradient explosion and un-
stable learning. To solve this problem, sphere GAN uses a
geometric-aware transformation function, which transforms
the Euclidean space Rn to the hypersphere Sn. Note that
this function is implemented by the last dense layer of the
discriminator. Our transformation function is designed by a
diffeomorphism1 from Rn to Sn. Thus, the transformation
function is differentiable and can preserve dimensionality
at every point of the feature space. The next section intro-
duces stereographic projection as a geometric transforma-
tion function.

1The diffeomorphism is a bijective and differentiable function, which
preserves the dimensionality of the tangent space of the domain and image
smooth manifolds.

Figure 2. Inverse of stereographic projection on Euclidean
plane Π−1 : R2 → S2/{N}. Each red line denote the geodesics
on R2 and S2.

3.3. Geometric aware transformation function

The inverse of the stereographic projection is a diffeo-
morphism from the Euclidean space Rn to the hypersphere
Sn. Intuitively, the inverse of the stereographic projection
can be considered a way of projecting the hyperplane onto
the hypersphere. Let p = (p1, . . . , pn) be a coordinate sys-
tem of Rn and N = (0, . . . , 1) be a north pole of the hy-
persphere. Then, the inverse of the stereographic projection

Π−1 : Rn → Sn/{N} is deﬁned as follows:
, ||p||2 − 1
||p||2 + 1(cid:19) .

Π−1(p) = (cid:18)

||p||2 + 1

2p

(7)

After projecting two points p, q ∈ Rn through the inverse

of the stereographic projection, we measure the distance be-
tween two points, in terms of hypersphere metrics:

ds(Π−1(p), Π−1(q))

= arccos(cid:18)||p||2||q||2 − ||p||2 − ||q||2 + 4p · q + 1

(||p||2 + 1) (||q||2 + 1)

(cid:19) ,

(8)

where ds is the distance function deﬁned on Sn.

Geometrically, ds can be considered a geodesic dis-
tance. As shown in Fig.2, the geodesic distance between
two points on the hypersphere is much shorter than the Eu-
clidean distance and is bounded on the hypersphere (i.e.,
yellow sphere), thus implementing geometric transforma-
tion is equivalent to impose global constraint to hyperplane.
As a result, it enables stable training when using sphere
GAN with the objective function in (4).

Lemma 1. The distance function in (8) is differentiable and
is bounded.

The distance function in (8) satisﬁes non-negativity,
symmetry, and triangle inequality and is differentiable. The
distance between any two points is bounded, because the
hypersphere is a compact manifold. For example, the Eu-
clidean distance between two points 0 = (0, . . . , 0) and

4295

trast, the distance deﬁned on the hypersphere in (8) con-

q = (t, . . . , t) diverges: √nt2 → ∞ as t → ∞. By con-
nt2+1 (cid:17) → π as
verges: d(Π−1(0), Π−1(q)) = arccos(cid:16) −nt2+1
t → ∞. The geometric-aware transformation function of
sphere GAN makes the distribution divergence of the dis-
criminator outputs bounded, thereby enforcing stable train-
ing dynamics.
In addition, the function preserves the di-
mensionality of the feature spaces and maintains differen-
tiability.

4. Analysis of Sphere GAN

This section presents a mathematical analysis of sphere

GAN.

4.1. Link to IPMs

We ﬁrst prove that minimizing the objective function in
(4) amounts to minimizing IPMs. For this purpose, we de-
ﬁne geometric central moments on the Riemannian mani-
fold. Let M be the compact, connected, and geodesically
complete Riemannian manifold with Borel σ-algebra, Σ.
Both p ∼ P and q ∼ Q are probability measures deﬁned
on the measurable space (M, Σ). Then, the IPM is deﬁned
as follows:

Deﬁnition 1. The IPM is a distance measure between two
probability measures P and Q:

γ(P, Q) = sup

,

(9)

ZM

f dP −ZM

f ∈F(cid:12)(cid:12)(cid:12)(cid:12)

f dQ(cid:12)(cid:12)(cid:12)(cid:12)

where F is a class of real-valued bounded measurable func-
tions on M.

We can deﬁne the geometric moments on M:

Deﬁnition 2. The r-th central moment of P on (M, Σ) for
given a point p0 is

IPM of sphere GAN. While mr
P in (11) corresponds to
s(p0, D(x))] in (4), M can be replaced by Sn2 and
Ex[dr
x0 can be set to north pole N. Then, we obtain the same
equation as (4), which implies that minimizing the objec-
tive function in (4) amounts to minimizing IPMs in (11).

However, there are several differences between conven-
tional IPMs and the IPMs of sphere GAN. The function
space of our IPM is the set of bounded distance functions
on M centered at p0, Cp0 (M). Thus, sphere GAN parame-
terizes distance functions:

Ex[dr

s(p0, D(x))] ≃

1
N

N

Xi=1

dr
s(p0, D(xi)),

(12)

where {xi} is the set of images. By contrast, the function
space of the IPM of WGAN is the set of 1-Lipschitz dis-
criminators. Thus, it parameterizes discriminators.

Ex[D(x)] ≃

N

Xi=1

D(xi),

(13)

where D ∈ Lip1.
4.2. Link to Wesserstein distance

γSn is the IPM of sphere GAN deﬁned in (11), where
M = Sn. The generator of sphere GAN aims to reduce γS,
which is equivalent to matching higher-order central mo-
ments between two probability measures P and Q deﬁned
on Sn:

Proposition 1. As P weakly converges to Q,

• γSn → 0
• mr
P → mr
Let W r

Q for all r

Sn be the r-Wesserstein distance of probability
measures deﬁned on Sn. Then, minimizing γSn is equiv-
alent to minimizing the summation of r-Wesserstein dis-
tances over all r.

dr(p0, p)dP(p),

(10)

Proposition 2. As γSn converges to 0,

mr

P = ZM
where 1 ≤ r < ∞ and mr
distance function on M.

P < ∞. dr is the Riemannian

In sphere GAN, we deﬁne a new IPM between P and Q:

Deﬁnition 3. The IPM based on the moment difference is

γM(P, Q) = sup

d∈Cp0 (M)Xr (cid:12)(cid:12)mr
where Cp0 (M) is a class of bounded distance functions from
a given point p0 to another point on M.

Q(cid:12)(cid:12) ,
P − mr

(11)

When we compare Deﬁnition 1 with Deﬁnition 3,
we note relations between conventional IPMs and the

Xr

W r

Sn (P, Q) → 0.

(14)

The result of Proposition 2 is not surprising because
weak convergence is strongly related to the Wesserstein dis-
tance [33]. In conventional GANs based on the Wesserstein
distance [2, 9, 24, 37], objective functions are designed as a
dual form by the Kantorovich-Rubinstein duality theorem.
In the dual form, only the 1-Wesserstein distance can be im-
plemented for achieving efﬁcient learning of GANs. Con-
trary to conventional GANs, sphere GAN can use more gen-
eral r-Wesserstein distances, and thus, the function space is
much broader.

2Note that the hypersphere satisﬁes all assumptions mentioned earlier

in this section.

4296

4.3. Gradient Analysis

By using γSn over other IPMs, sphere GAN can com-
pute the gradients of loss functions by choosing different
moments of γSn . The selection of different moments leads
to different learning behaviors as the gradients differ. We
found that any moment enables stable learning using sphere
GAN.

Lemma 2. Ex∼P(cid:2)||∇xdr

s(N, D(x))||2(cid:3) < ∞ for all r.

Lemma 2 tells us that using the hypersphere is a rea-
sonable choice for stably learning GANs, where the norm
of gradient is bounded during the training. But our sphere
GAN can have large gradients because no penalty is im-
posed on the discriminator. Thus, it has a potential risk of
gradient explosion. However, in experiments, we observed
that the average magnitude of the norm of gradients at each
iteration is affordable when using the Adam optimizer.

5. Experiments

5.1. Implementation Details

Hyper-parameters: The network was trained with batch
size of 64.
In all experiments, we used the Xavier ini-
tialization and Adam optimizer for both the generator and
the discriminator. We ﬁxed the hyper-parameters of the
Adam optimizer for the generator and discriminator to α =
1E − 4, β1 = 0, β2 = 0.9.
In experiments using Con-
vNet, we set the moment modes to P5
1 dr. In other exper-
iments, we set the dimension of the hypersphere to S1024
and the moment modes to P3
In conventional IPM-
based GANs, the discriminator was updated multiple times
and the generator, one time, per iteration. Contrary to these
GANs, in sphere GAN, both networks were updated one
time per iteration3.
Geometric Block: We added the geometric block to the
last convolutional layer of the discriminator for geometric-
aware transformation. The discriminator (D) and geometric
block (GB) were designed as follows:

1 dr.

D : X → ConvBlocks → GB

GB : ReLU → AverageMeanPooling
→ DenseLayer(Rn) → ISGP(Sn ⊂ Rn+1),

where X ⊂ Rn is an input and ISGP denotes the inverse of

stereo-graphic projection. The pseudo code for ISGP and
detailed network structures are provided in the supplemen-
tary materials.
Baseline Network: We conducted unsupervised image
generation tasks using two baseline networks: ConvNet and
ResNet. For ConvNet, we followed the network architec-
ture proposed in [20] to build both the generator and the

discriminator. It consists of transposed convolutional blocks
in the generator and convolutional blocks in the discrimina-
tor, in which each blocks consists of two convolutional lay-
ers. For ResNet, we followed the network architectures pro-
posed in [9]. In both discriminator networks, we used layer
normalization [15] for the normalization unit suggested in
[22], and we attached the geometric block GB to the last
convolutional block for geometric transformation. Details
of the network architectures are provided in the supplemen-
tary materials.
Environments: All experiments were conducted using a
single GTX Titan GPU. Sphere GAN was implemented us-
ing Keras-2.2.4 with Tensorflow-1.11.0 back-
end.

5.2. Dataset and Evaluation Metrics

Dataset: We conducted experiments on CIFAR-10 [13],
STL-10 [6], and LSUN [38] datasets. CIFAR-10 and STL-
10 contains around 50K and 100K natural images of size
32 × 32 and 96 × 96 with 10 different classes, respectively.
For STL-10, we downsized original images to a size of 48×
48. For LSUN, we used around 3M bedroom images that
were resized to 64 × 64.
Evaluation Metrics: To quantitatively evaluate the net-
works, we used two metrics for image generation tasks: in-
ception score (IS) [27] and Fr´echet inception distance (FID)
[11]. By using these metrics, we compared sphere GAN
against other IPM-based GANs with various datasets. In all
experiments, we generated 50K images to evaluate GANs
in terms of IS and FID. For implementation, we used open
source code provided by the authors4.

IS is strongly correlated to human judgment and in-
ception. The generated images were applied to an in-
ception convolutional network [29] to obtain the condi-
tional distribution p(y|x), and IS was calculated as follows:
exp(cid:0)E(cid:2)DKL[p(y|x)||p(y)](cid:3)(cid:1) where p(y) is approximated
by 1
n=1 p(y|xn). On the other hand, FID overcomes
the problems of IS by estimating the 2-Wesserstein distance
of Gaussian distributions induced by the outputs of hidden
activation (pool3 of inception model). FID is consistent
with increasing disturbances and human judgment. FID be-
tween two image distributions P1, P2 is deﬁned as follows:

N PN

FID(P1, P2) = ||m1 − m2||2
2 ),
(15)
where mi and Ci are the Gaussian mean and covariance
matrix obtained from Pi, respectively.

2+T r(C1+C2−2(C1C2)

1

5.3. Ablation Study

This section aims to answer the following three ques-

tions:

3One study has investigated the dynamics of learning GANs [11]. How-

4 IS: https://github.com/openai/improved-gan, FID:

ever, it is difﬁcult to perform direct comparisons and analyses.

https://github.com/bioinf-jku/TTUR.

4297

Mode 1
Mode 2
Mode 3

e
r
o
c
s
 
n
o

i
t

p
e
c
n

I

7.6

7.4

7.2

7

6.8

6.6

6.4

6.2

6

16

64

256

1024

Dimension of hypersphere

Figure 3. Inception scores (IS) on CIFAR-10 with ConvNet ac-
cording to different moment matching modes and different dimen-
sions of hypersphere. Red, yellow, and blue bars denote mo-
ment modes: P1 dr, P3
1 dr, respectively. The hor-
izontal axis denotes the dimensions of hypersphere Sn : n =
16, 64, 256, 1024.

1 dr, and P5

Figure 4. Norm of gradient for Sphere GAN and WGAN-GP
discriminator networks.

Q1: Does training GANs with higher moments improve the
quality of samples?
Q2: Does training GANs with higher dimensions of the hy-
persphere improve performance?
Q3: Does the norm of gradients behave well during train-
ing?

Answer to Q1: We conducted unsupervised image gen-
eration tasks with different moments to show that higher
moments help to improve performance. In this experiment,
various summation modes were used for the GAN objec-
tive. As shown in Fig.3, matching higher moments in the
feature space considerably improves performance. We ob-
served that higher than ﬁfth-order moments deteriorate the
performance in the CIFAR-10 dataset, because higher mo-
ments induces high magnitude of gradients, and this may
i=1 dr
was suitable for large networks in general. Conventional
GANs based on the Wesserstein distance did not improve
their accuracy as higher-order moments were used.

cause unstable learning. However, in experiments,P3

Table 2. Unsupervised image generation results on CIFAR-10.
IS : higher is better, FID : lower is better. For networks with ⋆, we
used the results reported in [20].

Method

CIFAR-10 (real)

MMD GAN [16]
Weight clipping⋆
WGAN-GP⋆
Spectral Norm-WD⋆
Sphere GAN-Conv
WGAN-GP-ResNet [9]
χ2 GAN [31]
Fisher GAN [22]
Coulomb GAN [32]
Spectral Norm-WD⋆
WGAN-LP [24]
WGAN-CT [37]
Spectral Norm [20]
Sphere GAN-ResNet

IS

11.24 ± .12
6.17 ± .07
6.41 ± .11
6.68 ± .06
7.20 ± .08
7.57 ± .05
7.86 ± .07
7.88 ± .10
7.90 ± .05
7.96 ± .06
8.02 ± .08
8.12 ± .12
8.22 ± .05
8.39 ± .08

-

FID

7.8

-

42.6
40.2
32.0

-
-
-
-

27.3
22.5

-
-

21.7
17.1

Answer to Q2: We observed that the dimensions of the
hypersphere should be large enough to ensure that the in-
formation contained in the feature space is meaningful in
using geometric moments. In other methods where the fea-
ture space is one dimension (e.g., Wesserstein distance), the
dimension of the feature space was not enough to deliver
the information of higher-order statistics. As demonstrated
in Fig.3, higher dimensions of the hypersphere signiﬁcantly
improved the accuracy of sphere GAN.
Answers to Q3: We evaluated the norm of gradients at
each iteration to show that GANs can be trained stably
with the proposed metric. As shown in Fig.4, the norm of
gradients started to converge after 100K iterations, while
WGAN-GP easily attained the convergence.
In sphere
GAN, the norm of gradients was smoothly bounded with
the proposed metric.

5.4. Quantitative and Qualitative Results

CIFAR-10 :
Table 2 summarizes quantitative results.
Sphere GAN-ResNet achieved state-of-the-art scores for
both IS and FID with a large margin. Sphere GAN-Conv
also outperformed WGAN-GP and MMD GAN.
STL-10 :
In experiments with STL-10, we used approx-
imately one-half the number of network parameters com-
pared to the original network used in [20]. Despite the
small number of network parameters, sphere GAN-ResNet
signiﬁcantly outperformed SN-GAN and other IPM-based
GANs, as shown in Table 3.
LSUN Bedroom :
In this experiment, we reported FID
only because IS was not meaningful, as noted in [4]. The
results in Table 4 indicate that sphere GAN-ResNet outper-
formed state-of-the-art GANs.

4298

Table 3. Unsupervised image generation results on STL-10. For
networks with ⋆, we used the results reported in [20].

Method

STL-10 (real)
Weight clipping⋆
WGAN-GP⋆
Sphere GAN-Conv
Warde-Farley [36]
Spectral Norm⋆
Sphere GAN-ResNet

IS

26.08 ± .26
7.57 ± .10
8.42 ± .13
8.43 ± .09
8.51 ± .13
9.10 ± .04
9.55 ± .11

FID

7.9
64.2
55.1
44.1

-

40.1
31.4

Table 4. Unsupervised image generation results on LSUN Bed-
room. For networks with ⋆, we used the results reported in [4].

Method

LSUN Bedroom (real)
Cram´er GAN⋆
WGAN-GP⋆
MMD-GAN-rq⋆
Sphere GAN

FID

2.36
54.2
41.4
32.0
16.9

1
5

s
n
o

i
t

a
r
e

t
i
 

0
0
1

 
r
o

f
 

d
n
o
c
e
s
 

e
g
a
r
e
v
A

8

7

6

5

4

3

2

1

0

WGAN-GP WGAN-CT

LSGAN

DCGAN SphereGAN

Figure 5. Averaged computation time over 100 iterations for
different GAN variants. The yellow and red bars denote the av-
eraged computation time when the updating ratio of the generator
and discriminator is 1 : 1 and 1 : 5, respectively.

Training Time: In Fig.5, we calculated the averaged train-
ing time over 100 iterations for different methods. WGAN-
CT and WGAN-GP were clearly much slower than other
methods (around 40% slower than DCGAN) because they
calculate the norm of gradients ||∇ˆxD(ˆx)||2 at every itera-
tion. The training time of sphere GAN is much shorter than
that of other IPM-based GANs and almost the same as that
of vanilla DCGAN [25] and LSGAN [18].

We qualitatively evaluated sphere GAN using three
datasets. Figs.6 and 7 show the qualitative results of sphere
GAN for the LSUN-bedroom and STL-10 datasets, respec-
tively. The qualitative results indicate that sphere GAN was
trained stably and hardly suffered from mode collapse prob-
lems. Most generated images are photo-realistic.

6. Conclusion

This paper proposes sphere GAN, a novel IPM-based
GAN. Sphere GAN deﬁnes IPMs on the hypersphere (i.e.,

Figure 6. Qualitative results of sphere GAN for LSUN-bedroom
dataset

Figure 7. Qualitative results of sphere GAN for STL-10 dataset

a type of Riemannian manifolds), and therefore, it can be
trained stably using bounded IPMs. High-order moment
matching enables sphere GAN to exploit useful information
about data and to provide accurate results. Experimental re-
sults demonstrate that sphere GAN shows state-of-the-art
performance compared to IPM-based GANs for the LSUN,
STL-10, and CIFAR-10 datasets.

Acknowledgements

This work was supported by Institute for Information &
communications Technology Planning & evaluation(IITP)
grant funded by the Korea government(MSIT) (No.2017-0-
01780).

4299

References

[1] P. Achlioptas, O. Diamanti, I. Mitliagkas, and L. Guibas.
Learning representations and generative models for 3d point
clouds. In ICLR, 2018. 1

[2] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein gener-

ative adversarial networks. In ICML, 2017. 1, 2, 5

[3] M. G. Bellemare, I. Danihelka, W. Dabney, S. Mohamed,
B. Lakshminarayanan, S. Hoyer, and R. Munos. The cramer
distance as a solution to biased wasserstein gradients. arXiv
preprint arXiv:1705.10743, 2017. 2

[4] M. Bikowski, D. J. Sutherland, M. Arbel, and A. Gretton.

Demystifying MMD GANs. In ICLR, 2018. 7, 8

[5] Y. Chen, Y.-K. Lai, and Y.-J. Liu. Cartoongan: Genera-
tive adversarial networks for photo cartoonization. In CVPR,
2018. 1

[6] A. Coates, A. Ng, and H. Lee. An analysis of single-layer
In AISTATS,

networks in unsupervised feature learning.
2011. 6

[7] K. Ehsani, R. Mottaghi, and A. Farhadi. Segan: Segmenting

and generating the invisible. In CVPR, 2018. 1

[8] I. Goodfellow,

J. Pouget-Abadie, M. Mirza, B. Xu,
D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Gen-
erative adversarial nets. In NIPS, 2014. 1

[9] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C.
Courville. Improved training of wasserstein GANs. In NIPS,
2017. 1, 2, 3, 5, 6, 7

[10] P. Henderson, W.-D. Chang, P.-L. Bacon, D. Meger,
J. Pineau, and D. Precup. Optiongan: Learning joint reward-
policy options using generative adversarial inverse reinforce-
ment learning. In AAAI, 2018. 1

[11] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and
S. Hochreiter. GANs trained by a two time-scale update rule
converge to a local nash equilibrium. In NIPS, 2017. 6

[12] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image
translation with conditional adversarial nets. In CVPR, 2017.
1

[20] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida. Spectral
normalization for generative adversarial networks. In ICLR,
2018. 2, 6, 7, 8

[21] Y. Mroueh, C.-L. Li, T. Sercu, A. Raj, and Y. Cheng. Sobolev

GAN. In ICLR, 2018. 2

[22] Y. Mroueh and T. Sercu. Fisher gan. In NIPS, 2017. 2, 6, 7

[23] A. M¨uller.

Integral probability metrics and their generat-
ing classes of functions. Advances in Applied Probability,
29(2):429–443, 1997. 2

[24] H. Petzka, A. Fischer, and D. Lukovnikov. On the regular-

ization of wasserstein GANs. In ICLR, 2018. 1, 2, 3, 5, 7

[25] A. Radford, L. Metz, and S. Chintala. Unsupervised repre-
sentation learning with deep convolutional generative adver-
sarial networks. arXiv preprint arXiv:1511.06434, 2015. 8

[26] S. Reed, Z. Akata, L. X. Yan, B. Logeswaran, Schiele, and
H. Lee. Generative adversarial text to image synthesis. In
ICML, 2016. 1

[27] T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Rad-
ford, and X. Chen. Improved techniques for training GANs.
In NIPS, 2016. 6

[28] Y. Song, C. Ma, X. Wu, L. Gong, L. Bao, W. Zuo, C. Shen,
R. Lau, and M.-H. Yang. Vital: Visual tracking via adversar-
ial learning. In CVPR, 2018. 1

[29] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna.
Rethinking the inception architecture for computer vision. In
CVPR, 2016. 6

[30] G. J. Sz´ekely and M. L. Rizzo. Energy statistics: A class of
statistics based on distances. Journal of statistical planning
and inference, 143(8):1249–1272, 2013. 2

[31] C. Tao, L. Chen, R. Henao, J. Feng, and L. C. Duke. Chi-

square generative adversarial network. In ICML, 2018. 7

[32] T. Unterthiner, B. Nessler, C. Seward, G. Klambauer,
M. Heusel, H. Ramsauer, and S. Hochreiter. Coulomb
GANs: Provably optimal nash equilibria via potential ﬁelds.
In ICLR, 2018. 7

[33] C. Villani. Optimal Transport: Old and New. Springer Berlin

[13] A. Krizhevsky. Learning multiple layers of features from

Heidelberg, 2008. 5

tiny images. Technical report, Citeseer, 2009. 6

[14] C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunningham,
A. Acosta, A. P. Aitken, A. Tejani, J. Totz, Z. Wang, and
W. Shi. Photo-realistic single image super-resolution using a
generative adversarial network. In CVPR, 2017. 1

[15] J. Lei Ba, J. R. Kiros, and G. E. Hinton. Layer normalization.

arXiv preprint arXiv:1607.06450, 2016. 6

[16] C.-L. Li, W.-C. Chang, Y. Cheng, Y. Yang, and B. Poczos.
Mmd gan: Towards deeper understanding of moment match-
ing network. In NIPS, 2017. 2, 7

[17] J. Lin, Y. Xia, T. Qin, Z. Chen, and T.-Y. Liu. Conditional

image-to-image translation. In CVPR, 2018. 1

[18] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. P. Smol-
ley. Least squares generative adversarial networks. arXiv
preprint arXiv:1611.04076, 2017. 8

[34] X. Wang and A. Gupta. Generative image modeling using
style and structure adversarial networks. In ECCV, 2016. 1

[35] X. Wang, A. Shrivastava, and A. Gupta. A-fast-rcnn: Hard
In

positive generation via adversary for object detection.
CVPR, 2017. 1

[36] D. Warde-Farley and Y. Bengio. Improving generative adver-
sarial networks with denoising feature matching. In ICLR,
2017. 8

[37] X. Wei, Z. Liu, L. Wang, and B. Gong. Improving the im-
proved training of wasserstein GANs. In ICLR, 2018. 1, 2,
3, 5, 7

[38] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and
J. Xiao. Lsun: Construction of a large-scale image dataset
using deep learning with humans in the loop. arXiv preprint
arXiv:1506.03365, 2015. 6

[19] M. Mathieu, C. Couprie, and Y. LeCun. Deep multi-scale
video prediction beyond mean square error. In ICLR, 2016.
1

[39] J. Yu, Z. Lin, J. Yang, X. Shen, X. Lu, and T. S. Huang.
In

Generative image inpainting with contextual attention.
CVPR, 2018. 1

4300

[40] Z. Zhang, L. Yang, and Y. Zheng. Translating and seg-
menting multimodal medical volumes with cycle- and shape-
consistency generative adversarial network. In CVPR, 2018.
1

[41] J. Zhao, M. Mathieu, and Y. LeCun. Energy-based generative

adversarial network. In ICLR, 2017. 2

4301

