A Local Block Coordinate Descent Algorithm for the CSC Model

Ev Zisselman

Technion

Jeremias Sulam

Johns Hopkins University

Michael Elad

Technion

Israel Institute of Technology
ev zis@campus.technion.ac.il

jsulam1@jhu.edu

Israel Institute of Technology

elad@cs.technion.ac.il

Abstract

The Convolutional Sparse Coding (CSC) model has re-
cently gained considerable traction in the signal and im-
age processing communities. By providing a global, yet
tractable, model that operates on the whole image, the CSC
was shown to overcome several limitations of the patch-
based sparse model while achieving superior performance
in various applications. Contemporary methods for pur-
suit and learning the CSC dictionary often rely on the Al-
ternating Direction Method of Multipliers (ADMM) in the
Fourier domain for the computational convenience of con-
volutions, while ignoring the local characterizations of the
image. In this work we propose a new and simple approach
that adopts a localized strategy, based on the Block Coor-
dinate Descent algorithm. The proposed method, termed
Local Block Coordinate Descent (LoBCoD), operates lo-
cally on image patches. Furthermore, we introduce a novel
stochastic gradient descent version of LoBCoD for training
the convolutional Ô¨Ålters. This Stochastic-LoBCoD lever-
ages the beneÔ¨Åts of online learning, while being applicable
even to a single training image. We demonstrate the advan-
tages of the proposed algorithms for image inpainting and
multi-focus image fusion, achieving state-of-the-art results.

1. INTRODUCTION

Sparse representation has been shown to be a very pow-
erful model for many real-world signals, leading to impres-
sive results in various restoration tasks such as denoising
[10], deblurring [7], inpainting [11, 25], super-resolution
[7, 40] and recognition [37], to name a few. The core as-
sumption of this model is that signals can be expressed as
a linear combination of a few columns, also called atoms,

taken from a matrix D ‚àà RN √óM termed a dictionary. Con-
cretely, for a signal X ‚àà RN , the model assumption is that
X = DŒì + V , where V is a noise vector with bounded
energy kV k2 < «´, which allows for a slight deviation from
the model and/or may account for noise in the signal. The

vector Œì ‚àà RM is the sparse representation of the signal,

obtained by solving the pursuit problem [1, 9]:

ÀÜŒì = arg min

Œì

kŒìk0 s.t. kX ‚àí DŒìk2 < «´,

(1)

where kŒìk0 counts the number of non-zeros in Œì. The solu-
tion of problem (1) can be approximated using greedy algo-
rithms such as Orthogonal Matching Pursuit (OMP) [4] or
convex relaxation algorithms such as Basis Pursuit (BP) [5].
Over the years, various methods have been proposed to
adaptively learn the dictionary D from real data. Prime ex-
amples are K-SVD [1], MOD [12], Double sparsity [29],
Online dictionary learning [24], Trainlets [33], and more.

When dealing with high-dimensional signals, learning
the dictionary suffers from the curse of dimensionality, ren-
dering this task infeasible. To cope with this problem,
many algorithms suggest training a local model on fully-
overlapping patches taken from the signal X. This patch-
based technique has gained much popularity due to its sim-
plicity and high-performance [7, 10, 25, 40]. Yet, patch-
based approaches are known to be sub-optimal as they ig-
nore the relations between neighboring patches [28, 32].

An alternative approach to meet this challenge is posed
by the Convolutional Sparse Coding (CSC) model. This
model assumes that the signal can be represented as a su-
perposition of a few local Ô¨Ålters, convolved with sparse
feature-maps. The CSC model utilizes a structured dictio-
nary (union of narrowly banded convolutional matrices) that
facilitates a global handling of the signal. This model has
been the subject of an extensive research in the past several
years, shown to lead to superior performance in applica-
tions such as super-resolution [17], inpainting [18], image
separation [26], source separation [20] and audio process-
ing [16].

Contemporary CSC based algorithms often rely on the
ADMM [2] formulation for representation-extraction and
Ô¨Ålter-training. While the majority of works employ ADMM
in the Fourier domain [3, 18, 35], a recent approach (SBDL)
proposed by Papyan at el. [26], adopts a local point of view
and trains the Ô¨Ålters in terms of only local computations
in the signal domain. The SBDL algorithm demonstrates

8208

state-of-the-art performance compared to the Fourier-based
methods, albeit still relying on the ADMM algorithm. As
such, this approach incurs additional memory and sensitiv-
ity to additional parameters, it only accommodates a batch-
learning mode, and its convergence is questionable1.

In this work we propose intuitive and easy-to-implement
algorithms, based on the block coordinate descent ap-
proach, for solving the global pursuit and the CSC Ô¨Ålter
learning problems, all done with local computations in the
original domain. The proposed pursuit algorithm operates
without auxiliary variables nor extra parameters for tun-
ing. We call this algorithm Local Block Coordinate De-
scent (LoBCoD). In addition, we introduce a stochastic gra-
dient descent variant of LoBCoD for training the convolu-
tional Ô¨Ålters. This algorithm leverages the beneÔ¨Åts of online
learning, while being applicable even to a single training-
image. The LoBCoD algorithm and its stochastic version
show faster convergence and achieve a better solution to
the CSC problem compared to the previous ADMM-based
methods (global or local).

The rest of this paper is organized as follows: Section
2 reviews the CSC model and discusses previous methods.
The proposed pursuit algorithm is presented in Section 3. In
Section 4 we discuss dictionary update methods and intro-
duce the stochastic LoBCoD algorithm. We compare these
methods with previously published approaches in section
5. Section 6 extends our methods to image inpainting and
multi-focus image fusion, followed by empirical results in
Section 7. Section 8 concludes this work.

2. Convolutional sparse coding

The CSC model assumes that a signal2 X ‚àà RN can
be represented by the sum of m convolutions. These are
built by feature maps {Zi}m
i=1, each of length of the original
signal N , convolved with m small support Ô¨Ålters {di}m
i=1
of length n ‚â™ N . In the dictionary learning problem, one
minimizes the following cost function over both the Ô¨Ålters
and the feature maps3:

min
di,Zi

1
2kX ‚àí

mX

i=1

di ‚àó Zik2

2 + Œª

mX

i=1

kZik1.

(2)

Given the Ô¨Ålters, the above problem becomes the CSC pur-
suit task of Ô¨Ånding the representations {Zi}m
i=1. Consider
a global dictionary D to be the concatenation of m banded
circulant matrices, where each matrix represents a convolu-
tion with one Ô¨Ålter di. By permuting its columns, the global
dictionary D consists of all shifted versions of a local dic-
tionary DL of size n √ó m, containing the Ô¨Ålters {di}m

i=1

1While SBDL‚Äôs pursuit method is provably converging, this is no longer

true when the dictionary is updated within the ADMM.

2The description given focuses on 1D signals for simplicity of the pre-
sentation, and all our treatment applies to higher dimensions just as well.

3We assume that the Ô¨Ålters are normalized to a unit l2-norm.

Figure 1: The CSC model and its local components.

as its columns, and the global sparse vector Œì is simply the
interlaced concatenation of all the feature maps {Zi}m
i=1.
Such a structure is depicted in Figure 1. Using the above
formulation, the convolutional dictionary learning problem
(2) can be rewritten as

min
D,Œì

1
2kX ‚àí DŒìk2

2 + ŒªkŒìk1.

(3)

Similar to our earlier comment, when D is known, we ob-
tain the CSC pursuit problem, deÔ¨Åned as

min

Œì

1
2kX ‚àí DŒìk2

2 + ŒªkŒìk1.

(4)

Herein, we review some of the deÔ¨Ånitions from [27] as they
will serve us later for the description of our algorithms.

i=1

PT
i

DLŒ±i, where PT

as X = PN

The global sparse vector Œì can be broken into N non-
overlapping m dimensional local vectors Œ±i, referred to as
needles. This way, one can express the global vector X
i ‚àà RN √ón is the oper-
ator that positions DLŒ±i in the i-th location and pads the
rest of the entries with zeros. On the other hand, a patch
PiX = PiDŒì taken from the signal X equals to ‚Ñ¶Œ≥i (see
Figure 1), where ‚Ñ¶ ‚àà Rn√ó(2n‚àí1)m is a stripe dictionary
containing DL in its center, and Œ≥i is the stripe vector con-
taining the local vector Œ±i in its center. In other words, a
stripe Œ≥i is the sparse vector that codes all the content in
the patch PiX, whereas a needle Œ±i only codes part of the
information within it.

The theoretical work in [27] suggested an analysis of the
CSC global model, augmented by a localized sparsity mea-
sure. Inspired by this analysis, herein we maintain such a
local-global decomposition and propose a global algorithm
that operates locally on image patches.

3. Proposed Method: CSC Pursuit

3.1. Local Block Coordinate Descent

In this section we focus on the pursuit of the representa-
tions, leaving the study of updating the dictionary for Sec-
tion 4. The convolutional sparse coding problem presented
in the previous section is solved by minimizing the global

8209

=Œ≥i‚àà‚Ñù2ùëõ‚àí1ùëöùêèiX‚àà‚ÑùùëõŒ±i‚àà‚ÑùùëöùêÉ‚àà‚ÑùùëÅ√óùëÅùëöX‚àà‚ÑùùëÅŒì‚àà‚ÑùùëÅùëöùêÉùêø‚àà‚Ñùùëõ√óùëöùõÄ‚àà‚Ñùùëõ√ó2ùëõ‚àí1ùëö‚ãÆ‚ãÆ‚ãÆ‚ãÆobjective of Equation (4). In this paper, we adopt a local
strategy and split the global sparse vector Œì into local vec-
tors, needles Œ±i, and express the global CSC problem in
term of such needles and the local dictionary DL by

min

DL,{Œ±i}

1
2kX ‚àí

NX

i=1

PT
i

DLŒ±ik2

2 + Œª

NX

i=1

kŒ±ik1.

(5)

However, rather than optimizing with respect to all the nee-
dles together, we suggest to treat the needles sequentially,
and optimize with respect to each block Œ±i separately. As
such, the update rule of each needle can be written as

min
Œ±i

1
2k(X ‚àí

NX

j=1
j6=i

PT
j

DLŒ±j) ‚àí PT

i

DLŒ±ik2

2 + ŒªkŒ±ik1.

Algorithm 1: The stochastic LoBCoD pursuit and dic-
tionary learning algorithm

Input: signal X, initial DL, initial needles {Œ±0
Output: needles {Œ±i}N
Initialization: R = X ‚àí bX, bX = PN
k = 0
while not converged do

i}N
i=1
i=1, the trained dictionary DL
DLŒ±0
i ,

PT
i

i=1

k = k + 1
for j = 1:n do

Computation of the residual:
PT
i

Rj = R + X

DLŒ±k‚àí1

i

i‚ààLj

Sparse pursuit: ‚àÄi ‚àà Lj (in parallel)
1
2kPiRj ‚àí DLŒ±ik2
Œ±k
i = arg min

Œ±i

2 + ŒªkŒ±ik1

By deÔ¨Åning Ri = (X‚àíPN

j=1
j6=i

(6)
DLŒ±j) as the residual im-

PT
j

age without the contribution of the needle Œ±i, we can rewrite
Equation (6) as

min
Œ±i

1
2kRi ‚àí PT

i

DLŒ±ik2

2 + ŒªkŒ±ik1.

(7)

While the above minimization involves global variables,
such as the residual Ri, one can show4 that this can be de-
composed into an equivalent and local problem:

min
Œ±i

1
2kPiRi ‚àí DLŒ±ik2

2 + ŒªkŒ±ik1.

(8)

end

end

Computation of the reconstructed signal:

bX = bX + X

i‚ààLj

PT
i

DL(Œ±k

i ‚àí Œ±k‚àí1

i

)

Computation of the residual signal:

R = X ‚àí bX

Computation of the gradient w.r.t DL:

‚àáDL = ‚àí X

i‚ààLj

i )T
PiR¬∑ (Œ±k

Dictionary update:

DL = P1[DL ‚àí Œ∑‚àáDL ]

This follows from the observation that the update rule of the
needle Œ±i is affected only by pixels of the corresponding
patch PiRi (the part that fully overlaps with DLŒ±i).

The main idea of the block coordinate descent algorithm
is that every step minimizes the overall penalty w.r.t. a cer-
tain block of coordinates, while the other ones are set to
their most updated values. Following this idea, every local
pursuit (8) proceeds by updating the global reconstructed

signal bX and the global residual R = X ‚àí bX, as a prepro-

cessing stage that precedes the update of the next needle,
based on the most updated values of the previous needles.

An important insight is that needles that have no foot-
print overlap in the image can be updated efÔ¨Åciently in
parallel in the above algorithm without changing the algo-
rithm‚Äôs outcome. This enables employing efÔ¨Åcient batch-
implementations of the LARS algorithm [8]. Alternatively,
the calculation can be distributed across multiple processors
to gain a signiÔ¨Åcant speedup in performance. To formalize
these observations, we deÔ¨Åne the layer Li as the set of nee-
dles that have no induced overlap in the image. We sweep
through these layers and update their respective needles in
parallel, followed by updating the global reconstructed sig-

nal bX and the global residual R. This way, the number of

4The proof is provided in the supplementary material.

the layers imposes the number of the inner iterations, which
will determine the complexity of our Ô¨Ånal algorithm. In that
manner, the number of the inner iterations depends only on

the patch size; for ‚àön √ó ‚àön patches, the number of layers

is n. This pursuit algorithm is presented in Algorithm 1.
Note that this algorithm can clearly be extended to iterate
over multiple signals, but for the sake of brevity we assume
that the data corresponds to an individual signal X.

3.2. Boundary Conditions and Initialization

In the formulation of the CSC model, as shown in Figure
1, we assumed that the dictionary is comprised of a set of
banded circulant matrices, which impose a circulant bound-
ary conditions on the signals.
In practice, however, sig-
nals and images do not exhibit circulant boundary behavior.
Therefore, our model incorporates a preemptive treatment
of the boundaries. We adopt a similar approach to [26], in
which the signal boundaries are padded with n‚àí 1 elements
prior to decomposing it with the model. At the end of the
process, we discard the added padding by cropping the n‚àí1
boundary elements from the reconstructed signal and from
the resulting feature maps (sparse representation).

8210

Another beneÔ¨Åcial preprocess step is needles initializa-
tion. A good initialization would equally spread the contri-
bution of the needles towards signal reconstruction. With
that goal, we set the initial value of each needle Œ±i to be
the sparse representation of 1
PiX, i.e its relative portion
n
of the corresponding patch. This can be done by solving the
following local pursuit for every needle:

Œ±0

i = arg min

Œ±i

1
2k

1
n

PiX ‚àí DLŒ±ik2

2 + ŒªkŒ±ik1,

(9)

as a preprocess stage of our algorithm.

4. CSC Dictionary Learning

When addressing the question of learning the CSC Ô¨Ål-
ters, the common strategy is to alternate between sparse-
coding and dictionary update steps for a Ô¨Åxed number of
iterations. The dictionary update step aims to Ô¨Ånd the min-
imum of the quadratic term of Equation (5) subject to the
constraint of normalized dictionary columns:

min
DL

1
2kX ‚àí

NX

PT
i

DLŒ±ik2
s.t {kdik2 = 1}m
i=1.

i=1

2

(10)

One can do so in a batch manner which requires access to
the entire dataset at every iteration, or in an online (stochas-
tic) manner that enables access to only small part of the
dataset at every update step. This way it is also applicable
for streaming data scenarios, when the probability distribu-
tion of the data changes over time.

4.1. Batch Update

Usually, for ofÔ¨Çine applications where the whole dataset
is given and can be stored in memory, the batch approach
is generally simpler, and thus we start with its description.
The typical approach is to alternate between sparse coding
(4) and dictionary update (10). For the latter, solving prob-
lem (10) requires Ô¨Ånding the optimum DL that satisÔ¨Åes the
normalization constraint. One can Ô¨Ånd this optimal solution
using projected steepest descent: perform steepest descent
with a small step size and project the solution to the con-
straint set after each iteration, until convergence. To that
end, the gradient of the objective in problem (10) w.r.t. DL
is5:

‚àáDL = ‚àí

Pi(X ‚àí bX)¬∑ Œ±T
i .

(11)

NX

i=1

This batch dictionary update rule follows the line of
thought of the MOD algorithm [12], and thus improves the
solution in each step. However, it exhibits a very slow con-
vergence rate since each dictionary update can be performed
only after Ô¨Ånishing the entire sparse coding (pursuit) stage,
which is markedly inefÔ¨Åcient, as the pursuit is the most
time consuming part of the algorithm. This brings us to
the Stochastic-LoBCoD alternative.

4.2. Local Stochastic Gradient Descent Approach

The traditional Stochastic Gradient Descent (SGD) ap-
proach restricts the computation of the gradient to a subset
of the data and advances in the direction of this noisy gradi-
ent with every update step. Building upon this concept and
the fact that Equation (11) reveals a separable gradient w.r.t
the patches and their corresponding needles, we can update
the dictionary in a stochastic manner. Rather than conclud-
ing the entire pursuit stage and then advancing in the direc-
tion of the global gradient, we can take a small step size Œ∑
and update the dictionary after Ô¨Ånding the sparse represen-
tation of only a small group of needles. According to Sec-
tion 3, every iteration updates a group of needles, referred
to as a layer Li, which in turn could now serve to update
the dictionary. This way, our algorithm convergences faster
and adopts the stochastic behavior of the SGD while still
operating on a single image.

The Ô¨Ålters should be normalized after every dictionary
update by projecting them onto the l2 unit ball. Here, due
to the choice of small step size, we simply normalize the
atoms after every dictionary update:

DL = P1[DL ‚àí Œ∑‚àáDL ].

Where P1[¬∑] denotes the operator that projects the dictio-
nary atoms onto the unit ball. The Ô¨Ånal algorithm that incor-
porates the dictionary update is summarized in Algorithm 1.
Note that, although this dictionary update rule introduces
an extra parameter (the step size Œ∑), determining its value
is rather intuitive and can be performed automatically by
setting it to 1 ‚àí 2% of the norm of the gradient. Further-
more, this update rule may also leverage any stochastic opti-
mization algorithm such as Momentum, Adagrad, Adadelta,
Adam [30] etc., with their authors‚Äô recommended parame-
ter values. This choice of parameter setting is sufÔ¨Åcient, as
will be demonstrated empirically in Section 7. In the rest of
this work we will use this dictionary update rule, as it shows
superior results.

5. Relation to Other Methods

The Ô¨Ånal update step for the local dictionary DL is obtained
by advancing in the direction of this gradient (11) and nor-
malizing the columns of the resulting DL in each iteration,
until convergence.

5This derivation can be found in the supplementary material.

In this section we describe the advantages of the pro-

posed approach over Fourier and ADMM based methods.
Parallel computation: Our algorithm is trivial to paral-
lelize efÔ¨Åciently across multiple processors by virtue of op-
erating directly on the image patches. One can split the

8211

Time Complexity

6.1. Image Inpainting

Method

[22]

(Sparse)

[22]

(Freq.)

SBDL

Ours

qImN log(N )
}
|

{z

+

T-pursuit

IN mk
| {z }

SGD using sparse matrix

qImN log(N )
}
|

{z

+ ImN log(N ) + IN m
}

{z

|

T-pursuit

SGD in the Fourier domain

IN nm + IN (k
|

{z

3 + mk

2)

}

LARS

2

+ nm

| {z }

Gram

+ IN k(n + m) + nm

|

{z

K-SVD

2

}

IN nm + IN (k
|

{z

3 + mk

2)

}

LARS

+ n

2

2

m

| {z }

Gram

+ IN (n + nk + m)
}

{z

|

Stochastic-LoBCoD

Table 1: Complexity analysis of our method compared to
the online algorithms presented in [22] and the SBDL al-
gorithm [26].
I: number of signals, N: signal dimension,
m: number of Ô¨Ålters, n: patch size, k: maximum number of
non-zeros per needle, q: number of inner iterations for the
pursuit algorithm. The dominant terms are in red color.

computations between N/n processors, corresponding to
the number of the needles in every layer.
Online learning: The proposed algorithm, due to its local
stochastic manner, can work in a streaming mode, where
the probability distribution of the patches varies over time.
Another aspect of this advantage is our ability to run in an
online manner, even for a single input image. This stands in
sharp contrast to other recent online methods [21, 34] that
allow for online training but only in the case of streaming
images. Other approaches took a step further and proposed
partitioning the image into sub-images [22], but this is still
far from our approach, which can stochastically estimate the
gradient for each needle.
Parameter free: Contrary to ADMM-based approaches,
our algorithm is unhindered by cumbersome manual
parameter-tuning at the pursuit stage. Moreover, it bene-
Ô¨Åts from an intuitively tuned parameter (the step size Œ∑) in
the dictionary learning stage, as described as Section 4.
Memory efÔ¨Åcient: Our algorithm has better storage com-
plexity compare to the ADMM-based approaches [18, 26]
since the update of the sparse vector is performed in-place
and does not require any auxiliary variables.

Table 1 compares the complexity6 of executing an epoch
in our algorithm with that of the batch algorithm in [26]
and the online algorithms in [22]. The conclusion is that
our algorithm scales linearly with the global dimension N,
while the competing online algorithms grow as O(Nlog(N)).

6. Image Processing via CSC

Having established the foundations for our algorithms,
we now detail their extended variants for tackling the task
of image inpainting and multi-focus image fusion. We also
present adaptations of our algorithm for tackling the tasks
of multi-exposure image fusion and salt-and-pepper text im-
age denoising in the supplementary material.

6The full explanation can be found in the supplementary material.

The task of image inpainting pertains to Ô¨Ålling-in miss-
ing pixels at known locations in the image. Assume we are

given a corrupted image Y = AX, where A ‚àà RN √óN
is a binary diagonal matrix that represents the degradation
operator, so that A(i, i) = 0 implies that the pixel xi is
masked. The goal of image inpainting is to reconstruct the
original image X. Using the CSC formulation, this can be
performed by Ô¨Årst solving the following problem:

min

Œì

1
2kY ‚àí ADŒìk2

2 + ŒªkŒìk1,

(12)

and then taking the found representation Œì and multiplying
by D. By applying the steps described in Section 3, we
split the above global optimization problem into a series of
more manageable problems, each acting on a block of coor-
dinates, i.e. a needle. This yields the following version of
Equation (8):

min
Œ±i

1
2kPiRi ‚àí AiDLŒ±ik2

2 + ŒªkŒ±ik1.

(13)

Here, Ai = PiAPT
i

sponding i-th patch, and Ri = (Y ‚àí APN

is the operator that masks the corre-
DLŒ±j) is

PT
j

j=1
j6=i

the residual between the corrupted image and the degraded
version of the reconstructed image, where the residual Ri
does not account for the needle Œ±i. As mentioned in Sec-
tion 3, we parallelize the computations of the needles that
comprised each layer. The dictionary DL can be pretrained
on an external, uncorrupted dataset or trained on the cor-
rupted image directly using the following gradient:

‚àáDL = ‚àí X

i‚ààLj

PiAT (Y ‚àí A bX)¬∑ Œ±T
i ,

(14)

where bX = PN

DLŒ±j is the reconstructed image.
The gradient derivation above is identical to that in Section
4, but with the exception of incorporating the mask A.

PT
j

j=1

6.2. Multi focus image fusion

Image fusion techniques aim to integrate complimentary
information from multiple images, captured with different
focal settings, into an all-in-focus image of higher quality.
Many patch-based sparse formulations were proposed to ad-
dress this task, such as choose-max OMP [38], simultane-
ous OMP [39], and coupled sparse representation [14]. In
this work, we adopt a similar scheme to [23], which utilizes
the CSC for tackling the task of image-fusion, but with the
distinction of solving a uniÔ¨Åed minimization problem.

Assume we are given a set of source images {Y k}L

k=1 to
fuse, as well as a set of pretrained Ô¨Ålters {di}m
i=1. We start
by decomposing each image Y k into a base component Y k
b
and an edge component Y k
e by imposing distinctive priors.

8212

algorithms9 [30]. Figure 2 presents a comparison of the ob-
jective (2) as a function of time for each of the competing
algorithms, showing that our method achieves the fastest
convergence. Figure 4 shows the obtained dictionaries.

We also compared our method to the online stochastic
gradient descent (SGD) based algorithms in [22], which op-
erate in the spatial and in the Fourier domains. Here we ran-
domly selected a training set of 40 images, and a test set of 5
different images from the MIRFLICKER-1M dataset [19].
Figure 3 presents the objective of the test set as a function of
time, showing that our algorithm converges faster. Figure 5
shows the dictionaries obtained by the three methods, illus-
trating similar quality. Note that our algorithm is capable of
operating online even if trained on one image, a possibility
that is not supported by [22].

For the base component Y k
b we penalize the l2 norm of its
gradient, while for the edge component we employ the CSC
e = Pm
model such that Y k
i . Practically, for each
image Y k we solve the uniÔ¨Åed minimization problem:

i=1 di ‚àó Z k

min
i },Y k

b

{Z k

1
2kY k ‚àí

mX

i=1

i ‚àí Y k

b k2

2

di ‚àó Z k
mX

i=1

+Œª

kZ k

i k1 + ¬µ

(15)

1
2k‚àáY k

b k2
2.

the
This is done by alternating between minimizing w.r.t.
base component Y k
i=1. The
former boils down to a least square problem, and the latter
is solved using our LoBCoD algorithm7.

b and the feature maps {Z k

i }m

After decomposing all the images, we aim to fuse their
components. For each image, we build an activity map ÀúAk,
as the sum of the absolute values of {Z k
i=1. For robust-
ness, we convolve ÀúAk with a uniform kernel Us ‚àà Rs√ós:
ÀúAk(u, v) = Xm

i (u, v)k1, Ak = ÀúAk ‚àó Us. (16)

i=1kZ k

i }m

Based on the observation that a signiÔ¨Åcant value in the ac-
tivity map Ak indicates a sharp region in the corresponding
image Y k, we reconstruct the all-in-focus components by
assembling the most prominent regions based on their val-
ues in the corresponding activity maps:

Z f
i (u, v) = Z k‚àó

i (u, v), Y f
k‚àó = arg max

b (u, v) = Y k‚àó
(Ak(u, v)).

b

(u, v),

(17)

Figure 2: Run time comparison between our method and
the batch methods in [26], [15] and [36].

k

i }m

i=1 and Y f

where {Z f
b are the feature maps and the base
component of the fused image Y f . Finally, the fusion result
is obtained by gathering its components:

Y f = Y f

b +

mX

i=1

di ‚àó Z f
i .

(18)

7. Experiments

The full LoBCoD implementation, documentation and

demos that reproduce our results, are available online8.

7.1. Run Time Comparison

To begin with, and to provide a comparison to other state
of the art methods, we evaluate the performance of the pro-
posed algorithm for solving Equation (5) against state of the
art batch algorithms for CSC: the SBDL algorithm [26], the
algorithm in [36] and the algorithm presented in [15], all
using the same settings on the Fruit dataset [13]. For learn-
ing the dictionary, we used the ADAM and the Momentum

7Additional information can be found in the supplementary material.
8https://github.com/EvZissel/LoBCoD

Figure 3: Run time comparison between our method and
the online algorithms in [22].

7.2. Image Inpainting

We apply our algorithm to the task of image inpainting,
as described in Section 6.1, and compare our results to [26].
In Section 6.1 we described two viable methods for train-
ing the dictionary; utilizing an external dataset or training
directly on the corrupted source image. For the former, we
used the Fruit dataset [13] for both algorithms, as shown in

9The parameter settings are described in the supplementary material.

8213

Table 2: Inpainting comparison [dB] between the proposed LoBCoD and the SBDL [26] algorithms.

Barbara

Boat

House

Lena

Peppers

C.man

Couple

Finger

Hill

Man Montage

SBDL external

Proposed external

SBDL internal

Proposed internal

30.41

30.93

31.98

32.50

31.76

31.82

32.04

32.27

36.17

36.58

36.19

36.74

35.92

36.15

36.01

36.17

33.69

33.54

34.03

34.48

28.76

28.88

28.85

29.04

32.16

32.46

32.18

32.56

30.91

31.75

30.96

31.76

33.12

33.25

33.21

33.42

33.04

33.18

32.99

33.25

28.93

29.18

28.95

29.23

(a) Ours

(b) SBDL [26]

(c) [15]

Figure 4: Comparison between the dictionaries obtained us-
ing the Stochastic-LoBCoD method vs. the methods in [26]
and [15] on the Fruit dataset [13].

(a) Barbara in-focus

(b) Barbara out-of-focus

(a) Ours

(b) [22] Sparse

(c) [22] Freq.

Figure 5: Comparison between the dictionaries obtained us-
ing the Stochastic-LoBCoD method vs. the online methods
in [22] on the MIRFLICKR-1M dataset [19].

Figure 4. The corrupted images were created by applying a
randomly generated mask with 50% missing pixels on the
original images. All the corrupted test images were mean-
subtracted prior to applying both algorithms by subtracting
the patch-average of the unmasked pixels. In addition, we
tuned Œª in Equation (12) for every corrupted test image, to
account for their varying complexity. The top two rows of
Table 2 present the results using an external dataset in terms
of peak signal-to-noise ratio (PSNR) on a set of 11 test im-
ages, showing that our method leads to better results. Next,
we train the dictionary of both algorithms on the corrupted
image itself. The results are presented at the bottom two
rows of Table 2, indicating that the Stochastic-LoBCoD al-
gorithm achieves better results.

7.3. Multi focus image fusion

(c) [23] 41.96dB

(d) Proposed 42.27dB

(e) ButterÔ¨Çy in-focus

(f) ButterÔ¨Çy out-of-focus

(g) [23] 35.30dB

(h) Proposed 36.01dB

Figure 6: Fusion performance comparison on synthetic im-
ages. The PSNR values were computed between the recon-
structed and the original images.

We conclude by applying our LoBCoD algorithm to the
task of multi-focus image fusion, as described in the previ-
ous section. We evaluate our proposed method using syn-
thetic data, as well as data from a real dataset, and compare
our results to [23]. The dictionaries of both methods were
pretrained on the Fruit dataset [13].

the standard image Barbara and created two input images
of blurred foreground and blurred background. Image blur-
ring was performed using a 9√ó 9 Gaussian blur kernel with
œÉ = 2. We repeated the same procedure on the image But-
terÔ¨Çy10, using a 16 √ó 16 Gaussian blur kernel with œÉ = 4.

For the synthetic experiment, we extracted a portion of

10The image was taken form the dataset in [6].

8214

(a) Original

(b) [23]

(c) Proposed

(a) Near in-focus

(b) Far in-focus

(d) [23]

(e) Proposed

Figure 7: Zoom in on the fusion results of the image Butter-
Ô¨Çy. Figures (d) and (e) present the error images of (b) and
(c), respectively. The error images were computed between
the fusion results and the original image (a).

(a) Bird Foreground (b) Bird Background

(c) [23] 39.29dB (d) Proposed 39.81dB

(c) [23]

(d) Proposed

Figure 10: Fusion examples of real images taken from [31].

We adapted our approach for fusion of colored images,
and showed the result on the image Bird11. We generate
a pair of blurred background and foreground color images
by applying a 16 √ó 16 Gaussian blur kernel with œÉ = 4
on each RGB channel. We chose to blur the image in the
RGB color space to emulate a blur of a camera. Afterwords,
both blurred colored images were treated by transforming
them to the Lab color space. The PSNR for the Bird image
was computed between the L channels of the original and
the reconstructed images. We present the results together
with their PSNR values in Figure 8 and 9, showing that our
approach leads to visually and quantitatively better results.
Lastly, for the real dataset experiment, we ran our pro-
posed algorithm on the image-pair Clocks taken from [31].
Figure 10 presents the resulting fused images, showing
comparable results on this image-pair.

Figure 8: Fusion comparison between the proposed method
and the method in [23] on the image Bird.

8. Conclusions

(a) [23]

(b) Proposed

(c) [23]

(d) Proposed

Figure 9: Zoom in on the fusion results of the image Bird.
Figure (c) and (d) present the L channel error compared to
that of the original image.

Both sets of synthetic blurred images are presented in Fig-
ure 6, alongside their reconstructed images, and the corre-
sponding PSNR values. The resulting images demonstrate
that our approach leads to visually and quantitatively bet-
ter results. Figure 7 presents a zoom-in view of our recon-
structed image ButterÔ¨Çy, compared to the result of [23] and
the original image; showing that for images with prominent
blur our method achieves visually better results.

In this work we have introduced the local block coor-
dinate descent (LoBCoD) algorithm for performing pursuit
for the global CSC model, while operating locally on im-
age patches. We demonstrated its advantages over con-
tending state-of-the-art methods in terms of memory re-
quirements, efÔ¨Åcient parallel computation, and its exemp-
tion from meticulous manual tuning of parameters. In ad-
dition, we proposed a stochastic gradient descent version
(Stochastic-LoBCoD) of this algorithm for training the con-
volutional Ô¨Ålters. We highlighted its unique qualities as an
online algorithm that retains the ability to act on a single
image. Finally, we illustrated the advantages of the pro-
posed algorithm on a set of applications and compared it
with competing state-of-the-art methods.

9. Acknowledgments

This work was supported by the Israel Science Founda-

tion (ISF) under Grant 335/18.

11The image was taken form the dataset in [7]

8215

References

[1] M. Aharon, M. Elad, and A. Bruckstein. K-svd: An al-
gorithm for designing overcomplete dictionaries for sparse
representation.
IEEE Transactions on signal processing,
54(11):4311‚Äì4322, 2006.

[2] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, et al.
Distributed optimization and statistical learning via the al-
ternating direction method of multipliers. Foundations and
Trends R(cid:13) in Machine learning, 3(1):1‚Äì122, 2011.

[3] H. Bristow, A. Eriksson, and S. Lucey. Fast convolutional
sparse coding.
In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 391‚Äì398,
2013.

[4] S. Chen, S. A. Billings, and W. Luo. Orthogonal least squares
methods and their application to non-linear system identiÔ¨Å-
cation. International Journal of control, 50(5):1873‚Äì1896,
1989.

[5] S. S. Chen, D. L. Donoho, and M. A. Saunders. Atomic
decomposition by basis pursuit. SIAM review, 43(1):129‚Äì
159, 2001.

[6] W. Dong, L. Zhang, G. Shi, and X. Li. Nonlocally central-
ized sparse representation for image restoration. IEEE Trans-
actions on Image Processing, 22(4):1620‚Äì1630, 2013.

[7] W. Dong, L. Zhang, G. Shi, and X. Wu. Image deblurring
and super-resolution by adaptive sparse domain selection and
adaptive regularization.
IEEE Transactions on Image Pro-
cessing, 20(7):1838‚Äì1857, 2011.

[8] B. Efron, T. iHastie, I. Johnstone, R. Tibshirani, et al. Least
angle regression. The Annals of statistics, 32(2):407‚Äì499,
2004.

[9] M. Elad. Sparse and Redundant Representations: From
Theory to Applications in Signal and Image Processing.
Springer, 2010.

[10] M. Elad and M. Aharon.

Image denoising via sparse and
redundant representations over learned dictionaries.
IEEE
Transactions on Image processing, 15(12):3736‚Äì3745, 2006.

[11] M. Elad, J.-L. Starck, P. Querre, and D. L. Donoho. Simul-
taneous cartoon and texture image inpainting using morpho-
logical component analysis (mca). Applied and Computa-
tional Harmonic Analysis, 19(3):340‚Äì358, 2005.

[12] K. Engan, S. O. Aase, and J. H. Husoy. Method of opti-
mal directions for frame design. In Acoustics, Speech, and
Signal Processing, 1999. Proceedings., 1999 IEEE Interna-
tional Conference on, volume 5, pages 2443‚Äì2446. IEEE,
1999.

[13] R. Fergus, M. D. Zeiler, G. W. Taylor, and D. Krishnan.
Deconvolutional networks.
In 2010 IEEE Computer Soci-
ety Conference on Computer Vision and Pattern Recogni-
tion(CVPR), volume 00, pages 2528‚Äì2535, 2010.

[14] R. Gao and S. A. Vorobyov. Multi-focus image fusion via
coupled sparse representation and dictionary learning. arXiv
preprint arXiv:1705.10574, 2017.

[15] C. Garcia-Cardona and B. Wohlberg. Subproblem coupling
in convolutional dictionary learning.
In Image Process-
ing (ICIP), 2017 IEEE International Conference on, pages
1697‚Äì1701. IEEE, 2017.

[16] R. Grosse, R. Raina, H. Kwong, and A. Y. Ng. Shift-invariant
sparse coding for audio classiÔ¨Åcation. In The Twenty-Third
Conference on Uncertainty in ArtiÔ¨Åcial Intelligence (UAI),
pages 149‚Äì158, 2007.

[17] S. Gu, W. Zuo, Q. Xie, D. Meng, X. Feng, and L. Zhang.
Convolutional sparse coding for image super-resolution. In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 1823‚Äì1831, 2015.

[18] F. Heide, W. Heidrich, and G. Wetzstein. Fast and Ô¨Çexible
In Proceedings of the IEEE
convolutional sparse coding.
Conference on Computer Vision and Pattern Recognition,
pages 5135‚Äì5143, 2015.

[19] M. J. Huiskes, B. Thomee, and M. S. Lew. New trends and
ideas in visual concept detection: the mir Ô¨Çickr retrieval eval-
uation initiative. In Proceedings of the international confer-
ence on Multimedia information retrieval, pages 527‚Äì536.
ACM, 2010.

[20] H.-W. Liao and L. Su. Monaural source separation using
IEEE Signal Processing

ramanujan subspace dictionaries.
Letters, 25(8), 2018.

[21] J. Liu, C. Garcia-Cardona, B. Wohlberg, and W. Yin. On-
line convolutional dictionary learning.
In Image Process-
ing (ICIP), 2017 IEEE International Conference on, pages
1707‚Äì1711. IEEE, 2017.

[22] J. Liu, C. Garcia-Cardona, B. Wohlberg, and W. Yin.
First-and second-order methods for online convolutional
dictionary learning. SIAM Journal on Imaging Sciences,
11(2):1589‚Äì1628, 2018.

[23] Y. Liu, X. Chen, R. K. Ward, and Z. J. Wang.

Image fu-
sion with convolutional sparse representation. IEEE signal
processing letters, 23(12):1882‚Äì1886, 2016.

[24] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary
learning for sparse coding. In Proceedings of the 26th annual
international conference on machine learning, pages 689‚Äì
696. ACM, 2009.

[25] J. Mairal, M. Elad, and G. Sapiro. Sparse representation for
color image restoration. IEEE Transactions on image pro-
cessing, 17(1):53‚Äì69, 2008.

[26] V. Papyan, Y. Romano, J. Sulam, and M. Elad. Convolu-
In ICCV,

tional dictionary learning via local processing.
pages 5306‚Äì5314, 2017.

[27] V. Papyan, J. Sulam, and M. Elad. Working locally
thinking globally: Theoretical guarantees for convolutional
sparse coding.
IEEE Transactions on Signal Processing,
65(21):5687‚Äì5701, 2017.

[28] Y. Romano and M. Elad. Patch-disagreement as away to im-
prove k-svd denoising. In Acoustics, Speech and Signal Pro-
cessing (ICASSP), 2015 IEEE International Conference on,
pages 1280‚Äì1284. IEEE, 2015.

[29] R. Rubinstein, M. Zibulevsky, and M. Elad. Double sparsity:
Learning sparse dictionaries for sparse signal approximation.
IEEE Transactions on signal processing, 58(3):1553‚Äì1564,
2010.

[30] S. Ruder. An overview of gradient descent optimization al-

gorithms. arXiv preprint arXiv:1609.04747, 2016.

[31] S. Savi¬¥c. Multifocus image fusion based on empirical mode
decomposition. In Twentieth International Electro technical
and Computer Science Conference, 2011.

8216

[32] J. Sulam and M. Elad. Expected patch log likelihood with a
sparse prior. In International Workshop on Energy Minimiza-
tion Methods in Computer Vision and Pattern Recognition,
pages 99‚Äì111. Springer, 2015.

[33] J. Sulam, B. Ophir, M. Zibulevsky, and M. Elad. Trainlets:
Dictionary learning in high dimensions. IEEE Transactions
on Signal Processing, 64(12):3180‚Äì3193, 2016.

[34] Y. Wang, Q. Yao, J. T. Kwok, and L. M. Ni. Scalable online
IEEE Transactions on Image

convolutional sparse coding.
Processing, 2018.

[35] B. Wohlberg. EfÔ¨Åcient convolutional sparse coding.

In
Acoustics, Speech and Signal Processing (ICASSP), 2014
IEEE International Conference on, pages 7173‚Äì7177. IEEE,
2014.

[36] B. Wohlberg. Boundary handling for convolutional sparse
representations. In Image Processing (ICIP), 2016 IEEE In-
ternational Conference on, pages 1833‚Äì1837. IEEE, 2016.

[37] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma.
Robust face recognition via sparse representation.
IEEE
transactions on pattern analysis and machine intelligence,
31(2):210‚Äì227, 2009.

[38] B. Yang and S. Li. Multifocus image fusion and restoration
with sparse representation. IEEE Transactions on Instrumen-
tation and Measurement, 59(4):884‚Äì892, 2010.

[39] B. Yang and S. Li. Pixel-level image fusion with simul-
Information fusion,

taneous orthogonal matching pursuit.
13(1):10‚Äì19, 2012.

[40] J. Yang, J. Wright, T. S. Huang, and Y. Ma. Image super-
IEEE transactions on

resolution via sparse representation.
image processing, 19(11):2861‚Äì2873, 2010.

8217

