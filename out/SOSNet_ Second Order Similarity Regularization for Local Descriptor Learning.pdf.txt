SOSNet: Second Order Similarity Regularization for

Local Descriptor Learning

Yurun Tian∗,1,2 Xin Yu3 Bin Fan†,1 Fuchao Wu1 Huub Heijnen4 Vassileios Balntas†,4

1 National Laboratory of Pattern Recognition, Institute of Automation,

Chinese Academy of Sciences, Beijing, China

2University of Chinese Academy of Science, Beijing, China

3Australian Center for Robotic Vision, Australian National University

4Scape Technologies

{yurun.tian,bfan,fcwu}@nlpr.ia.ac.cn xin.yu@anu.edu.au {huub,vassileios}@scape.io

Abstract

Despite the fact that Second Order Similarity (SOS) has
been used with signiﬁcant success in tasks such as graph
matching and clustering, it has not been exploited for learn-
ing local descriptors. In this work, we explore the poten-
tial of SOS in the ﬁeld of descriptor learning by building
upon the intuition that a positive pair of matching points
should exhibit similar distances with respect to other points
in the embedding space. Thus, we propose a novel regu-
larization term, named Second Order Similarity Regular-
ization (SOSR), that follows this principle. By incorpo-
rating SOSR into training, our learned descriptor achieves
state-of-the-art performance on several challenging bench-
marks containing distinct tasks ranging from local patch re-
trieval to structure from motion. Furthermore, by designing
a von Mises-Fischer distribution based evaluation method,
we link the utilization of the descriptor space to the match-
ing performance, thus demonstrating the effectiveness of
our proposed SOSR. Extensive experimental results, empir-
ical evidence and in-depth analysis are provided, indicat-
ing that SOSR can signiﬁcantly boost the matching perfor-
mance of the learned descriptor.

1. Introduction

The process of describing local patches is a fundamen-
tal component in many computer vision tasks such as 3D
reconstruction [31, 33], large scale image localization [30]
and image retrieval [29]. Early efforts mainly focused on
the heuristic design of hand-crafted descriptors, by apply-
ing a set of ﬁlters to the input patches.
In recent years,

∗Research conducted while Yurun and Xin were interns at Scape Tech-

nologies

†Corresponding authors

(a) Triplet Loss

(b) Triplet Loss + SOSR

Figure 1. Qualitative results of our proposed SOSR on features
learned for the 10 digits of the MNIST [19] dataset. Each digit is
represented by a different colour on the unit sphere. We can ob-
serve that by using our SOSR method that encourages second or-
der similarity, more compact individual clusters are learned com-
pared to standard triplet loss.

large datasets with corresponding ground truths have led
to the development of large scale learning methods, which
stimulated a wave of works on descriptor learning. Re-
cent work has shown that these learning based methods are
able to signiﬁcantly outperform their hand-crafted counter-
parts [1, 22].

One of the most important challenges of learning based
methods is the design of suitable loss functions for the train-
ing stage. Since nearest neighbour matching is done di-
rectly using Euclidean distances, most of the recent meth-
ods focus on optimizing objectives related to First Or-
der Similarity (FOS) by forcing descriptors from matching
pairs to have smaller L2 distance than non-matching ones
[34, 2, 26, 17, 36, 15].

Second Order Similarity (SOS) has been used for graph
matching and clustering tasks [10, 11, 43], due to the fact
that it can capture more structural information such as shape
and scale, while at the same time being robust to deforma-

111016

tions and distortions. On the other hand, FOS and near-
est neighbor matching are only limited to pairwise compar-
isons. However, utilizing SOS for large scale problems typ-
ically requires signiﬁcant computational power [10, 11, 43],
and thus matching and reconstruction tasks still rely on
brute force or approximate nearest neighbor matching [31].
In this work, we explore the possibility of using SOS for
learning high performance local descriptors. In particular,
we are interested in formulating a SOS constraint as a regu-
larization term during training, in order to harness its power
during the matching stage, without any computational over-
head.

Evaluation of descriptors is also a key issue. A good
evaluation method can provide insights for designing de-
scriptors. Performance indicators, such as false positive rate
[7] and mean average precision [1], are widely used. How-
ever, it is still unclear how the utilization of the descriptor
space, such as the degrees of intra-class concentration and
inter-class dispersion, contributes to the ﬁnal performance.
Therefore, in order to explain the impact of SOS on the
matching performance, we further introduce an evaluation
method based on the von Mises-Fisher distribution [6].

Our main contributions are: (1) We introduce a novel
regularization method, named Second Order Similarity
Regularization (SOSR), that enforces Second Order Sim-
ilarity (SOS) consistency. To the best of our knowledge,
SOS has not been incorporated into the process of learning
local feature descriptors. (2) By combining our SOSR with
a triplet loss, our learned descriptor is able to signiﬁcantly
outperform previous ones and achieves state-of-the-art re-
sults on several benchmarks related to local descriptors. (3)
We introduce a new evaluation method that is based on the
von Mises-Fisher distribution for examining the utilization
of the descriptor space. The proposed evaluation method
can illustrate links between distributions of descriptors on
the hypersphere and their matching performance.

This paper is organized as follows: In Sec. 2, we brieﬂy
review related works. In Sec. 3 and Sec. 4, we introduce
our Second Order Similarity Regularization as well as a new
method for evaluating the descriptors on a unit hypersphere.
Subsequently, in Sec. 5, we present results on several chal-
lenging benchmarks. Lastly, we conduct ablation study of
our proposed SOSR in Sec. 6.

2. Related works

Early works on local patch description focused on low
level processes such as gradient ﬁlters and intensity com-
parisons, including SIFT [21], GLOH [24], DAISY [39],
DSP-SIFT [12] and LIOP [38]. A comprehensive review
can be found in [25].

With the emergence of annotated patch datasets [7], a
signiﬁcant amount of data-driven methods focused on im-
proving hand-crafted representations using machine learn-

ing methods. The authors of [8, 9] use linear projections to
learn discriminative descriptors, while convex optimization
is used for learning an optimal descriptor sampling conﬁgu-
ration in [35]. BinBoost [37] is trained based on a boosting
framework, and in RFD [13], the most discriminative re-
ceptive ﬁelds are learned based on the labeled training data.
BOLD [3] uses patch speciﬁc adaptive online selection of
binary intensity tests.

Convolutional neural networks (CNNs) enable end-to-
end descriptor learning from raw local patches, and have
become the de-facto standard for learning local patch de-
scriptors in recent years. MatchNet [14] adopts a Siamese
network for local patch matching, while DeepCompare [40]
further explores various network architectures. Song et
al. [27] propose the lifted structured embedding for the task
of feature embedding. DeepDesc [34] removes the need for
a specially learned distance metric layer, and instead uses
Euclidean distances and hard sample mining. TFeat [2] uses
triplet learning constraints with shallow convolutional net-
works and fast hard negative mining, and L2Net [36] ap-
plies progressive sampling with a loss function that takes
into account the whole training batch while producing de-
scriptors that are normalized to unit norm. The L2Net ar-
chitecture was widely adopted by consequent works. Hard-
Net [26] surpasses L2Net by implementing a simple hinge
triplet loss with the “hardest-within-batch” mining, con-
ﬁrming the importance of the mining strategy. Keller et
al. [17] propose to learn consistently scaled descriptors by a
mixed context losses and a scale aware sampling. Instead of
focusing on patch matching, DOAP [15] imposes a retrieval
based ranking loss and achieves the current state of the
art performance on several benchmarks. GeoDesc [22] in-
tegrates geometry constraints from multi-view reconstruc-
tions to beneﬁt the learning process by improving the train-
ing data. The authors of [41], propose a Global Orthogonal
Regularization term to better exploit the unit hypersphere.

While the recent improvements in the ﬁeld of learn-
ing CNN patch descriptors are signiﬁcant, methods men-
tioned above are limited to optimizing the FOS measured
by L2 distances of positive and negative pairs, and the po-
tential of SOS has not been exploited in the area of de-
scriptor learning. On the other hand, graph matching al-
gorithms [10, 11, 43] have been developed based on SOS
due to its robustness to shape distortions. Furthermore,
[20] proves that using SOS can achieve better cluster per-
formance. Thus, our key idea is to introduce second order
similarity constraints at the training stage for robust patch
description.

3. Learning Descriptor with Second Order

Similarities

In this section, we introduce how to incorporate SOS as
a regularization term into our training procedure. By em-

11017

ploying FOS and SOS losses, we train our network in an
end-to-end manner.

3.1. Preliminaries

For a training batch consisting of N pairs of matching
patches, a convolutional neural network is applied to each
patch so as to extract its descriptor. The corresponding pos-
itive descriptor pairs are denoted as {xi, x

+
i }i=1...N

3.2. First Order Similarity Loss

First Order Similarity (FOS) loss, which enforces dis-
tances between matching descriptors to be small while those
of non-matching ones to be large, has been widely used for
learning local descriptors [2, 36, 15, 22]. In our method, we
ﬁrst employ a loss term to constraint the FOS as follows:

where d(2)(xi, x
x
the differences between distances.

+
i ) measures the similarity between xi and
+
j }j6=i, using

from the perspectives of {xj}j6=i and {x

+
i

In order to enforce SOS, we formulate our SOSR regu-

larization term as:

RSOS =

1
N

N

X

i=1

+
d(2)(xi, x
i ).

(3)

Note that RSOS does not force distances between match-
ing descriptors to decrease or distances between non-
matching ones to increase. Thus, it cannot be solely used
without an LF OS term, and can only be served as a regular-
ization term.

3.4. Objective Function For Training

Our goal is to learn a robust descriptor in terms of both
FOS and SOS, therefore, our total objective function is ex-
pressed as:

LT = LF OS + RSOS,

(4)

,

N

LF OS =

1
N

i (cid:1)2
i − dneg

X
i=1
dpos
i = d(xi, x

max(cid:0)0, t + dpos
+
i ),
+
j ), d(x

i

+
i , x

+
i , xj), d(x

(d(xi, xj), d(xi, x

dneg
i = min
∀j,j6=i

+
j )),
(1)
where t is the margin, d(u, v) = ku − vk2 is the L2 dis-
tance, dpos
indicates the distance between a positive pair
i
and dneg
represents the distance between a negative pair.
We employ the same mining strategy as in HardNet [26]
to ﬁnd the “hardest-within-batch” negatives. Note that, in
Eqn. (1), we use a Quadratic Hinge Triplet (QHT) loss in-
stead of the conventional Hinge Triplet (HT) Loss. Com-
pared with HT, QHT weights the gradients with respect to
the parameters of the network by the magnitude of the loss.
This means that the larger dneg
is, the smaller the gra-
dients are. In Sec. 6.1 we provide evidence that this simple
modiﬁcation can lead to signiﬁcant performance improve-
ments.

i − dpos

i

3.3. Second Order Similarity Regularization

Besides the ﬁrst order constraints imposed by LF OS, it
has been demonstrated that incorporating information from
higher order similarities can improve the performance of
clustering [20] and graph matching [10]. Thus, we propose
to impose a second order constraint to further supervise the
process of descriptor learning.

A training mini-batch can be viewed as two sets of de-
scriptors with one-to-one correspondence, i.e., {xi}i=1...N
+
and {x
i }i=1...N . For this case, we deﬁne the second order
similarity between xi and x

+
i as:

d(2)(xi, x

+

i ) = vuut

N

X

j6=i

(d(xi, xj) − d(x

+
i , x

+
j ))2,

(2)

where the two terms are weighted equally.

3.5. Implementation Details

During training, we observed that using all the samples
in a mini-batch as input to the RSOS term led to inferior
results. This is due to the fact that for a given pair of match-
ing descriptors, many of their non-matching descriptors are
already far away. Thus, these distant negatives need no fur-
ther optimization. Subsequently, SOS calculated on these
“easy” negatives may produce noisy gradients and there-
fore damage the performance. Inspired by the concept of
active graph in [11], we employ nearest neighbor search to
exclude those far away negatives for each positive pair. Let
zi be the class label of the ith positive pair, and ci be the ith
set of class labels. In particular, ci stores the class labels
which are within the K Nearest Neighbors (KNN) of the
ith positive pair. Thus, we deﬁne the criterion of neighbor
selection for each ci as:

ci = {zj : xi ∈ KNN(xj) ∨ x

+
i ∈ KNN(x

+
j )},

∀j ∈ 1 . . . N, j 6= i

(5)

where KNN(xi) denotes the K Nearest Neighbors of de-
scriptor xi. Note that there is a possibility of intersection
+
between the KNN(xi) and KNN(x
i ) sets. Thus, the car-
dinality of ci ranges from K to 2K. Therefore, in Eqn (3)
we calculate SOS for the ith pair as:

d(2)(xi, x

+

i ) = vuut

N

X

j6=i,zj ⊂ci

(d(xi, xj) − d(x

+
i , x

+
j ))2.

(6)
We adopt the architecture of L2Net [36] to embed lo-
cal patches to 128-dimensional descriptors. Note that all

11018

descriptors are normalized to unit vectors. To prevent over-
ﬁtting, we also employ a dropout layer with a drop rate of
0.1 before the last convolutional layer. Similar to previous
works [36, 26], all patches are resized to 32 × 32 and nor-
malized by subtracting the per-patch mean and dividing the
per-patch standard deviation. We use the PyTorch library
[28] to train our local descriptor network. Our network is
trained for 100 epochs using the Adam optimizer [18] with
α = 0.01, β1 = 0.9 and β2 = 0.999 as in the default
settings. For the training hyperparameters, the number of
training pairs N is set to 512, i.e., the batch size is 1024, K
is set to 8, that is, 8 nearest neighboring pairs are selected to
calculate SOS for a given pair, and the margin t in the FOS
loss is set to be 1.

4. Evaluating the Unit Hypersphere Utilization

Indicators like false positive rate and mean average pre-
cision have been widely used for evaluating the perfor-
mance of descriptors [1, 39]. However, such indicators
fail to provide insights on properties of the learned de-
scriptors, i.e., how the utilization of the descriptor space
such as the intra-class and inter-class distributions, con-
tribute to the ﬁnal performance. To investigate this, previ-
ous works[41, 36] visualize the distributions of the positive
and negative distances as histograms. However, while such
visualizations illuminate the distance distributions, they fail
to capture the structure of the learned descriptor space.

Since most modern methods rely on normalized descrip-
tors, we propose to leverage the von Mises-Fisher (vMF)
distribution which deals with the statistical properties of
unit vectors that lie on hyperspheres (interested readers can
ﬁnd more information in [6]). A q-dimensional descriptor,
can be thought as a random point on the (q−1)-dimensional
unit hypersphere Sq−1. Speciﬁcally, a random unit vector x
(i.e., kxk2 = 1) obeys a q-variate vMF distribution if its
probability density function is as follows:

f (x|µ, κ) = cq(κ)eκµ

T

x,

(7)

where kµk2 = 1, q ≥ 2 and κ ≥ 0. The normalizing
constant cq(κ) is deﬁned as:

cq(κ) =

κq/2−1

(2π)q/2Iq/2−1(κ)

,

(8)

According to [6], the maximum likelihood estimation of

κ can be obtained from the following equation:

A(ˆκ) =

Iq/2(ˆκ)
Iq/2−1(ˆκ)

= ¯R =

1
N

k

N

X

i=1

xik2,

(9)

where ˆκ is the estimation of κ and ¯R is called the mean
resultant length. Since A(·) is a ratio of Bessel functions
[4] with no analytic inverse, we cannot directly take ˆκ =
A−1( ¯R). According to [5], ˆκ can be approximated by a
monotonically increasing function of ¯R, where ¯R = 0 leads
to ˆκ = 0 and ¯R = 1 indicates ˆκ = ∞. Therefore, ¯R can be
used as a proxy for measuring κ.

Descriptors from the ith class can be interpreted as
samples drawn from a vMF distribution f i
intra).
The cluster center µi
is a sample from vMF density
finter(µ|ν, κinter). Further, to investigate the utilization of
the unit hypersphere, we deﬁne the following parameters:

intra(x|µi, κi

Rintra =

1
M

¯Rintra

i

,

M

X

i

M

Rinter =

µik2,

1
M

k

X
i=1
Rinter
Rintra

,

ρ =

(10)

where M is the total number of classes and ¯Rintra
is the
mean resultant length for the ith class. In Eqn. (10), Rintra
and Rinter measure the intra-class concentration, inter-class
dispersion respectively, and the ratio ρ is a overall evalua-
tion.

i

The vMF distribution has been used in image cluster-
ing [4] and classiﬁcation [42]. However, we propose to
use it solely for evaluating the utilization of the descriptor
space, since unlike in the classiﬁcation tasks, current local
patch datasets can not guarantee sufﬁcient intra-class sam-
ples for accurate estimation of the vFM parameters, e.g.,
some classes in the widely used UBC Phototour [7] dataset
only have 2 samples, and such estimation errors in training
stage may lead to inferior performance.

5. Experiments

where Ik(·) is the modiﬁed Bessel function of the ﬁrst kind
and order k. The vMF density f (x|µ, κ) is parameterized
by the mean direction µ and the concentration parameter κ.
κ is used to characterize how strongly the unit vectors drawn
from f (x|µ, κ) are concentrated in the mean direction µ,
with larger values of κ indicating stronger concentration. In
particular, when κ = 0, f (x|µ, κ) reduces to the uniform
distribution on Sq−1, and as κ → ∞, f (x|µ, κ) approaches
a point density.

We name our learned descriptor Second Order Simi-
larity Network (SOSNet).
In this section, we compare
our SOSNet with several state-of-the-art methods,
i.e.,
DeepDesc(DDesc) [34], TFeat [2], L2Net [36], Hard-
Net(HNet) [26], HardNet with GOR [41], Scale-Aware De-
scriptor [17], DOAP [15] and GeoDesc [22]. We per-
form our experiments on three publicly available datasets,
[7], HPatches [1] and ETH
namely UBC Phototour
SfM[32]. For TFeat [2], L2Net [36], HardNet [26], and

11019

Train
Test

SIFT [21]

DeepDesc [34]
MatchNet [2]

L2Net [36]

CS L2Net [36]
HardNet [26]

HardNet-GOR [26, 41]

Michel et al. [17]

SOSNet

TFeat+ [2]
L2Net+ [36]

CS L2Net+ [36]
HardNet+ [26]

HardNet-GOR+ [26, 41]

DOAP+ [15]

DOAP-ST+ [15] [16]

SOSNet+

GeoDesc+ [22]
SOSNet-HP+

Notredame Yosemite

Liberty Yosemite

Liberty Notredame

Liberty
29.84
10.9

Notredame

22.53
4.40

Yosemite

27.29
5.69

7.04
3.64
2.55
1.47
1.72
1.79
1.25
7.39
2.36
1.71
1.49
1.48
1.54
1.47
1.08

11.47
5.29
4.24
2.67
2.89
2.96
2.84
10.13
4.70
3.87
2.51
2.43
2.62
2.29
2.12

3.82
1.15
0.87
0.62
0.63
0.68
0.58
3.06
0.72
0.56
0.53
0.51
0.43
0.39
0.35

5.65
1.62
1.39
0.88
0.91
1.02
0.87
3.80
1.29
1.09
0.78
0.78
0.87
0.78
0.67

11.6
4.43
3.81
2.14
2.10
2.51
1.95
8.06
2.57
2.07
1.96
1.76
2.00
1.98
1.03

8.70
3.30
2.84
1.65
1.59
1.64
1.25
7.24
1.71
1.3
1.84
1.53
1.21
1.35
0.95

5.47
2.10

1.94
0.79

4.72
1.39

Mean

26.55
6.99
8.05
3.24
2.61
1.57
1.64
1.77
1.46
6.64
2.23
1.76
1.51
1.41
1.45
1.38
1.03
4.05
1.42

Table 1. Patch veriﬁcation performance on the UBC phototour dataset. Numbers denote false positive rates at 95% recall. All descriptors
are 128-dimensional, except that TFeat is 256. and sufﬁx “+” indicates data augmentation. We can observe that our SOSNet outperforms
other methods in all cases.

GeoDesc∗ [22], we use the pre-trained models released by
the authors, and for GOR [41], we employ the code pro-
vided by the authors. For Scale-Aware Descriptors [17] and
DOAP [15], we report their results from their published pa-
pers since their training codes and pre-trained models are
unavailable.

5.1. UBC Phototour

UBC Phototour dataset [7] is currently the most widely
used dataset for local patch descriptor learning. It consists
of three subsets, Liberty, Notredame, and Yosemite. For
evaluations on this dataset, models are trained on one subset
and tested on the other two. We follow the standard evalua-
tion protocol of [7] by using the 100K pairs provided by the
authors and report the false positive rate at 95% recall.

In Table. 1, SIFT represents a baseline hand-crafted de-
scriptor, and the others are CNN based methods. As in-
dicated by Table. 1, our SOSNet achieves the best perfor-
mance by a signiﬁcant margin in comparison to the state-
of-the-art approaches. Note that, DOAP incorporates a Spa-
tial Transformer Network (STN) [16] into the network to
resist geometrical distortions in the patches.
In contrast,
our SOSNet does not require any extra geometry rectifying
layer and yet achieves superior performance. We can ex-
pect the performance of our method to further increase, by

∗The training dataset of GeoDesc is not publicly available. Therefore,

comparisons of GeoDesc with other methods may be unfair.

incorporating an STN. GeoDesc generates inferior results
due to the possible differences between its training dataset
and UBC Phototour. In addition, it is worth noting that even
when trained on HPatches (SOSNet-HP+), our descriptor is
able to closely match the best performing methods, which is
signiﬁcant since UBC and HPatches exhibit vastly different
patch distributions. This is a testament to the generalization
ability of our method.

5.2. HPatches

HPatches dataset [1] consists of over 1.5 million patches
extracted from 116 viewpoint and illumination changing
scenes. According to the different levels of geometric noise,
the extracted patches can be divided into three groups: easy,
hard, and tough. There are three evaluation tasks, patch
veriﬁcation, patch retrieval, and image matching. We show
results for all three tasks in Fig. 2. As shown in Fig. 2,
our SOSNet outperforms state-of-the-art methods on all the
three tasks both for methods trained on Liberty (-LIB) and
on HPatches (-HP). It is worth noting that our descriptor
outperforms DOAP in the retrieval task, even though DOAP
employs a ranking loss speciﬁcally designed for maximiz-
ing the mean Average Precision (mAP) for patch retrieval.
This indicates that our SOSR can lead to more discrimina-
tive descriptors, without the need for a specialized ranking
loss.

11020

Figure 2. Veriﬁcation, matching and retrieval results on test set split ‘a’ of HPatches [1]. Colour of the marker indicates EASY, HARD,
and TOUGH noise. The type of the marker corresponds to the variants of the experimental settings.

5.3. ETH dataset

Different from the aforementioned datasets that focus on
patches, the ETH SfM benchmark [32] aims to evaluate
descriptors for a Structure from Motion (SfM) task. This
benchmark investigates how different methods perform in
terms of building a 3D model from a set of available 2D
images.

In this experiment, we compare our SOSNet with the
state-of-the-art methods by quantifying the SfM quality,
i.e., measuring the number of registered images, recon-
structed sparse points,
image observations, mean track
length and mean reprojection error. Following the proto-
cols in [32], we do not conduct the ratio test, in order to
investigate the direct matching performance of the descrip-
tors.

Table 2 shows the evaluation results of the 3D recon-
struction, in which SOSNet exhibits the best overall perfor-
mance. In particular, SOSNet is able to signiﬁcantly outper-
form other methods in terms of metrics related to the den-
sity of the reconstructed 3D model, i.e. the number of reg-
istered sparse points, and the number of observations. It is
worth noting that SOSNet produces even more matches than
GeoDesc [22], which is speciﬁcally designed and trained
for a SfM task. Similarly to the observations in [32, 22],
SIFT achieves the smallest reprojection error on all tests,
thus demonstrating that it is still an attractive choice for im-
age matching. This can be explained by the fact that fewer
matches seem to lead to a trend for lower reprojection er-
rors. Furthermore, since the reprojection errors are less than
1px for all descriptors, we can conclude that this metric may
not reﬂect performance differences between descriptors in
practice. Finally, we can observe that our method is able
to register signiﬁcantly more images compared to SIFT. For
example, in Madrid Metropolis sequence, SIFT was
able to register only 38% of the available 2D images for

the ﬁnal 3D model, while our method registered 65% of the
images. This indicates that our method is more suitable for
large scale and challenging reconstructions.

6. Discussion

In this section, we perform several experiments to pro-
vide a more in-depth analysis about how each component
in SOSNet contributes to its ﬁnal performance. Besides
reporting matching performance in terms of FPR@95 rate
and mAP, we also demonstrate how the proposed SOSR
and other existing methods impact on the structure of the
learned descriptor space, using the methodology introduced
in Sec. 4.

6.1. Analysis of Performance Improvements

We argue that the performance increase of SOSNet
comes from three aspects: 1) the optimization method that
we employ, 2) the QHT, and 3) the proposed SOSR.

First, we investigate the impact of different optimiza-
tion methods, where the two most widely adopted meth-
ods, i.e., Stochastic Gradient Descent (SGD) and Adam [18]
are compared. For SGD, we use a starting learning rate of
0.01 and divided it by 10 at epoch 50, and for Adam, we
use the settings described in Sec. 5. As visible in Fig. 3(a)
and Fig. 3(b), Adam [18] leads to better performance com-
pared to SGD. Note that, using Hinge Triplet (HT) loss with
Adam already surpasses the previous state-of-art method,
i.e., DOAP [15] that uses a sophisticated ranking loss.

Second, we compare QHT against HT. As shown in
Fig. 3(a) and Fig. 3(b), performance improvements from
HT to QHT are quite obvious for both SGD and Adam
cases. This is mainly due to the fact that QHT loss adap-
tively weights the gradients by the magnitude of the loss,
i.e., dneg − dpos.

Third, we compare our SOSR with another regulariza-

11021

020406080100PatchVeriﬁcationmAP[%]SOSNet-HPaGeoDescSOSNet-LibDOAP-LibHNet-LibL2Net-LibTFeat-LibDDesc-LibSIFT94.5290.5887.6987.6487.1984.3380.5678.4863.35InterIntra020406080100ImageMatchingmAP[%]SOSNet-HPaGeoDescSOSNet-LibHNet-LibDOAP-LibL2Net-LibTFeat-LibDDesc-LibSIFT66.4958.1351.4450.0749.5442.2727.9926.4824.42ViewpIllum020406080100PatchRetrievalmAP[%]SOSNet-HPaGeoDescSOSNet-LibDOAP-LibHNet-LibL2Net-LibDDesc-LibTFeat-LibSIFT84.7075.3070.3069.7469.0063.7552.7250.6842.10HPatchesResultsEasyHardTough# Image

# Registered

# Sparse Points

# Observations

Track Length

Reproj. Error

Fountain

Herzjesu

South Building

Madrid Metropolis

Gendarmenmarkt

11

8

128

1344

1463

SIFT
DSP-SIFT
L2Net
GeoDesc
SOSNet
SIFT
DSP-SIFT
L2Net
Geodesc
SOSNet
SIFT
DSP-SIFT
L2Net
GeoDesc
SOSNet
SIFT
DSP-SIFT
L2Net
GeoDesc
SOSNet
SIFT
DSP-SIFT
L2Net
GeoDesc
SOSNet

11
11
11
11
11
8
8
8
8
8

128
128
128
128
128
500
467
692
809
844
1035
979
1168
1208
1201

14K
14K
17K
16K
17K
7.5K
7.7K
9.5K
9.2K
9.7K
108K
112K
170K
170K
178K
116K
99K
254k
306K
335K
338K
293K
667k
779K
816K

70K
71K
83K
83K
85K
31K
32K
40K
40K
41K
653K
666K
863K
887K
913K
733K
649K
1067K
1200K
1411K
1872K
1577K
2611K
2903K
3255K

4.79
4.78
4.88
5.00
4.92
4.22
4.22
4.24
4.35
4.26
6.04
5.91
5.07
5.21
5.11
6.32
6.52
4.20
3.91
4.21
5.523
5.381
3.91
3.72
3.984

0.39px
0.37px
0.47px
0.47px
0.43px
0.43px
0.45px
0.51px
0.51px
0.53px
0.54px
0.58px
0.63px
0.64px
0.67px
0.60px
0.66px
0.69px
0.66px
0.70px
0.69px
0.74px
0.73px
0.74px
0.77px

Table 2. Evaluation results on ETH dataset [32] for SfM. We can observe that our proposed SOSNet signiﬁcantly outperforms other
methods in terms of the number of registered sparse points and number of observations. This indicates that the models that are built using
our descriptor are signiﬁcantly denser.

tion term recently proposed in [41], i.e., the Global Or-
thogonal Regularization (GOR). As shown in Fig. 3(a) and
Fig. 3(b), SOSR achieves signiﬁcant and consistent perfor-
mance improvements across all training epochs, while the
FPR curves with and without GOR are sometimes inter-
twined, showing minor performance enhancement, and this
phenomenon is also observed in [15].

To sum up, Adam, QHT and SOSR bring on average
11.63%, 5.46%, and 19.49% relative performance im-
provements, respectively. Note that when calculating the
relative performance increase caused by SOSR, we aver-
age the FPR@95 over HT, QHT for both SGD and Adam
from epoch 50 to epoch 100, with the same rule applying to
Adam and QHT.

6.2. Impact of K and N

As described in Sec. 4, each training batch is formed by
N pairs of patches, and within each batch, K nearest neigh-
bors are used to calculate SOSR. In this section, we analyze
the impact of the hyperparameters N and K on the match-
ing performance SOSNet. Speciﬁcally, we vary N and K
from 256 to 2048 and 4 to 32, respectively. All models are
trained on Liberty and tested on the other two subsets, i.e.,
Notredame and Yosemite. We report the mean FPR@95
of the two test sets in Fig. 3(c). Across all the settings,
N = 512 with K = 8 achieves the best performance.

6.3. Analysis of the Descriptor Space

To visualize the changes in the descriptor space caused
by SOSR, we ﬁrst conduct a toy experiment on the MNIST
[19] dataset. Speciﬁcally, we modify the L2Net architec-
ture [36] by setting the number of output channels of the
last convolutional layer as 3. The network is trained with
a batch size of 20, i.e., each batch contains 10 classes with
2 images per class. After training, we visualize the distri-
bution of the descriptors on a unit sphere in Fig 1. It can
be clearly seen that SOSR makes each cluster more con-
centrated, thus indicating that in the low dimensional space
enforcing SOS constraint improves FOS.

Unlike clustering 10 classes of images on a unit sphere,
it is hard to directly visualize the distribution of descriptors
on S127 from tens of thousands of classes. We have tried di-
mensionality reduction techniques such as tSNE [23]. How-
ever, it is hard to get any insightful conclusions visually
about the structure of the descriptor space due to the distor-
tions introduced by the dimensionality reduction process.

In order to provide quantitative results, we employ the
evaluation method described in Sec. 4. Speciﬁcally, we
evaluate Eqn. (10) by using 90K randomly selected classes
from the HPatches dataset. To avoid noisy estimation of
Rinter, like Rintra, we compute it by averaging 10K random
tests, where in the ith test a Rinter
is estimated by sam-
pling descriptors randomly from all classes(one descriptor
per class). The results are shown in Fig. 4, and several in-

i

11022

HT
HT+GOR
HT+SOS
QHT
QHT+GOR
QHT+SOSR
HardNet
DOAP

]

%
[
5
9
@
R
P
F

 1.8

 1.6

 1.4

 1.2

 1

 0.8

 10  20  30  40  50  60  70  80  90

# Training epoch

(a) Training with SGD.

(b) Training with Adam.

(c) Impact of N and K

Figure 3. Analysis of Performance Improvements. HT stands for Hinge Triplet and QHT stands for Quadratic Hinge Triplet. All models
are trained on Liberty and the FPR@95 is averaged over Yosemite and Notredame. Note that SOSNet is denoted as QHT+SOSR.

It is interesting to note that in low dimensional space
(Fig. 1), SOSR helps to make more concentrated intra-class
distributions, while in high dimensional space (Fig. 4) it
helps to make inter-class distribution more scattered. We ar-
gue that this phenomenon is related to the dimension of the
descriptors. When the descriptor space is of less complex-
ity, e.g., S2, there is less ﬂexibility for adjusting descriptor
distributions. Therefore to ensure high second order simi-
larity, SOSR enforces descriptors from the same class to be-
come one point. In contrast, for high dimensional descriptor
space which is hard to visualize or even imagine, e.g., S127,
experimental results show that SOSR leads to a more scat-
ter inter-class distribution, i.e., the descriptors exploit more
area on the hypersphere. To sum up, the adjustment of the
descriptor space by SOSR leads to better matching perfor-
mance, thus demonstrating our intuition that enforcing SOS
in the training stage is reasonable.

7. Conclusions

In this work, we propose a regularization term named
Second Order Similarity Regularization (SOSR) for the pur-
pose of incorporating second order similarities into the lean-
ing of local descriptors. We achieve state-of-the-art perfor-
mance on several standard benchmarks on different tasks
including patch matching, veriﬁcation, retrieval, and 3D re-
construction, thus demonstrating the effectiveness of the
proposed SOSR. Furthermore, we propose an evaluation
method based on the von Mises-Fisher distribution to inves-
tigate the impact of enforcing second order similarity during
training. By leveraging this evaluation method, we observe
how the intra-class and inter-class distributions affect the
performance of different descriptors.

This work is

Acknowledgement.
supported by
the National Natural Science Foundation of China
(61573352,61876180), the Young Elite Scientists Sponsor-
ship Program by CAST (2018QNRC001), the Australian
Research Council Centre of Excellence for Robotic Vision
(project number CE140100016) and Scape Technologies.

11023

Figure 4. Performance in terms of the mean resultant length for the
HPatches dataset. SIFT [21] is normalized to have unit length.

teresting observations can be drawn:

• The ratio ρ drops in accordance with the performance
ranking, i.e., SIFT < TFeat < L2Net < HardNet <
SOSNet, indicating that it is a reasonable performance
indicator.

• As performance increases from SIFT to SOSNet, Rinter
decreases monotonically, showing that the more space
on the hypersphere has been exploited. Speciﬁcally,
descriptors can harness more expressive power of S127
by exploiting more space of it, thus leading to better
matching performance.

• With more space on S127 being exploited, Rintra also
drops, which means there are more scattered intra-
class distributions. However, as long as the inter-
class distribution is scattered enough, less concentrated
intra-class distributions do not damage the matching
performance.

• SIFT has the highest Rintra, indicating that the intra-
class distributions are very concentrated. Meanwhile,
it also has the highest Rinter, showing that most of the
classes are gathered in a small region of S127, while
leaving most of the area unexploited.

 0.8 1 1.2 1.4 1.6 1.8 10 20 30 40 50 60 70 80 90FPR@95[%]# Training epochHTHT+GORHT+SOSQHTQHT+GORQHT+SOSRHardNetDOAP 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1032K=8K=4K=16K=32FPR@95[%]KN=256N=512N=1024N=2048 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9Rinter/RintraRinterRintraSIFTTFeatL2NetHardNetSOSNetReferences

[1] Vassileios Balntas, Karel Lenc, Andrea Vedaldi, and Krys-
tian Mikolajczyk. Hpatches: A benchmark and evaluation
of handcrafted and learned local descriptors.
In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), volume 4, page 6, 2017. 1, 2, 4, 5, 6

[2] Vassileios Balntas, Edgar Riba, Daniel Ponsa, and Krystian
Mikolajczyk. Learning local feature descriptors with triplets
and shallow convolutional neural networks. In British Ma-
chine Vision Conference (BMVC), volume 1, page 3, 2016.
1, 2, 3, 4, 5

[3] Vassileios Balntas, Lilian Tang, and Krystian Mikolajczyk.
Bold-binary online learned descriptor for efﬁcient image
matching. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 2367–
2375, 2015. 2

[4] Arindam Banerjee, Inderjit S Dhillon, Joydeep Ghosh, and
Suvrit Sra. Clustering on the unit hypersphere using von
mises-ﬁsher distributions. Journal of Machine Learning Re-
search, 6(Sep):1345–1382, 2005. 4

[5] Arindam Banerjee, Inderjit S Dhillon, Joydeep Ghosh, and
Suvrit Sra. Clustering on the unit hypersphere using von
mises-ﬁsher distributions. Journal of Machine Learning Re-
search, 6(Sep):1345–1382, 2005. 4

[6] Edward Batschelet. Circular statistics in biology, volume

111. Academic press London, 1981. 2, 4

[7] Matthew Brown, Gang Hua, and Simon Winder. Discrim-
IEEE PAMI,

inative learning of local image descriptors.
33(1):43–57, 2011. 2, 4, 5

[8] Matthew Brown, Gang Hua, and Simon Winder. Discrim-
IEEE PAMI,

inative learning of local image descriptors.
33(1):43–57, 2011. 2

[9] Hongping Cai, Krystian Mikolajczyk, and Jiri Matas. Learn-
ing linear discriminant projections for dimensionality reduc-
tion of image descriptors. IEEE PAMI, 33(2):338–352, 2011.
2

[10] Minsu Cho, Jungmin Lee, and Kyoung Mu Lee. Reweighted
random walks for graph matching.
In European Confer-
ence on Computer Vision (ECCV), pages 492–505. Springer,
2010. 1, 2, 3

[11] Minsu Cho and Kyoung Mu Lee. Progressive graph match-
ing: Making a move of graphs via probabilistic voting. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pages 398–405. IEEE,
2012. 1, 2, 3

[12] Jingming Dong and Stefano Soatto. Domain-size pooling
in local descriptors: Dsp-sift.
In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 5097–5106, 2015. 2

[13] Bin Fan, Qingqun Kong, Tomasz Trzcinski, Zhiheng Wang,
Chunhong Pan, and Pascal Fua. Receptive ﬁelds selection
for binary feature description. IEEE Transactions on Image
Processing, 23(6):2583–2595, 2014. 2

[14] Xufeng Han, Thomas Leung, Yangqing Jia, Rahul Suk-
thankar, and Alexander C Berg. Matchnet: Unifying feature
and metric learning for patch-based matching. In Proceed-

ings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 3279–3286, 2015. 2

[15] Kun He, Yan Lu, and Stan Sclaroff. Local descriptors op-
timized for average precision. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), pages 596–605, 2018. 1, 2, 3, 4, 5, 6, 7

[16] Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al.
Spatial transformer networks. In Advances in Neural Infor-
mation Processing Systems (NIPS), pages 2017–2025, 2015.
5

[17] Michel Keller, Zetao Chen, Fabiola Maffra, Patrik Schmuck,
and Margarita Chli. Learning deep descriptors with scale-
aware triplet networks. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR).
IEEE, 2018. 1, 2, 4, 5

[18] Diederik P Kingma and Jimmy Ba. Adam: A method for
arXiv preprint arXiv:1412.6980,

stochastic optimization.
2014. 4, 6

[19] Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick
Haffner. Gradient-based learning applied to document recog-
nition. Proceedings of the IEEE, 86(11):2278–2324, 1998.
1, 7

[20] Wen-Yan Lin, Siying Liu, Jian-Huang Lai, and Yasuyuki
Matsushita. Dimensionalitys blessing: Clustering images by
underlying distribution. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
pages 5784–5793, 2018. 2, 3

[21] David G Lowe. Distinctive image features from scale-
invariant keypoints.
the IEEE Interna-
tional Conference on Computer Vision (ICCV), 60(2):91–
110, 2004. 2, 5, 8

Proceedings of

[22] Zixin Luo, Tianwei Shen, Lei Zhou, Siyu Zhu, Runze Zhang,
Yao Yao, Tian Fang, and Long Quan. Geodesc: Learning
local descriptors by integrating geometry constraints. In Eu-
ropean Conference on Computer Vision (ECCV), pages 170–
185. Springer, 2018. 1, 2, 3, 4, 5, 6

[23] Laurens van der Maaten and Geoffrey Hinton. Visualizing
data using t-sne. Journal of Machine Learning Research,
9(Nov):2579–2605, 2008. 7

[24] Krystian Mikolajczyk and Cordelia Schmid. A performance
IEEE PAMI, 27(10):1615–

evaluation of local descriptors.
1630, 2005. 2

[25] Krystian Mikolajczyk and Cordelia Schmid. A performance
IEEE PAMI, 27(10):1615–

evaluation of local descriptors.
1630, 2005. 2

[26] Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic,
and Jiri Matas. Working hard to know your neighbor’s mar-
gins: Local descriptor learning loss. In Advances in Neural
Information Processing Systems (NIPS), pages 4826–4837,
2017. 1, 2, 3, 4, 5

[27] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio
Savarese. Deep metric learning via lifted structured feature
embedding. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 4004–
4012, 2016. 2

[28] Adam Paszke, Sam Gross, Soumith Chintala, Gregory
Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Al-

11024

[42] Xuefei Zhe, Shifeng Chen, and Hong Yan. Directional
statistics-based deep metric learning for image classiﬁcation
and retrieval. arXiv preprint arXiv:1802.09662, 2018. 4

[43] Feng Zhou and Fernando De la Torre. Factorized graph
matching. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 127–
134. IEEE, 2012. 1, 2

ban Desmaison, Luca Antiga, and Adam Lerer. Automatic
differentiation in pytorch. In NIPS-W, 2017. 4

[29] Filip Radenovi´c, Giorgos Tolias, and Ondˇrej Chum. Cnn
image retrieval learns from bow: Unsupervised ﬁne-tuning
with hard examples. In European Conference on Computer
Vision (ECCV), pages 3–20. Springer, 2016. 1

[30] Torsten Sattler, Will Maddern, Akihiko Torii, Josef Sivic,
Tom´as Pajdla, Marc Pollefeys, and Masatoshi Okutomi.
Benchmarking 6dof urban visual localization in changing
conditions. CoRR, abs/1707.09092, 2017. 1

[31] Johannes L Schonberger and Jan-Michael Frahm. Structure-
from-motion revisited. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
pages 4104–4113, 2016. 1, 2

[32] Johannes Lutz Sch¨onberger, Hans Hardmeier, Torsten Sat-
tler, and Marc Pollefeys. Comparative evaluation of hand-
crafted and learned local features.
In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR), 2017. 4, 6, 7

[33] Johannes L Sch¨onberger, Enliang Zheng,

[34] Edgar Simo-Serra, Eduard Trulls, Luis Ferraz,

Jan-Michael
Frahm, and Marc Pollefeys. Pixelwise view selection for
unstructured multi-view stereo. In European Conference on
Computer Vision (ECCV), pages 501–518. Springer, 2016. 1
Iasonas
Kokkinos, Pascal Fua, and Francesc Moreno-Noguer. Dis-
criminative learning of deep convolutional feature point de-
scriptors. In Proceedings of the IEEE International Confer-
ence on Computer Vision (ICCV). 1, 2, 4, 5

[35] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
Learning local feature descriptors using convex optimisation.
IEEE PAMI, 36(8):1573–1585, 2014. 2

[36] Yurun Tian, Bin Fan, Fuchao Wu, et al. L2-net: Deep learn-
ing of discriminative patch descriptor in euclidean space. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), volume 1, page 6, 2017.
1, 2, 3, 4, 5, 7

[37] Tomasz Trzcinski, Mario Christoudias, Pascal Fua, and Vin-
cent Lepetit. Boosting binary keypoint descriptors. In Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), pages 2874–2881, 2013. 2

[38] Zhenhua Wang, Bin Fan, and Fuchao Wu. Local intensity
order pattern for feature description. In Proceedings of the
IEEE International Conference on Computer Vision (ICCV),
pages 603–610. IEEE, 2011. 2

[39] Simon Winder, Gang Hua, and Matthew Brown. Picking the
best daisy. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 178–
185. IEEE, 2009. 2, 4

[40] Sergey Zagoruyko and Nikos Komodakis. Learning to com-
In
pare image patches via convolutional neural networks.
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pages 4353–4361, 2015.
2

[41] Xu Zhang, X Yu Felix, Sanjiv Kumar, and Shih-Fu Chang.
Learning spread-out local feature descriptors.
In Proceed-
ings of the IEEE International Conference on Computer Vi-
sion (ICCV), pages 4605–4613, 2017. 2, 4, 5, 7

11025

