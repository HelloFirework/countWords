A convex relaxation for multi-graph matching

Paul Swoboda∗,1,2, Dagmar Kainm¨uller3,4, Ashkan Mokarian3,4, Christian Theobalt1,2, Florian Bernard1,2

1MPI Informatics 2Saarland Informatics Campus 3Berlin Institute of Health 4MDC Berlin

Abstract

1

2

We present a convex relaxation for the multi-graph
matching problem. Our formulation allows for partial pair-
wise matchings, guarantees cycle consistency, and our ob-
jective incorporates both linear and quadratic costs. More-
over, we also present an extension to higher-order costs.
In order to solve the convex relaxation we employ a mes-
sage passing algorithm that optimizes the dual problem.
We experimentally compare our algorithm on established
benchmark problems from computer vision, as well as on
large problems from biological image analysis, the size of
which exceed previously investigated multi-graph matching
instances.

1. Introduction

Finding correspondences between images or shapes is
a long-standing problem in computer vision and computer
graphics research. Such problems are of high relevance for
various applications, among them tracking, segmentation or
shape modelling. However, many formulations of the corre-
spondence problem, such as the well-known quadratic as-
signment problem (QAP), are known to be NP-hard. Most
correspondence problems can be interpreted as an instance
of the graph matching problem, where the objective is to
establish correspondences between the nodes of two given
graphs, such that the edges of both graphs are matched con-
sistently. The multi-graph matching (MGM) problem gen-
eralizes graph matching to simultaneously establishing cor-
respondences between more than two graphs. For multiple
matchings, the notion of cycle consistency arises: assume
that Xpq is the assignment matrix between graph p and q.
The condition XprXrq = Xpq ∀p, q, r is called cycle con-
sistency, see Figure 1 for an illustration.

Multi-matching problems are, among others, relevant
for multi-view reconstruction, tracking of objects in videos
or shape collection alignment. Generally, computing cor-
respondences via multi-graph matching results in higher-

∗Email of corresponding author: pswoboda@mpi-inf.mpg.de

3

graph A

1

2

1

2

3

graph B

3

graph C

Figure 1. Illustration of cycle consistency in multi-graph match-
ing (best viewed in color). Each graph A, B, C comprises three
nodes (green, blue, purple) and three edges (white lines). The true
correspondence is indicated by the node colour and node labels 1,
2, 3. Matchings between pairs of graphs are shown by coloured
lines (A↔B in yellow, A↔C in gray, and B↔C in blue). Wrong
matchings are indicated by dashed lines. The multi-matching
A1↔B2↔C2↔A2 is not cycle consistent.

quality solutions in comparison to matches computed by a
series of graph matching problems only. The reason is that
spurious matches introduced by noise in the data can be cor-
rected, since each correspondence between two graphs de-
pends on other matches via cycle consistency.

While matching problems between two graphs are well-
studied and have received attention since more than ﬁfty
years [6, 18, 28, 20, 9, 36, 35, 48, 30, 26, 12, 1, 16, 11, 4, 46,
49, 14, 21, 2, 19], the multi-graph matching problem is less
well-studied and hence offers great potential for improve-
ments, both on the theoretical and practical side.
In this
work we propose a novel multi-graph matching approach
that has the following main contributions:

11156

Contributions.

In contrast to most prior work, our
approach is based on a principled and theoretically well-
grounded convex optimization approach that (i) jointly op-
timizes a general quadratic multi-graph matching objective
while considering cycle consistency constraints, (ii) pro-
vides primal/dual gaps w.r.t. a strong relaxation, (iii) is in-
dependent of the initialization, (iv) is scalable to large-scale
problems due to the use of state-of-the-art message pass-
ing techniques, and (v) can be easily extended to the multi-
hypergraph matching problem. To our knowledge, there ex-
ists no solver in the literature that combines these desirable
characteristics.

2. Related work

We review relevant algorithmic prior work for the graph

matching and the multi-graph matching problem below.

Graph-matching. The simplest version of graph match-
ing is the linear assignment problem (LAP) that can be
solved in polynomial time with the Hungarian [24] or Auc-
tion [6] algorithm. For quadratic costs, the graph matching
problem is also known as the quadratic assignment prob-
lem (QAP) [18].
It is considered to be one of the prac-
tically most difﬁcult NP-hard problems [28]. Therefore,
many heuristics and approximative algorithms have been
proposed, among them algorithms based on Lagrangian re-
laxation [36, 47, 35], semideﬁnite programming [30, 16],
and other techniques from convex optimization [12, 1, 11,
4]. Apart from that, primal heuristics have been pro-
posed that are based on spectral techniques [20, 9], path-
following [46, 49, 14], loopy belief propagation [2], and
ADMM [19]. For survey papers that give an overview of
techniques used in the combinatorial optimization commu-
nity we refer to [28, 21]. Higher-order variants of graph
matching, known as hypergraph matching, have also been
considered, e.g. in [25, 10].

Our algorithm can be considered as an extension of the
message passing techniques proposed in [47, 35] from the
graph matching problem to the more difﬁcult multi-graph
matching problem.

Multi-graph matching. Various techniques have been
applied for solving multi-graph matching problems. The
method [32] holds a tensor that represents all pairwise
matchings simultaneously. This way, cycle consistency is
satisﬁed, but their approach is not scalable. A fast algo-
rithm for MGM based on clustering was proposed in [37],
where, however, only linear costs are considered.

In [44], the authors alternatingly optimize the individ-
ual graph matching problems and enforce cycle consis-
tency repeatedly to obtain progressively better MGM so-
lutions. The work [38] proposes a smooth nonconvex rank-
constrained formulation of the multi-matching problem and
utilize block coordinate descent on the resulting problem.
Other approaches include extensions of random walk based

methods [29], factorized graph matching [49] or matrix fac-
torization [45]. The authors of [43] propose to alternat-
ingly use existing graph matching solvers such that ulti-
mately cycle consistency is achieved. The work [42, 41]
also use existing graph matching solvers and gradually ex-
tend the problem by adding cycle consistency constraints
until a feasible multi-graph matching is obtained. However,
the works [43, 42, 41] do not use an overall optimization
formulation.

In [16, 4], the authors consider a convex relaxation for
MGM based on semideﬁnite programming. While the
approach [16] relies on a variable lifting that makes the
problem computationally expensive, the approach in [4] is
lifting-free but only discussed for the case of full matchings.
Another line of works split the solution of the MGM
problem into two steps: solving the individual pairwise
graph matching problems ﬁrst, and enforcing cycle consis-
tency as post-processing. The works [27, 7, 50, 31, 22,
5] assume they are given individual matchings and then
postprocess them via matrix factorization to obtain cycle-
consistent matchings, which they call permutation synchro-
nization. Similarly, in [3] the authors improve given match-
ings, but they do not obtain cycle-consistent matchings.

Organization. Section 3 contains our overall multi-
graph matching approach.
In Section 3.1 we formally
state the MGM problem, in Section 3.2 we describe the
general Lagrange decomposition framework for linear pro-
gramming (LP) relaxations, and in Section 3.3 we present
the MGM problem decomposition within this framework.
To obtain a scalable solver for the resulting LP we pro-
pose to use message passing, where we describe the mes-
sages in Section 3.4, and the solver itself in Section 3.5.
Since cycle consistency is enforced through a cubic num-
ber of constraints, in Section 3.6 we propose a dual cutting
plane algorithm to include only the required constraints in a
working set. We discuss extensions to the multi-hypergraph
matching problem in Section 3.7. Finally, in Section 4 we
experimentally evaluate our solver on problems from com-
puter vision and biomedical image analysis. We provide ad-
ditional details in Appendix A. Code and datasets are avail-
able from https://github.com/LPMP/LPMP.

3. Lagrangian MGM relaxation

In this section we will ﬁrst present the multi-graph
matching problem with quadratic costs. Next, we review
the Lagrange decomposition framework [34] and show how
it can be applied to decompose the MGM into efﬁciently
solvable subproblems. We also review the message pass-
ing algorithm from [34] for general decompositions and de-
tail how our MGM decomposition can be optimized by this
method. Last, we describe a dual cutting plane algorithm
for cycle consistency constraints.

Since the problem decomposition is complex, the nota-

11157

tion necessary to describe it is so as well. To aid the reader
we consistently use symbols for indices which refer to the
same type of object. The used index variables are sum-
marised in Table 1.

Table 1. Notational conventions

symbol meaning

j, k
s, t
p, q, r
i, ℓ
{·}[pq]
[pq]
{·}
d
mp

subproblem
vector and matrix indices
index of pairwise GM problems
temporary indices for sums
matching from p to q, p < q

matching from q to p, p < q
number of graphs
number of nodes in graph p

3.1. Problem formulation

We phrase the problem of multi-graph matching as
jointly solving pairwise graph matching problems between
all pairs of graphs under additional cycle consistency con-
straints. Although our approach is applicable to consid-
ering subsets of pairwise graph matchings, for notational
convenience we phrase the MGM problem as the match-
ing of all possible pairs of graphs. We assume that the
cost for matching the p-th graph and the q-th graph, where
p, q ∈ [d] := {1, . . . , d} for d being the total number of
graphs, is given by (x[pq])⊤W [pq]x[pq], so that the MGM
problem reads

min

{X [pq]∈Pmpmq }

s.t.

(x[pq])⊤W [pq]x[pq]

Xp,q∈[d]

X [pq]X [qr] ≤ X [pr] ,

(1)

(2)

where we deﬁne x[pq] := vec(X [pq]) and the set of m × n
(partial) permutation matrices Pmn is deﬁned as

Pmn = {X ∈ {0,1}m×n : X 1n≤1m, X ⊤1m≤1n} .

(3)

Note that we write all indices that refer to pairs (or triplets)
of graphs in the MGM problem in brackets, e.g. W [pq].
Proposition 1. Let (X [pq])p,q∈[d] be a set of partial match-
ings. Then constraints (2) cut off all non-cycle-consistent
elements.

We give a minimal example showing when constraints 2

are active in Example 1 in the Appendix.

3.2. Lagrange decomposition

We will solve Problem (1) in a Lagrange decomposi-
tion framework. To this end we recapitulate the framework
in [34], where the class of Integer Relaxed Pairwise Sepa-
rable Linear Programs (IRPS-LP) is deﬁned. IRPS-LPs are
a special case of dual decomposition [13].

Deﬁnition 1 (IRPS-LP [34]). Let N ∈ N and let G =
(V, E) be a graph with V = {1, . . . , N }. For every j ∈ V,
let dj ∈ N, let Y j ⊆ {0, 1}dj , and let θj ∈ Rdj . Let Λ :=
conv(Y 1) × · · · × conv(Y N ). For every {j, k} = e ∈ E,
let me ∈ N, Aj,k ∈ {0, 1}me×dj and Ak,j ∈ {0, 1}me×dk
such that

∀x ∈ Y j : Aj,kx ∈ {0, 1}me , and
∀x ∈ Y k : Ak,jx ∈ {0, 1}me .

(4)

(5)

Then, the LP written below is called integer relaxed pair-
wise separable w.r.t. the graph G.

hθj, µji

min

µ∈Λ Xj∈V

subject to ∀{j, k} ∈ E : Aj,kµj = Ak,jµk .

(6)

(7)

Here, G = (V, E) deﬁne a general problem decomposi-
tion graph relevant for IRPS-LP that shall not be confused
with the graphs that we aim to match. Every j ∈ V deﬁnes
a subproblem, and every edge jk ∈ E deﬁnes a dependency
of subproblems. Def. 1 is more speciﬁc than a general La-
grange decomposition, since, ﬁrstly, the subproblems are
assumed to be binary, and secondly, the linear constraints
(7) that describe the dependence of subproblems are deﬁned
by 01-matrices that map 01-vectors to 01-vectors.
IRPS-
LPs are amenable to efﬁcient optimization by the message
passing framework of [34].

In what follows, we will refer to subproblems j ∈ V by
the distinctive names we give to the free variables xj ∈ Y j
they optimize over. It will be clear from context when we
use subproblem variables xj to refer to the subproblem j.

3.3. Multi graph matching decomposition

We will propose a decomposition of Problem (1) as
IRPS-LP. In Fig. 2 we illustrate the subproblem decom-
position. Our decomposition consists of three types of
subproblems:
(i) matching subproblems that account for
matching nodes from one graph to the other, (ii) quadratic
cost subproblems that account for matching edges from one
graph to another, and (iii) cycle consistency subproblems
that constrain matchings from three distinct graphs to be
valid multi-matchings. In what follows, we will use the fol-
lowing notation rule: Let a pairwise graph matching prob-
lem between graphs p and q be given, where w.l.o.g. p < q.
There are two matching directions, with which we will as-
sociate two sets of variables: Given nodes (resp. edges) in
p, match to nodes (resp. edges) in q. We write variables
related to this forward direction as {·}[pq], where the re-
spective variable is inserted in place of {·}. For the reverse
direction, i.e. matching from q to p, we distinguish variables

by writing them as {·}

[pq]

.

Matching subproblems. As the matching subproblems
are analogous for all pairwise GM problems p, q, we ﬁx p, q

11158

pairwise GM problem 			(𝑥 "# )<𝑊 "# 𝑥 ["# ]	

pairwise GM problem 			(𝑥 "$ )<𝑊 "$ 𝑥["$]

pairwise GM problem 			(𝑥 #$ )<𝑊 #$ 𝑥[#$]

s

𝑥̅& 	 ∈ 0,1 67

𝑠 ∈ [𝑚"]

𝑥’ 	 ∈ 0,1 68

𝑡 ∈ [𝑚#]

𝑥̅ & 	 ∈ 0,1 6>

𝑠 ∈ [𝑚"]

𝑥’ 	 ∈ 0,1 68

𝑡 ∈ [𝑚$]

𝑥̅ & 	 ∈ 0,1 6>

𝑠 ∈ [𝑚#]

𝑥’ 	 ∈ 0,1 67

𝑡 ∈ [𝑚$]

𝑥̅&’ 	 ∈ 0,1 67×67 	

𝑥&’ 	 ∈ 0,1 68×68	

𝑥̅&’ 	 ∈ 0,1 6>×6> 	

𝑥&’ 	 ∈ 0,1 68×68	

𝑥̅&’ 	 ∈ 0,1 6>×6> 	

𝑥&’ 	 ∈ 0,1 67×67 	

𝑠 ∈ 𝑚" 	
𝑡 ∈ [𝑚"]

𝑠 ∈ 𝑚# 	
𝑡 ∈ [𝑚#]

𝑠 ∈ 𝑚" 	
𝑡 ∈ [𝑚"]

𝑠 ∈ 𝑚$ 	
𝑡 ∈ [𝑚$ ]

𝑠 ∈ 𝑚# 	
𝑡 ∈ [𝑚#]

𝑠 ∈ 𝑚$ 	
𝑡 ∈ [𝑚$ ]

l

m
e
b
o
r
p
b
u
s

l

s
m
e
b
o
r
p
b
u
s

i

g
n
h
c
t
a
m

t
s
o
c
 
c
i
t

a
r
d
a
u
q

i

y
c
n
e
t
s
s
n
o
c
 
e
c
y
c

l

l

s
m
e
b
o
r
p
b
u
s

couplings:
matching/matching
matching/quadratic
matching/cycle consistency

𝑥 "#$ ,&’ = 𝑎& , 𝑏’, 𝑐&’
𝑠 ∈ [𝑚"], 𝑡 ∈ [𝑚$ ]

𝑐&’ 	 ∈ {0,1}

𝑎& 	 ∈ 0,1 67

𝑏’ 	 ∈ 0,1 67

cycle consistency constraint 			𝑋 ["# ]𝑋 #$ ≤ 𝑋 ["$]

Figure 2. Overview of the subproblem decomposition and their couplings for a triplet of pairwise GM problems [pq], [pr], [qr], along with
the [pqr] cycle consistency constraint (best viewed in color). The rounded rectangles correspond to (some of) the nodes of V in Def. 1, and
the coloured lines correspond to (some of) the edges of E, respectively.

and omit the superscripts p, q for the sake of an easier ex-
planation (e.g. we use X instead of X [pq]). We write the
(mp×mq)-dimensional partial matching matrix X in terms
of matrix rows and columns as

X1,∗
...

Xmp,∗

X =





=(cid:2)X∗,1

. . . X∗,mq(cid:3) .

(8)

a

∈
subproblem with

every row with index s
deﬁne

[mp] of X
For
set
feasible
we
s
= {x ∈ {0, 1}mq : hx, 1i ≤ 1}, and for every col-
Y
umn with index t ∈ [mq] we deﬁne a factor with feasible
set Y t = {x ∈ {0, 1}mp : hx, 1i ≤ 1}. It follows that
X ∈ Pmpmq is equivalent to (9) in conjunction with (10):

(Xs,∗)⊤ ∈ Y

s

for s ∈ [mp], and

X∗,t ∈ Y t for t ∈ [mq] .

(9)

(10)

We add each row and column of X as a subproblem to V,
so that we have one mq-dimensional variable xs ∈ Y
for
each [s] ∈ mp, and one mp-dimensional variable xt ∈ Y t
for each [t] ∈ mq.
In order to ensure that the variables
{xs}, {xt} form a valid X ∈ Pmpmq , they are coupled via
the equality constraints

s

(x1)⊤

...

(xmp )⊤







. . .

=(cid:2)x1

xmq(cid:3) .

(11)

The constraints (11) correspond to constraints (6) between
Y

and Y t, as they can be expressed as

s

As,txs = At,sxt .

(12)

Quadratic cost subproblems. Again, as the quadratic
costs for all pairwise GM problems p, q are analogous,
we ﬁx p, q and omit the superscripts p, q for the sake of
an easier explanation.
In order to linearize the quadratic
cost x⊤W x from (1), where x ∈ Rmpmq and W ∈
Rmpmq×mpmq , we ﬁrst observe that

x⊤W x =


x1
...
xmq

⊤





W (11)

...

W (mq1)

· · · W (1mq)
. . .
· · · W (mqmq)

...







x1
...
xmq




(13)

,

where xs ∈ Y s for s ∈ [mq] and W (st) ∈ Rmp×mp ,

=

mq

Xs,t=1

(xs)⊤W (st)xt .

(14)

The blockwise decomposition in equation (14) deﬁnes
unary and pairwise potentials similarly as in a Markov Ran-
dom Field (MRF) as follows: Each diagonal element in
block W (ss) for s ∈ [mq] deﬁnes a unary cost θs =
0.5· diag(W (ss)), so that we can write the cost function
0.5·(xs)⊤W (ss)xs for each unary s-factor (s ∈ [mq]) as
hxs, θsi (the factor 0.5 accounts for the decomposition in
variables {·} and {·}).

For each non-diagonal block W (st) with s, t ∈ [mq], s <
t we deﬁne a pairwise factor with feasible set Y st = {x ∈
{0, 1}mp×mp : 1⊤x1 = 1}. We connect unary variables
xs ∈ Y s and xt ∈ Y t with pairwise variable xst ∈ Y st via
constraints as follows:

As,stxs = Ast,s vec(xst) ⇔ xs = xst1

At,stxt = Ast,t~(xst) ⇔ xt = (xst)⊤1

(15)

11159

The pairwise costs are θst = 0.5·(W (st) + (W (ts))⊤),
so that we can write the quadratic cost
function
0.5·((xs)⊤W (st)xt + (xt)⊤W (ts)xs) in terms of each pair-
wise st-factor (s, t ∈ [mq], s < t) as the linear term
hxst, θsti. Analoguously, we deﬁne the costs for the vari-
ables xs, xt, xst, s, t ∈ [mp]. Note that this construction
corresponds to the local polytope [39].

Cycle consistency subproblems. Since the cycle con-
sistency subproblems couple the individual pairwise graph
matching problems, in this paragraph we cannot drop the
superscripts p, q, r, so that we e.g. write X [pq] instead of
X, and x[pq],s ∈ Y [pq],s instead of xs ∈ Y s.

Let now the triplet of matchings X [pq], X [qr] and X [pr]
be given. The element-wise matrix inequality X [pq]X [qr] ≤
X [pr] comprises mpmr scalar inequalities. Let us consider
the scalar inequality at position (s, t) ∈ [mp] × [mr], which
reads

Such reparametrizated cost functions can be obtained as fol-
lows: For any two dependent subproblems {j, k} = e ∈ E
with associated constraint matrices Aj,k ∈ {0, 1}me×dj ,
Ak,j ∈ {0, 1}me×dk (see Def. 1), we can change the costs
θj and θk by an arbitrary vector ∆ ∈ Rme according to the
update rules

ˆθj := θj + (Aj,k)⊤∆
ˆθk := θk − (Ak,j)⊤∆ .

(18)

(19)

We refer to any update of θ according to the rules (18)–(19)
as message passing. Message passing does not change the
cost of any primal feasible solution, as

hˆθj, µji + hˆθk, µki

= hθj + (Aj,k)⊤∆, µji + hθk − (Ak,j)⊤∆, µki
= hθj, µji + hθk, µki + h∆, Aj,kµj − Ak,jµki

(20)

(21)

(22)

X [pq]

s,∗ X [qr]

∗,t = Xi∈[mq]

X [pq]

s,i X [qr]

i,t ≤ X [pr]

st

.

(16)

(7)
= hθj, µji + hθk, µki .

Accordingly, we deﬁne the feasible set

Y [pqr],st = {x[pqr],st = (a, b, c) ∈ {0, 1}mq×mq×1 :

ha, bi ≤ c} .

(17)

For any p, q, r, s, t, the matching constraints Aj,kµj =
Ak,jµk from (7) translate into

(i) x[pq],s = a for x[pq],s ∈ Y

[pq],s

from (9)

(ii) x[qr],t = b for x[qr],t ∈ Y [qr],t from (10)

(iii) x[pr],s

t

= c for x[pr],s

t

∈ Y

[pr],s

from (9), and

(iv) x[pr],t

s

= c for x[pr],t

s

∈ Y [pr],t from (10),

where x[pqr],st = (a, b, c) ∈ Y [pqr],st.

Note that here we explicitly indicate the indices of the
pairwise graph matching problems for the feasible sets in

(9) and (10), e.g. we write Y
given p, q.

[pq],s

to denote Y

s

in (9) for

Remark 2. Only one of the constraints (iii) and (iv) is
necessary. We include both in our formulation, since con-
straints will translate into Lagrangian variables and for our
algorithm it will be advantageous to have this overcomplete
representation since it leads to more frequent updates.

3.4. Messages

As already indicated above, instead of directly solving
the primal problem (6), we solve its dual. Speciﬁcally,
we consider the space of reparametrized cost functions θ
that are equivalent to θ, where we require that for every
primal µ admissible to (6) it holds that hµ, θi = hµ, θi.

Message passing does, however, change the dual lower

bound L(θ) to (6) given by

L(θ) :=Xj∈V

hθj, xi .

min
x∈Y j

(23)

The maximum of L(θ) over all costs obtainable by mes-
sage passing is equal to the minimum of (6), by linear pro-
gramming duality. We seek to alter the costs θ by means of
message passing so as to maximize the lower bound L(θ).
Elementary message updates. We call a message up-
date elementary, if it acts on a pair of factors {j, k} ∈ E and
reparametrizes factors j and k by a message ∆ as in (18)
and (19). An elementary message is required to mono-
tonically decreases the lower bound L(θ), and addition-
ally is maximal w.r.t. a partial order, as described in [34].
Since in our case all elementary messages can be mechan-
ically derived by following [34], we give the correspond-
ing updates between the matching/quadratic/cycle consis-
tency subproblem factors in Table 2. We denote the message
computation by ∆ = msg(j, k) and the reparametrization
by repam(∆, j, k). Our overall algorithm will proceed by
passing a series of reweighted elementary messages.

3.5. Message passing algorithm

Algorithm 1 shows a forward pass of the general mes-
sage passing algorithm for IRPS-LP. It proceeds by sequen-
tially visiting a subset of subproblems in a given order. For
each visited factor j it ﬁrst receives elementary message up-
dates from a subset of neighboring subproblems R→
j . Sec-
ond, it sends messages to another set of neighboring sub-
problems S→
j via scaled elementary message passing up-
dates with weights ω→
j . In the backward pass, we reverse

11160

j ∈ V

k ∈ V

∆ = msg(j, k)

xs ∈ Y

s

xt ∈ Y t

xs ∈ Y s
xst ∈ Y st
xst ∈ Y st
xs ∈ Y

s

xst ∈ Y
xst ∈ Y

st

st

xt ∈ Y t

xs ∈ Y

s

xst ∈ Y st
xs ∈ Y s
xt ∈ Y t
xst ∈ Y

st

xs ∈ Y
xt ∈ Y

s

t

matching/matching
(x)

t ) − min

θ

s

s

θ

(xs

x∈Y

s\{xs

t }

θt(xt

s) − min

x∈Y t\{xt

s}

θt(x)

matching/quadratic

θs(x)

s

θ

(x)

θs − min
x∈Y s
min→ θst
min↓ θst
s
− min
θ
x∈Y
st
min→ θ
st
min↓ θ

s

matching/cycle consistency

x[pq],s ∈ Y

[pq],s

(a, b, c) ∈ Y [pqr],st

[pq],s

θ

− min

[pq],s

x∈Y

x[qr],t ∈ Y [qr],t

(a, b, c) ∈ Y [pqr],st

θ[qr],t − min

[pq],s

θ

(x)

θ[qr],t(x)

x[pr],s ∈ Y

[pr],s

(a, b, c) ∈ Y [pqr],st

[pr],s

θ

x∈Y [qr],t
) −

(x[pr],s

t

x[pr],t ∈ Y [pr],t

(a, b, c) ∈ Y [pqr],st

θ[pr],t(x[pr],t

s

) −

min
[pr],s\{x

x∈Y

[pr],s
t

min
x∈Y [pr],t\{x

[pr],t
s

}

[pr],s

θ

(x)

}
θ[pr],t(x)

(a, b, c) ∈ Y [pqr],st
(a, b, c) ∈ Y [pqr],st
(a, b, c) ∈ Y [pqr],st
(a, b, c) ∈ Y [pqr],st

[pq],s

x[pq],s ∈ Y
x[qr],t ∈ Y [qr],t
[pr],s
x[pr],s ∈ Y
x[pr],t ∈ Y [pr],t

(min (ai, ai + bi + c, minj6=i{ai + bj}) − min (0, c, minj{bj}))i=1,...,mq
(min (bi, ai + bi + c, minj6=i{ai + bj}) − min (0, c, mini{ai}))j=1,...,mp
min (z, z + mini{ai + bi}) − min (0, mini{ai}, minj{bj}, mini6=j{ai + bj})
min (z, z + mini{ai + bi}) − min (0, mini{ai}, minj{bj}, mini6=j{ai + bj})

Table 2. Elementary message updates. Notation min→ A denotes row-wise minimum of matrix A, while min↓(A) denotes column-wise
minimum of A.

the order of visited factors so that in Alg. 1 we replace
(R→, S→, ω→) by (R←, S←, ω←).

For notational convenience below, we deﬁne Nj := {k :
{j, k} ∈ E} as the neighbours of the j-th subproblem in the
subproblem graph (V, E).

For solving the MGM formulation above with Algo-

rithm 1, we specify the free parameters as follows:

• Vupdate corresponds to all matching subproblems.
• Order on Vupdate: We order the graph matching
subproblems (1) lexicographically w.r.t. indices p, q ∈
[d].
For a given graph matching problem between p
and q we order the associated matching subproblems
by ﬁrst considering the column matching subproblems
x[pq],1, . . . , x[pq],mq followed by the row matching subprob-
lems x[pq],1, . . . , x[pq],mp . Moreover, we deﬁne

• R→
j

• S→
j

• ω→
j

:=

Nj\{x[pq],st : s < t},

:=(Nj\{x[pq],st : s < t},
:=(Nj\{x[pq],st : s > t},

Nj\{x[pq],st : s > t},
1
j } .
:= S→
j

and S←
j

#{S→

j = x[pq],t ,
j = x[pq],t , and
j = x[pq],t ,
j = x[pq],t , and

We deﬁne R←
j
“<” by “>” and vice versa for R→

:= R→
j and S→
j .

j , i.e. we swap the

Algorithm 1: Forward pass of message passing for
IRPS-LP
1 for j ∈ Vupdate ⊂ V in ascending order do
2

Receive messages:
for k ∈ R→

j ⊂ {k ∈ V : {j, k} ∈ E} do

∆ = msg(k, j);
repam(∆, k, j);

end
Send messages:
for k ∈ S→

j ⊂ {k ∈ V : {j, k} ∈ E} do

∆k = msg(j, k);

end
for k ∈ S→

j ⊂ {k ∈ V : {j, k} ∈ E} do

repam(ω→

j,k · ∆k, k, j);

end

3

4

5

6

7

8

9

10

11

12

13

14 end

3.6. Cutting planes for cycle consistency

There are O(m2d3), m = maxp∈[d]{mp}, cycle consis-
tency subproblems, namely one for each triplet of graphs

11161

p, q, r ∈ [d] and each pair of nodes s ∈ [mp], t ∈ [mr].
Hence, it is not practical to add all of them at once. Since
many of them will not be necessary to achieve the LP-
optimum, we pursue a cutting plane approach in which we
only add those cycle consistency subproblems that are guar-
anteed to increase the dual lower bound L(θ). Speciﬁcally,
we begin the optimization without any cycle consistency
subproblems. When no progress occurs or after some num-
ber of iterations, we start adding cycle consistency subprob-
lems. To this end, we ﬁrst enumerate all graph matching
triplets {p, q, r}, p, q, r ∈ [d]. For each triplet we enumer-
ate all associated cycle consistency subproblems x[pqr],st
and test how much the dual lower bound would increase if
we add x[pqr],st. We record the increase and add the K best
cycle consistency subproblems, where K is a ﬁxed number
of subproblems to add. The guaranteed increase of the dual
lower bound from addition of subproblem x[pqr],st can be
computed with Algorithm 2, see Appendix A.

3.7. Multi hypergraph matching

Our framework can easily be extended to the hy-
pergraph matching case.
For the third-order case, we
have 3-tensors W ′[pq] instead of a matrices W [pq] in (1).
In other words, we have a multi-linear symmetric form
W ′[pq] ∈ Rmpmq×mpmq×mpmq instead of a matrix W [pq] ∈
Rmpmq×mpmq as in (1). To account for this higher order
cost formulation we introduce third-order cost subproblems
and connect them to quadratic subproblems, exactly as done
for MRFs, see [40, 17]. While the hypergraph matching for-
mulation could be used to optimize over a more complicated
cost formulation, we use it to tighten our LP-relaxation, as
done for MRFs [40]. This is equivalent to having third-order
cost subproblems in the Lagrange decomposition with zero
cost. Since adding all possible third-order cost subproblems
would be computationally prohibitive, we employ the cut-
ting plane approach proposed in [33] which uses reductions
to max-cut problems to ﬁnd violated cycle inequalities. The
found cycles are subsequently triangulated to yield third-
order subproblems in our formulation.

3.8. Runtime

The runtime per iteration for the basic relaxation is lin-
ear in the number of non-zero entries #{ij : Wij 6= 0} and
the number of triplet constraints, since the respective oper-
ations in Table 2 can be computed in corresponding time.
When we additionally tighten our problem, the correspond-
ing message passing operations can be naively performed in
time O(m3
p) for p ∈ [d] and each third-order cost subprob-
lem. More efﬁcient message passing operations for zero-
cost third-order subproblems are described in [23], where
an expected running time of O(m2

p log(mp)) is given.

4. Experiments

In this section we provide an experimental evaluation of

our algorithm, for which we consider two variants:

MP: Our message passing Algorithm 1 with the cycle
consistency cutting plane routine from Section 3.6. We ob-
tain a primal solution from the dual solution using permu-
tation synchronization [27] applied on the dual costs after
they have been rounded based on solving an LAP.

MP-T: As the MP-algorithm above, but with additional

tightening as described in Section 3.7.

4.1. Synthetic MGM problems

from the authors
Using the experimental protocol
[41], we generate four different conﬁgurations of
of
synthetic MGM problems
(complete, density,
deform, outlier), where for each of them we con-
sider the number of graphs d to vary from 4 to 16. For
details on the problem generation we refer to [41]. We com-
pare our MP/MP-T algorithms to RRWM [8], composition-
based afﬁnity optimisation (CAO) [41], MatchOpt (mOpt)
[44], permutation synchronisation (mSync) [27], and the
recent state-of-the-art DS* method [4]. The results are
shown in Fig. 3. Our MP-T approach performs similar
to DS* on the complete and density instances, and
much better compared to the other methods. Note that in
contrast to DS*, our approach explicitly considers outliers,
and as such our methodology is particularly well-suited in
setups with a large portion of outliers (see outlier case).
Apart from complete, where MP is already tight, the
tightening (Section 3.7) signiﬁcantly improves the results,
as can be seen when comparing MP with MP-T. We believe
it is an advantage of our method that it can be extended
to optimizing tighter LP-relaxations, while this would be
difﬁcult to do in more ad-hoc approaches [8, 42, 44, 4, 27].

4.2. CMU House & Hotel

In this experiment we consider the CMU house and
hotel sequences, which are image sequences that come
with annotated ground truth. In order to obtain challenging
MGM problems, we consider a setting where 40% of the
points are outliers (the total number of points is 10 per im-
age). For this, we have followed the protocol of [41], where
further details are described. We consider the same set of
MGM algorithms as in Section 4.1. The results of this ex-
periment are shown in Fig. 4. In both datasets, our method
(MP-T) achieves a signiﬁcantly higher precision compared
to all other methods, while also achieving a better recall.
This again conﬁrms the robustness of our approach.

4.3. C. elegans

Here we consider the large-scale worms dataset of [15].
The goal is to ﬁnd corresponding nuclei of C. elegans, a fa-
mous model organism in biology. The dataset contains 30

11162

rrwm

cao-c*

cao-c

mOpt

mSync

DS*

Our (MP)

Our (MP-T)

synthetic / complete

1

0.8

0.6

0.4

0.2

i

i

n
o
s
c
e
r
p

synthetic / density

synthetic / deform

synthetic / outlier

0.8

0.6

0.4

0.2

i

i

n
o
s
c
e
r
p

1

0.8

0.6

0.4

0.2

i

i

n
o
s
c
e
r
p

4

8

12

16

4

8

12

16

4

8

12

16

4

8

12

16

d

synthetic / complete

1

0.8

0.6

0.4

0.2

l
l

a
c
e
r

d

d

d

synthetic / density

synthetic / deform

synthetic / outlier

0.8

0.6

0.4

0.2

l
l

a
c
e
r

l
l

a
c
e
r

1

0.8

0.6

0.4

0.2

i

i

n
o
s
c
e
r
p

l
l

a
c
e
r

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

4

8

12

16

4

8

12

16

4

8

12

16

4

8

12

16

d

d

d

d

Figure 3. Results on synthetic data (best viewed in color). Note that in the ﬁrst column (complete) the methods DS*, MP and MP-T
achieve a perfect matching in all cases.

house / outlier

hotel / outlier

i

i

n
o
s
c
e
r
p

0.8

0.6

0.4

0.2

0

4

8

12

16

4

8

12

16

d

house / outlier

d

hotel / outlier

1

0.5

l
l

a
c
e
r

0

0.7

0.6

0.5

0.4

0.3

1

0.8

0.6

0.4

i

i

n
o
s
c
e
r
p

l
l

a
c
e
r

4

8

12

16

4

8

12

16

d

d

Figure 4. Results on CMU house and hotel multi-graph match-
ing problems (best viewed in color). Refer to Fig. 3 for the legend.

three-dimensional microscopy images of individual worms
and segmentations of their nuclei, where each 3D image de-
picts one worm that has 558 nuclei. As such, the result-
ing nuclei matching problems are among the largest graph
matching instances ever investigated in the literature (see
[35]; note that the pairwise problems we establish for this
work differ slightly from the worm matching problems of
[35] in that they are 30·29/2 worm-to-worm matching prob-
lems, as opposed to 30 atlas-to-worm matching problems).
We derive a range of MGM problems by selecting subsets
of worms of varying cardinality. The results are summa-
rized in Table 3. It can be seen that with successively larger
numbers of graphs the precision and recall are improved.
We would like to stress that the largest instances have 36
million optimization variables and methods [8, 42, 44, 4]
do not scale well enough. Method [27] does not allow for
quadratic costs, hence we cannot report competing algorith-
mic results for this dataset.

d
W
time
prec.
recall

7

6

5

4

2

10
0.8M 4M 8M 12M 17M 22M 29M 36M
165
.79
.43

130
.78
.43

110
.76
.42

20
.70
.41

35
.73
.42

90
.75
.42

3
.71
.41

50
.73
.41

8

9

Table 3.
Quantitative results for the worms dataset solved
with [35] for d = 2 and MP for the multi-graph case d > 2. We
give the number of non-zero entries #{ij : Wij 6= 0}, the time in
minutes for solving and obtained precision and recall.

5. Conclusion

We have presented a principled and theoretically well-
grounded convex relaxation for the multi-graph matching
problem based on a Lagrange decomposition. We have
phrased MGM as simultaneously solving pairwise graph
matching problems that communicate with each other based
on cycle consistency constraints. Our proposed formula-
tion is general as it can handle linear, quadratic, and higher-
order matching costs, while at the same time considering
cycle consistency constraints. Due to the convex formula-
tion it is independent of the initialization, and due to the
duality principle we obtain primal/dual gaps that can serve
as optimality certiﬁcates. Moreover, we have demonstrated
that by using additional higher-order terms one can obtain
a tighter relaxation. In order to computationally solve the
dual problem, we use an efﬁcient algorithm based on mes-
sage passing. In our experiments we considered standard
computer vision benchmark problems, as well as problems
from biomedical image analysis. The experimental results
demonstrate the merits of our approach.

Acknowledgments

This work was partially funded by the ERC Consolidator
Grant 4DRepLy (770784).

11163

References

[1] Yonathan Aﬂalo, Alexander Bronstein, and Ron Kimmel. On
convex relaxation of graph isomorphism. Proceedings of the
National Academy of Sciences, 112(10):2942–2947, 2015.

[2] Dragomir Anguelov, Praveen Srinivasan, Hoi-cheung Pang,
Daphne Koller, Sebastian Thrun, and James Davis. The cor-
related correspondence algorithm for unsupervised registra-
tion of nonrigid surfaces.
In L. K. Saul, Y. Weiss, and L.
Bottou, editors, Advances in Neural Information Processing
Systems 17, pages 33–40. MIT Press, 2005.

[3] Federica Arrigoni, Eleonora Maset, and Andrea Fusiello.
In

Synchronization in the symmetric inverse semigroup.
ICIAP, 2017.

[4] Florian Bernard, Christian Theobalt, and Michael Moeller.
DS*: Tighter lifting-free convex relaxations for quadratic
matching problems. In CVPR, 2018.

[5] Florian Bernard, Johan Thunberg, Jorge Goncalves, and
Synchronisation of partial multi-
Christian Theobalt.
matchings via non-negative factorisations. Pattern Recog-
nition, 92:146–155, 2019.

[6] Dimitri P Bertsekas. Network optimization: Continuous and

discrete models. Athena Scientiﬁc, 1998.

[7] Yuxin Chen, Leonidas J Guibas, and Qi-Xing Huang. Near-
In

optimal joint object matching via convex relaxation.
ICML, 2014.

[8] Minsu Cho, Jungmin Lee, and Kyoung Mu Lee. Reweighted

random walks for graph matching. ECCV, 2010.

[9] T Cour, P Srinivasan, and J Shi. Balanced graph matching.

NIPS, 2006.

[10] Olivier Duchenne, Francis Bach, In-So Kweon, and Jean
Ponce. A tensor-based algorithm for high-order graph
matching.
IEEE transactions on pattern analysis and ma-
chine intelligence, 33(12):2383–2395, 2011.

[11] Nadav Dym, Haggai Maron, and Yaron Lipman. DS++ -
A ﬂexible, scalable and provably tight relaxation for match-
ing problems. ACM Transactions on Graphics (TOG), 36(6),
2017.

[12] Fajwel Fogel, Rodolphe Jenatton, Francis Bach, and Alexan-
dre d’Aspremont. Convex relaxations for permutation prob-
lems. In NIPS, 2013.

[13] Monique Guignard and Siwhan Kim. Lagrangean decompo-
sition: A model yielding stronger Lagrangean bounds. Math-
ematical programming, 39(2):215–228, 1987.

[18] Eugene L Lawler. The quadratic assignment problem. Man-

agement science, 9(4):586–599, 1963.

[19] D Khuˆe Lˆe-Huu and Nikos Paragios. Alternating direction

graph matching. In CVPR, 2016.

[20] Marius Leordeanu and Martial Hebert. A spectral technique
for correspondence problems using pairwise constraints. In
ICCV, 2005.

[21] Eliane Maria Loiola, Nair Maria Maia de Abreu, Paulo
Oswaldo Boaventura Netto, Peter Hahn, and Tania Maia
Querido. A survey for the quadratic assignment problem. Eu-
ropean Journal of Operational Research, 176(2):657–690,
2007.

[22] Eleonora Maset, Federica Arrigoni, and Andrea Fusiello.
Practical and efﬁcient multi-view matching. In ICCV, 2017.

[23] Julian McAuley and Tib´erio Caetano. Exploiting within-
clique factorizations in junction-tree algorithms. In Proceed-
ings of the Thirteenth International Conference on Artiﬁcial
Intelligence and Statistics, pages 525–532, 2010.

[24] James Munkres. Algorithms for the assignment and trans-
portation problems. Journal of the Society for Industrial and
Applied Mathematics, 5(1):32–38, Mar. 1957.

[25] Quynh Nguyen, Antoine Gautier, and Matthias Hein. A ﬂex-
ible tensor block coordinate ascent scheme for hypergraph
matching. 2015.

[26] Carl Olsson, Anders P Eriksson, and Fredrik Kahl. Solving
large scale binary quadratic problems - spectral methods vs.
semideﬁnite programming. CVPR, 2007.

[27] Deepti Pachauri, Risi Kondor, and Vikas Singh. Solving the
multi-way matching problem by permutation synchroniza-
tion. In NIPS, 2013.

[28] Panos M Pardalos, Franz Rendl, and Henry Wolkowicz. The
quadratic assignment problem - a survey and recent develop-
ments. DIMACS Series in Discrete Mathematics, 1993.

[29] Han-Mu Park and Kuk-Jin Yoon. Consistent multiple graph
matching with multi-layer random walks synchronization.
Pattern Recognition Letters, 2018.

[30] Christian Schellewald and Christoph Schn¨orr. Probabilistic
In EMM-

subgraph matching based on convex relaxation.
CVPR, 2005.

[31] Yanyao Shen, Qixing Huang, Nati Srebro, and Sujay Sang-
In NIPS,

havi. Normalized spectral map synchronization.
2016.

[32] X Shi, H Ling, W Hu, and J Xing. Tensor power iteration for

[14] B Jiang, J Tang, C Ding, and B Luo. Binary constraint pre-

multi-graph matching. In CVPR, 2016.

serving graph matching. In CVPR, 2017.

[15] Dagmar Kainmueller, Florian Jug, Carsten Rother, and Eu-
gene W Myers. Active Graph Matching for Joint Segmenta-
tion and Annotation of C. Elegans. In Medical Image Com-
puting and Computer-Assisted Intervention–MICCAI 2014,
pages 81–88. Springer, 2014.

[16] Itay Kezurer, Shahar Z Kovalsky, Ronen Basri, and Yaron
Lipman. Tight relaxation of quadratic matching. Comput.
Graph. Forum, 2015.

[17] Vladimir Kolmogorov. A new look at reweighted message
passing. IEEE transactions on pattern analysis and machine
intelligence, 37(5):919–930, 2015.

[33] David Sontag, Do Kook Choe, and Yitao Li. Efﬁciently
searching for frustrated cycles in MAP inference.
In Pro-
ceedings of the Twenty-Eighth Conference on Uncertainty in
Artiﬁcial Intelligence (UAI-12), pages 795–804, Corvallis,
Oregon, 2012. AUAI Press.

[34] Paul Swoboda, Jan Kuske, and Bogdan Savchynskyy. A dual
ascent framework for Lagrangean decomposition of combi-
natorial problems. In CVPR, 2017.

[35] Paul Swoboda, Carsten Rother, Hassan Abu Alhaija, Dagmar
Kainm¨uller, and Bogdan Savchynskyy. Study of Lagrangean
decomposition and dual ascent solvers for graph matching.
In CVPR, 2017.

11164

[36] L Torresani and V Kolmogorov. A dual decomposition ap-
proach to feature correspondence. TPAMI, 35(2):259–271,
2013.

[37] Roberto Tron, Xiaowei Zhou, Carloes Esteves, and Kostas
Daniilidis. Fast multi-image matching via density-based
clustering. In ICCV, 2017.

[38] Qianqian Wang, Xiaowei Zhou, and Kostas Daniilidis.
Multi-image semantic matching by mining consistent fea-
tures. In CVPR, 2018.

[39] Tomas Werner. A linear programming approach to max-sum
problem: A review. Pattern Analysis and Machine Intelli-
gence, IEEE Transactions on, 29(7):1165–1179, 2007.

[40] Tom´aˇs Werner. High-arity interactions, polyhedral relax-
ations, and cutting plane algorithm for soft constraint opti-
misation (MAP-MRF).
In Conf. on Computer Vision and
Pattern Recognition, Anchorage, USA, June 2008.

[41] J Yan, M Cho, H Zha, and X Yang. Multi-graph matching
via afﬁnity optimization with graduated consistency regular-
ization. TPAMI, 38(6):1228–1242, 2016.

[42] Junchi Yan, Yin Li, Wei Liu, Hongyuan Zha, Xiaokang
Yang, and Stephen Mingyu Chu. Graduated consistency-
regularized optimization for multi-graph matching. ECCV,
2014.

[43] Junchi Yan, Yu Tian, Hongyuan Zha, Xiaokang Yang, Ya
Zhang, and Stephen M Chu. Joint optimization for consistent
multiple graph matching. ICCV, 2013.

[44] J. Yan, J. Wang, H. Zha, X. Yang, and S. Chu. Consistency-
driven alternating optimization for multigraph matching: A
uniﬁed approach. In IEEE Transactions on Image Process-
ing, 2015.

[45] J Yan, H Xu, H Zha, X Yang, and H Liu. A matrix decom-
position perspective to multiple graph matching. In ICCV,
2015.

[46] Mikhail Zaslavskiy, Francis Bach, and Jean-Philippe Vert. A
path following algorithm for the graph matching problem.
TPAMI, 31(12):2227–2242, 2009.

[47] Zhen Zhang, Qinfeng Shi, Julian McAuley, Wei Wei, Yan-
ning Zhang, and Anton van den Hengel. Pairwise matching
through max-weight bipartite belief propagation. In CVPR,
2016.

[48] Q Zhao, S E Karisch, F Rendl, and H Wolkowicz. Semidef-
inite programming relaxations for the quadratic assignment
problem. Journal of Combinatorial Optimization, 2(1):71–
109, 1998.

[49] Feng Zhou and Fernando De la Torre. Factorized graph

matching. TPAMI, 38(9):1774–1789, 2016.

[50] Xiaowei Zhou, Menglong Zhu, and Kostas Daniilidis. Multi-
image matching via fast alternating minimization. In ICCV,
2015.

11165

