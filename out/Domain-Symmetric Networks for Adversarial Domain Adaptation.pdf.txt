Domain-Symmetric Networks for Adversarial Domain Adaptation

Yabin Zhang1,2, Hui Tang1, Kui Jia ∗1, and Mingkui Tan1

1South China University of Technology

2DAMO Academy, Alibaba Group

{zhang.yabin,eehuitang}@mail.scut.edu.cn, {kuijia,mingkuitan}@scut.edu.cn

Abstract

Unsupervised domain adaptation aims to learn a model
of classiﬁer for unlabeled samples on the target domain,
given training data of labeled samples on the source do-
main.
Impressive progress is made recently by learning
invariant features via domain-adversarial training of deep
networks. In spite of the recent progress, domain adaptation
is still limited in achieving the invariance of feature distri-
butions at a ﬁner category level. To this end, we propose in
this paper a new domain adaptation method called Domain-
Symmetric Networks (SymNets). The proposed SymNet is
based on a symmetric design of source and target task clas-
siﬁers, based on which we also construct an additional clas-
siﬁer that shares with them its layer neurons. To train the
SymNet, we propose a novel adversarial learning objective
whose key design is based on a two-level domain confusion
scheme, where the category-level confusion loss improves
over the domain-level one by driving the learning of inter-
mediate network features to be invariant at the correspond-
ing categories of the two domains. Both domain discrim-
ination and domain confusion are implemented based on
the constructed additional classiﬁer. Since target samples
are unlabeled, we also propose a scheme of cross-domain
training to help learn the target classiﬁer. Careful ablation
studies show the efﬁcacy of our proposed method. In partic-
ular, based on commonly used base networks, our SymNets
achieve the new state of the art on three benchmark domain
adaptation datasets.

1. Introduction

Deep learning methods have achieved great success in
various machine learning tasks. A common pre-requisite
for such success is the availability of massive amounts of
annotated training data. For many other tasks, however,

∗Corresponding author

these training data are either difﬁcult to collect, or anno-
tating them costs prohibitively. Therefore, to address the
scarcity of annotated data on some target tasks/domains,
there is a strong motivation to leverage the massively avail-
able annotated data on related source ones via a manner of
transfer learning or domain adaptation [17]. Unfortunately,
this attractive learning paradigm suffers from the problem
of domain shift [8], which stands as a major obstacle for
adapting the learned models on source domains to be useful
for target ones.

Domain adaptation aims to obtain models that have
smaller risks on target data. Theoretical analysis [2] sug-
gests that such a target risk can be minimized by bounding
the risk of a model on the source data and the discrepancy
between distributions of the two domains, which inspires
many of existing methods [28, 31, 11, 32, 25, 3, 4, 26, 27,
10, 19]. Among existing methods, those based on domain-
adversarial training of deep networks [3, 4] achieve the cur-
rent state of the art on many benchmark domain adapta-
tion datasets [21, 1, 29]. Inspired by generative adversarial
networks [6], domain-adversarial training typically plays a
minimax game to learn a domain discriminator, which aims
to distinguish features of source samples from those of tar-
get samples, and a feature extractor, which aims to learn
domain-invariant feature representations in order to confuse
the domain discriminator. Domain alignment is expected
when the minimax optimization reaches an equilibrium.

In spite of the remarkable empirical results achieved by
domain-adversarial training methods, they still suffer from
a major limitation: even though the feature extractor is well
trained to give domain-invariant features of both the source
and target samples, the corresponding model/classiﬁer is
trained on the source samples and cannot perfectly gener-
alize to the target ones, i.e., the joint distributions of fea-
ture and category are not well aligned across data domains.
Some of existing methods have paid attention to this issue.
For example, in [22, 34, 30], pseudo labels are assigned
to target samples, on which the category-level alignment

5031

In [12, 18], multiplicative interactions be-
is promoted.
tween feature representations and category predictions are
exploited as high-order features to help adversarial training.

These existing methods have to some extent alleviated
the above issue. To push further along this line, we pro-
pose in this paper a novel design of Domain-Symmetric
Networks (SymNets) to facilitate, via adversarial training,
the alignment of joint distributions of feature and category
across data domains. Similar to [13], our proposed Sym-
Net contains an explicit task classiﬁer for the target domain.
Different from [13], we also construct an additional classi-
ﬁer that shares its neurons with those of the source and tar-
get classiﬁers (cf. Section 3.1 for how the three classiﬁers
are constructed). In this work, we propose a novel adversar-
ial learning method to train the thus constructed SymNet,
which includes category-level and domain-level confusion
losses and can thus enhance domain-invariant feature learn-
ing towards the category level. To make the target classiﬁer
more symmetric with the source one in terms of predict-
ing task categories, we also propose a cross-domain train-
ing scheme to help training of the target classiﬁer. Careful
ablation studies show the efﬁcacy of key designs of our pro-
posed SymNet.

We summarize our main contributions as follows.

• We propose in this paper a novel method termed Sym-
Net for adversarial domain adaptation. Our proposed
SymNet is based on a symmetric design of source and
target task classiﬁers, based on which we also con-
struct an additional classiﬁer that shares with them its
layer neurons. Both domain discrimination and do-
main confusion are implemented based on the con-
structed additional classiﬁer.

• To train the SymNet, we propose a novel adversar-
ial learning method based on two-level domain con-
fusion losses, where the category-level confusion loss
improves over the domain-level one by driving the
learning of intermediate network features to be invari-
ant at the corresponding categories of the two domains.
Since target samples are unlabeled, we also propose a
scheme of cross-domain training to help learn the tar-
get classiﬁer.

• We conduct careful ablation studies to investigate the
efﬁcacy of key designs of our proposed SymNet.
These studies empirically corroborate our designs. In
particular, based on commonly used base networks,
our proposed SymNets achieve the new state of the art
on benchmark domain adaptation datasets of Ofﬁce-31
[21], ImageCLEF-DA [1], and Ofﬁce-Home [29].

2. Related Works

In this section, we brieﬂy review recent domain adapta-
tion methods, in particular those aiming to align the joint
distributions of feature and category across two data do-
mains [22, 34, 30, 13, 23, 12, 18].

Existing domain adaptation methods [28, 11, 32, 25, 3,
4, 26, 27, 13, 22, 34, 30, 12, 18] typically learn domain in-
variant features to minimize the domain discrepancy. Some
of the existing methods [28, 11, 32, 25, 3, 4, 27] neglect the
alignment between the corresponding categories of the two
domains. In contrast, to align the joint distributions of fea-
ture and category across two data domains, Saito et al. [22]
proposes to asymmetrically use three task classiﬁers, where
two task classiﬁers are utilized to label the unlabeled target
samples according to their prediction consistency and the
conﬁdence, and another task classiﬁer is trained by these
target samples with pseudo labels. However, the trueness of
pseudo labels is doubtful and false labels have a profoundly
negative impact on the performance. To improve the relia-
bility of pseudo labels for target samples, Zhang et al. [34]
reweights the target samples by the degree of confusion be-
tween domains, speciﬁcally those target samples which well
confuse the domain discriminator in domain labels, are thus
assigned by higher weights. Xie et al. [30] aligns the cen-
troid of each category between the two domains, instead of
treating the pseudo labels as true ones directly. Long et al.
[13] uses a residual function to model the shift between the
learned task classiﬁers of the two domains, which can be
useful in the adaptation tasks of small domain discrepancy
but inadequate to tackle the large domain discrepancy. In
[12, 18], multiplicative interactions between feature repre-
sentations and category predictions are exploited as high-
order features to help adversarial training. By taking the
category decision boundaries into account, Saito et al. [23]
proposes to detect the target samples near the category de-
cision boundaries by maximizing the discrepancy between
the outputs of two separate task classiﬁers and learn a fea-
ture extractor to generate features near the source support
for these target samples to minimize the discrepancy.

To further promote the alignment of joint distributions
of feature and category across data domains, our SymNets
contain an explicit task classiﬁer for the target domain and
an additional classiﬁer to enable domain discrimination and
domain confusion, and have two-level domain confusion
losses, where the category-level confusion loss improves
over the domain-level one by driving the learning of inter-
mediate network features to be invariant at the correspond-
ing categories of the two domains.

3. The Proposed Domain-Symmetric Networks

In unsupervised domain adaptation, we are given a
i=1 of ns labeled samples

source domain Ds = {(x

i )}ns

i , ys
s

5032

Figure 1. The architecture of our proposed SymNet, which includes a feature extractor G and three classiﬁers of C s, C t and C st. Note that
the classiﬁer C st shares its layer neurons with C s and C t. The red and blue colors indicate the target data and source data, and the losses
generated by them, respectively. The yellow and green colors represent the feature extractor and classiﬁers, and the losses applied to them,
respectively. The middle dashed rectangle presents a toy example of the features of the SymNet that are invariant at the corresponding
categories of two domains. Please refer to the main text for how the two-level domain confusion training objectives are deﬁned.

t

j)}nt

and a target domain Dt = {(x
j=1 of nt unlabeled sam-
ples. The i.i.d. assumption is violated as the source domain
Ds and target domain Dt are assumed to be different. The
goal of unsupervised domain adaptation is to learn a feature
extractor G and a classiﬁer C such that the expected target
t)), yt)] can be minimized for a
risk E(xt,yt)∼Dt [L(C(G(x
certain loss L.

Theoretical analysis [2] suggests that the target risk can
be minimized by bounding the source risk and the discrep-
ancy between two domains. Inspired by GANs [6], domain-
adversarial training [3, 4] is explored to achieve the later
objective. As summarized in [27], there are three ways to
implement the domain-adversarial training losses: minimax
[3, 4], confusion [26], and GAN [27]. We introduce the do-
main confusion loss [26] that is most related to our method.

Given a deep neural network that is composed of convo-
lutional and fully-connected (FC) layers, the domain confu-
sion method uses the lower convolutional layers as the fea-
ture extractor G and upper FC layers as the task classiﬁer
C. The domain discriminator D, which is in parallel with
C, is added on top of G to distinguish features of samples
from the two domains. Source risk minimization is achieved
based on a standard supervised classiﬁcation objective:

tor D using the following objective:

min
D

Edomain = −

−

1
ns

1
nt

ns

X

i=1
nt

X

j=1

log(1 − D(G(x

s
i ))

log(D(G(x

t
j)).

(2)

Given a D, the domain confusion loss aims to learn G to
maximally “confuse” the two domains, by computing the
cross entropy between the domain predictions and a uni-
form distribution over domain labels:

min

G

Fdomain =

1
2

Edomain −

1
2ns

ns

X

i=1

log(D(G(x

s
i ))

−

1
2nt

nt

X

j=1

log(1 − D(G(x

t
j)).

(3)

Domain alignment
is achieved by learning a domain-
invariant G based on the following adversarial objective of
domain confusion:

min
G,C

min
D

Etask(G, C) + λFdomain(G, D)

Edomain(G, D),

(4)

min
C,G

Etask =

1
ns

ns

X

i=1

Ls (C(G(x

s

i )), ys

i ) ,

where λ is a trade-off parameter.

(1)

3.1. A Symmetric Design of Source and Target Task

Classiﬁers

where Ls is typically a cross-entropy loss. Due to the ex-
istence of domain discrepancy, there is a large drop in per-
formance when directly applying the model trained by (1)
to the target data. Given feature representations of different
domains extracted by G, we can learn a domain discrimina-

As discussed in Section 1, although impressive results
are obtained by existing methods of domain-adversarial
training, they still suffer from the fundamental challenge
of unsupervised domain adaptation, i.e., the joint distribu-
tions of feature and category cannot be well aligned across
data domains. To address this challenge, we propose in this

5033

paper a novel domain-symmetric network (SymNet), with
the corresponding domain-adversarial training method. We
ﬁrst present architectural design of our proposed SymNet as
follows (cf. Figure 1 for an illustration).

s(x) ∈ RK and v

s(x) ∈ [0, 1]K and p

The design of a SymNet starts with two parallel task clas-
siﬁers C s and C t. Assume each of the two classiﬁers is
based on a single FC layer (with a subsequent softmax oper-
ation). C s and C t respectively contain K s and K t neurons
corresponding to the numbers of categories on the source
and target domains. In unsupervised domain adaptation, we
have K s = K t = K. For an input x of the SymNet,
t(x) ∈ RK
we respectively denote as v
the output vectors of C s and C t before the softmax op-
t(x) ∈ [0, 1]K after
eration, and p
the softmax operation. Except for C s and C t, our Sym-
Net also has a classiﬁer C st whose design is as follows.
t(x) for an input x, we ﬁrst concate-
Given v
t(x)] ∈ R2K , and we then
nate them to form [v
apply the softmax operation to the concatenated vector to
st(x) ∈ [0, 1]2K . We thus have
have a probability vector p
st(x). For ease of subsequent notations, we
C st(G(x)) = p
also write ps
k (x)), k ∈ {1, . . . , K},
for the kth element of the category probability vector p
s(x)
st(x)) predicted by C s(G(x)) (resp.
(resp. p
C t(G(x)) or C st(G(x))).

k(x) (resp. pt

k(x) or pst

s(x) and v

t(x) or p

s(x); v

Note that there exists no an explicit domain discriminator
in our design of SymNet. Both the domain discrimination
and domain confusion is achieved by applying appropriate
losses to the classiﬁer C st, which we will present shortly.
We ﬁrst present in the following how to train C s and C t.
Learning of Source Task Classiﬁer

The task classiﬁer C s is trained using the following

cross-entropy loss over the labeled source samples:

min
C s

E s
task(G, C s) = −

1
ns

ns

X

i=1

log(ps
ys
i

(x

s
i )).

(5)

Cross-Domain Learning of Target Task Classiﬁer

Since target samples are unlabeled, there exist no direct
supervision signals to learn a task classiﬁer C t. Our idea is
to leverage the labeled source samples, and use the follow-
ing cross-entropy loss to train C t:

min
C t

E t
task(G, C t) = −

1
ns

ns

X

i=1

log(pt
ys
i

(x

s
i )).

(6)

At a ﬁrst glance, it seems that (6) learns C t that is a du-
plicate of C s. However, a domain discrimination training
via C st will make them distinguishable. In fact, the use of
(6) is essential to establish a neuron-wise correspondence
between C s and C t, which provides the basis to achieve
category-level domain confusion presented in Section 3.2.
The use of labeled source samples in (6) also makes the
learned C t more discriminative among task categories. We

Figure 2. An intuitive presentation of how the loss (7) differenti-
ates the target classiﬁer C t from the source classiﬁer C s.

present ablation studies in Section 4.3 that conﬁrm the efﬁ-
cacy of our way of learning the target task classiﬁer C t.
Domain Discrimination

Both C s and C t are trained using the labeled source sam-
ples. To differentiate between them, we leverage the con-
structed classiﬁer C st in the SymNet. We train C st using
the following two-way cross-entropy loss:

min
C st

E st
domain(G, C st) = −

−

1
nt

1
ns

nt

X

j=1

ns

X

i=1

log(

K

X

k=1

log(

K

X

k=1

pst
k+K(x

t
j))

pst
k (x

s
i )),

(7)

k=1 pst

k (x) and PK

where PK
k+K(x) can be viewed as
the probabilities of classifying an input sample x as the
source and target domains respectively. The objective of
the loss (7) is intuitively illustrated in Figure 2.

k=1 pst

Ideally, for the total 2K neurons of C st, the combined
effect of imposing losses (5), (6), and (7) would be to make
the set of ﬁrst K neurons discriminative among task cate-
gories, the set of last K neurons discriminative among task
categories, and to make the two sets distinguishable from
s of the
each other. For example, for a source sample x
category k, both C s and C t tend to make accurate predic-
tions, and for C st, the probability of pst
k would be larger
than pst
k+K , due to the use of loss (7). Similarly, for a target
t of the category k, both C s and C t tend to make
sample x
accurate predictions, and for C st, the probability of pst
would be larger than pst
k .

k+K

3.2. A Two level Domain Confusion Training of

Domain Symmetric Networks

Similar to existing methods, we adopt the general strat-
egy of adversarial training to learn an invariant feature ex-
tractor G for the SymNet. More speciﬁcally, we propose a
novel two-level domain confusion method that is based on
a domain-level confusion loss and a category-level confu-
sion loss. The proposed two-level losses aim to maximally

5034

“ confuse” the two domains in order to align the joint distri-
butions of feature and category across them.

To have a category-level confusion loss, we again rely on
labeled source samples. For a source sample of category k,
we identify its corresponding pair of the kth and (k + K)th
neurons in C st, and use a cross-entropy between predictions
on this neuron pair and uniform distribution, which gives
the following objective to learn the feature extractor G:

min

G

F st

category(G, C st) = −

−

1
2ns

1
2ns

ns

X

i=1
ns

X

i=1

log(pst
i +K(x
ys

s
i ))

log(pst
ys
i

(x

s
i )).

(8)

To have a domain-level confusion loss, we use the unla-
beled target samples, since label information is unnecessary
for confusion at the domain level. For a target sample, we
simply use a cross-entropy between aggregated predictions
from the two half sets of neurons in C st, and uniform dis-
tribution, which gives the following objective to learn the
feature extractor G:

min

G

F st

domain(G, C st) = −

−

1
2nt

1
2nt

nt

X

j=1

nt

X

j=1

log(

log(

K

X

k=1

K

X

k=1

pst
k+K(x

t
j))

pst
k (x

t
j)).

minimization loss is only used here to update G, in order to
reduce the side effect that due to large domain shift, target
samples may be stuck into wrong category predictions in
the early stage of training, and are difﬁcult to be corrected
later on.

3.3. The Overall Training Objective of Domain 

Symmetric Networks

Combining the losses (5), (6), and (7) for updating clas-
siﬁers, (8) and (9) of category- and domain-level confusion
for updating the feature extractor G, and also the regularizer
(10), we have the following training objective for a SymNet:

min

C s,C t,C st
F st

min

G

E s
task(G, C s) + E t

task(G, C t) + E st

domain(G, C st)

category(G, C st) + λ(F st

domain(G, C st) + Mst(G, C st)),

(11)

where λ ∈ [0, 1] is a trade-off parameter to suppress
domain(G, C st) and Mst(G, C st) at
noisy signals of F st
category(G, C st) is noise-
early stages of training. The F st
free since it is based on the labeled source samples.

4. Experiments

We evaluate our SymNets on unsupervised domain adap-
tation tasks of three benchmark datasets and investigate the
effects of the components in detail. The codes are available
at http://sites.scut.edu.cn/GPI/main.psp

(9)

4.1. Setup

Note that one may opt for another domain-level confusion
loss by using labeled source samples. We note that effect
of such an additional loss may have been subsumed by the
category-level confusion loss (8), which uses labeled source
samples.

3.2.1 Entropy Minimization Principle

Entropy minimization principle [7] is adopted by some do-
main adaptation methods [13, 33, 24] to enhance discrimi-
nation of learned models for target data. In this work, we
adapt this principle to the symmetric structure of our pro-
posed SymNet. We propose the following entropy mini-
mization objective that enhances discrimination among task
categories by summing over the probabilities at each pair of
category-corresponding neurons in C st:

Mst(G, C st) = −

min

G

1
nt

nt

K

X

X

qst
k (x

j=1

k=1

t

j)log(qst

k (x

t
j)),

k (x

(10)
t
where qst
j ), k ∈ {1, . . . , K}. As
suggested by [33], instead of using (10) for updating both
the feature extractor G and the classiﬁer C st, the entropy

j) + pst
t

j) = pst
t

k+K(x

k (x

Ofﬁce-31 The ofﬁce-31 dataset [21] is a standard bench-
mark dataset for domain adaptation, which contains 4, 110
images of 31 categories shared by three distinct domains:
Amazon (A), Webcam (W) and DSLR (D). We follow the
common evaluation protocol on all six adaptation tasks.
ImageCLEF-DA The ImageCLEF-DA dataset [1] is a
benchmark dataset for ImageCLEF 2014 domain adapta-
tion challenge, which contains three domains: Caltech-256
(C), ImageNet ILSVRC 2012 (I) and Pascal VOC 2012 (P).
For each domain, there are 12 categories and 50 images in
each category. The three domains in this dataset are of the
same size, which is a good complementation of the Ofﬁce-
31 dataset where different domains are of different sizes.
We evaluate all methods on all six adaptation tasks.
Ofﬁce-Home The Ofﬁce-Home dataset [29] is a very chal-
lenging dataset for domain adaptation, which contains
15, 500 images from 65 categories of everyday objects in
the ofﬁce and home scenes, shared by four signiﬁcantly dif-
ferent domains: Artistic images (Ar), Clip Art (Cl), Product
images (Pr) and Real-World images (Rw). We evaluate all
methods on all 12 adaptation tasks.

We compare our SymNets with shallow domain adapta-
tion methods [16, 5] and the state-of-the-art deep domain

5035

Table 1. Accuracy (%) on the Ofﬁce-31 dataset [21]. All methods are based on models adapted from a 50-layer ResNet.

Methods
ResNet-50 [9]
GFK [5]
TCA [16]
DAN [11]
RTN [13]
RevGrad [3]
ADDA [27]
JAN-A[14]
MADA [18]
iCAN [34]
Kang et al. [10]
CDAN+E [12]
SymNets

A → W D → W W → D
99.3±0.1
68.4±0.2
98.2±0.0
72.8±0.0
99.6±0.0
72.7±0.0
80.5±0.4
99.6±0.1
99.4±0.1
84.5±0.2
99.1±0.1
82.0±0.4
98.4±0.3
86.2±0.5
86.0±0.4
99.7±0.1
99.6±0.1
90.0±0.1

96.7±0.1
95.0±0.0
96.7±0.0
97.1±0.2
96.8±0.1
96.9±0.2
96.2±0.3
96.7±0.3
97.4±0.1

92.5

86.8±0.2
94.1±0.1
90.8±0.1

98.8

99.3±0.1
98.6±0.1
98.8±0.3

100.0

100.0±.0
100.0±.0
100.0±.0

A → D
68.9±0.2
74.5±0.0
74.1±0.0
78.6±0.2
77.5±0.3
79.7±0.4
77.8±0.3
85.1±0.4
87.8±0.2

90.1

88.8±0.4
92.9±0.2
93.9±0.5

D → A
62.5±0.3
63.4±0.0
61.7±0.0
63.6±0.3
66.2±0.2
68.2±0.4
69.5±0.4
69.2±0.3
70.3±0.3

72.1

74.3±0.2
71.0±0.3
74.6±0.6

W → A
60.7±0.3
61.0±0.0
60.9±0.0
62.8±0.2
64.8±0.3
67.4±0.5
68.9±0.5
70.7±0.5
66.4±0.3

69.9

73.9±0.2
69.3±0.3
72.5±0.5

Avg
76.1
77.5
77.6
80.4
81.6
82.2
82.9
84.6
85.2
87.2
87.2
87.7
88.4

Table 2. Accuracy (%) on the ImageCLEF-DA dataset [1]. All methods are based on models adapted from a 50-layer ResNet.

Methods
ResNet-50 [9]
DAN [11]
RevGrad [3]
MADA [18]
iCAN [34]
CDAN+E [12]
SymNets

I → P

74.8±0.3
74.5±0.4
75.0±0.6
75.0±0.3

79.5

P → I

83.9±0.1
82.2±0.2
86.0±0.3
87.9±0.2

89.7

I → C

91.5±0.3
92.8±0.2
96.2±0.4
96.0±0.3

94.7

C → I

78.0±0.2
86.3±0.4
87.0±0.5
88.8±0.3

89.9

C → P

65.5±0.3
69.2±0.4
74.3±0.5
75.2±0.2

78.5

P → C

91.2±0.3
89.8±0.4
91.5±0.6
92.2±0.3

92.0

77.7±0.3
80.2±0.3

90.7±0.2
93.6±0.2

97.7±0.3
97.0±0.3

91.3±0.3
93.4±0.3

74.2±0.2
78.7±0.3

94.3±0.3
96.4±0.1

Avg
80.7
82.5
85.0
85.8
87.4
87.7
89.9

adaptation methods [11, 13, 3, 27, 14, 18, 19, 10, 12]. We
follow standard evaluation protocols for unsupervised do-
main adaptation [3, 11]: all labeled source samples and all
unlabeled target samples are used for training. The average
classiﬁcation accuracy and the standard error of each adap-
tation task are reported on three random experiments. Our
SymNets and all comparative methods are based on models
adapted from a 50-layer ResNet [9]. Especially, the deep
representations output by the layer pool5 of ResNet are used
as features for shallow methods.

We implement our SymNets based on PyTorch. A 50-
layer ResNet pre-trained on the ImageNet dataset [20],
which excludes the last FC layer, is adopted as the feature
extractor G. We ﬁne-tune the feature extractor G and train
a classiﬁer C st from scratch through back propagation. The
learning rate of the classiﬁer C st is 10 times that of the fea-
ture extractor G. All parameters are updated by stochastic
gradient descent (SGD) with momentum of 0.9. The batch
size is set to 128. We follow [3] to employ the annealing
strategy of learning rate and the progressive strategy of λ:
the learning rate is adjusted by ηp =
(1+αp)β , where p is
the progress of training epochs linearly changing from 0 to
1, η0 = 0.01, α = 10 and β = 0.75, which are optimized
to promote convergence and low error on source samples; λ
1+exp(−γ·p) − 1,
is gradually changed from 0 to 1 by λp =
where γ is set to 10 in all experiments. Our classiﬁcation

η0

2

results are obtained from the target task classiﬁer Ct unless
otherwise speciﬁed, and the comparison between the perfor-
mance of the source and target task classiﬁers is illustrated
in Figure 4.

4.2. Results

The classiﬁcation results on the Ofﬁce-31 [21],
ImageCLEF-DA [1] and Ofﬁce-Home [29] datasets are re-
ported in Table 1, Table 2 and Table 3, respectively. For fair
comparison, results of other methods are either directly re-
ported from their original papers if available or quoted from
[12]. Our SymNets outperform all state-of-the-art methods
on three benchmark datasets, highly afﬁrming the effective-
ness of our SymNets in aligning the joint distributions of
feature and category across domains. It is compelling that
our SymNets substantially enhance the classiﬁcation accu-
racies on difﬁcult adaptation tasks (e.g. A → D and D →
A) and the challenging dataset (e.g. Ofﬁce-Home). The
Ofﬁce-Home dataset is a very challenging dataset for do-
main adaptation due to following reasons as described in its
original paper [29]: (1) the number of categories is large
in each domain; (2) different domains are visually very dis-
similar; (3) the in-domain classiﬁcation accuracy is low. Es-
pecially, the presence of large number of categories preju-
dices the domain alignment methods [3, 11, 27] for their ig-
norance of the alignment between corresponding categories
of the two domains. It is desirable that our SymNets dramat-

5036

Table 3. Accuracy (%) on the Ofﬁce-Home dataset [29]. All methods are based on models adapted from a 50-layer ResNet.

Methods
ResNet-50 [9]
DAN [11]
RevGrad [3]
CDAN+E [12]
SymNets

Ar→Cl Ar→Pr Ar→RwCl→Ar Cl→Pr Cl→Rw Pr→Ar Pr→Cl Pr→Rw Rw→ArRw→Cl Rw→Pr Avg
46.1
34.9
56.3
43.6
45.6
57.6
50.7
65.8
67.6
47.7

41.2
51.5
51.8
56.7
52.6

31.2
43.6
43.7
50.9
48.8

37.4
45.8
47.0
57.6
64.2

59.9
74.3
76.8
81.6
82.7

60.4
67.7
68.5
77.3
79.5

53.9
63.1
63.2
70.9
74.5

46.2
60.4
60.9
70.0
74.2

50.0
57.0
59.3
70.6
72.9

58.0
67.9
70.1
76.0
78.5

41.9
56.5
58.5
70.0
71.3

38.5
44.0
46.1
57.4
64.2

Table 4. Ablation experiments on the Ofﬁce-31 dataset [21]. All methods are based on models adapted from a 50-layer ResNet. Please
refer to the main text for the detail deﬁnitions of these methods.

Methods
ResNet-50 [9]
ResNet-50 (Adding Em) [9]
Domain Confusion [26]
Domain Confusion (Adding Em) [26]
SymNets (w/o E t
task)
SymNets (w/o Mst)
SymNets (w/o confusion)
SymNets (w/o category confusion)
SymNets

A → W D → W W → D
99.5±0.1
79.9±0.3
89.3±0.1
100.0±.0
99.8±0.0
83.0±0.1
100.0±.0
89.8±0.7
99.6±0.2
75.3±0.9
87.9±0.1
99.9±0.1
100.0±.0
89.2±0.6
99.8±0.0
89.9±0.6
90.8±0.1
100.0±.0

96.8±0.4
99.0±0.1
98.5±0.3
99.0±0.2
95.9±0.2
98.4±0.2
99.0±0.3
98.1±0.1
98.8±0.3

A → D
84.1±0.4
89.2±0.7
83.9±0.0
90.1±0.3
75.1±0.9
90.8±0.5
93.8±0.3
93.7±0.5
93.9±0.5

D → A
64.5±0.3
73.4±0.1
66.9±0.4
73.9±0.7
60.2±0.3
67.4±0.6
73.7±0.2
71.9±0.2
74.6±0.6

W → A
66.4±0.4
69.0±0.2
66.4±0.1
69.0±0.8
62.7±0.7
69.7±0.7
65.9±0.6
73.5±0.1
72.5±0.5

Avg
81.9
86.6
83.1
87.0
78.1
85.7
86.9
87.8
88.4

ically improve the performance on most adaptation tasks,
demonstrating the efﬁciency of our proposed two-level do-
main confusion training of SymNets in aligning the joint
distributions of feature and category across domains.

4.3. Analysis

Ablation Study In this section, we conduct ablation ex-
periments on the Ofﬁce-31 dataset [21] to investigate the
effects of different components in our SymNets, which are
based on models adapted from a 50-layer ResNet. We begin
with the simplest baseline that ﬁne-tunes on source sam-
ples the ResNet-50 model that is pre-trained on the Ima-
geNet dataset [20], which is denoted as “ResNet-50”. To
ﬁnd out how the existing domain confusion method intro-
duced in Section 3 performs, we conduct the experiment us-
ing the adversarial objective of domain confusion (4), which
is denoted as “Domain Confusion”. To make it clear how
our adopted entropy minimization loss presented in Sec-
tion 3.2.1 can help the above two baselines, we additionally
optimize the entropy minimization loss of target samples
over their feature extractors and denote them as “ResNet-50
(Adding Em)” and “Domain Confusion (Adding Em)” re-
spectively. To investigate how different components in our
SymNets beneﬁt the adaptation performance, we remove
the cross-domain category supervised loss E t
task(G, C t) (6)
and the entropy minimization loss Mst(G, C st) (10) from
the overall adversarial training objective (11), the training
settings of which are denoted as “SymNets (w/o E t
task)” and
“SymNets (w/o Mst)”, respectively. Note that classiﬁca-
tion accuracies for SymNets (w/o E t
task) are obtained from

the source task classiﬁer C s due to the inexistence of the di-
rect supervision signals in target task classiﬁer C t. Besides,
to explore the effects of our proposed two-level domain con-
fusion losses, we degenerate the category-level confusion
loss F st
category (8) for source samples to a domain-level one:

min

G

−

1
2ns

ns

X

i=1

log(

K

X

k=1

pst
k (x

s
i )) −

1
2ns

ns

X

i=1

log(

K

X

k=1

pst
k+K(x

s
i )),

(12)

the training setting of which is denoted as “SymNets (w/o
category confusion)”. We remove the domain-level con-
fusion loss F st
domain (9) for target samples from the over-
all adversarial training objective (11) and degenerate the
category-level confusion loss F st
category (8) for source sam-
ples to a general category classiﬁcation loss:

min

G

−

1
2ns

ns

X

i=1

log(ps
ys
i

(x

s
i )) −

1
2ns

ns

X

i=1

log(pt
ys
i

(x

s
i )),

(13)

the training setting of which is denoted as “SymNets (w/o
confusion)”.

The results are reported in Table 4. “Domain Confu-
sion” performs much better than “ResNet-50”, and “Sym-
Nets (w/o category confusion)” improves over “SymNets
(w/o confusion)”, testifying the effectiveness of the domain-
level confusion in the feature alignment. Observed that
the performance of “SymNets (w/o E t
task)” suffers a slump
of 10.3%, manifesting the importance of the cross-domain

5037

(a) ResNet-50

(b) Domain Confusion

(c) Domain Confusion (Adding Em)

(d) SymNets

Figure 3. The t-SNE visualization of feature representations learned by (a) ResNet-50, (b) Domain Confusion, (c) Domain Confusion
(Adding Em) and (d) SymNets. Note that the blue and red points are samples from the source domain A and target domain W respectively.

the source task classiﬁer and target task classiﬁer are spec-
iﬁed to corresponding domains. As the training proceeds,
the joint distributions of feature and category are gradually
aligned across domains, thus the performance of two task
classiﬁers almost converge to the same level.

Feature Visualization We visualize the network activa-
tions from feature extractors of “ResNet-50”, “Domain
Confusion”, “Domain Confusion (Adding Em)” and our
SymNets on the adaptation task A → W by t-SNE [15]
in Figure 3. The source and target domains are not well
aligned for features of “ResNet-50”. For features of “Do-
main Confusion”, the two domains are better aligned, how-
ever, the data structure of target samples is scattered and
the shared categories across domains are not well aligned.
For features of “Domain Confusion (Adding Em)”, the data
structure of target samples is well preserved, but the shared
categories across domains are not well aligned. For fea-
tures of our SymNets, the shared categories across domains
are perfectly aligned while different categories are well dis-
tinguished. The effectiveness of the two-level domain con-
fusion training of SymNets in aligning joint distributions of
feature and category across domains is veriﬁed intuitively.

5. Conclusion

We propose a novel adversarial learning method termed
domain-symmetric networks (SymNets) to overcome the
limitation in aligning the joint distributions of feature and
category across domains via two-level domain confusion
losses. The category-level confusion loss improves over
the domain-level one by driving the learning of intermediate
network features to be invariant at the corresponding cate-
gories of the two domains. As a component of the SymNets,
an explicit target task classiﬁer is learned through a cross-
domain training scheme. Experiments on three benchmark
datasets verify the efﬁcacy of our proposed SymNets.

Acknowledgment. This work is supported in part by the National
Natural Science Foundation of China (Grant No.: 61771201), and
the Program for Guangdong Introducing Innovative and Enter-
preneurial Teams (Grant No.: 2017ZT07X183).

5038

Figure 4. Convergence performance on the adaptation task of A →
W by ResNet-50, Domain Confusion, Domain Confusion (Adding
Em), and the source and target task classiﬁers of our SymNets,
which are denoted as SymNets-S and SymNets-T respectively.

category supervised loss E t
task(G, C t) (6) to learn a well-
performed target task classiﬁer in the two-level confusion
training of SymNets. SymNets enhances the adaptation
performance over “SymNets (w/o category confusion)”,
certifying the usefulness of our proposed category-level
confusion in the alignment between corresponding cate-
gories of the two domains. The entropy minimization loss
Mst(G, C st) (10) consistently improves both the two base-
lines of “ResNet-50” and “Domain Confusion” and our
SymNets by a large margin in performance, demonstrating
its efﬁcacy. By fair comparison, our SymNets achieve the
best result among these ablation experiments, conﬁrming
their excellent effect in aligning the joint distributions of
feature and category across domains.

Convergence Performance We compare the conver-
gence performances of task classiﬁers of C s and C t in
our SymNets with “ResNet-50”, “Domain Confusion” and
“Domain Confusion (Adding Em)” in Figure 4. The test
errors of different methods on the adaptation task A → W
are reported. We observe that our SymNets converge much
smoother. The convergence performances of the source task
classiﬁer C s and target task classiﬁer C t are expected. At
the beginning of adversarial training, the performance of
the target task classiﬁer on target samples is better, since

References

[1] Imageclef-da dataset.

http://imageclef.org/

2014/adaptation/.

[2] Shai Ben-David,

John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.
A theory of learning from different domains. Machine learn-
ing, 79(1-2):151–175, 2010.

[3] Yaroslav Ganin and Victor S. Lempitsky. Unsupervised do-
main adaptation by backpropagation. In Proceedings of the
32nd International Conference on Machine Learning, ICML
2015, Lille, France, 6-11 July 2015, pages 1180–1189, 2015.

[4] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal
Germain, Hugo Larochelle, Mario Marchand, and Victor
Lempitsky. Domain-adversarial training of neural networks.
Journal of Machine Learning Research, 17(1):2096–2030,
2017.

[5] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman.
Geodesic ﬂow kernel for unsupervised domain adaptation.
In Computer Vision and Pattern Recognition (CVPR), 2012
IEEE Conference on, pages 2066–2073. IEEE, 2012.

[6] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets.
In Advances
in neural information processing systems, pages 2672–2680,
2014.

[7] Yves Grandvalet and Yoshua Bengio.

learning by entropy minimization.
information processing systems, pages 529–536, 2005.

Semi-supervised
In Advances in neural

[8] A. Gretton, AJ. Smola, J. Huang, M. Schmittfull, KM. Borg-
wardt, and B. Sch¨olkopf. Covariate shift and local learning
by distribution matching, pages 131–160. MIT Press, Cam-
bridge, MA, USA, 2009.

[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016.

[10] Guoliang Kang, Liang Zheng, Yan Yan, and Yi Yang. Deep
adversarial attention alignment for unsupervised domain
adaptation: the beneﬁt of target expectation maximization.
In The European Conference on Computer Vision (ECCV),
September 2018.

[11] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I.
Jordan. Learning transferable features with deep adaptation
networks.
In Proceedings of the 32Nd International Con-
ference on International Conference on Machine Learning -
Volume 37, ICML’15, pages 97–105. JMLR.org, 2015.

[12] Mingsheng Long, ZHANGJIE CAO, Jianmin Wang, and
Michael I Jordan. Conditional adversarial domain adapta-
tion. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neu-
ral Information Processing Systems 31, pages 1640–1650.
Curran Associates, Inc., 2018.

[14] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I.
Jordan. Deep transfer learning with joint adaptation net-
works. In Proceedings of the 34th International Conference
on Machine Learning, ICML 2017, Sydney, NSW, Australia,
6-11 August 2017, pages 2208–2217, 2017.

[15] Laurens van der Maaten and Geoffrey Hinton. Visualiz-
ing data using t-sne. Journal of machine learning research,
9(Nov):2579–2605, 2008.

[16] Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang
Yang. Domain adaptation via transfer component analy-
sis. IEEE Transactions on Neural Networks, 22(2):199–210,
2011.

[17] Sinno Jialin Pan, Qiang Yang, et al. A survey on transfer
learning. IEEE Transactions on knowledge and data engi-
neering, 22(10):1345–1359, 2010.

[18] Zhongyi Pei, Zhangjie Cao, Mingsheng Long, and Jianmin
Wang. Multi-adversarial domain adaptation. In AAAI Con-
ference on Artiﬁcial Intelligence, 2018.

[19] Pedro O Pinheiro and AI Element. Unsupervised domain
adaptation with similarity learning.
In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 8004–8013, 2018.

[20] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-
jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,
Aditya Khosla, Michael Bernstein, et al.
Imagenet large
scale visual recognition challenge. International Journal of
Computer Vision, 115(3):211–252, 2015.

[21] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Dar-
rell. Adapting visual category models to new domains. In
European conference on computer vision, pages 213–226.
Springer, 2010.

[22] Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada.
Asymmetric tri-training for unsupervised domain adaptation.
In Doina Precup and Yee Whye Teh, editors, Proceedings
of the 34th International Conference on Machine Learning,
volume 70 of Proceedings of Machine Learning Research,
pages 2988–2997, International Convention Centre, Sydney,
Australia, 06–11 Aug 2017. PMLR.

[23] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat-
suya Harada. Maximum classiﬁer discrepancy for unsuper-
vised domain adaptation. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
3723–3732, 2018.

[24] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon.
A dirt-t approach to unsupervised domain adaptation. arXiv
preprint arXiv:1802.08735, 2018.

[25] Baochen Sun and Kate Saenko. Deep coral: Correlation
alignment for deep domain adaptation.
In European Con-
ference on Computer Vision, pages 443–450. Springer, 2016.
[26] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko.
Simultaneous deep transfer across domains and tasks.
In
Proceedings of the IEEE International Conference on Com-
puter Vision, pages 4068–4076, 2015.

[13] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I
Jordan. Unsupervised domain adaptation with residual trans-
fer networks. In Advances in Neural Information Processing
Systems, pages 136–144, 2016.

[27] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
Adversarial discriminative domain adaptation. In Computer
Vision and Pattern Recognition (CVPR), volume 1, page 4,
2017.

5039

[28] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and
Trevor Darrell. Deep domain confusion: Maximizing for
domain invariance. arXiv preprint arXiv:1412.3474, 2014.

[29] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty,
and Sethuraman Panchanathan. Deep hashing network for
unsupervised domain adaptation.
In Proc. CVPR, pages
5018–5027, 2017.

[30] Shaoan Xie, Zibin Zheng, Liang Chen, and Chuan Chen.
Learning semantic representations for unsupervised domain
adaptation. In International Conference on Machine Learn-
ing, pages 5419–5428, 2018.

[31] Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang,
Yong Xu, and Wangmeng Zuo. Mind the class weight bias:
Weighted maximum mean discrepancy for unsupervised do-
main adaptation. In The IEEE Conference on Computer Vi-
sion and Pattern Recognition (CVPR), volume 3, 2017.

[32] Werner Zellinger, Thomas Grubinger, Edwin Lughofer,
Thomas Natschl¨ager, and Susanne Saminger-Platz. Central
moment discrepancy (cmd) for domain-invariant representa-
tion learning. arXiv preprint arXiv:1702.08811, 2017.

[33] Jing Zhang, Zewei Ding, Wanqing Li, and Philip Ogun-
bona. Importance weighted adversarial nets for partial do-
main adaptation.
In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 8156–
8164, 2018.

[34] Weichen Zhang, Wanli Ouyang, Wen Li, and Dong Xu.
Collaborative and adversarial network for unsupervised do-
main adaptation.
In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 3801–
3809, 2018.

5040

