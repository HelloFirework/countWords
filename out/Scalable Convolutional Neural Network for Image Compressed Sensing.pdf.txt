Scalable Convolutional Neural Network for Image Compressed Sensing

Wuzhen Shi1, Feng Jiang1

,

2, Shaohui Liu1

,

2, and Debin Zhao1

2

,

1School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China

2Peng Cheng Laboratory, Shenzhen, China

{wzhshi, fjiang, shliu, dbzhao}@hit.edu.cn

Abstract

Recently, deep learning based image Compressed Sens-
ing (CS) methods have been proposed and demonstrated su-
perior reconstruction quality with low computational com-
plexity. However, the existing deep learning based image
CS methods need to train different models for different sam-
pling ratios, which increases the complexity of the encoder
and decoder. In this paper, we propose a scalable convo-
lutional neural network (dubbed SCSNet) to achieve scal-
able sampling and scalable reconstruction with only one
model. Speciﬁcally, SCSNet provides both coarse and ﬁne
granular scalability. For coarse granular scalability, SC-
SNet is designed as a single sampling matrix plus a hier-
archical reconstruction network that contains a base layer
plus multiple enhancement layers. The base layer provides
the basic reconstruction quality, while the enhancement lay-
ers reference the lower reconstruction layers and gradu-
ally improve the reconstruction quality. For ﬁne granular
scalability, SCSNet achieves sampling and reconstruction
at any sampling ratio by using a greedy method to select
the measurement bases. Compared with the existing deep
learning based image CS methods, SCSNet achieves scal-
able sampling and quality scalable reconstruction at any
sampling ratio with only one model. Experimental result-
s demonstrate that SCSNet has the state-of-the-art perfor-
mance while maintaining a comparable running speed with
the existing deep learning based image CS methods.1

1. Introduction

Compressed Sensing (CS) [11] depicts a new paradig-
m for signal acquisition and reconstruction, which imple-
ments sampling and compression jointly. Given a sampling
matrix Φ ∈ Rm×n with m << n, CS states that a signal
x ∈ n×1, which can be represented sparsely in a transform
domain, can be well reconstructed from its linear measure-
ments y = Φx. Since the CS theory guarantees that a signal

1Test code is available at: https://github.com/wzhshi/SCSNet.

Figure 1. The reconstruction quality and running speed compar-
ison on CPU. The compared traditional CS methods are marked
with blue font, and the compared deep learning based CS meth-
ods are marked with green font. The chart is based on Set11 [20]
results of sampling ratio of 0.1.

can be reconstructed with high quality at low sampling ra-
tio when the signal is sparse in some domain, there has been
signiﬁcant interest in CS. Some works have been proposed
to apply CS to image acquisition [12, 17], source coding
[28, 15], wireless broadcast [37, 21], and so on.

In the study of CS, the two main challengges are (1) the
design of sampling matrix and (2) reconstructing the origi-
nal signal from its linear measurements [14, 1]. To the ﬁrst
challenge, the representative sampling matices include: the
random matrix [14], the binary matrix [1, 23], and the struc-
tural matrix [9, 15]. To the second challenge, the representa-
tive methods include: convex-optimization algorithms (e.g.
[8, 35, 13]), the greedy algorithms (e.g. [24, 33, 30]), and
the iterative thresholding algorithms (e.g. [16]). The iter-
ative nature of these traditional methods lead to high com-
putational complexity, which hampers their practical appli-
cations. Recently, a few deep learning based image CS re-
construction methods [26, 20, 4, 32, 39, 36] have been pro-
posed. As shown in Figure 1, the deep learning based im-

12290

age CS methods can achieve better performance with lower
computational complexity than the traditional methods.

The common problem of the existing deep learning
based image CS methods is that they train different mod-
els for different sampling ratios, which increases the com-
plexity of the encoder and decoder. Too many models con-
sume considerable storage, memory bandwidth, and com-
putational resources. Especially, these resource demands
become prohibitive for embedded mobile applications. In
addition, if the reconstruction quality at a given sampling
ratio is not satisﬁed, the existing deep learning based im-
age CS methods have to resample all measurements. This
will lead to oversampling and harm the object being cap-
tured (e.g. medical imaging). Furthermore, some works
[37, 21] investigate the image CS for wireless broadcast,
in which different users will decode different quality im-
ages from different amount of measurements based on their
channel conditions. Thus, scalable reconstruction is pre-
ferred. Both these two cases (medical imaging and wire-
less broadcast) expect scalable sampling and scalable re-
construction, which are not considered by the existing deep
learning based image CS methods.

In this paper, we propose a scalable convolutional neu-
ral network (dubbed SCSNet) to achieve scalable sampling
and scalable reconstruction that provides both coarse and
ﬁne granular scalability with only one model. For coarse
granular scalability, SCSNet is designed as a single sam-
pling matrix plus a hierarchical reconstruction network that
contains a base layer (BL) and multiple enhancement lay-
ers (EL). The same with the coarse granular scalability of
H.264 and H.265 [5], the BL of SCSNet provides the basic
reconstruction quality. The ELs reference the lower layers
and gradually improve the reconstruction quality. For ﬁne
granular scalability, SCSNet achieves sampling and recon-
struction at any sampling ratio by using a greedy algorithm
to select the measurement bases2. Compared with the exist-
ing deep learning based methods, SCSNet implements scal-
able sampling and scalable reconstruction at any sampling
ratio with only one model. Experimental results show that
SCSNet has the state-of-the-art reconstruction quality while
maintaining a comparable running speed with the existing
deep learning based image CS methods.

The main contributions of this paper are as follows:

• A scalable convolutional neural network (dubbed SC-
SNet) is proposed to achieve scalable sampling and s-
calable reconstruction with only one model.

• Coarse granular scalable sampling and scalable recon-
struction using CNN is presented, in which the BL
provides the basic reconstruction quality and the EL-
s gradually improve the reconstruction quality.

2Each row of the sampling matrix is called as a measurement base in

this paper.

• Fine granular scalable sampling and scalable recon-
struction is introduced, which employs a greedy
method to select the measurement bases. The ﬁne
granular scalability can sample and recover the image
at any sampling ratio.

2. Related work and motivation

We review the related work by grouping the existing
methods into traditional CS methods and deep learning
based CS methods. Generally, the traditional CS meth-
ods recover a signal from the CS measurements by solv-
ing a sparsity-regularized optimization problem. The well-
known methods include:
the convex optimization meth-
ods [7], the greedy algorithms [24, 33], and the gradient-
descent methods [8, 35, 13]. For image CS, some methods
introduce image prior as a regularization item. For exam-
ple, Li et al. [22] used the total variation (TV) regularized
constraint to replace the sparsity-based one for enhancing
the local smoothness. In [40], Zhang et al. proposed group
sparse representation (GSR) for image CS recovery by en-
forcing image sparsity and non-local self-similarity simulta-
neously. In addition, the block based compressed sampling
(BCS) and projected Landweber based CS reconstruction
methods [14, 27, 6] have also been proposed, in which ad-
ditional optimization criteria can be easily incorporated. In
[27], discrete wavelet transform (DWT) is used to encour-
age image sparsity. In [6], multi-hypothesis (MH) predic-
tions is considered for CS reconstruction of both still im-
ages and video sequences.

Recently, some deep learning based image CS methods
have been explored. These methods can be roughly divid-
ed into block-by-block reconstruction methods [26, 20, 39,
36] and end-to-end reconstruction methods [32]. In [26],
Mousavi et al. proposed a stacked denoising autoencoder
(SDA) to capture statistical dependencies between the d-
ifferent elements of certain signals and improve signal re-
construction performance.
In [20], Kulkarni et al. used
a CNN (ReconNet) for image block reconstruction and an
off-the-shelf denoiser for deblocking. In [39], Zhang et al.
cast the iterative shrinkage-thresholding algorithm as CN-
N (ISTA-Net).
In [36], Xu et al. proposed a Laplacian
pyramid reconstructive adversarial network (LAPRAN) that
generates multiple outputs with different resolution simul-
taneously. These block-by-block reconstruction method-
s [26, 20, 39, 36] will cause blocking artifact. Compared
with these methods, CSNet [32] can avoid blocking artifact
by learning an end-to-end mapping between measurements
and the whole reconstructed images. However, the exist-
ing deep learning based CS methods need to train different
models for different sampling ratios, which increases the
complexity of the encoder and decoder.

Image CS has been explored for many kinds of applica-
tions such as image acquisition [12, 17], image/video source

12291

coding [28, 15], medical imaging [31], and wireless broad-
cast [37, 21]. The existing deep learning based CS methods
use different models for different sampling ratios. This will
cause difﬁculty for storage and hardware implementation.
In addition, some applications need scalable sampling and
scalable reconstruction. In medical imaging, oversampling
may harm the object being captured. Scalable reconstruc-
tion is preferred in wireless broadcast. However, scalable
sampling and scalable reconstruction are not considered by
the existing deep learning based image CS methods.

3. Proposed method

3.1. Overview of SCSNet

Figure 2 shows the network structure schematic of SC-
SNet with two ELs. SCSNet uses a convolution layer with
speciﬁc ﬁlter size and stride to implement BCS. The recon-
struction network of SCSNet has a BL and multiple ELs.
Both BL and EL have an initial reconstruction network and
a deep reconstruction network. The initial reconstruction
network of BL directly generates the initial reconstructed
image from the measurements. The initial reconstruction
networks of ELs ﬁrst use the measurements to obtain the
supplementary information (i.e. residual), and then add the
initial reconstruction of the lower reconstruction layers to
generate the initial reconstruction of ELs. A deep recon-
struction network is used to reﬁne the initial reconstruction
in each reconstruction layer. This hierarchical reconstruc-
tion network structure is similar to the decoder architecture
of scalable video coding [5], and provides coarse granular
scalability.

To implement ﬁne granular scalable sampling and scal-
able reconstruction, SCSNet ﬁrst recognizes the importance
of each measurement base ofﬂine. The higher reconstruc-
tion layers reference the initial reconstruction of the low-
er reconstruction layers, so the measurement bases in the
lower reconstruction layers are more important than those
in the higher reconstruction layers. The importance of the
measurement bases in the same reconstruction layer are de-
termined by a greedy method. SCSNet achieves sampling
and reconstruction at any sampling ratio by removing some
unimportant measurement bases and the corresponding con-
nection to the reconstruction network.

3.2. Coarse granular scalability

3.2.1 BCS with a convolution layer

BCS divides the images into non-overlapping blocks of size
B ×B ×l, where B and l are the spacial size and the amount
of channel, respectively. Note that all our experiments are
conducted on grayscale images, so l = 1 in this paper. To
the jth block xj , BCS is represented as yj = ΦBxj , where
ΦB is the sampling matrix of size nB × lB2 (for sampling

ratio α, nB = (cid:4)αlB2(cid:5)). This process can be converted to a

convolution layer with speciﬁc ﬁler size and stride as

y = S (x) = Ws ∗ x

(1)

where Ws corresponds to nB ﬁlters of support B × B × l.
This convolution layer is represented as Conv(B, l, nB) in
Figure 2, . There is no bias in the layer, and no activation
function after this layer. To ensure the ﬁxed sampling ratio,
the stride of this convolution layer is B × B to implemen-
t non-overlapping sampling. With this speciﬁc convolution
layer, the sampling matrix can be learned by jointly optimiz-
ing this convolution layer and the reconstruction network.

3.2.2 Hierarchical initial reconstruction network

The measurements obtained by the sampling layer can be
treated as nB feature maps that are divided into multiple
groups as marked with different colors in Figure 2. BL
uses only one group of measurements to get the initial re-
construction. Each EL uses one group of measurements to
generate a reconstruction residual, and reference the lower
layers to improve the initial reconstruction quality.

Given the measurements y, CSNet [32] obtains the initial
reconstruction by using a convolution layer and a combina-
tion layer that is expressed as

˜I (y) = Wint ∗ y
γ (cid:16)˜I11 (y)(cid:17) · · ·
. . .

...

γ (cid:16)˜I1w (y)(cid:17)

...

γ (cid:16)˜Ih1 (y)(cid:17) · · · γ (cid:16)˜Ihw (y)(cid:17)

(2)

(3)









˜x = I (y) = κ

where Wint corresponds to lB2 ﬁlters, ˜Iab (y) is a 1 × 1 ×
lB2 vector, a and b are the space indices of ˜I (y), h and
w represent the numbers of blocks in row and column re-
spectively, γ (·) is the reshape function that converts the
1×1×lB2 vector to a B×B×l block, κ (·) is the concatena-
tion function that concatenates all these blocks to generate
a whole image.

In this work, BL uses Eq.(2) and Eq.(3) to get the initial
reconstruction, but each EL just uses Eq.(2) and Eq.(3) to
get a reconstruction residual as shown in Figure 2. The ini-
tial reconstruction in the ith EL is the reconstruction residu-
al of the ith EL plus the initial reconstruction of the (i−1)th
EL or BL. Suppose the ith group of measurements are ob-
tained with ni measurement bases, Wint in Eq.(2) corre-
sponds to lB2 ﬁlters of support 1 × 1 × ni.

3.2.3 Hourglass-shape deep reconstruction network

After getting the initial reconstruction,
there is a non-
linear reconstruction process in the traditional BCS meth-
ods [14, 27]. In this work, a deep reconstruction network

12292

Figure 2. The network structure schematic of SCSNet with two ELs.

Figure 3. The network structure of Deep Reconstruction.

is used to further reﬁne the reconstructed images in BL and
ELs. Dong et al. [10] shows that hourglass-shape network
has good performance with low computational complexity.
In addition, many works [18] show residual learning can ac-
celerate the network convergence speed and boost the net-
work performance. Based on the existing works, our deep
reconstruction network is a hourglass-shape residual learn-
ing network as shown in Figure 3.

The hourglass-shape residual learning network includes
six kinds of operations, i.e. feature extraction, shrinking,
non-linear mapping, expanding, feature aggregation, and
skip connection. All these operations are convolution layers
with different size ﬁlters except skip connection. This forms
a symmetric structure, thick at the ends, and thin in the mid-
dle. We represent a convolution layer as conv(f, in, out),
where f , in, and out are the spacial size of the ﬁlters, the
amount of the input channels, and the amount of the output
channels, respectively. Then, feature extraction, shrinking,
non-linear mapping, expanding and feature aggregation are
represented as conv(f, l, d), conv(f, d, s), conv(f, s, s),
conv(f, s, d), and conv(f, d, l), where l is the amount of
image channel. Note that d >> s, which ensures that the
deep reconstruction is a compact hourglass-shape network.
To increase the network non-linear, the non-linear mapping
is cascaded k times. All these convolution layers are fol-
lowed with a ReLu [29] activation layer except the last con-
volution layer. A skip connection is added between the ini-
tial and the ﬁnal reconstruction.

3.2.4 Loss function

Suppose the reconstruction network has T initial recon-
structions and T ﬁnal reconstructions, we have 2T objec-
tives to minimize. We adopt the mean square error (MSE)
as the loss function to supervise each initial reconstruction
and ﬁnal reconstruction. With these constraints, all initial
and ﬁnal reconstructions are expected to correctly recon-
struct the desired image, which can accelerate network con-
vergence and boost the ﬁnal reconstruction quality. Adap-
tive moment estimation (Adam) [19] is used to optimize all
network parameters.

3.3. Fine granular scalability

Fine granular scalability is necessary, which increases
the ﬂexibility in applications. For example, if BL is for the
sampling ratio of 0.01 and the ﬁrst EL is for the sampling
ratio of 0.05 in a well-trained model, it cannot be applied
directly to reconstruct image at sampling ratio of 0.04. The
ﬁne granular scalability makes it possible to sample and re-
construct image at any sampling ratio with one model. To a
given sampling ratio r, which is smaller than the sampling
ration ri of the ith EL (for convenience, BL is treated as a
speciﬁc EL) but larger than the sampling ratio ri−1 of the
(i − 1)th EL, we remove some unimportant measurement
bases and the corresponding connections to the reconstruc-
tion network in the ith EL. To obtain as good reconstruction
as possible, we use a greedy algorithm to preserve the most

12293

Algorithm 1 The greedy method for measurement base se-
lection. M orders the measurement bases from least impact
on PSNR to most impact.
Input: Validation set {xj}, and the index i of EL
Output: the order M of measurement bases in the ith EL

1: M ← ∅, Z = {1, 2, · · · , L};
2: for k = 1 to L do
3: max psnr ← −∞;
4:

for z ∈ Z and z /∈ M do

M ′ ← M ∪ {z};
compute avg psnr when the measurement bases
indexed by M ′ are removed in the ith EL;
if avg psnr > max psnr then

max psnr = avg psnr, max z ← z;

5:

6:

7:

8:

9:

end if
end for

10:
11: M ← M ∪ {max z};
12: end for

important measurement bases.

Suppose the ith EL uses L measurement bases that their
indexes are represented as Z = {1, 2, · · · , L}. When some
measurement bases and their connections to the reconstruc-
tion network are removed, we hope the remaining measure-
ments provide as good reconstruction as possible. Hence, to
preserve the most important measurement bases, we solve
the following optimization problem

arg min

M

N

(cid:16)R(i)

M (cid:16)S(i)

Pj=1
s.t. M ⊂ Z = {1, 2, · · · , L}

M (xj)(cid:17) + R(i−1) (cid:0)S(i−1) (xj)(cid:1) − xj(cid:17)2

(4)
where xj is a validation sample, S(i−1) and R(i−1) are the
measurements and the reconstruction of the (i − 1)th EL,
S(i)
M and R(i)
M are measurements and the reconstructed resid-
ual of the ith EL after removing those measurements in-
dexed by a subset M of Z.

We use a greedy method to solve Eq.(4). The idea is to
select a best option in each step. For a given amount of mea-
surement bases, the solution of Eq.(4) is those measurement
bases that provide highest average PSNR. As illustrated in
Algorithm 1, M is the order set of the measurement bases
in the ith EL, and it is empty in the beginning. In Step 3
to Step 11, we select only one index to move into M that
has less impact on the average PSNR. That is, the index be
moved into M in ﬁrst is more unimportant than the index
be moved into M in later. After L iterations, we obtain the
order of the measurement bases in the ith EL based on their
importance to the reconstruction quality.

As the importance order of the measurement bases can
be obtained by using Algorithm 1, it is easy to implement
sampling and reconstruction at any desired sampling ratio

with only one model and provides as good reconstruction
as possible, which provides ﬁne granular scalability.

4. Experiments

4.1. Dataset and implementation details

Similar to the traditional image CS methods [27, 22, 6,
40], the block size is set B = 32 and l = 1. In our ex-
periment, SCSNet contains one BL and six ELs that corre-
sponds to sampling ratio of 0.01, 0.05, 0.1, 0.2, 0.3, 0.4 and
0.5, respectively. The ﬁlter size in the initial reconstruction
is computed based on the sampling ratio and the block size
as introduced in Subsection 3.2.2. In the deep reconstruc-
tion network, we set f = 3, l = 1, d = 128, s = 32, and
k = 13 respectively. To optimize the network parameter-
s, the learning ratios of the ﬁrst 50, the 51 to 80 and the
last 20 epochs are 10−3, 10−4, and 10−5, respectively. The
training data is the same with CSNet. That is, the training
set (200 images) and test set (200 images) of the BSDS500
database [2] form the training dataset. Each image is cut
into multiple patches of size 96 × 96. Finally, only 89600
patches are used to optimize the network parameters.

4.2. Comparison with the state of the arts

4.2.1 Comparison with traditional methods

The compared traditional methods include: wavelet method
(DWT) [27],
total variation (TV) method [22], multi-
hypothesis (MH) method [6], and group sparse represen-
tation (GSR) method [40]. CSNet [32] is also listed for
comparison. All these methods are popular BCS method-
s. The implementation codes of the compared methods are
downloaded from the author’s websites and the default pa-
rameter settings are used in our experiments. We compare
these methods on three popular test dataset, i.e. Set5 (5 im-
ages) [3], Set14 (14 images) [38] and the BSD100 (100 im-
ages) [25]. Note that all experiments are conducted on the
Y channel of the YUV color space. Seven sampling ratios,
i.e. 0.01, 0.05, 0.1, 0.2, 0.3, 0.4 and 0.5, are investigated.
Both quantitative and qualitative comparisons are given.

The average PSNR and SSIM on the three test datasets
are shown in Table 1. The best results are marked in bold
font. The quantitative results show that SCSNet outper-
forms the ﬁve compared CS methods at all sampling ratios.
Specially, compared with DWT, TV, MH, GSR, and CSNet,
SCSNet gains by average 7.45 dB, 5.16 dB, 4.31 dB, 2.58
dB, and 0.50 dB, respectively, over seven sampling ratios
and three datasets. The average SSIM also shows SCSNet
is signiﬁcantly superior to the ﬁve compared methods.

Figure 4 shows a visual quality comparison of image CS
recovery in the case of sampling ratio of 0.2. We have mag-
niﬁed a subregion of each image to compare the reconstruc-
tion details of each image. Obviously, SCSNet achieves bet-
ter visual quality than the traditional methods. Although the

12294

Figure 4. Visual quality comparisons of CS recovery on PPT3 from Set14 [38] in the case of sampling ratio = 0.2.

Figure 5. Visual quality comparisons of CS recovery on Parrots from Set11 [20] in the case of sampling ratio = 0.1.

visual differences between the reconstruction results of SC-
SNet and CSNet are small, SCSNet gets higher PSNR and
SSIM values. All the experimental results demonstrate SC-
SNet not only has property of scalability but also has state-
of-the-art performance.

4.2.2 Comparison with deep learning based methods

The compared deep learning based methods include: SDA
[26], ReconNet [20], ISTA-Net [39], ISTA-Net+ [39] and
CSNet [32]. LAPRAN [36] gets high PSNR with a ﬂexible
resolution. However, the reconstruction results of LAPRAN
have signiﬁcant blocking artifact, and the pretrained models
of LAPRAN have not been released. Therefore, we do not
make comparison with LAPRAN in this paper. We follow
[39] to use Set11 [20] and BSD68 [25] as the test images.
Table 2 shows the average PSNR of different deep learning
based methods on ﬁve sampling ratios. The results of SDA,
ReconNet, ISTA-Net, and ISTA-Net+ are taken from [39].
As shown, SCSNet obtains signiﬁcantly higher average P-
SNR than the compared deep learning based methods at the
ﬁve sampling ratios on Set11 and BSD68. Figure 5 shows a
visual comparison between various image CS methods. As
shown, both ReconNet and ISTA-Net+ have blocking arti-
fact. In contrast, SCSNet does not have blocking artifact
and obtains better visual effect. SCSNet is the scalable ex-

Table 2. Average PSNR comparison of different deep learning
based image CS methods on Set11 [20] and BSD68 [25].

Data

Alg.

Set11

BSD68

SDA [26]

ReconNet [20]
ISTA-Net [39]
ISTA-Net+ [39]

CSNet [32]

SCSNet
SDA [26]

ReconNet [20]
ISTA-Net [39]
ISTA-Net+ [39]

CSNet [32]

SCSNet

Sampling Ratio

0.5
28.95
31.50
37.43
38.07
37.51
39.01
28.35
29.86
33.60
34.01
34.89
35.77

0.4
27.79
30.58
35.36
36.06
36.10
36.92
27.41
29.08
31.85
32.21
32.53
33.86

0.3
26.63
28.74
32.91
33.82
33.86
34.62
26.38
27.53
29.93
30.34
31.45
31.87

0.1
22.65
24.28
25.80
26.64
28.10
28.48
23.12
24.15
25.02
25.33
27.10
27.28

0.01
17.29
17.27
17.30
17.34
20.94
21.04

-
-
-
-

22.34
22.37

tension of CSNet. SCSNet outperforms CSNet because it
uses a better reconstruction network.

4.2.3 Running time comparison

Table 3 shows the average running time comparisons be-
tween various algorithms for reconstructing a 256×256 im-
age at sampling ratio of 0.01 and 0.1. The running times of
SAD and ReconNet are taken from [20]. The running times
of ISTA-Net and ISTA-Net+ are the average running time
of seven sampling ratio taken from [39]. The running times

12295

Table 1. Average PSNR and SSIM comparisons of different image CS algorithms on Set5 [3], Set14 [38] and BSD100 [25]

Data

Set5

Set14

BSD100

Avg.

Ratio
0.01
0.05
0.1
0.2
0.3
0.4
0.5
0.01
0.05
0.1
0.2
0.3
0.4
0.5
0.01
0.05
0.1
0.2
0.3
0.4
0.5

DWT [27]

TV [22]

MH [6]

GSR [40]

CSNet [32]

SCSNet

PSNR
9.27
14.27
24.74
30.83
33.61
35.32
36.87
8.97
14.52
24.16
28.13
30.38
31.99
33.54
9.63
14.81
23.46
27.26
29.23
30.72
32.17
24.95

SSIM PSNR
15.53
0.1402
23.16
0.3559
27.07
0.7680
0.8749
30.45
32.75
0.9050
34.89
0.9249
36.75
0.9409
15.26
0.0989
0.2933
22.24
25.24
0.6798
28.07
0.7882
30.12
0.8389
32.03
0.8753
0.9044
33.84
15.98
0.1067
23.05
0.2935
25.46
0.6343
27.58
0.7516
0.8108
29.27
30.86
0.8524
32.46
0.8862
0.6535
27.24

SSIM PSNR
18.08
0.4554
23.67
0.6678
28.57
0.7865
0.8709
32.08
34.06
0.9107
35.65
0.9363
37.21
0.9540
17.23
0.3890
0.5815
21.64
26.38
0.6887
29.47
0.7844
31.37
0.8424
33.03
0.8837
0.9148
34.52
18.21
0.3995
21.36
0.5690
25.16
0.6612
28.09
0.7557
0.8191
29.85
31.35
0.8660
32.86
0.9019
0.7447
28.09

SSIM PSNR
18.87
0.4472
24.95
0.6566
29.99
0.8211
0.8881
34.17
36.83
0.9158
38.81
0.9337
40.65
0.9482
17.87
0.3970
0.5567
22.54
27.50
0.7282
31.22
0.8237
33.74
0.8694
35.78
0.9009
0.9239
37.66
18.90
0.4076
22.16
0.5169
25.91
0.6673
29.18
0.7746
0.8307
31.33
33.20
0.8695
34.94
0.9012
0.7513
29.82

SSIM PSNR
24.02
0.4909
29.32
0.7270
32.30
0.8654
0.9257
35.63
37.90
0.9492
39.89
0.9626
40.96
0.9724
22.73
0.4337
0.6140
26.65
28.91
0.7705
31.86
0.8642
34.00
0.9071
35.95
0.9336
0.9522
37.05
23.69
0.4431
26.61
0.5682
28.40
0.7071
30.88
0.8156
0.8723
32.89
34.13
0.9096
36.09
0.9359
0.7914
31.90

SSIM PSNR
24.21
0.6378
29.74
0.8354
32.77
0.9015
36.15
0.9451
38.45
0.9630
40.44
0.9736
42.22
0.9784
22.87
0.5556
26.92
0.7238
29.22
0.8119
32.19
0.8908
34.51
0.9276
36.54
0.9495
38.41
0.9607
23.78
0.5441
26.77
0.6908
28.57
0.7787
31.10
0.8681
33.24
0.9146
35.21
0.9250
37.14
0.9587
32.40
0.8445

SSIM
0.6468
0.8472
0.9083
0.9487
0.9655
0.9755
0.9820
0.5631
0.7322
0.8181
0.8945
0.9311
0.9525
0.9659
0.5483
0.6972
0.7844
0.8731
0.9190
0.9470
0.9649
0.8507

Figure 6. Average PSNR comparisons on Set5 [3] and Set14 [38] when preserving different number of measurement base of BL by the
proposed method and the random method.

for DWT, TV, MH, GSR, and CSNet are the implementa-
tion times on the platform of an Intel Core i7-3770 CPU
plus a NVIDIA GTX960 GPU with the codes download
from the author’s websites. SCSNet runs on the platform
of an Intel Core i7-7700 CPU plus a NVIDIA GTX1080
GPU. As shown in Table 3, the four compared tradition-
al methods take roughly several seconds to several min-
utes to reconstruct an image. This may be because they
need repeated iterative operations. All the compared deep
learning based methods run faster than those compared tra-
ditional methods. Although SCSNet runs slower than the
compared deep learning based methods on GPU, SCSNet
can run faster than ReconNet, ISTA-Net, and ISTA-Net+ on
CPU. In our experiment, SCSNet is implemented using the
DagNN wrapper of MatConvNet package [34]. In practical
application, we can reimplement SCSNet using the other
deep learning framework for faster running speed.

Table 3. Average running time (in seconds) of various algorithms
for reconstructing a 256 × 256 image.

Algorithm

DWT [27]

TV [22]
MH [6]
GSR [40]
SDA [26]

ReconNet [20]
ISTA-Net [39]
ISTA-Net+ [39]

CSNet [32]

SCSNet

Ratio = 0.01

Ratio = 0.1

CPU

GPU

CPU

GPU

10.3176
2.3349
23.1006
235.6297

-

0.5193
0.9230
1.3750
0.2950
0.5103

-
-
-
-

0.0045
0.0244
0.0390
0.0470
0.0157
0.1050

10.5539
2.5871
19.0405
230.4755

-

0.5258
0.9230
1.3750
0.2941
0.5146

-
-
-
-

0.0029
0.0195
0.0390
0.0470
0.0155
0.1332

4.3. Study of ﬁne granular scalability

SCSNet provides measurement base level of ﬁne granu-
lar scalability. The greedy method for measurement base se-
lection introduced in Subsection 3.3 is a data driven method.

12296

Figure 7. Average PSNR comparisons between different deep learning based image CS methods on Set11 [20] and BSD68 [25] in the case
of sampling ratio = 0.04.

In our experiment, we use the 50 images from the validation
set of the BSDS500 database [2] to determine the impor-
tance of each measurement base. For comparison, we also
randomly determine the importance of each measurement
base. The random seed is 10.

We implement progressive sampling and progressive re-
construction based on the importance of each measurement
base. That is, the encoder acquires measurements with the
most important measurement base in ﬁrst, and gives to the
decoder. The decoder gradually improves the reconstructed
image quality as more measurements it receives. Figure 6
shows the results of progressive sampling and progressive
reconstruction using the BL of SCSNet. As shown, the pro-
posed greedy method is an effective way for measurement
base selection because it provides signiﬁcant higher average
PSNR than the random selection method.

In addition, we also verify sampling and reconstruction
at different sampling ratios by using one model. Table 4
shows the average PSNR at nine sampling ratios, which are
obtained by using one well-trained model. The results of
sampling ratio of 0.01, 0.05 and 0.1 correspond to the BL,
the ﬁrst and the second EL, respectively, while the other re-
sults are obtained by removing some measurement bases.
As shown, SCSNet can provide good reconstruction for s-
calable sampling and scalable reconstruction with only one
model. In Figure 7, the results of the compared deep learn-
ing based image CS methods are obtained by the models
that are specially trained for sampling ratio of 0.04, while
the results of SCSNet are obtained by removing some mea-
surement bases of the well-trained model. As shown, SC-
SNet does not need to train the special model for sampling
ratio of 0.04, but it still signiﬁcantly outperforms the com-
pared methods in this sampling ratio.

Table 4. The average PSNR of SCSNet at nine different sampling
ratios using only one well-trained model.

Sampling ratio

Data

0.05

0.04

0.03

0.02

0.01
24.21 24.57 26.10 27.83 29.74 29.93 30.78 31.76 32.77
Set5
21.04 21.55 22.84 24.29 25.85 26.22 27.00 27.82 28.52
Set11
22.87 23.20 24.42 25.65 26.92 27.20 27.89 28.58 29.22
Set14
22.37 22.86 23.73 24.62 25.43 25.90 26.38 26.86 27.28
BSD68
BSD100 23.78 24.14 24.98 25.88 26.77 27.07 27.57 28.09 28.57

0.09

0.07

0.08

0.1

compressed sensing. SCSNet is the ﬁrst to implement s-
calable sampling and scalable reconstruction using CNN,
which provides both coarse granular scalability and ﬁne
granular scalability. For coarse granular scalability, SC-
SNet is designed as a single sampling matrix plus a hier-
archical reconstruction network that has a BL and multiple
ELs. BL provides the basic reconstruction quality, while
ELs improve the reconstructed image quality by generating
the reconstruction residual and referencing the lower layers.
An effective greedy method for measurement base selection
has also been introduced. By removing some unimportant
measurement bases and their corresponding connection to
the reconstruction network, SCSNet achieves ﬁne granular
scalable sampling and reconstruction. Compared with the
existing deep learning based methods, SCSNet provides s-
calable sampling and scalable reconstruction that provides
the chance to implement sampling and reconstruction at any
sampling ratio with only one model. Experimental result-
s show that SCSNet has the state-of-the-art reconstruction
quality while maintaining a comparable running speed with
the existing deep learning based image CS methods.

6. Acknowledement

5. Conclusion

While observing the limitation of the existing deep learn-
ing based image CS methods, we have proposed a scalable
convolutional neural network (dubbed SCSNet) for image

This work was supported by the National Basic Research
Program of China (2015CB351804), the National Natu-
ral Science Foundation of China under Grants 61872116,
61672188, 61572155, and the Alibaba Innovative Research
(AIR) Program.

12297

References

[1] Arash Amini and Farokh Marvasti. Deterministic con-
struction of binary, bipolar, and ternary compressed sens-
ing matrices.
IEEE Transactions on Information Theory,
57(4):2360–2370, 2011.

[2] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Con-
tour detection and hierarchical image segmentation.
IEEE
transactions on pattern analysis and machine intelligence,
33(5):898–916, 2011.

[3] Marco Bevilacqua, Aline Roumy, Christine Guillemot, and
Marie Line Alberi-Morel. Low-complexity single-image
super-resolution based on nonnegative neighbor embedding.
2012.

[4] Lei Bo, Hancheng Lu, Yujiao Lu, Jianwen Meng, and Wen-
zhe Wang. FompNet: Compressive sensing reconstruction
with deep learning over wireless fading channels. In 2017
9th International Conference on Wireless Communications
and Signal Processing (WCSP), pages 1–6. IEEE, 2017.

[5] Jill M Boyce, Yan Ye, Jianle Chen, and Adarsh K Ramasub-
ramonian. Overview of SHVC: scalable extensions of the
high efﬁciency video coding standard.
IEEE Transactions
on Circuits and Systems for Video Technology, 26(1):20–34,
2016.

[6] C. Chen, E. W Tramel, and J. E. Fowler. Compressed-
sensing recovery of images and video using multihypothesis
predictions. In 2011 conference record of the forty ﬁfth asilo-
mar conference on signals, systems and computers (ASILO-
MAR), pages 1193–1198. IEEE, 2011.

[7] S. S. Chen, D. L. Donoho, and M. A. Saunders. Atomic
decomposition by basis pursuit. SIAM Review, 43(1):129–
159, 2001.

[8] Ingrid Daubechies, Michel Defrise, and Christine De Mol.
An iterative thresholding algorithm for linear inverse prob-
lems with a sparsity constraint. Communications on Pure
and Applied Mathematics, 57(11):1413–1457, 2004.

[9] K. Q. Dinh, H. J. Shim, and B. Jeon. Measurement cod-
ing for compressive imaging using a structural measuremnet
matrix.
In 2013 IEEE International Conference on Image
Processing, pages 10–13. IEEE, 2013.

[10] Chao Dong, Chen Change Loy, and Xiaoou Tang. Accel-
erating the super-resolution convolutional neural network.
In Computer Vision – ECCV 2016, pages 391–407, Cham,
2016. Springer International Publishing.

[11] David L Donoho. Compressed sensing. IEEE Transactions

on Information Theory, 52(4):1289–1306, 2006.

[12] Marco F Duarte, Mark A Davenport, Dharmpal Takbar, Ja-
son N Laska, Ting Sun, Kevin F Kelly, and Richard G Bara-
niuk. Single-pixel imaging via compressive sampling. IEEE
Signal Processing Magazine, 25(2):83–91, 2008.

[13] M´ario AT Figueiredo, Robert D Nowak, and Stephen J
Wright. Gradient projection for sparse reconstruction: Ap-
plication to compressed sensing and other inverse problem-
s.
IEEE Journal of Selected Topics in Signal Processing,
1(4):586–597, 2007.

[14] L. Gan. Block compressed sensing of natural images.

In
2007 15th International Conference on Digital Signal Pro-
cessing, pages 403–406. IEEE, 2007.

[15] X. Gao, J. Zhang, W. Che, X. Fan, and D. Zhao. Block-
based compressive sensing coding of natural images by local
structural measurement matrix. In 2015 Data Compression
Conference, pages 133–142. IEEE, 2015.

[16] J. Haupt and R. Nowak. Signal reconstruction from noisy
random projections. IEEE Transactions on Information The-
ory, 52(9):4036–4048, 2006.

[17] Ronan Kerviche, Nan Zhu, and Amit Ashok. Information-
optimal scalable compressive imaging system. In Computa-
tional Optical Sensing and Imaging, pages CM2D–2. Optical
Society of America, 2014.

[18] Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Accurate
image super-resolution using very deep convolutional net-
works. In Computer Vision and Pattern Recognition, pages
1646–1654, 2016.

[19] Diederik Kingma and Jimmy Ba. Adam: A method for
arXiv preprint arXiv:1412.6980,

stochastic optimization.
2014.

[20] Kuldeep Kulkarni, Suhas Lohit, Pavan Turaga, Ronan Ker-
viche, and Amit Ashok. ReconNet: Non-iterative reconstruc-
tion of images from compressively sensed measurements. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 449–458, 2016.

[21] Chengbo Li, Hong Jiang, Paul Wilford, Yin Zhang, and Mike
Scheutzow. A new compressive video sensing framework
for mobile broadcast. IEEE Transactions on Broadcasting,
59(1):197–205, 2013.

[22] C. Li, W. Yin, and Y. Zhang. Tval3: Tv minimization
by augmented lagrangian and alternating direction agorith-
m 2009. Available: http://www.caam.rice.edu/$\
sim$optimization/L1/TVAL3/.

[23] Weizhi Lu, Tao Dai, and Shu-Tao Xia. Binary matrices for
compressed sensing. IEEE transations on signal processing,
66(1):77, 2018.

[24] St´ephane G Mallat and Zhifeng Zhang. Matching pursuit-
IEEE Transactions on

s with time-frequency dictionaries.
Signal Processing, 41(12):3397–3415, 1993.

[25] David Martin, Charless Fowlkes, Doron Tal, and Jitendra
Malik. A database of human segmented natural images and
its application to evaluating segmentation algorithms and
measuring ecological statistics. In Computer Vision, 2001.
ICCV 2001. Proceedings. Eighth IEEE International Con-
ference on, volume 2, pages 416–423. IEEE, 2001.

[26] Ali Mousavi, Ankit B. Patel, and Richard G. Baraniuk.
A deep learning approach to structured signal recovery.
In Communication, Control, and Computing, pages 1336–
1343, 2016.

[27] S. Mun and J. E. Fowler. Block compressed sensing of im-
ages using directional transforms.
In 2009 16th IEEE in-
ternational conference on image processing (ICIP), pages
3021–3024. IEEE, 2009.

[28] Sungkwang Mun and James E Fowler. DPCM for quantized
block-based compressed sensing of images. In Signal Pro-
cessing Conference (EUSIPCO), 2012 Proceedings of the
20th European, pages 1424–1428. IEEE, 2012.

[29] Vinod Nair and Geoffrey E Hinton. Rectiﬁed linear units im-
prove restricted boltzmann machines. In Proceedings of the

12298

27th International Conference on Machine Learning (ICML-
10), pages 807–814, 2010.

[30] Deanna Needell and Joel A Tropp. Cosamp: Iterative sig-
nal recovery from incomplete and inaccurate samples. Ap-
plied and Computational Harmonic Analysis, 26(3):301–
321, 2009.

[31] Tran Minh Quan, Thanh Nguyen-Duc, and Won-Ki Jeong.
Compressed sensing mri reconstruction using a generative
adversarial network with a cyclic loss. IEEE transactions on
medical imaging, 37(6):1488–1497, 2018.

[32] Wuzhen Shi, Feng Jiang, Shengping Zhang, and Debin Zhao.
Deep networks for compressed image sensing. In Multime-
dia and Expo (ICME), 2017 IEEE International Conference
on, pages 877–882. IEEE, 2017.

[33] Joel A Tropp and Anna C Gilbert. Signal recovery from ran-
dom measurements via orthogonal matching pursuit. IEEE
Transactions on Information Theory, 53(12):4655–4666,
2007.

[34] A. Vedaldi and K. Lenc. Matconvnet: Convolutional neural
networks for matlab. In Proceedings of the 23rd ACM Inter-
national Conference on Multimedia, pages 689–692. ACM,
2015.

[35] Stephen J Wright, Robert D Nowak, and M´ario AT Figueire-
do. Sparse reconstruction by separable approximation. IEEE
Transactions on Signal Processing, 57(7):2479–2493, 2009.
[36] Kai Xu, Zhikang Zhang, and Fengbo Ren. Lapran: A s-
calable laplacian pyramid reconstructive adversarial network
for ﬂexible compressive sensing reconstruction. In European
Conference on Computer Vision, pages 491–507. Springer,
2018.

[37] Wenbin Yin, Xiaopeng Fan, Yunhui Shi, Ruiqin Xiong, and
Debin Zhao. Compressive sensing based soft video broad-
cast using spatial and temporal sparsity. Mobile Networks
and Applications, 21(6):1002–1012, 2016.

[38] R. Zeyde, M. Elad, and M. Protter. On single image scale-up
using sparse-representations. In International conference on
curves and surfaces, pages 711–730. Springer, 2010.

[39] Jian Zhang and Bernard Ghanem. ISTA-Net: Interpretable
optimization-inspired deep network for image compressive
sensing. In Proceedings of the IEEE Conference on Comput-
er Vision and Pattern Recognition, pages 1828–1837, 2018.
[40] J. Zhang, D. Zhao, and W. Gao. Group-based sparse repre-
sentation for image restoration. IEEE Transactions on Image
Processing, 23(8):3336–3351, 2014.

12299

