Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds

using Convolutional Neural Networks

Yizhak Ben-Shabat

Michael Lindenbaum

Anath Fischer

Mechanical Engineering

Computer Science

Mechanical Engineering

Techion IIT
Haifa, Israel

Techion IIT
Haifa, Israel

Techion IIT
Haifa, Israel

sitzikbs@gmail.com

mic@cs.technion.ac.il

meranath@technion.ac.il

Abstract

tion [21] and surface reconstruction [11].

In this paper, we propose a normal estimation
method for unstructured 3D point clouds. This method,
called Nesti-Net, builds on a new local point cloud rep-
resentation which consists of multi-scale point statis-
tics (MuPS), estimated on a local coarse Gaussian grid.
This representation is a suitable input to a CNN archi-
tecture. The normals are estimated using a mixture-
of-experts (MoE) architecture, which relies on a data-
driven approach for selecting the optimal scale around
each point and encourages sub-network specialization.
Interesting insights into the network’s resource dis-
tribution are provided. The scale prediction signif-
icantly improves robustness to diﬀerent noise levels,
point density variations and diﬀerent levels of detail.
We achieve state-of-the-art results on a benchmark syn-
thetic dataset and present qualitative results on real
scanned scenes.

1. Introduction

Commodity 3D sensors are rapidly becoming an in-
tegral part of autonomous systems. These sensors, e.g.
RGB-D cameras or LiDAR, provide a 3D point cloud
representing the geometry of the scanned objects and
surroundings. This raw representation is challenging
to process since it lacks connectivity information or
structure, and is often incomplete, noisy and contains
point density variations. In particular, processing it by
means of the highly eﬀective convolutional neural net-
works (CNNs) is problematic because CNNs require
structured, grid-like data as input.

When available, additional local geometric informa-
tion, such as the surface normals at each point, induces
a partial local structure and improves performance of
diﬀerent tasks such as over-segmentation [3], classiﬁca-

Estimating the normals from a raw, point-only,
cloud,
is a challenging task due to diﬃculties asso-
ciated with sampling density, noise, outliers, and de-
tail level. The common approach is to specify a local
neighborhood around a point and to ﬁt a local basic
geometric surface (e.g. a plane) to the points in this
neighborhood. Then the normal is estimated from the
ﬁtted geometric entity. The chosen size (or scale) of
the neighborhood introduces an unavoidable tradeoﬀ
between robustness to noise and accuracy of ﬁne de-
tails. A large-scale neighborhood over-smoothes sharp
corners and small details but is otherwise robust to
noise. A small neighborhood, on the other hand, may
reproduce the normals more accurately around small
details but is more sensitive to noise. Thus it seems
that an adaptive, data-driven scale may improve esti-
mation performance.

We propose a normal estimation method for un-
structured 3D point clouds.
It features a mixture-
of-experts network for scale prediction, which signif-
icantly increases its robustness to diﬀerent noise lev-
els, outliers, and varying levels of detail. In addition,
this method overcomes the challenge of feeding point
clouds into CNNs by extending the recently proposed
3D modiﬁed Fischer Vector (3DmFV) representation
[4] to encode local geometry on a coarse multi-scale
grid. It outperforms state-of-the-art methods for nor-
mal vector estimation.
The main contributions of this paper are:

• A new normal estimation method for unstructured
3D point clouds based on mixture of experts and
scale prediction.

• A local point representation which can be used as

input to a CNN.

110112

Figure 1. Nesti-Net pipeline for normal estimation. For each point in a given point cloud, we compute a multi-scale point
statistics representation (MuPS). Then, a scale manager network is used to determine the optimal scale and uses the
corresponding expert sub-network to estimate the normal.

2. Related-work

2.1. Deep learning for unstructured 3D point clouds

The point cloud representation is challenging for
deep learning methods because it is both unstructured
and point-wise unordered. In addition, the number of
points in the point cloud is usually not constant. Sev-
eral methods were proposed to overcome these chal-
lenges. Voxel-based methods embed the point cloud
into a voxel grid but suﬀer from several accuracy-
complexity tradeoﬀs [16]. The PointNet approach
[20, 21] applies a symmetric, order-insensitive, func-
tion on a high-dimensional representation of individual
points. The Kd-Network [14] imposes a kd-tree struc-
ture on the points and uses it to learn shared weights
for nodes in the tree. The recently proposed 3DmFV [4]
represents the points by their deviation from a Gaus-
sian Mixture Model (GMM) whose Gaussians are uni-
formly positioned on a coarse grid.

In this paper, we propose a point-wise and multi-
scale variation of 3DmFV. Instead of generating a
structured representation for the entire point cloud, we
represent each point and its neighbors within several
scales.

2.2. Normal estimation

A classic method for normal estimation uses Princi-
pal Component Analysis (PCA) [12]. It ﬁrst speciﬁes
the neighbors within some scale, and then uses PCA
regression to estimate a tangent plane. Variants ﬁt-
ting local spherical surfaces [10] or jets [7] (truncated
Taylor expansion) were also proposed. To be robust to
noise, these methods usually choose a large-scale neigh-
borhood, leading them to smooth sharp features and

to fail in estimating normals near edges. Computing
the optimal neighborhood size can decrease the esti-
mation error [18] but requires the (usually unknown)
noise standard deviation value and a costly iterative
process to estimate the local curvature and additional
density parameters.

Other approaches rely on using Voronoi cells of point
clouds [2, 17, 9]. These methods are characterized by
robustness to sharp features but are sensitive to noise.
To overcome this challenge, Alliez et al.
[1] proposed
PCA-Voronoi approach to create cell sets which group
adjacent cells to provide some control over smoothness.
While many of these methods hold theoretical guaran-
tees on approximation and robustness, in practice they
rely on a preprocessing stage in the presence of strong
or unstructured noise in addition to a ﬁne-tuned set of
parameters.

A few deep learning approaches have been proposed
to estimate normal vectors from unstructured point
clouds. Boulch et al. proposed to transform local point
cloud patches into a 2D Hough space accumulator by
randomly selecting point triplets and voting for that
plane’s normal. Then, the normal is estimated from
the accumulator by designing explicit criteria [5] for bin
selection or, more recently, by training a 2D CNN [6] to
estimate it continuously as a regression problem. This
method does not fully utilize the 3D information since
it loses information during the transformation stage.
We reﬀer to this method as HoughCNN in the evalu-
ation section. A more recent method, PCPNnet [11],
uses a PointNet [20] architecture on local point neigh-
borhoods of multiple scales. It achieves good normal
estimation performance and has been extended to esti-
mating other surface properties. However, it processes

10113

the multi-scale point clouds jointly and does not select
an optimal scale. This type of architecture tends to
encourage averaging during training rather than spe-
cialization [13].

In this paper we propose a method that approxi-
mates the local normal vector using a point-wise, multi-
scale 3DmFV representation which serves as an input
to a deep 3D CNN architecture. In addition, we learn
the neighborhood size that minimizes the normal es-
timation error using a mixture of experts (MoE) [13],
which encourages specialization.

2.3. Representing point clouds using 3DmFV

The 3DmFV representation for point clouds [4]
achieved good results for point cloud classiﬁcation us-
ing a 3D CNN. See Section 3.1 for details. In this pa-
per we propose the Multi-scale Point Statistics (MuPS)
representation, which extends the 3DmFV and com-
putes a point-wise multi-scale 3DmFV.

with the GMM density is:

uλ(p) =

K

Xk=1

wkuk(p).

(2)

The 3DmFV uses a uniform GMM on a coarse
m × m × m 3D grid, where m is an adjustable parame-
ter usually chosen to be from m = 3 to 8. The weights
are set to be wk = 1
K , the standard deviation is set to
be σk = 1
m , and the covariance matrix to be Σk = σkI.
Although the parameters in GMMs are usually set us-
ing maximum likelihood estimation, here uniformity is
crucial for shared weight ﬁltering (convolutions).

The FV is expressed as the sum of normalized gra-
dients for each point pt. The 3DmFV is speciﬁed sim-
ilarly using additional symmetric functions, i.e. min
and max. They are symmetric in the sense proposed
in [20] and are therefore adequate for representing the
structureless and orderless set of points. Adding these
functions makes the representation more informative
and the associated classiﬁcation more accurate [4]:

3. Approach

T

The proposed method is outlined in Figure 1.

It
receives a 3D point cloud as input and consists of two
main stages. In the ﬁrst stage, we compute a multiscale
point representation, denoted MuPS. In the second
stage we feed it into a mixture-of-experts (MoE) CNN
architecture and estimate the normal at each point as
output. The stages are detailed below.

3.1. MuPS - Multi-scale point statistics

MuPS is a local multi-scale representation which
computes point statistics on a coarse Gaussian grid.
It builds on the well-known Fisher Vector (FV) [22],
and the recently proposed 3DmFV representation [4].
Therefore, we ﬁrst outline the FV and the 3DmFV,
and then continue to the MuPS representation and its
attractive properties.
FV and 3DmFV for 3D point clouds: Given
a set of T 3D points X = {pt ∈ R3, t = 1, ...T}
and a set of parameters for a K component GMM,
λ = {(wk, µk, Σk), k = 1, ...K}, where wk, µk, Σk are
the mixture weight, center, and covariance matrix of
the k-th Gaussian. The likelihood of a single 3D point
p associated with the k-th Gaussian density is

uk(p) =

1

(2π)D/2|Σk|1/2 exp(cid:26)−

1
2

(p − µk)′Σ−1

k (p − µk)(cid:27) .

(1)

Therefore, the likelihood of a single point associated

G X

F Vλ =

Lλ∇λ log uλ(pt),

Xt=1
t=1 Lλ∇λ log uλ(pt)(cid:12)(cid:12)(cid:12)λ=α,µ,σ
PT
maxt(Lλ∇λ log uλ(pt)|λ=α,µ,σ
mint(Lλ∇λ log uλ(pt))|λ=µ,σ

(3)

(4)




G X

3DmF Vλ = 


where Lλ is the square root of the inverse Fisher Infor-
mation Matrix, and the normalized gradients are:

T

G X

αk =

1
√wk

T

(γt(k) − wk),

Xt=1
γt(k)(cid:18) pt − µk
Xt=1
γt(k)(cid:20) (pt − µk)2

σ2
k

σk (cid:19) ,

− 1(cid:21) .

(5)

(6)

(7)

G X

µk =

1
√wk

G X

σk =

1

√2wk

T

Xt=1

Here, we follow [15] and ensure that uλ(x) is a valid dis-
tribution by changing the variable wk to αk to simplify
the gradient calculation using :

wk =

exp(αk)
j=1 exp(αj)

PK

.

(8)

In addition, γt(k) expresses the soft assignment of point
pt to Gaussian k, as obtained from the derivatives:

γt(k) =

wkuk(pt)
j=1 wjuj(pt)

PK

.

(9)

10114

The FV and 3DmFV are normalized by the number of
points in order to be sample-size independent [22]:

G X
F Vλ ←

1
T

G X
F Vλ , G X

3DmF Vλ ←

1
T

G X

3DmF Vλ .

(10)

Note that these are global representations which are
applied to the entire set, i.e., the entire point cloud.
MuPS deﬁnition : For each point p in point set X
we ﬁrst extract n point subsets ˜Xi(ri)|i=1,...n ⊂ X
which contain Ti(p, ri) points and lie within a distance
of radius ri from p. We refer to each of these subsets
as a scale. Note that each scale may contain a
diﬀerent number of points. For scales with many
points, we set a maximal point threshold, and sample
a random subset of Tmax points for that scale. Here,
ri and Tmax are design parameters. Next, the scales
(subsets) are independently translated and uniformly
scaled so that they ﬁt into a zero-centered unit sphere
with p mapped to the origin. Then, the 3DmFV
representation is computed for each scale relative to a
Gaussian grid positioned around the origin; see above.
Concatenating the 3DmFVs of all scales yields the
MuPS representation:

Scale manager 

Input: MuPS

3D Inception: [3, 5, 128]
3D Inception: [3, 5, 256]
3D Inception: [3, 5, 256]

maxpool [2, 2, 2]

3D Inception: [2, 4, 512]
3D Inception: [2, 4, 512]

maxpool [2, 2, 2]

3D Inception: [1, 2, 512]

maxpool [2, 2, 2]

FC [1024]
FC [256]
FC [128]

FC [n]
softmax
Output: qi

Expert 

Input: 

˜Xi(ri)
3DmF V

G
 

3D Inception: [3, 5, 128]
3D Inception: [3, 5, 256]

maxpool [2, 2, 2]

3D Inception: [2, 4, 256]

maxpool [2, 2, 2]

3D Inception: [2, 4, 512]

maxpool [2, 2, 2]

FC [512]
FC [128]
FC [64]
FC [3]

Output: Ni

3D Inception: [c1,  c2,  M]

Input: [m x m x m x L]

Avg. pool: 

CNN

Filter: [c1 x c1 x c1 ]

Channels: 1

Filter: [1x1x1]
Channels : M

CNN

CNN

CNN

Filter: [1x1x1]
Channels : M

Filter: [c1 x c1 x c1]

Filter: [c2 x c2 x c2]

Channels : M/2

Channels : M/2

Concatenate

Output: [m x m x m x 3N]

Figure 2. The mixture of experts and 3D Inception mod-
ule architecture details. The scale manager and experts
use several convolutional and maxpooling layers followed
by fully connected layers.

G p

M uP S = (cid:16)G

˜X1(r1)
3DmF V , ..., G

˜Xn(rn)

3DmF V(cid:17) .

(11)

MuPS properties: The MuPS representation overcomes
the main challenges associated with feeding point
clouds into CNNs. The symmetric functions make it
independent of the number and order of points within
each scale. In addition, the GMM gives it its grid struc-
ture, necessary for the use of CNNs. Furthermore, the
multi-scale representation incorporates description of
ﬁne detail as well as robustness to noise.

3.2. The Nesti-Net architecture

The deep network architecture is outlined in Fig-
ure 1 (the green part). It is a mixture-of-experts ar-
chitecture [13] which consists of two modules: a scale
manager network module, and an experts module. The
MoE architecture was chosen in order to overcome the
averaging eﬀect of typical networks when solving a re-
gression problem.
Scale manager network : This module receives the
MuPS representation as input and processes it using
several 3D Inception inspired convolutions, and max-
pool layers, followed by four fully connected layers, af-
ter which a softmax operator is applied. The architec-
ture is speciﬁed in the top left part of Figure 2. The
output is a vector of n scalars qi, which can be in-
tuitively interpreted as the probability of expert i to

estimate the normal correctly.
Experts: The normal is estimated using n separate ”ex-
pert” networks. Each is a multi-layered 3D Inception
inspired CNN followed by four fully connected layers.
The MuPS representation is distributed to the experts.
This distribution is a design choice. We obtained the
best results when feeding each scale to two diﬀerent ex-
perts in addition to one expert which receives the en-
tire MuPS representation as input. Speciﬁcally, Nesti-
Net uses 7 experts: experts 1-2 receive the smallest
scale (1%), 3-4 the medium scale (3%), 5-6 the large
scale (5%), and expert 7 receives all the scales. The
last layer of each expert outputs a three-element vec-
tor Ni = (Nx, Ny, Nz)i. The ﬁnal predicted normal
(for point p) is Nargmax(qi), i.e., the normal associated
with the expert expected to give the best results. The
architecture is speciﬁed in the top right of Figure 2.
Loss function: We train the network to minimize the
diﬀerence between a predicted normal Ni and a ground
truth normal NGT . This diﬀerence is quantiﬁed by the
metric DN = sin θ, where the angle θ is the diﬀerence
between the vectors, and DN is calculated as the mag-
nitude of the cross product between these two vectors;
see Eq. 12. In addition, to encourage specialization of
each expert network, we follow [13] and minimize the

10115

loss:

L =

n

Xi=1

qi · DN =

n

Xi=1

qi kNi × NGTk
kNik · kNGTk

.

(12)

Using this loss, each expert is rewarded for specializing
in a speciﬁc input type. Note that during training, all
n normal vectors are predicted and used to compute
the loss and derivatives. However, at test time, we
compute only one normal, which is associated with
the maximal qi.

4. Evaluation

4.1. Datasets

For training and testing we used the PCPNet shape
dataset [11]. The trainset consists of 8 shapes:
four
CAD objects (fandisk, boxunion, ﬂower, cup) and
four high quality scans of ﬁgurines (bunny, armadillo,
dragon and turtle). All shapes are given as triangle
meshes and densely sampled with 100k points. The
data is augmented by introducing Gaussian noise for
each point’s spacial location with a standard deviation
of 0.012, 0.006, 0.00125 w.r.t the bounding box. This
yields a set with 3.2M points and 3.2M corresponding
training examples. The test set consists of 22 shapes,
including ﬁgurines, CAD objects, and analytic shapes.
For evaluation we use the same 5000 point subset per
shape as in [11].

For qualitative testing on scanned data, we used the
NYU Depth V2 dataset [19] and the recent ScanNet
dataset [8], which include RGB-D images of indoor
scenes.

4.2. Training details

All variations of our method were trained using
32,768 (1024 samples×32 shapes) random subsets of
the 3.2M training samples at each epoch. For each
point, we extract 512 neighboring points enclosed
within a sphere of radius r. For neighborhoods with
more than 512 points, we perform random sampling,
and for those with fewer points we use the maximum
number of points available. For the MuPS represen-
taiton we chose to use an m = 8 Gaussian grid. We
used Tensorﬂow on a single NVIDIA Titan Xp GPU.

4.3. Normal estimation performance

We use the RMS normal estimation error metric for
comparing the proposed NestiNet to other deep learn-
ing based [11, 6] and geometric methods [12, 7]. We
also analyze robustness for two types of data corrup-
tions (augmentations):

• Gaussian noise - perturbing the points with three
levels of noise speciﬁed by σ, given as a percentage
of the bounding box.

• Density variation - selecting a subset of the points
based on two sampling regimes: gradient, simulat-
ing eﬀects of distance from the sensor, and stripes,
simulating occlusions.

For the geometric methods, we show results for three
diﬀerent scales: small, medium and large, which corre-
spond to 18, 112, 450 nearest neighbors. For the deep
learning based methods we show the results for the
single-scale (ss) and multi-scale (ms) versions. Addi-
tional evaluation results using other metrics are avail-
able in the supplemental material.

Table 1 shows the unoriented normal estimation re-
sults for the methods detailed above. It can be seen
that our method outperforms all other methods across
all noise levels and most density variations.
It also
shows that both PCA and Jet perform well for spe-
ciﬁc noise-scale pairs.
In addition, for PCPNet and
HoughCNN, using a multi-scale approach only mildly
improves performance.

Figure 3 illustrates Nesti-Net’s results on three point
clouds. For visualization, the normal vector is mapped
to the RGB cube.
It shows that for complex shapes
(pillar, liberty) with high noise levels, the general di-
rection of the normal vector is predicted correctly, but,
the ﬁne details and exact normal vector are not ob-
tained. For a basic shape (Boxysmooth) the added
noise does not aﬀect the results substantially. Most
notably, Nesti-Net shows robustness to point density
corruptions. The angular error in each point is visual-
ized in Figure 4 for the diﬀerent methods using a heat
map. For PCA and Jet we display the best result out
of the three scales (small, medium, and large, speciﬁed
above), and for PCPNet the best out of its single-scale
and multi-scale options. For all methods, it can be seen
that more errors occur near edges, corners and small
regions with a lot of detail and high curvature. Nesti-
Net suﬀers the least from this eﬀect due to its scale
manager, which allows it to adapt to the diﬀerent local
geometry types. Figure 5 shows the performance of
the scale manager network. A color is assigned to each
expert and the chosen expert color is visualized over the
point cloud. This provides some insight regarding each
expert’s specialization. For example, the ﬁgure shows
that experts 1, 2 (small scale) specialize in points in
regions with high curvatures (near corners). Experts 3
and 4 (medium scale) specialize in the complex cases
where multiple surfaces are close to each other, or in
the presence of noise. As for the large-scale experts,
expert 5 specializes in planar surfaces with normal vec-

10116

Our

Nesti-Net

PCA [12]

Jet [7]

PCPNet [11] HoughCNN [6]

ms
6.99

small med
8.31

large
12.29 16.77

small med
7.60

large
12.35 17.35

ss
9.68

ms
9.62

Aug.

scale
None
Noise

σ = 0.00125
σ = 0.006
σ = 0.012
Density
Gradient
Stripes
average

10.11
17.63
22.28

9.00
8.47
12.41

12.00 12.87 16.87 12.36 12.84 17.42
40.36 18.38 18.94 41.39 18.33 18.85
52.63
53.21 27.68 23.41

27.5

23.5

12.81 17.26 8.49 13.13
13.66 19.87

17.8
9.14
9.42
13.39 19.29
21.97 16.25 18.87 21.95 16.29 19.02

8.61

11.46
18.26
22.8

13.42
11.74
14.56

11.37
18.87
23.28

11.7
11.16
14.34

ss

10.23

11.62
22.66
33.39

11.02
12.47
16.9

ms

10.02

11.51
23.36
36.7

10.67
11.95
17.37

Table 1. Comparison of the RMS angle error for unoriented normal vector estimation of our Nesti-Net method to classic
geometric methods (PCA [12] , Jet [7]) with three scales, and deep learning methods (PCPNet [11], HoughCNN [6])

Figure 3. Nesti-Net normal prediction results for diﬀerent
noise levels (columns 1-4), and density distortions (columns
5-6). The colors of the points are normal vectors mapped to
RGB. This ﬁgure is best viewed digitally on a large screen.

tors, which have a large component in the x direction,
whereas expert 6 specializes in planar surfaces, which
have a large component in the y direction. Expert 5
also specializes in very noisy planar surfaces with a
large component in the z direction. Expert 7 (com-
bined scales) plays multiple roles; it handles points on
planar surfaces which have a large component in the z
direction, complex geometry, and low to medium noise.
Figure 6 shows the number of points assigned to each
expert for all points in the test set, and the average er-
ror per expert. It shows an inverse relation between the
number of points assigned to an expert and its average
error: the more points assigned to the expert, the lower
the error. This is consistent with the deﬁnition of the
cost function. Timing performance and visualization
of additional results are provided in the supplemental
material.

Figure 4. Normal estimation error results for Nesti-Net
compared to other methods for three types of point clouds
with low noise level (σ = 1%). The colors of the points cor-
respond to angular diﬀerence, mapped to a heatmap rang-
ing from 0-60 degrees; see bottom color bar. The number
under each point cloud is its RMS error.

4.4. Scale selection performance

We analyze the inﬂuence of scale selection on the
normal estimation performance. We create several ab-
lations of our method.

• ss - A single scale version which directly feeds a
3DmFV representation into a CNN architecture
(a single-scale MuPS).

• ms - A multi-scale version which feeds the MuPS

representation into a CNN architecture.

• ms-sw - A multi scale version which ﬁrst tries to

10117

Aug.

ss

scale

0.01 0.05

0.01
0.05

ms ms-sw NestiNet
0.01
0.03
0.05
6.99

0.01
0.05

0.01
0.05

7.88

7.76

None
Noise

9.32 12.73 10.83

10.29 10.11
18.45 17.63
22.25 22.28

σ = 0.00125 11.31 13.36 12.98 10.46
σ = 0.006
36.5 18.37 21.06 18.43
σ = 0.012 55.24 23.14 26.03 22.59
Density
Gradient
Stripes
average

16.61 14.65 12.81 11.89
14.5 14.57 12.97 10.06
23.91 16.14 16.11 13.55

9.44
9.00
9.65
8.47
12.97 12.41
Table 2. Comparison of the RMS angle error for unoriented
normal vector estimation of our method using single-scale
(SS), multi-scale (MS), multi-scale with switching (MS-Sw
and multi-scale with mixture of experts (Nesti-Net)

unsupervised, i.e., does not need the additional noise
parameters as input during training.

4.5. Results on scanned data

We show qualitative results on scanned point clouds
from the ScanNet [8] and NYU Depth V2 [19] datasets
in Figure 7. For visualization we project the normal
vectors’ color back to the depth image plane. column
(c) shows the results for Nesti-Net, trained on synthetic
data with Gaussian noise. The estimated normals re-
veal the nonsmoothness of the scanned data associ-
ated with the correlated, non-Gaussian, noise signa-
ture associated with the scanning process. Essentially
it shows normal estimation of the raw data, rather than
the desired normal of the underlying surface. The raw
point clouds suﬀer from ”bumps” which get bigger as
the distance from the sensor increases. Further im-
provement may be obtained by training Nesti-Net on
data corrupted with scanner noise and with ground
truth normals, but such data is is currently not avail-
able and is diﬃcult to manually label. Instead, we train
Nesti-Net with normal vectors obtained from applying
a Total Variation (TV) algorithm on the depth map,
provided by Ladicky et al. [23] for the NYU depth V2
dataset. Note that TV substantially smooths ﬁne de-
tail and uses the depth image rather than unstructured
point clouds. Column (d) in Figure 7 shows that after
training on the TV data, the normal vector estimation
of the underlying surface improves signiﬁcantly. Col-
umn (b) shows the results of PCA with a medium scale
for reference, for small radius, the result is signiﬁcantly
noisier and for large radius it over-smooths detail, see
supplemental material. Note that Nesti-Net performs
the estimation on the raw point cloud and does not use
the depth image grid structure.

10118

Figure 5. Nesti-Net predicted experts (scales). Each color
represents the predicted expert for optimal normal estima-
tion. Color coding is given at the bottom.

Figure 6. Nesti-Net expert (scale) prediction statistics.
Number of points assigned to each expert (left), and av-
erage expert error (right).

estimate the noise level and then feeds the 3DmFV
representation of the corresponding input scale
into diﬀerent sub-networks for a discrete number
of noise levels (switching). Note that for this ver-
sion, the noise level is provided during training.

• NestiNet - The method described in Section 3

which uses an MoE network to learn the scale.

Details of the architectures for the above methods are
provided in the supplemental material.

Table 2 summarizes the results of the scale selec-
tion performance analysis.
It shows that Nesti-Net’s
scale selection performs better than all other varia-
tions. This is due to the trained scale-manager network
within the MoE. The single-scale version performs well
for speciﬁc noise-scale pairs but inferior performance
for an inadequate scale selection. The multi-scale varia-
tions show improvement; however, selecting the correct
scale yields improved performance over concatenating
multiple scales. The main advantage of Nesti-Net over
the switching variation is that the scale prediction is

Figure 7. Normal estimation results on scanned point clouds
from the ScanNet [8] (top), and NYU Depth V2 dataset [19]
(bottom). (a) RGB image, (b) PCA results using a medium
scale, (c) Nesti-Net results trained on synthetic data (d)
Nesti-net results trained on TV algorithm data.

5. Summary

In this work, we propose multi-scale point statistics,
a new representation for 3D point clouds that encodes
ﬁne and coarse details while using a grid structure. The
representation is eﬀective processed by a CNN archi-
tecture (Nesti-Net) for provide accurate normal estima-
tion, which can be used for various applications, e.g.
surface reconstruction. The mixture-of-experts design
of the architecture enables the prediction of an optimal
local scale and provides insights into the network’s re-
source distribution. The proposed representation and
architecture achieve state-of-the-art results relative to
all other methods and demonstrate robustness to noise
and occlusion data corruptions.

6. Acknowledegment

We gratefully acknowledge the support of NVIDIA
Corporation with the donation of the Titan Xp GPU
used for this research.

References

[1] P. Alliez, D. Cohen-Steiner, Y. Tong, and M. Desbrun.
Voronoi-based variational reconstruction of unoriented
point sets.
In Symposium on Geometry Processing,
volume 7, pages 39–48, 2007.

[2] N. Amenta and M. Bern. Surface reconstruction by
voronoi ﬁltering. Discrete & Computational Geometry,
22(4):481–504, 1999.

[3] Y. Ben-Shabat, T. Avraham, M. Lindenbaum, and
A. Fischer. Graph based over-segmentation methods
for 3d point clouds. Computer Vision and Image Un-
derstanding, 2018.

[4] Y. Ben-Shabat, M. Lindenbaum, and A. Fischer.
3dmfv: Three-dimensional point cloud classiﬁcation in
real-time using convolutional neural networks. IEEE
Robotics and Automation Letters, 3(4):3145–3152,
2018.

[5] A. Boulch and R. Marlet. Fast and robust normal
estimation for point clouds with sharp features.
In
Computer Graphics Forum, volume 31, pages 1765–
1774. Wiley Online Library, 2012.

[6] A. Boulch and R. Marlet. Deep learning for robust
normal estimation in unstructured point clouds. Com-
puter Graphics Forum, 35(5):281–290, 2016.

[7] F. Cazals and M. Pouget. Estimating diﬀerential quan-
tities using polynomial ﬁtting of osculating jets. Com-
puter Aided Geometric Design, 22(2):121–146, 2005.

[8] A. Dai, A. X. Chang, M. Savva, M. Halber, T. A.
Funkhouser, and M. Nießner.
Scannet: Richly-
annotated 3d reconstructions of indoor scenes. In The
IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), volume 2, page 10, 2017.

[9] T. K. Dey and S. Goswami. Provable surface recon-
struction from noisy samples. Computational Geome-
try, 35(1-2):124–141, 2006.

[10] G. Guennebaud and M. Gross. Algebraic point set
surfaces. ACM Transactions on Graphics (TOG),
26(3):23, 2007.

[11] P. Guerrero, Y. Kleiman, M. Ovsjanikov, and N. J.
Mitra. Pcpnet learning local shape properties from raw
point clouds. Computer Graphics Forum, 37(2):75–85,
2018.

[12] H. Hoppe, T. DeRose, T. Duchampt, J. McDonald,
and W. Stuetzle. Surface reconstruction from unorga-
nized points. Computer Graphics, 26:2, 1992.

[13] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E.
Hinton. Adaptive mixtures of local experts. Neural
Computation, 3(1):79–87, 1991.

[14] R. Klokov and V. Lempitsky. Escape from cells: Deep
kd-networks for the recognition of 3d point cloud mod-
els. In The IEEE International Conference on Com-
puter Vision (ICCV), pages 863–872, Oct 2017.

[15] J. Krapac, J. Verbeek, and F. Jurie. Modeling spatial
layout with ﬁsher vectors for image categorization. In
The IEEE International Conference on Computer Vi-
sion (ICCV), pages 1487–1494. IEEE, 2011.

[16] D. Maturana and S. Scherer. Voxnet: A 3d convo-
lutional neural network for real-time object recogni-
tion.
In IEEE/RSJ International Conference on In-
telligent Robots and Systems (IROS), pages 922–928.
IEEE, 2015.

[17] Q. M´erigot, M. Ovsjanikov, and L. J. Guibas. Voronoi-
based curvature and feature estimation from point
clouds. IEEE Transactions on Visualization and Com-
puter Graphics, 17(6):743–756, 2011.

[18] N. J. Mitra and A. Nguyen. Estimating surface nor-
mals in noisy point cloud data. In Proceedings of the
Nineteenth Annual Symposium on Computational ge-
ometry, pages 322–328. ACM, 2003.

[19] P. K. Nathan Silberman, Derek Hoiem and R. Fer-
gus. Indoor segmentation and support inference from
RGBD images. In European Conference on Computer
Vision (ECCV), pages 746–760, 2012.

10119

[20] C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet:
Deep learning on point sets for 3d classiﬁcation and
segmentation. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), July 2017.

[21] C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++:
Deep hierarchical feature learning on point sets in a
metric space. arXiv preprint arXiv:1706.02413, 2017.
[22] J. S´anchez, F. Perronnin, T. Mensink, and J. Verbeek.
Image classiﬁcation with the ﬁsher vector: Theory and
practice. International Journal of Computer Vision,
105(3):222–245, 2013.

[23] B. Zeisl, M. Pollefeys, et al. Discriminatively trained
dense surface normal estimation.
In European con-
ference on computer vision, pages 468–484. Springer,
2014.

10120

