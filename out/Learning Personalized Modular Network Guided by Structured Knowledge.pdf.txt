Learning Personalized Modular Network Guided by Structured Knowledge

Xiaodan Liang

Sun Yat-sen University

xdliang328@gmail.com

Abstract

The dominant deep learning approaches use a "one-size-
ﬁts-all" paradigm with the hope that underlying characteris-
tics of diverse inputs can be captured via a ﬁxed structure.
They also overlook the importance of explicitly modeling
feature hierarchy. However, complex real-world tasks of-
ten require discovering diverse reasoning paths for differ-
ent inputs to achieve satisfying predictions, especially for
challenging large-scale recognition tasks with complex label
relations. In this paper, we treat the structured commonsense
knowledge (e.g. concept hierarchy) as the guidance of cus-
tomizing more powerful and explainable network structures
for distinct inputs, leading to dynamic and individualized
inference paths. Give an off-the-shelf large network conﬁgu-
ration, the proposed Personalized Modular Network (PMN)
is learned by selectively activating a sequence of network
modules where each of them is designated to recognize par-
ticular levels of structured knowledge. Learning semantic
conﬁgurations and activation of modules to align well with
structured knowledge can be regarded as a decision-making
procedure, which is solved by a new graph-based reinforce-
ment learning algorithm. Experiments on three semantic
segmentation tasks and classiﬁcation tasks show our PMN
can achieve superior performance with the reduced num-
ber of network modules while discovering personalized and
explainable module conﬁgurations for each input.

1. Introduction

Recent successes of deep neural networks in common
tasks [12, 19, 8] have been accompanied by the increas-
ingly complex and deep network architectures tailored for
each task. Most existing works follow the “one-size-ﬁts-
all" paradigm and hope that all relationships between inputs
and targets can be learned via implicit feature propagation
along with the ﬁxed network routine, regardless of whether
the inputs are too easy or difﬁcult for the network capac-
ity. However, different examples actually need specialized
network structures or feature propagation routines with re-
spect to their distinct complexities and speciﬁc targets. This

can be well motivated by the feature visualization study
in [27] where interpretable feature hierarchy can be learned
in current neural networks. For example, in terms of image
recognition, for easy images (e.g. most common dog), net-
work compression [22, 36, 34] can be pursued by pruning
some redundant network modules. In contrast, for difﬁcult
images (e.g. rare concepts, such as violin), more sophisti-
cated structures or external constraints [39, 30, 7] should
be exploited to improve the model capability. The varying
requirement of the model complexity by different instances
indicates the potential beneﬁts of dynamic networks, where
most appropriate and explainable network structures can be
discovered for different inputs.

Some existing input-dependent networks [36, 23] are
mainly designed for compressing networks by dynamically
executing different modules of a network model. However,
their learned policies for selecting speciﬁc modules are solely
driven by the ﬁnal reward (i.e. classiﬁcation accuracy). Such
policy learning lacks the essential structure interpretability
to explain why a particular module is activated and results
in heavy exploration cost to ﬁnd an optimal selection se-
quence. On the contrary, an important merit of the human
perception system [29] is its ability to adaptively allocate
time and inspection for visual recognition and exploit ex-
ternal knowledge for better decision-making. For example,
at the ﬁrst single glimpse, it is sufﬁcient to recognize some
coarse classes (e.g. animals, human or scenes). Based on this
impression, more time and attention are devoted to further
understand among ﬁne-grained concepts (e.g. cat or dogs)
by associating their characteristics with those of semantic
correlated concepts (e.g. parents in concept hierarchy).

To mimic this dynamic reasoning system, we propose to
learn dynamic module conﬁgurations to infer personalized
reasoning paths for each input, named as Personalized Mod-
ular Network (PMN), as shown in Figure 1. Moreover, it is
beneﬁcial to bridge visual feature hierarchy with common-
sense human knowledge which can be formed as various
undirected graphs consisting of rich relationships among
concepts. For example, “Shetland Sheepdog" and “Husky"
share one superclass “dog" due to some common character-
istics. Beyond only inferring the binary selection of each

18944

Basic	Network	
Structure

Structured	Knowledge

Graph

Conv.

module

module

module

module

module

module

…

module

object

person

Sports-things

PMNs

plain mountain whole

baby girl woman male

ball glove frisbee skis

Conv.

module

module

module

module

module

module

…

module

table-things

food-things

kitchen-things

desk

table diningtable

sandwich pizza cake salad

cutlery

cup plate bottle

Figure 1. Our PMN aims to learn different module computations for each input and each module is designated to recognize concepts of
distinct knowledge levels (e.g. object or person), given a basic network structure and the prior structured knowledge.

module as previous works did, our PMN aims to further
determine which particular levels of structured knowledge
each module is capable enough to infer, and reconﬁgure
the selected modules to make them semantic coherent with
structured knowledge.

Learning to sequentially select modules for addressing
particular levels of knowledge can be formulated as a se-
quential decision-making procedure. We propose a new
graph-based reinforcement learning algorithm, which speci-
ﬁes varying knowledge level set as the particular action space
for each network module, driven by a graph search function
over structured knowledge. Particularly, the action space of
each network module is contains the ﬁner-levels of knowl-
edge (e.g cat or dog) relative to activated levels (e.g. animals)
by former modules, which enforces early modules character-
ize easy knowledge while later modules with more feature
abstraction are responsible for more ﬁne-grained knowledge.
Taking features produced by the module for each image as in-
puts, a recurrent policy network is learned to reason over the
evolved action space. And the reward function is designed to
encourage both early-stopping the network propagation and
obtaining higher recognition accuracy for balancing both
efﬁciency and accuracy.

We demonstrate the superior performance achieved by our
PMN on three segmentation tasks (COCO-Stuff, PASCAL-
Context, and ADE20k) and two classiﬁcation tasks (CIFAR-
10 and CIFAR-100). More interestingly, our PMN discovers
meaningful patterns of module conﬁgurations for different
images, and also reduce the number of activated modules for
easy samples to obtain good computation efﬁciency.

2. Related Work

Instance-speciﬁc Computation. Conditional compu-
tation methods have been proposed to dynamically exe-
cute different modules of a network speciﬁed for each
instance [4, 3, 36]. Learning with reinforcement learn-
ing [3, 23, 10], sparse activations are usually estimated to
selectively turn on and off a subset of modules based on
the input. Their rewards driven only by ﬁnal accuracy are

accumulated after a sequence of decisions computed after
each layer, resulting in overhead policy execution. In con-
trast, our PMN introduces the structured knowledge graph
to guide module selections for reaching good interpretabil-
ity, and a new graph-based reinforcement learning is pro-
posed to evolve action space for each module. Moreover, the
graph-based reinforcement learning also makes all routing
decisions in a single step for reducing overhead cost and
computations. Most recently, Liang et al. [20] explicitly
incorporate concept hierarchy into network construction by
adding more modules upon the basic network, leading to
heavier computation. On the contrary, our PMN fully ex-
ploits the capability of existing module in characterizing
different concepts, which can selectively reduce the module
usage for easy examples or reconﬁgure outputs of modules
for difﬁcult examples.

Dynamic feature computation in vision and NLP ap-
plications. Dynamic feature computation has also been ex-
plored in vision and natural language applications [6, 32, 15],
actively deciding which frames, regions or text entity mod-
ules to execute. There also exists some early prediction
models, a type of conditional computation models that exit
once a criterion is satisﬁed at early layers. BranchyNet [35]
is composed of branches at each layer to make early clas-
siﬁcation decisions. Figurnov et al. [11] apply Adaptive
Computation Time (ACT) to each spatial position of multi-
ple image blocks. This method identiﬁes instance-speciﬁc
ResNet conﬁgurations, but only allows conﬁgurations that
use early and contiguous blocks. Instead, our PMN allows
different semantic conﬁgurations of modules towards align-
ing with structured knowledge. Our approach, posed as the
general dynamic network learning, can be easily incorpo-
rated for these downstream tasks.

3. Approach

We now present the proposed Personalized Modular Net-
works (PMN). As illustrated in Figure 2, given an input x,
our PMN is to ﬁnd the best semantic conﬁgurations of a min-
imum number of modules in one predeﬁned network, such

8945

policy	network

policy	network

policy	network

policy	network

…

…

module

module

…

module

module

module

module

module

prediction

Weighted	prediction

module

prediction

Weighted	prediction

Graph	
search

Graph	
search

Graph	
search

…

module

prediction

Weighted	prediction

Expected	gradients	for	all	actions

Reward

Cross-entropy	loss

Avg prediction

module Activated	module

Early-stop

Selections	of	knowledge	levels

Keep	action

Hidden	states

Figure 2. Personalized Modular Networks (PMN) which discovers dynamic module conﬁgurations for each input via a graph-based
reinforcement learning. The features of each module are passed a recurrent policy network to produce probabilities of early-stop action and
selections of adaptive knowledge levels which are determined by a graph searching function. Features from activated modules are then
passed through a prediction network to obtain ﬁnal predictions, which are then softly weighted by selections of knowledge levels. Finally,
expected gradients are back-propagated through all actions based on a reward function.

that each selected module can be designated to characterize
speciﬁc levels of structured knowledge. Treating the task
of ﬁnding this conﬁguration as a search problem becomes
intractable for deeper models as the number of potential con-
ﬁgurations grows exponentially with the number of modules,
and it is non-trivial to directly adopt a supervised learning
framework. We thus propose a graph-based reinforcement
learning to derive optimal module conﬁgurations, which
speciﬁes evolving action space for each module following
structured knowledge.

3.1. Structured Knowledge Graph

Here, we explore the semantic concept graph as one kind
of external structured knowledge , formulated as G =<
N , E >, where N consists of all concepts {ni} in a prede-
ﬁned knowledge graph and each graph edge (ni, nj) indi-
cates ni (e.g. chair) is the parent concept of nj (e.g. arm-
chair). Our PMN thus learns to conﬁgure the most appro-
priate knowledge levels to be recognized given a speciﬁc
module by searching over a group of parent concepts (e.g
chair) that has at least two child concepts within N . The
available knowledge level set (action set) for each module
is thus equal to the number of parent concepts. The action
selection of each module is a multi-classiﬁcation problem as
multiple levels of structured knowledge can be characterized
in the same module when the extracted features have enough
discriminative capability.

3.2. Graph based Reinforcement Learning

Action Space. Given a network structure S, we regard
network layers/blocks as the set of conﬁgurable modules
1 ∈ S. Taking ResNets [12] as the example, each
{sk}K
residual block that is bypassed by identity skip-connections
is one module. The conﬁgurations of {sk}K
1 ∈ S indicate
taking actions to each module sk, including early-stop action
Tk, keep action Dk or knowledge level selections ak among
a set of available parent concepts Ωk = {n1,k, . . . , nMk,k}
shown as yellow boxes in Figure 3. Speciﬁcally, the early-
stop action corresponds to early-stopping network execution
if extracted features are enough to make predictions; the keep
action just propagates over this module as normal networks;
the knowledge-level selection action indicates selecting a
subset of parent nodes to enforce this module to recognize
their children concepts.

Recurrent Policy Network. We develop a recurrent pol-
icy network to produce actions for each module. First, a bi-
nary policy vector is estimated to indicate early-stop or con-
tinue; if continue, a multi-choice policy vector is estimated
where knowledge levels with larger than 0.5 probabilities are
selected while a keep action is selected if none of the levels is
activated. Unlike standard reinforcement learning, we train
the policy to predict all actions of all modules at once. This
is essentially a Markov Decision Process (MDP) given the
input state and can also be viewed as contextual bandit [18]
or associative reinforcement learning [33]. Formally, we
denote the recurrent policy network as FW parameterized by
the weights W. FW sequentially predicts probabilities of all

8946

actions, so that we can sample actions following the graph
hierarchy routine. FW takes the features xk produced by
each module sk and the updated hidden states hk−1 from the
previous module sk−1 as inputs, and outputs the probabili-
ties for one-dim early-stop action Tk and Mk-dim actions in
knowledge level set Ωk. For each module sk, we ﬁrst sample
its early-stop action Tk from one-dim Bernoulli distribution:

qk = FW(x, hk−1),

πW(Tk|x, hk−1) = qTk

k (1 − qk)1−Tk ,

(1)

(2)

where qk is its action probability after a Sigmoid function.
Tk = 0 and Tk = 1 indicate network computation is early-
stopped at the module sk or continues respectively. If Tk =
1, we then deﬁne a policy of modular conﬁguration ak as a
Mk-dimensional Bernoulli distribution:

Ωk = φ(G, {a1, . . . , ak−1}),
pk = FW(x, hk−1, Ωk),

πW(ak|x, Ωk, hk−1) =

Mk

Y

j=1

p

ak,j
k,j (1 − pk,j)1−ak,j ,

(3)
(4)

(5)

where the available knowledge level set Ωk is obtained by the
graph search functioning φ that takes the whole knowledge
graph G and action histories {a1, . . . , ak−1} of previous
modules as inputs. The j-th entry of the vector pk ∈ [0, 1]
represents the likelihood of its corresponding knowledge
level nk,j being activated in this module. The action ak ∈
{0, 1} is selected based on pk. Here, ak,j = 1 and ak,j = 0
indicate this module is responsible for recognizing the child
categories (e.g. cat,dog) for the j-th knowledge level (e.g.
animal) or not, respectively. If Pj ak,j = 0 that indicates
none of levels is activated, then keep action Dk is selected
for this module by treating it as a normal block.

Graph Searching Function. Given a action history
{a1, . . . , ak−1} of previous modules and the whole graph
G, the graph searching function φ(·) ﬁnds an evolved action
space Ωk, as illustrated in Figure 3. Intuitively, we encour-
age coarse knowledge levels (e.g. animals) are recognized
earlier than more ﬁne-grained levels (e.g. mammal) since
categories in more ﬁne-grained levels require features with
more powerful discriminative capabilities in deeper layers. It
is noteworthy that not all modules will recognize knowledge
levels. Thus, given actions {a1, . . . , ak−1} where some of
them may be empty, we denote their accumulated activated
knowledge levels Ω′
k, that is, a list of graph nodes are ac-
tivated. We thus expand Ω′
k into Ωk by bringing in the
2-hop children nodes of activated graph nodes following G.
This graph searching function has several merits: a) each
module is also encouraged to recognize knowledge levels
that are already addressed in previous modules. Its under-
lying motivation is that we allow the ﬂexibility for the case
that later modules have superior recognition capability with

more powerful features; b) new ﬁne-grained knowledge lev-
els are made available for a later module to enforce it embed
more elaborated semantics; c) the inclusion of 2-hop chil-
dren nodes (children and their children) of activated nodes
will allow skipping over some useless intermediate nodes
in a deeper graph, rather than strictly only activating their
immediate children.

Reward Function. We only consider knowledge-level
actions before the early-stopping action Tm = 0 happens
at m-th module, to encourage both correct predictions and
minimal module usage, the reward function is computed
based on all non-empty actions a′ in a = {ak}:

ˆY =

1
|a′| X

β(ak)FΦ(sk),

R(a, T) = λ(1 − (

)2) + A( ˆY, Y),

ak∈a′
m
K

(6)

(7)

where ˆY indicates ﬁnal predictions by averaging the
weighted predictions β(ak)FΦ(sk) of each module sk.
FΦ(·) is a linear layer for the classiﬁcation task or a con-
volution layer for semantic segmentation task, which takes
features of each module as inputs and outputs predictions for
|N | concepts in the graph G. β(ak) outputs distinct weights
for each nodes conditioned on ak, that is, 1 for concepts
under activated knowledge levels and 0.8 for other concepts.
Each selected module is thus able to contribute to recognize
for all concepts and just gives higher conﬁdences about chil-
dren concept predictions of its assigned knowledge levels.
A( ˆY, Y) is the accuracy function between the prediction ˆY
and groundtruth Y. Here, ( m
K )2 measures the percentage of
module utility. A higher reward will be given to the policy
that uses less modules and achieves higher accuracy. The
hyper-parameter λ controls the trade-off between efﬁciency
(module usage) and accuracy.

Thus, our PMN works as follows: the recurrent policy net-
work FW decides which knowledge levels are selected for
predictions for each module and which module to early-stop
network computation. The prediction is generated by run-
ning the prediction network FΦ, conditioning on predicted
actions.

3.3. Personalized Modular Network Optimization

To learn the optimal parameters W of the policy network

FW, we maximize the expected reward:

J = E{T,a}∼πW [R(a, T)].

(8)

We utilize policy gradient [33] to compute the gradients

of J:

∇WJ = E[R(a, T)∇W(log πW(Tk, ak|x, Ωk, hk−1)],

(9)

8947

Structured	Knowledge	Graph

artifact

object

whole

ocean

produce

cloud

Edible
fruit

vegetable

covering

structure

instument

conveyance

organism

vehicle

…

Vascular

plant

animal

person

mush
room

sweet
pepper

…

man

Male
child

Entity

Ω":

&"

Ω$:

&$

Ω%:

&%:
…

Graph	Search	Function

Entity

object

produce

object

artifact

whole

organism

structure

instrument

covering

organism

instrument

Vascular

plant

animal

person

man

conveyance

vehicle

man

vehicle

Figure 3. Graph search function which outputs an available knowledge level set Ωk (i.e. parent concepts), conditioning on activated concepts
ak−1 and structured knowledge G.

We approximate the expected gradient in Eqn. 9 with Monte-
Carlo sampling using all samples in a mini-batch. These
gradient estimates are unbiased, but exhibit high variance.
To reduce variance, we utilize a self-critical baseline R(˜a, ˜T)
as in [28] and rewrite Eqn. 9 as:

∇WJ = E[B∇W(log πW(Tk, ak|x, Ωk, hk−1)],

(10)

where B = R(a, T) − R(˜a, ˜T), and ˜a and ˜T are deﬁned
as the maximally probable conﬁguration under the current
policy, e.g., ˜ak,j = 1 if pk,j > 0.5 and otherwise ˜ak,j = 0.
We further encourage exploration by introducing a parameter
α to bound the probability distribution q = {qk} and p =
{pk} and prevent it from saturating, by creating a modiﬁed
distribution q′ and p′:

q′ = α · q + (1 − α) · (1 − q)
p′ = α · p + (1 − α) · (1 − p).

(11)
(12)

This bounds the distribution in the range 1 − α ≤ p′ ≤ α
and 1 − α ≤ q′ ≤ α. Policy gradient methods are typically
extremely sensitive to their initialization. We thus ﬁrst pre-
train the prediction network FΦ using standard supervised
learning with cross-entropy loss. Then recurrent policy net-
work Fr and prediction network FΦ are jointly optimized.
The parameters of the prediction network FΦ are trained
with the cross-entropy loss L( ˆY, Y) over prediction ˆY and
the groundtruth Y.

4. Experiments

The proposed PMN is generally applicable to various
applications. Here we choose the popular image recognition-
related tasks as the running examples to validate its superior-
ity. Experiments are conducted on both semantic segmenta-
tion tasks on Coco-Stuff [5], Pascal-Context dataset [26] and
ADE20K dataset [40], and image-level classiﬁcation task on
CIFAR-10 and CIFAR-100 [17].

Method

FCN [25]

DeepLabv2 (ResNet-101) [8]

DAG RNN + CRF [31]
OHE + DC + FCN [14]

DSSPN (ResNet-101) [20]

Fixed (16/26)

Random (16/26)
Distribute (16/26)

Policy (18/26)

Policy-adaptive (18/26)

Our PMN (16/26)

Class acc. acc. mean IoU

38.5
45.5
42.8
45.8
47.0

43.3
44.1
45.1
46.2
46.3
48.1

60.4
65.1
63.0
66.6
68.5

64.1
64.7
64.9
65.7
66.1
69.9

27.2
34.4
31.2
34.3
36.2

30.9
31.5
31.4
34.9
35.8
38.4

Table 1. Comparison on Coco-Stuff test set (%). All our models
are based on ResNet-101. “(16/26)" means using 16 modules on
average for all test images, compared 26 modules in full ResNet-
101.

4.1. Semantic Segmentation

Dataset. We focus on the dense prediction tasks on
three public datasets that all aim at recognizing over large-
scale categories, which poses more realistic challenges than
other small segmentation sets. Speciﬁcally, Coco-Stuff
dataset [5] contains 10,000 complex images from COCO
with dense annotations of 91 thing (e.g. book, clock, vase)
and 91 stuff classes (e.g. ﬂower, wood, clouds), where
9,000 images are for training and 1,000 for testing. ADE20k
dataset [40] is annotated with 150 semantic concepts, and
includes 20,210 images for training and 2,000 for valida-
tion. PASCAL-Context dataset [26] consists of 59 object
classes and one background, which has 4,998 images for
training and 5105 for testing. We use standard evaluation
metrics of pixel accuracy (pixAcc) and mean Intersection of
Union (mIoU).

Network details. We conduct our experiments using Py-
torch framework, 2 GTX TITAN X 12GB cards on a single

8948

Method

mean IoU

Method

mean IoU pixel acc.

FCN [25]

CRF-RNN [39]
ParseNet [24]
BoxSup [9]
HO CRF [1]
Piecewise [21]
VeryDeep [37]
DeepLab-v2 [8]

Our PMN (14/26)

37.8
39.3
40.4
40.5
41.3
43.3
44.5
45.7

46.8

Table 2. Comparison on PASCAL-Context test set(%). “(14/26)"
means using 14 modules on average for all test images, compared
26 modules in full ResNet-101.

server. We use the Imagenet-pretrained ResNet-101 [12]
networks as our pre-deﬁned network architecture following
the procedure of [8] and employ output stride = 8 to give
ﬁnal prediction. Given basic ResNet-101 organized into four
segments (i.e., [3, 4, 23, 3]), we treat the later 23 residual
blocks and 3 residual blocks as conﬁgurable modules, result-
ing in 26 modules in total that our PMN needs to infer over.
Note that features from 3-th ConvBlock and 4-th ConvBlock
are with 512-dim and 2048-dim, respectively. In order to
employ a recurrent policy, the 2048-dim features from 4-th
ConvBlock are ﬁrst transformed into 512-dim using a lin-
ear layer and ReLU layer. The features of each module are
passed into global average pooling layer to obtain a 512-
dim vector and then fed into the recurrent policy network.
Our policy network FW stacks a LSTM [13] with 512 hid-
den units and a linear layer that outputs the probabilities of
the maximum number of parent concepts and the early-stop
action. FW then samples actions for both early-stop and
knowledge-level selection actions in an autoregressive fash-
ion: the hidden states for decoding actions in the previous
step are fed as inputs into the next step. At the ﬁrst step, FW
receives an empty embedding as input. Due to the usage
of graph searching function, only probabilities of activated
action space will be used for each module. We employ a
shared Atrous Spatial Pyramid Pooling (ASSP) [8] module
with pyramids of {6,12,18,24} to obtain pixel-wise predic-
tions from 512-dim features for each activated module. Final
pixel-wise predictions are produced by averaging weighted
predictions from activated modules with their speciﬁc atten-
tive knowledge levels, as described in Section 3.2. We set
α to 0.8. In terms of reward function, we empirically set
λ as 0.5 to balance the strengths of module usage term and
prediction accuracy term, and A( ˆY, Y) is computed as the
pixel accuracy metric.

Structured knowledge construction.

In all experi-
ments, a general structured knowledge graph (i.e. con-
cept hierarchy) is employed by combining labels from three
datasets, following [20]. Starting from the label hierarchy

SegNet [2]

DilatedNet [38]

DeepLabv2 (ResNet-101) [8]
DSSPN (ResNet-101) [20]

21.64
32.31
38.97
43.03

71.00
73.55
79.01
81.21

Our PMN (19/26)
Table 3. Comparison on ADE20K val set(%).

43.80

81.33

Method

mean IoU

PMN w/o overlap (13/26)

PMN (1-hop children) (22/26)
PMN w/o weighting (16/26)

Our PMN (16/26)

35.5
38.1
37.6

38.4

Table 4. More ablation studies for our graph search function on
Coco-Stuff dataset.

of COCO-Stuff [5] that includes 182 concepts and 26 super-
classes, we manually merge concepts from the rest two
dataset together by using WordTree as [20]. It results in
340 concepts in the ﬁnal concept hierarchical graph and its
maximal graph depth is twelve.

Training details. We ﬁx the moving means and varia-
tions in batch normalization layers of ResNet-101 during
ﬁnetuning. We optimize the objective function with respect
to the weights at all layers by the standard SGD procedure.
Inspired by [8], we use the “poly" learning rate policy and
set the base learning rate to 2.5e-3 for newly initialized lay-
ers and power to 0.9, and set the learning rate as 2.5e-4 for
pretrained layers. Our learning procedure has two steps: ﬁrst
pretrain network for 20 epochs by directly appending the
ASPP prediction layer on the ﬁnal block to get good parame-
ter initialization of prediction networks; then jointly train the
policy network and prediction network of the whole PMN
for 40 epochs on Coco-Stuff and PASCAL-Context, and 100
epochs for ADE20K dataset. Momentum and weight decay
are set to 0.9 and 0.0001 respectively. For data augmentation,
we adopt random ﬂipping, random cropping and random re-
size between 0.5 and 2 for all datasets. Due to the GPU
memory limitation, the batch size is used 4. The input crop
size is set as 513 × 513 for all datasets. During testing, the
actions are selected when its probability is larger than 0.5,
different from the Bernoulli sampling used during training.

4.1.1 Comparison with the state-of-the-arts

Table 1, 2, 3 report the result comparison with recent state-of-
the-art segmentation models on Coco-Stuff, Pascal-Context
and ADE20K dataset, respectively. We regard “DeepLabv2
(ResNet-101) [8]" as our fair baseline. Our PMN can achieve
superior performance with less modular usages on all three
datasets, which demonstrates the effectiveness of inferring

8949

Input

Activated	Knowledge	Levels	(k-th module)

Groundtruth

DeeplabV2

Our	PMNs

Input

Groundtruth

DeeplabV2

Our	PMNs

Organism

Person

Artifact

Building-stuff

Plant-stuff

Organism

2

4

4

5

6

2

Tree

Structure

Sports-things

Ground-stuff

Person

13

way

motorvehicle

indoorthings

Plant-stuff

Signal

4

10

8

15

Sky-stuff

Wall-stuff

woodyplant

7

7

10

8

9

6

6

8

(12/26)

(15/26)

Figure 4. Qualitative comparison results of our PMN with the baseline Deeplabv2 [8]. We also show the activated knowledge levels (parent
concepts) for k-th module for left two images. For each activated knowledge level, we only show the earliest module that is selected

meaningful and individualized module conﬁguration for each
image guided by structured knowledge. We present the av-
eraged modular usage for test images on each dataset, and
can observe it reduces about 40.7% (11/26), 48.2% (13/26)
and 29.6% (8/26) module computation in 4-th ConvBlock
and 5-th ConvBlock on Coco-Stuff, PASCAL-Context and
ADE20k, respectively. The very recent DSSPN [20] includes
a network layer for each parent concept, but it is hard to scale
up for large-scale concept set and results in redundant pre-
dictions for pixels that unlikely belongs to a speciﬁc concept.
On the contrary, our PMN speciﬁes different computation
overheads and designates each activated module to handle
more suitable knowledge levels for each input, achieving a
good balance between accuracy and efﬁciency.

More qualitative comparisons are shown in Figure 4. Be-
side the better prediction performance, our PMN is also able
to provide a deeper understanding of feature representation
learned in each module. It can be observed that different
modules are designated to recognize speciﬁc knowledge lev-
els and personalized inference paths are activated for distinct
inputs to achieve ﬁnal prediction.

4.1.2 Ablation Studies

We analysis main contributions of our PMN on the Coco-
Stuff dataset, as reported in Table 1 and 4.

Learned policies vs. heuristics. We compare our policy
learning with other alternative methods: (1) Fixed, which
keeps only the ﬁrst 16 modules active and appends an ASPP
prediction layer on the ﬁnal module; The reason we choose
16 is that it is the resulting averaged module usage by our
PMN for fair comparison; (2) Random, which keeps 16
randomly selected modules active, and the ﬁnal prediction is
obtained by averaging predictions from ASPP layers on each
module; (3) Distribute, which evenly distributes 16 modules
and averages predictions like Random. We can thus compare
different feature combination policies of different modules.
The results highlight the advantage of our instance-speciﬁc
and knowledge-aware policy learning by the proposed PMN.

The effect of structure-knowledge guided policies. We
also test policy learning strategies without using external
knowledge: 1) Policy, which only learns to determine the
early-stop action of modules, and combines predictions from
all modules; 2) Policy-adaptive, which decides both the early-
stop action and which module should contribute to ﬁnal
predictions. The superior results achieved by our knowledge-
guided policy learning verify again the beneﬁts of selecting
modules that reveal the properties of speciﬁc knowledge
levels rather than making the decision only based on ﬁnal
accuracy.

Graph searching function. We further evaluate the im-
portance of key settings in our graph search function which
is crucial for policy learning as it depicts the adaptive action
space: 1) “PMN w/o overlap" indicates a variant that the
activated knowledge levels should not appear in the new
action space Ωk, posed as an aggressive searching strategy.
Our results show more prediction reﬁnements from later
modules can improve the performance; 2) “PMN (1-hop
children)" that only includes 1-hop children of selected ac-
tions ak−1 into Ωk, results in activating more modules; 3)
“PMN w/o weighting" directly averages predictions of all
activated modules. Our full PMN achieves better perfor-
mance by adaptively combining different predictions. The
underlying reason is that the non-conﬁdent predictions on
certain categories by speciﬁc modules may damage the ﬁnal
performance.

4.2. Image Classiﬁcation Task

We further evaluate on CIFAR-10 (10 classes) and
CIFAR-100 [17] (100 classes), which consist of 60,000
32Ã32 colored images, with 50,000 images for training and
10,000 for testing. Performance is measured by image-level
classiﬁcation accuracy. For fair comparison with the recent
dynamic BlockDrop [36] that also explored the dynamic
module conﬁguration, we experiment with two ResNets:
ResNet-32 and ResNet-110 which start with a convolutional
layer followed by 15 and 54 residual blocks, respectively.
These residual blocks are treated as conﬁgurable modules in

8950

Method (CIFAR-10/-100) ResNet32 BlockDrop [36] Our PMN
7.8/13.4
6.9/28.7

15/15
7.7/30.7

6.9/13.1
8.8/31.3

Module usage

Error

ResNet101 BlockDrop [36] Our PMN
18.4/34.5
5.9/23.8

16.9/30.2
6.4/26.3

54/54
6.8/27.8

Table 5. Comparisons of our PMN with BlockDrop [36] on both CIFAR-10 and CIFAR-100. The ﬁrst three results are based on ResNet32
and the rest results are on ResNet101.

our PMN. The structured knowledge graph with 148 graph
nodes is generated by mapping 100 classes into WordTree,
as shown in Supplementary Material. The prediction layer
with 10/100 neurons is applied, and all other settings are
same with those for segmentation tasks. These models are
ﬁrst pretrained to match state-of-the-art performance on the
corresponding datasets when running without our PMN and
then jointly trained with our policy network. For training,
We use a learning rate of 1e-4, a weight decay of 0.0005 and
momentum of 0.9 and train models with a mini-batch size
of 128 on two GPUs using a cosine learning rate schedul-
ing [16] for 400 epochs. Observed from Table 5, our PMN
outperforms the original ResNet-32 and ResNet-101 models
and dynamic network BlockDrop [36] using less or compa-
rable number of modules on average. It demonstrates well
the advantages of learning explainable and dynamic module
conﬁgurations guided by structured knowledge.

5. Conclusion

We presented a novel Personalized Modular Network
(PMN) to learn dynamic and personalized inference paths
for different inputs, guided by structured knowledge. A
graph-based reinforcement learning was proposed to acti-
vate an evolved action space for each module routed by the
structured knowledge graph, and automatically designates
each module to recognize certain knowledge levels. We con-
ducted extensive experiments on both three benchmarks of
semantic segmentation and two image classiﬁcation tasks,
observing considerable gains over existing methods in terms
of the efﬁciency and accuracy. Our PMN also learned the
dynamic and meaningful inference paths.

References

[1] A. Arnab, S. Jayasumana, S. Zheng, and P. H. Torr.
Higher order conditional random ﬁelds in deep neural
networks. In ECCV, pages 524–540, 2016.

[2] V. Badrinarayanan, A. Kendall, and R. Cipolla. Segnet:
A deep convolutional encoder-decoder architecture for
image segmentation. In CVPR, 2015.

[3] E. Bengio, P.-L. Bacon, J. Pineau, and D. Precup. Con-
ditional computation in neural networks for faster mod-
els. arXiv preprint arXiv:1511.06297, 2015.

[4] Y. Bengio. Deep learning of representations: Looking
forward. In International Conference on Statistical
Language and Speech Processing, pages 1–37, 2013.

[5] H. Caesar, J. Uijlings, and V. Ferrari. Coco-stuff:
Thing and stuff classes in context. arXiv preprint
arXiv:1612.03716, 2016.

[6] Q. Cao, X. Liang, B. Li, G. Li, and L. Lin. Visual
question reasoning on general dependency tree. CVPR,
2018.

[7] S. Chandra, N. Usunier, and I. Kokkinos. Dense and
In

low-rank gaussian crfs using deep embeddings.
ICCV, 2017.

[8] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy,
and A. L. Yuille. Deeplab: Semantic image seg-
mentation with deep convolutional nets, atrous con-
volution, and fully connected crfs. arXiv preprint
arXiv:1606.00915, 2016.

[9] J. Dai, K. He, and J. Sun. Boxsup: Exploiting bounding
boxes to supervise convolutional networks for semantic
segmentation. In ICCV, pages 1635–1643, 2015.

[10] L. Denoyer and P. Gallinari. Deep sequential neural

network. arXiv preprint arXiv:1410.0510, 2014.

[11] M. Figurnov, M. D. Collins, Y. Zhu, L. Zhang,
J. Huang, D. Vetrov, and R. Salakhutdinov. Spatially
adaptive computation time for residual networks. arXiv
preprint, 2017.

[12] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual
learning for image recognition. In CVPR, pages 770–
778, 2016.

[13] S. Hochreiter and J. Schmidhuber. Long short-term
memory. Neural computation, 9(8):1735–1780, 1997.

[14] H. Hu, Z. Deng, G.-T. Zhou, F. Sha, and G. Mori.
Labelbank: Revisiting global perspectives for semantic
segmentation. arXiv preprint arXiv:1703.09891, 2017.

[15] R. Hu, J. Andreas, M. Rohrbach, T. Darrell, and
K. Saenko. Learning to reason: End-to-end mod-
ule networks for visual question answering. CoRR,
abs/1704.05526, 3, 2017.

8951

[16] G. Huang, Z. Liu, K. Q. Weinberger, and L. van der
Maaten. Densely connected convolutional networks.
In CVPR, 2017.

[31] B. Shuai, Z. Zuo, B. Wang, and G. Wang. Scene seg-
mentation with dag-recurrent neural networks. TPAMI,
2017.

[17] A. Krizhevsky and G. Hinton. Learning multiple layers

of features from tiny images. 2009.

[18] J. Langford and T. Zhang. The epoch-greedy algorithm
for multi-armed bandits with side information. In NIPS,
pages 817–824, 2008.

[19] X. Liang, L. Lee, and E. P. Xing. Deep variation-
structured reinforcement learning for visual relation-
ship and attribute detection. In CVPR, 2017.

[20] X. Liang, H. Zhou, and E. Xing. Dynamic-structured

semantic propagation network. CVPR, 2018.

[21] G. Lin, C. Shen, A. van den Hengel, and I. Reid. Efﬁ-
cient piecewise training of deep structured models for
semantic segmentation. In CVPR, pages 3194–3203,
2016.

[22] J. Lin, Y. Rao, J. Lu, and J. Zhou. Runtime neural

pruning. In NIPS, pages 2178–2188, 2017.

[23] L. Liu and J. Deng. Dynamic deep neural networks:
Optimizing accuracy-efﬁciency trade-offs by selective
execution. AAAI, 2018.

[24] W. Liu, A. Rabinovich, and A. C. Berg. Parsenet:
arXiv preprint

to see better.

Looking wider
arXiv:1506.04579, 2015.

[25] J. Long, E. Shelhamer, and T. Darrell. Fully convolu-
tional networks for semantic segmentation. In CVPR,
pages 3431–3440, 2015.

[32] Y.-C. Su and K. Grauman. Leaving some stones un-
turned: dynamic feature prioritization for activity de-
tection in streaming video. In ECCV, pages 783–800,
2016.

[33] R. S. Sutton and A. G. Barto. Reinforcement learning:
An introduction, volume 1. MIT press Cambridge,
1998.

[34] S. Tan, R. Caruana, G. Hooker, and A. Gordo.
arXiv preprint

Transparent model distillation.
arXiv:1801.08640, 2018.

[35] S. Teerapittayanon, B. McDanel, and H. Kung.
Branchynet: Fast inference via early exiting from deep
neural networks. In ICPR, pages 2464–2469, 2016.

[36] Z. Wu, T. Nagarajan, A. Kumar, S. Rennie, L. S. Davis,
K. Grauman, and R. Feris. Blockdrop: Dynamic infer-
ence paths in residual networks. CVPR, 2018.

[37] Z. Wu, C. Shen, and A. v. d. Hengel. Bridging category-
level and instance-level semantic image segmentation.
arXiv preprint arXiv:1605.06885, 2016.

[38] F. Yu and V. Koltun. Multi-scale context aggregation

by dilated convolutions. ICLR, 2016.

[39] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vi-
neet, Z. Su, D. Du, C. Huang, and P. H. Torr. Condi-
tional random ﬁelds as recurrent neural networks. In
ICCV, pages 1529–1537, 2015.

[26] R. Mottaghi, X. Chen, X. Liu, N.-G. Cho, S.-W. Lee,
S. Fidler, R. Urtasun, and A. Yuille. The role of context
for object detection and semantic segmentation in the
wild. In CVPR, 2014.

[40] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and
A. Torralba. Semantic understanding of scenes through
the ade20k dataset. arXiv preprint arXiv:1608.05442,
2016.

[27] C. Olah, A. Mordvintsev, and L. Schubert. Feature visu-
alization. Distill, 2017. https://distill.pub/2017/feature-
visualization.

[28] S. J. Rennie, E. Marcheret, Y. Mroueh, J. Ross, and
V. Goel. Self-critical sequence training for image cap-
tioning. CVPR, 2017.

[29] D. Schiebener, J. Morimoto, T. Asfour, and A. Ude.
Integrating visual perception and manipulation for au-
tonomous learning of object representations. Adaptive
Behavior, 21(5):328–345, 2013.

[30] A. G. Schwing and R. Urtasun. Fully connected deep
structured networks. arXiv preprint arXiv:1503.02351,
2015.

8952

