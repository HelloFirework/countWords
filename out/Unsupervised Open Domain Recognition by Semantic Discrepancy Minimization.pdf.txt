Unsupervised Open Domain Recognition by Semantic Discrepancy Minimization

Junbao Zhuo1

2

,

Shuhui Wang1 ∗

Shuhao Cui1

2

,

Qingming Huang1

2

,

1 Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS, Beijing, 100190, China

2 University of Chinese Academy of Sciences, Beijing, 100049, China

junbao.zhuo@vipl.ict.ac.cn

{wangshuhui,cuishuhao18s}@ict.ac.cn

qmhuang@ucas.ac.cn

Abstract

We address the unsupervised open domain recognition
(UODR) problem, where categories in labeled source do-
main S is only a subset of those in unlabeled target domain
T . The task is to correctly classify all samples in T includ-
ing known and unknown categories. UODR is challenging
due to the domain discrepancy, which becomes even hard-
er to bridge when a large number of unknown categories
exist in T . Moreover, the classiﬁcation rules propagated
by graph CNN (GCN) may be distracted by unknown cate-
gories and lack generalization capability.

To measure the domain discrepancy for asymmetric la-
bel space between S and T , we propose Semantic-Guided
Matching Discrepancy (SGMD), which ﬁrst employs in-
stance matching between S and T , and then the discrep-
ancy is measured by a weighted feature distance between
matched instances. We further design a limited balance
constraint to achieve a more balanced classiﬁcation out-
put on known and unknown categories. We develop Unsu-
pervised Open Domain Transfer Network (UODTN), which
learns both the backbone classiﬁcation network and GCN
jointly by reducing the SGMD, enforcing the limited bal-
ance constraint and minimizing the classiﬁcation loss on
S. UODTN better preserves the semantic structure and en-
forces the consistency between the learned domain invari-
ant visual features and the semantic embeddings. Experi-
mental results show superiority of our method on recogniz-
ing images of both known and unknown categories.

1. Introduction

We study the unsupervised open domain recognition
problem (UODR) in this paper. In UODR, a labeled source
domain S and unlabeled target domain T are given, where
the categories in S is only a subset of those in T . The
task is to classify all samples in T including known and
unknown categories, which is undoubtedly a more chal-

∗Corresponding author.

lenging task but closer to the case in real-world applica-
tions compared to other related tasks in Domain Adaptation
(DA) [2, 3, 4, 20, 21, 33, 40, 42, 34, 13, 5, 10, 25] and Zero-
Shot Learning (ZSL) [24, 11, 28, 16, 32, 15, 14, 29, 41].

The major differences among UODR and other related
problems are summarized in Table 1. Traditional unsuper-
vised DA [4, 20, 21, 33, 42] is too strict to assume that
S and T share the same categories. Researchers begin to
explore a more difﬁcult setting that S and T do not share
the same categories (asymmetric category space). In partial
adversarial-DA [3] and partial weighted-DA [40], the au-
thors addressed the problem that the category space of T is a
subset of S. However, the category space is still constrained
in close set expanded by source domain categories. For the
more difﬁcult setting, i.e., the category space of S is a sub-
set of T is rarely considered in DA ﬁeld. In open set DA [2],
there are unknown categories both in S and T , but the task
is to classify only the samples of known categories in the
target domain, while the samples of unknown categories are
ignored. In contrast, there is no unknown categories in S,
and all samples of known and unknown categories in target
domain are required to be classiﬁed in UODR. UODR is al-
so different from generalized ZSL [28, 16, 11, 32, 15, 14],
since in generalized ZSL all the data are from the same do-
main and there is no presumed domain discrepancy between
S (i.e., training set in ZSL) and T (i.e., testing set in ZS-
L). Therefore, existing solutions can not be directly used to
solve UODR problem due to its unique characteristics.

UODR is challenging due to the semantic discrepancy
between S and T , which can be explained from both fea-
ture distribution and semantic aspects. First, there is large
divergence on both content and distribution perspectives be-
tween S and T , which is also referred to as domain dis-
crepancy in existing DA studies [4, 20, 21, 33, 42]. The
domain discrepancy is even harder to bridge if a large num-
ber of unknown categories are injected into T . In this case,
directly applying techniques used in DA, e.g., MMD [20]
and DCORAL [33], would lead to negative transfer. Sec-
ond, it is hard to classify instances of unknown categories

750

Table 1: The major differences among UODR, DA and ZSL problems.

Domain

discrepancy

Unknown
classes in T

Classify all
samples in T

Use T

for training

Asymmetric
label space

Unsupervised DA

Partial Unsupervised DA
Unsupervised open set DA

Generalized ZSL

Transductive Generalized ZSL

UODR

X

X

X
×
×
X

×
×
X

X

X

X

X

X
×
X

X

X

X

X

X
×
X

X

×
X
×
–
–
X

without labeled training data or any auxiliary attributes in-
formation [16, 37]. With the knowledge on the relationship
among known and unknown categories, graph CNN (GC-
N) [15] can be used in UODR to propagate classiﬁcation
rules of known categories to unknown categories [38, 14].
However, in generalized ZSL, there exists mode collapse
that forces the prediction of unknown categories samples
into the seen categories. Worse still, the propagated classiﬁ-
cation rules on unknown categories may lack generalization
capability due to the domain discrepancy between S and T .
The key idea to address UODR is minimizing the seman-
tic divergence from both feature distribution and semantic
aspects. Speciﬁcally, on unlabeled domain T , there exists
many unknown categories with similar image instances giv-
en a certain known category in S. To reduce the distraction
brought by unknown categories in T , the domain-invariant
feature learning is performed by reducing the domain dis-
crepancy measured on data from the shared (known) cate-
gories of S and T . We propose Semantic-Guided Matching
Discrepancy (SGMD), which ﬁrst employs instance match-
ing between S and T to produce coarsely matched pairs [3].
The discrepancy is then measured by a weighted feature dis-
tances on these pairs, where the weight is the thresholded
similarity of their target domain classiﬁer responses. The
target domain classiﬁcation output provides semantic level
abstraction on a wide range of categories, and instance pair
with the same category label are assumed to have similar
classiﬁcation outputs. Therefore, the weight reﬂects the de-
gree of semantic consistency of each pair, and the weighted
distance calculation further reduces the negative effect of
noisy matching.

Similar as [38, 14], GCN is used to propagate the classi-
ﬁcation rules from known to unknown categories as the ﬁrst
step, where the category relation is described by WordNet.
The propagated classiﬁcation rules are then used to initial-
ize the classiﬁcation layer of backbone network. Based on
the backbone classiﬁcation network, to deal with seman-
tic shift from known to unknown categories, we design a
limited balance constraint to prevent target domain samples
of unknown categories being classiﬁed into known cate-
gories, and better avoid strongly biased classiﬁers on un-

known categories compared to the balance constraint pro-
posed by [32].

Putting the components together, we develop Unsuper-
vised Open Domain Transfer Network (UODTN), which
learns the backbone classiﬁcation network and GCN joint-
ly by reducing the SGMD, achieving the limited balance,
enforcing the semantic structure preserving via GCN, and
minimizing the classiﬁcation loss on S. Compared to multi-
stage learning paradigms [38, 14] that perform GCN-based
classiﬁcation model propagation and visual feature learn-
ing step-by-step, the joint classiﬁcation network and GCN
learning can better preserve the semantic structure and en-
force the consistency between the learned domain invariant
visual features and the semantic embeddings. We construct
two datasets for evaluating our method on UODR. Experi-
mental results show the effectiveness of our method on rec-
ognizing images of both known and unknown categories in
T . We make our collected data and codes publicly available
at https://github.com/junbaoZHUO/UODTN.

2. Related Work

Deep unsupervised domain adaptation. Most of the
deep unsupervised domain adaptation models are trained
by combining classiﬁcation loss on S with additional losses
such as discrepancy reducing losses [20, 33, 21, 4, 8], ad-
versarial discriminative losses [7, 34, 36], adversarial gen-
erative losses [19, 1, 13] and reconstruction losses [9]. We
only review some discrepancy-reducing-based methods that
closely related to our method. A single linear kernel is ap-
plied to only one Fully-Connected (FC) layer to minimize
Maximum Mean Discrepancy (MMD) in DDC [35]. The
sum of MMDs deﬁned between several FC layers, includ-
ing the last classiﬁcation layer, is considered in Deep Adap-
tation Network (DAN) [20]. In Joint Adaptation Network-
s [21], the joint distribution discrepancies of the multi-layer
activations are considered rather than separate adaptations
on marginal and conditional distributions which often re-
quire strong independence and/or smoothness assumption-
s on the factorized distributions.
Instead of MMD, do-
main discrepancy is measured by the difference between the

751

second-order statistics (i.e., covariance) [33, 42]. Domain
discrepancy on both convolutional representation and the
classiﬁcation layer is explicitly considered in [42]. PMD [4]
aims to approximate the ﬁrst-order Wasserstein distance be-
tween two domains via minimum weight graph matching.
These discrepancy-reducing-based methods can only han-
dle the case that S and T share the same label space.

Generalized ZSL. Generalized ZSL drops the as-
sumption that target domain contains only unknown cat-
egories [23, 17, 11, 32, 16, 28, 31]. Being the most
related problem to UODR, transductive generalized ZS-
L [11, 32, 28, 16] is performed in a semi-supervised learn-
ing manner that both the labeled source data and the unla-
beled target data are available, where there is no presumed
domain discrepancy between S and T . However, in UODR,
there exists domain discrepancy between S and T . Propa-
gated Semantic Transfer (PST) [28] exploits the manifold
structure of novel classes by incorporating external knowl-
edge, such as linguistic or expert speciﬁed information to
conduct label propagation. Unsupervised Attribute Align-
ment (UAA) [16] associates cross-domain attributes by reg-
ularized sparse coding which enforces attributes shared by
known and unknown categories to be similar. In [11], a nov-
el joint learning approach is proposed to learn the shared
model space (SMS) for models such that the knowledge
can be effectively transferred between classes using the at-
tributes. Unbias ZSL [32] enforces a balanced classiﬁer re-
sponses among known and unknown categories for unla-
beled target data to learn an unbiased embedding space for
ZSL.

Object recognition via knowledge graph. Salakhut-
dinov et al. [30] use WordNet to share the representations
among different object classiﬁers so that objects with few
training examples can borrow statistical strength from re-
lated objects. Deng et al. [6] apply the exclusion rules as a
constraint and add object-attribute relations into the graph
to train object classiﬁers for zero-shot applications. In con-
trast to these methods of using graph as constraints, a 6-
layer deep GCN is constructed to directly generate novel
object classiﬁers in [38]. In [14], the authors argue that too
many layers of GCN results in over-smooth classiﬁer and
propose to train a single layer GCN. Furthermore, in [14],
a more dense graph structure is utilized and ﬁne-tune the
feature space to adapt to the generated semantic embedding
space.

3. Method

3.1. Common Notations

Some common notations used in this paper are intro-
duced here. Suppose that there are NS source-domain
training examples DS = {zs
i=1 with labels LS =
{yi}NS
i=1, yi ∈ {1, 2, . . . , LS}, and NT unlabeled target-

i }NS

j}NT

domain examples DT = {zt
j=1 , where their labels
LT = {yj}NT
j=1, yj ∈ {1, 2, . . . , LT } are not available and
LS < LT . That is, there are LT − LS unknown categories
in target domain. zs
j are the raw images from source
and target domains respectively. Let φ(·) be the feature ex-
tractor and let ψS(·) and ψT (·) denote the classiﬁer pre-
trained on S and classiﬁer for target domain T .

i and zt

3.2. Framework

As shown in Figure 1, our Unsupervised Open Domain
Transfer Network (UODTN) contains a backbone classiﬁ-
cation network with classiﬁer layer for all LT categories in
target domain and a GCN that maintains the relationships
among all LT categories. We ﬁrst use GCN to generate the
semantics embeddings of unknown categories in target do-
main and then initialize the classiﬁer layer of backbone clas-
siﬁcation network by these semantic embeddings. Based on
the initialized backbone classiﬁcation network, we further
reduce the proposed semantic-guided matching discrepan-
cy, enforce the proposed limited balance constraint and inte-
grate GCN to minimize the semantic discrepancy in UODR
problem. The backbone classiﬁcation network and GCN are
jointly trained in an end-to-end manner with GCN aiming at
preserving semantic structure encoded in word vectors and
knowledge graph. The details are illustrated as follows.

3.3. Generating unknown class semantic embed 

dings

With the auxiliary information encoded in word vectors
and knowledge graph for unknown categories, we can gen-
erate the unknown class semantic embeddings via GCN. We
ﬁrst construct a graph with N nodes where each node is
a C-dimensional vector presenting a distinct concept/class.
In order to propagate the semantic embeddings of known
categories to unknown categories, additional nodes are re-
quired for constructing full path from known categories to
unknown categories. Each node is initialized with word
vector of the class name. The relationships among the class-
es in the knowledge graph, say, WordNet, are encoded in
form of a symmetric adjacency matrix A ∈ RN ×N , which
also includes self-loops. We propagate such relationship as
performing convolution on the graph

O = σ(D−1AXΘ)

(1)

where X ∈ RN ×C is composed of N word vectors and
Θ ∈ RC×F denotes the trainable weights. σ(·) denotes a
nonlinear activation function. D ∈ RN ×N is a degree ma-
trix where Dii = Pj Aij . By training the GCN to predict

the classiﬁer weights of known classes, the GCN simulta-
neously generates the classiﬁer weights of unknown classes
while preserves the semantic relationship exhibited in word

752

Figure 1: The proposed UODTN framework for UODR problem. It consists of a two-stream Siamese network representing
the source and target models where weights of all layers are shared and a GCN for propagating classiﬁcation rules of known
categories in source domain to unknown categories in target domain. The Siamese network and GCN are jointly trained in an
end-to-end manner. The proposed semantic-guided matching discrepancy is estimated on the features extracted from source
and target domain. By reducing the proposed discrepancy, UODTN is able to propagate more suitable source classiﬁers to
unknown categories in target domain as the source classiﬁers are based on domain-invariant features.

vectors and knowledge graph. The loss is

Linit =

1
2M

LSX

MX

i=1

j=1

(Oi,j − Wi,j)2

(2)

where W ∈ RLS ×M denotes the classiﬁer weights obtained
by extracting the weights of ψS(·), the classiﬁer pretrained
on source domain. We replace the original classiﬁer of pre-
trained ResNet-50 with the generated classiﬁers to form a
classiﬁcation network for source and target domain.

3.4. Semantic guided matching discrepancy

In real world scenario, there always exists domain dis-
crepancy between manually collected labeled data (source
domain) and practical data (target domain). Such domain
discrepancy leads to performance degradation on target do-
main and more severely, makes GCN propagate biased se-
mantic embeddings to unknown categories. Therefore, it is
urgent to reduce the domain discrepancy. However, it is dif-
ﬁcult to measure the domain discrepancy in UODR problem
since there are many unknown categories samples. Existing
domain discrepancy measurements such as MMD [20, 21]
and difference between correlation [33, 42], assume that the
source and target domain share same categories, which can
not handle asymmetric label space for UODR.

We propose semantic-guided matching discrepancy to
estimate the domain discrepancy. We extract the features of
all instances from source and target domain and construc-

t a bipartite graph between the two domains. The weights
of the bipartite graph are pairwise distance of all pairs. In
this work, we use L1 distance while other distance metric-
s can also be used. By solving minimum weight match-
ing problem via the Hungarian algorithm, we obtain coarse
and noisy matched instance pairs (pairs linked with red line
in the left part of Figure 1) between source and target do-
main. Directly reducing the discrepancy measured from
noisy matched instances pair will inevitably lead to negative
transfer. Hence, we propose to utilize the semantic consis-
tency of matched pairs to ﬁlter such noisy matched pairs.
Precisely, given matched source and target instances zs
i and
zt
i = φ(zs
i , we extract their features as f s
i ),
and calculate their classiﬁer responses ps
i ) and
pt
i = ψT (f t
i ) respectively, the semantic-guided matching
discrepancy is

i ) and f t
i = ψT (f s

i = φ(zt

Ld = X

i

d(f s

i , f t

i ) ∗ ✶(hps

i , pt

ii > τ )

(3)

i , f t

where d(f s
i ) is the distance metrics which can be L2 dis-
tance, the discrepancy metric encoded in domain discrimi-
nator when using adversarial training, etc. h·, ·i denotes in-
ner product. ✶ is indicator function and τ is a given thresh-
old. The similarity hps
ii reveals the degree of semantic
consistency of each pair since samples of the same classes
are assumed to have similar classiﬁcation responses.

i , pt

753

3.5. Limited balance constraint

To prevent target domain samples of unknown categories
being classiﬁed into known categories, it is straightforward
to add a balance constraint to classiﬁer responses for tar-
get domain instances. The vanilla balance constraint [32] is
calculated as:

Lb = −log

pt
j

(4)

LTX

j=LS +1

However, such balance constraint may grow into unexpect-
ed large value since there is no label for target domain,
which will result in biased classiﬁers of unknown cate-
gories. To prevent the classiﬁer response of unknown cat-
egories growing abnormally, we propose limited balance
constraint:

Llb = Rt +

w2
Rt

(5)

where Rt = PLT

j=LS +1 pt

j and w is a manually set constant
that control the ratio of classiﬁcation response of unknown
categories over all categories. Such constraint enforces the
ratio of classiﬁcation response of unknown categories over
all categories to lie in an appropriate range. Ideally, w can
be set according to the prior of the proportion of unknown
classes over all categories.

3.6. Semantic structure preserving via GCN

The semantic structure among categories exhibited in
word vectors and knowledge graph can not be well pre-
served via reducing semantic-guided matching discrepancy
and enforcing limited balance constraint. To preserve such
relationship, we integrate GCN into our training, resulting
in an end-to-end framework. Different from subsection 3.3,
semantic embeddings of all categories in target domain are
considered in the loss term:

Lgcn =

1
2M

LTX

MX

i=1

j=1

(Oi,j − cWi,j)2

(6)

where cW ∈ RLT ×M denotes the classiﬁer weights obtained

by extracting the weights of ψT (·), the classiﬁcation layer
for all categories in target domain. Unlike the method pro-
posed in [14], which ﬁxes the classiﬁer learnt from GCN
and ﬁne-tune the features, the classiﬁer in our model can be
well adapted to data while the semantic relationship of all
categories is still maintained via GCN.

where Lcls is classiﬁcation loss on labeled source domain.
λd, λb and λg are weights for semantic-guided matching
discrepancy minimizing loss, limited balance constraint and
structure preserving loss of GCN. Speciﬁcally, minimizing
semantic-guided matching discrepancy provides domain-
invariant features for classiﬁers of known and unknown cat-
egories. Further, the classiﬁers of known categories re-
ceive both the supervision of classiﬁcation loss and reg-
ularization of GCN. On the other hand, the classiﬁers of
unknown categories are trained with guidance from limited
balance constraint and GCN. Joint training is unhindered to
achieve better trade-off of classiﬁcation accuracy between
known and unknown categories in target domain. Minimiz-
ing sematic guided matching discrepancy actually propa-
gates semantic information from feature perspective while
GCN propagates semantic embeddings from semantic per-
spective. The UODR problem is actually an ill-conditioned
problem where limited balance constraint prevents ill solu-
tions of UODTN during the training progress.

4. Experiment

4.1. Datasets

We evaluate our method on two datasets: a small-scale
dataset I2AwA and a large-scale dataset I2WebV. The target
domain of I2AwA is AwA2[39] which is a replacement of
the original AwA dataset for zero-shot learning. It consists
of 50 animal classes, with a total of 37,322 images and an
average of 746 images per class. We use the proposed split
in [39] in which 40 classes are regarded as known categories
and the rest 10 classes as unknown categories. We collect a
source domain dataset with 40 known categories via Google
image searching engine. We manually remove the noisy im-
ages resulting 2,970 images in total. There exists domain
discrepancy between source and target domain as shown in
Figure2. As for I2WebV, its source domain is ILSVRC-
2012 with 1,000 classes which consists of 1,279,847 images
totally. The target domain of I2WebV is the validation set
of WebVision [18] with 5,000 classes, which is composed
of 294,009 images. I2WebV is a very challenging dataset
as there is large domain discrepancy between two domains
and large number of unknown categories in target domain,
some of which are very different from 1,000 known cate-
gories. The knowledge database we use for both I2AwA
and I2WebV is WordNet [22].

3.7. Joint training

4.2. Evaluation metrics

After initializing the classiﬁer layer of UODTN via
trained GCN in subsection 3.3, we utilize all proposed tech-
niques to train UODTN in an end-to-end manner. The total
loss is

L = Lcls + λdLd + λbLlb + λgLgcn

(7)

We perform classiﬁcation on the whole target domain
similar to generalized zero-shot learning and report the Top
1 Accuracies of known categories, unknown categories and
all categories on target domain for better understanding the
knowledge transfer process.

754

Table 3: Top1 Accuracies on I2WebV.

Known Unknown All

zGCN [38]
dGCN [14]
adGCN [14]
bGCN [32]

pmd-bGCN [4]
UODTN (Ukn.)
UODTN (Avg.)

43.8
45.2
45.8
47.4
47.2
51.9
57.3

2.2
2.0
2.2
2.2
2.2
3.2
2.4

11.1
11.3
11.6
12.0
11.9
13.8
14.2

for all categories are extracted via GloVe text model [27]
which is trained on Wikipedia. Word vectors for nodes in
graph are set as inputs of GCN. We use ResNet-50 [12] pre-
trained on ILSVRC-2012 as basic model where the last ful-
ly connected layer, i.e., the classiﬁcation layer is regarded
as the target that GCN tends to predict. We train the GC-
N with word vectors as inputs and classiﬁer of pretrained
ResNet-50 as target to obtain the initial classiﬁers of target
domain in I2WebV. As for I2AwA, the supervison informa-
tion for training GCN is classiﬁers ﬁnetuned on the source
domain of I2AwA. These initial classiﬁers are then concate-
nated into feature extractor of pretrained ResNet-50 (with
original classiﬁer layer removed) to form a backbone classi-
ﬁcation network for source and target domain. We ﬁx some
beginning convolutional layers of ResNet-50 to accelerate
the training process. The global average pooling responses
before classiﬁcation layer are thought as features and based
on these features we construct a bipartite graph with each
sub-graph representing source and target domain. We use
Hungarian algorithm to get minimum weight matched pairs
for estimating population matching discrepancy [4] and our
proposed semantic-guided matching discrepancy. Specif-
ically, we use the discrepancy metric encoded in domain
discriminator as distance metric in Eqn. (3). It is difﬁcult
to get minimum weight matched pairs for bipartite graph
based on large scale datasets. We simply apply divide and
conquer strategy to handle this issue. Take I2AwA as an
example, we randomly divide source/target domain into 5
folds, respectively. Then we construct 5 bipartite graphs for
each fold pair and use Hungarian algorithm to get minimum
weight matched pairs for 5 bipartite graphs. All of our ex-
periments are implemented with Pytorch [26]. More details
can be seen in our released codes.

4.5. Results and discussion

The classiﬁcation results on I2AwA and I2WebV are
shown in Table 2 and Table 3. As shown in Table 2 and Ta-
ble 3, our method UODTN outperforms all the baselines by
considerable margins, achieving 3.7% and 0.9% improve-
ments on unknown classes and all classes on I2AwA. For a
more challenging dataset I2WebV, we implement two vari-

755

Figure 2: The ﬁrst and second rows show the samples from
source and target domain of I2AwA respectively and images
of the same column belong to the same categories. The tar-
get samples are taken from natural scene while source data
that are collected from Internet, containing 3D model im-
ages of animals, which appear to be discrepant from target
domain on both content and distribution perspectives.

Table 2: Top1 Accuracies on I2AwA.

Known Unknown All

zGCN [38]
dGCN [14]
adGCN [14]
bGCN [32]

pmd-bGCN [4]

UODTN

77.2
78.2
77.3
84.6
84.7
84.7

21.0
11.6
15.0
28.0
27.1
31.7

65.0
64.0
64.1
72.6
72.5
73.5

4.3. Baselines

we compare our method with several baselines: zGC-
N [38], two variants including dGCN and adGCN pro-
posed in [14], bGCN and pmd-bGCN. zGCN is built up-
on graph which utilizes both word vectors and the categor-
ical relationships encoded in WordNet to predict the classi-
ﬁers of unknown categories. Following zGCN, the authors
in [14] utilize a more dense graph structure (dGCN) and
assign different weights for additional edges (adGCN). We
also construct bGCN, GCN with original balance constrain-
t proposed in state-of-the-art transductive zero-shot learn-
ing methods [32]. Furthermore, on the basic of bGCN,
we implement another variant of GCN, pmd-bGCN, which
further reduces the population matching discrepancy [4],
a state-of-the-art domain discrepancy measurement which
shows superiority over MMD.

4.4. Implementation details

We construct two distinct graphs based on WordNet [22]
for I2AwA and I2WebV respectively. The graph nodes in-
clude all categories of target domain and their children and
ancestors. Precisely, the number of nodes for graphs of
I2AwA and I2WebV are 255 and 7,460. The word vectors

Table 4: Ablation study on I2AwA.

Known Unknown All

zGCN [38]
UODTN (lb)

UODTN (lb+sgmd)

UODTN (lb+sgmd+gcn)

77.2
83.9
84.6
84.7

21.0
32.5
31.0
31.7

65.0
73.0
73.3
73.5

ants of UODTN with different λd, λb and λg according to
different trade-off between known and unknown categories.
Precisely, aiming at achieving higher average performance,
UODTN (Avg.)
shows 9.9%, 0.2% and 2.2% improve-
ments on known classes, unknown classes and all class-
es compared to bGCN. On the contrary, UODTN (Ukn.)
that pays more attention to unknown categories, achieves
remarkable improvement on unknown categories by 1.0%
while the overall top 1 accuracy is still higher that bGAN.
Noting that WebVision contains 4,000 unknown categories,
1.0% improvement is a great progress without any labels of
unknown categories available. We also obtain the follow-
ing observations: (1) zGCN, dGCN and adGCN obtained
from labeled source domain and knowledge graph can not
ﬁt target data well, as there is severe classiﬁcation confu-
sion between known and unknown categories. UODTN and
bGCN show improvement over zGCN, dGCN and adGCN
indicating that ﬁtting target domain data leads to better gen-
eralization of networks. However, comparing bGCN with
UODTN, we can see that merely introducing a balance con-
straint on classiﬁer responses is insufﬁcient as there exist-
s domain discrepancy between source and target domain.
Such domain discrepancy results in suboptimal classiﬁers
cause distracted semantic embeddings when being propa-
gated to unknown categories in target domain. (2) Merely
reducing the domain discrepancy estimated by traditional
methods leads to negative transfer as revealed by compar-
ison between bGCN and pmd-bGCN. Note that we assign
a very small weight to population matching discrepancy re-
ducing term for optimal results of pmd-bGCN. On the con-
trary, by reducing our proposed semantic-guided matching
discrepancy, such negative transfer can be avoided and more
domain-invariant features are learned by UODTN, which is
illustrated in 4.6.

4.6. Ablation Study

To go deeper with the efﬁcacy of semantic-guided
matching discrepancy, limited balance constraint and join-
t training of GCN, we conduct ablation study on I2AwA
by evaluating several models (Table 4): (1) zGCN, without
adding any proposed techniques in UODTN; (2) UODT-
N (lb), which includes only limited balance constraint;
(3) UODTN (lb+sgmd), which further contains semantic-
guided matching discrepancy reducing module; (4) UODT-
N (lb+sgmd+gcn), which is the full model with limited bal-
ance constraint, semantic-guided matching discrepancy re-

Figure 3: Visualizations of features learned by UODTN and
bGCN in target domain of I2AwA. From the black boxes
areas, we can see that samples of an unknown category are
mixed with a known category for bGCN, while these two
categories are well separated by UODTN. This validates
that semantic discrepancy is alleviated by UODTN.

Figure 4: The top three classiﬁer responses of UODTN with
various target inputs. Green/red means that the category
is known/unknown and GT means ground-truth. The ﬁrst
and second rows are examples of known categories and the
rest are drawn from unknown categories. We can see that
except ground-truth, UODTN assigns considerable weight
on related unknown/known categories for known/unknown
categories samples, indicating that the transferring mech-
anism of UODTN is effective. That is, the knowledge of
labeled source domain, word vectors and WordNet can be
transferred to unknown categories in a reasonable way.

ducing module and joint training of GCN. We can see that
UODTN (lb) outperforms zGCN [38] by a large margin s-
ince limited balance constraint can prevent the classiﬁer ac-
tivations on known categories growing abnormally. By the
way, from Table 2 and 4, we can see that UODTN (lb) out-
performs bGCN which shows the superiority of limited bal-

756

Table 5: Results for domain adaptation on I2WebV (the ﬁrst
row) and I2AwA (the second row).

ResNet MMD PMD SGMD

I2WebV (1K)

67.7

68.0

67.9

68.1

egory are mixed with those of known category for bGCN.
On the contrary, in Figure 3 (b), the two categories are well
separated by UODTN which qualitatively veriﬁes the effec-
tiveness of semantic-guided matching discrepancy, limited
balance constraint and joint training of GCN in UODTN.

I2AwA (40)

84.0

84.2

84.4

85.1

4.9. Illustrative examples

ance constraint over original balance constraint [32]. Fur-
ther, we can observe that UODTN (lb+sgmd) improves the
performance by 0.1% compared with UODTN (lb), which
validates that reducing semantic-guided matching discrep-
ancy can not only avoid negative transfer but also boost the
domain invariance of learned features. By further integrat-
ing GCN for joint training, UODTN (lb+sgmd+gcn) gain-
s improvement over UODTN (lb+sgmd). It is rational as
the relationship among all known and unknown categories
is essential for transferring effective semantic embeddings
for unlabeled unknown categories. Joint training with GCN
progressively maintains the semantic structure encoded in
word vector and knowledge graph to guarantee the boost of
UODTN.

We show some qualitative results of UODTN in Figure 4.
We observe that UODTN effectively transfers the semantic
embeddings of source domain to unknown categories in tar-
get domain. This property mainly depends on joint training
with GCN to preserve the semantic relationships between
known and unknown categories while improving the dis-
crimination ability of classiﬁer. Figure 4 provides some
correct classiﬁcation results of UODTN. For all instances,
except the true categories that the instances belong to, the
classiﬁers of correctly related unknown/known categories
are also activated with large conﬁdence. This indicates that
UODTN can effectively transfer the knowledge from both
labeled source domain, word vectors and knowledge graph.
More illustrative examples including incorrect results can
be seen in supplementary material.

4.7. Traditional domain adaptation

5. Conclusion

We conduct experiments for traditional domain adapta-
tion to validate that semantic-guided matching discrepancy
(SGMD) is capable of dealing DA. We simply adopt L2 dis-
tance for Eqn. (3) here. The source domain is ImageNet and
the target domain is a subset of Webvision that shares 1,000
categories with ImageNet for I2WebV. From the ﬁrst row
in Table 5, we can see that SGMD is slightly better than P-
MD and to MMD, demonstrating that weighted mechanism
is helpful for DA. Note that the matching is ﬁxed, so PMD
is poor than MMD. However, our SGMD is still better than
MMD which validates the effectiveness of weighted mech-
anism. Domain adaptation results on I2AwA are shown in
the second row in Table 5. The discrepancy between source
and target domain of I2AwA is large and the size of source
domain is small. Besides, the categories in AwA2 are simi-
lar so that domain adaptation on I2AwA is very challenging.
With ﬁxed matching, SGMD outperforms MMD and PMD
signiﬁcantly which validates the superiority of SGMD.

4.8. Visualization

We visualize the t-SNE embeddings of the images of
target domain with features extracted from best competi-
tor bGCN and our model UODTN on I2AwA in Figure 3.
We only visualize 15 known categories and 3 unknown cate-
gories for the sake of visualization quality and clarity. These
known categories include the categories that are related to
3 unknown for better understanding the inﬂuence between
known and unknown categories. From Figure 3 (a), we can
see that in the black box area, the samples of unknown cat-

We explore unsupervised open domain recognition prob-
lem, where an unlabeled target domain T and a discrepant
labeled source domain S that only covers a subset of cat-
egories of target domain are given, and the goal is to clas-
sify all instances of target domain. UODR is more chal-
lenging due to the semantic discrepancy between S and T ,
which exhibits large divergence on both content and dis-
tribution perspectives between S and T and semantic shift
from known to unknown categories between the two do-
mains. We develop Unsupervised Open Domain Transfer
Network (UODTN) , which learns the backbone classiﬁ-
cation network and GCN jointly by reducing the SGMD,
achieving the limited balance, enforcing the semantic struc-
ture preserving via GCN, and minimizing the classiﬁcation
loss on S. We collect two datasets for UODR problem and
extensive experiments validate the effectiveness of UODT-
N. In future work, discriminating known and unknown cat-
egories to alleviate the semantic shift in OUDR problem al-
so worths studying, since it is a non-trivial task as there is
function to distinguish known and unknown categories.

6. Acknowledgement

This work was supported in part by National Natural
Science Foundation of China: 61672497, 61620106009,
U1636214 and 61836002, in part by National Basic Re-
search Program of China (973 Program): 2015CB351800,
and in part by Key Research Program of Frontier Sciences
of CAS: QYZDJ-SSW-SYS013.

757

References

[1] K. Bousmalis, N. Silberman, D. Dohan, D. Erhan, and D. Kr-
ishnan. Unsupervised pixel-level domain adaptation with
generative adversarial networks. In CVPR, volume 1, page 7,
2017.

[2] P. P. Busto and J. Gall. Open set domain adaptation. In ICCV,

pages 754–763, 2017.

[3] Z. Cao, M. Long, J. Wang, and M. I. Jordan. Partial transfer
learning with selective adversarial networks. arXiv preprint
arXiv:1707.07901, 2017.

[4] J. Chen, C. LI, Y. Ru, and J. Zhu. Population matching dis-
crepancy and applications in deep learning.
In I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-
wanathan, and R. Garnett, editors, NIPS, pages 6262–6272.
Curran Associates, Inc., 2017.

[5] N. Courty, R. Flamary, D. Tuia, and A. Rakotomamonjy. Op-
timal transport for domain adaptation. IEEE transactions on
pattern analysis and machine intelligence, 39(9):1853–1865,
2017.

[6] J. Deng, N. Ding, Y. Jia, A. Frome, K. Murphy, S. Bengio,
Y. Li, H. Neven, and H. Adam. Large-scale object classiﬁ-
cation using label relation graphs. In ECCV, pages 48–64.
Springer, 2014.

[7] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle,
F. Laviolette, M. Marchand, and V. Lempitsky. Domain-
adversarial training of neural networks. The Journal of Ma-
chine Learning Research, 17(1):2096–2030, 2016.

[8] M. Ghifary, W. Bastiaan Kleijn, M. Zhang, and D. Balduzzi.
Domain generalization for object recognition with multi-task
autoencoders. In ICCV, pages 2551–2559, 2015.

[9] M. Ghifary, W. B. Kleijn, M. Zhang, D. Balduzzi, and
W. Li. Deep reconstruction-classiﬁcation networks for un-
supervised domain adaptation.
In ECCV, pages 597–613.
Springer, 2016.

[10] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow
kernel for unsupervised domain adaptation. In CVPR, pages
2066–2073. IEEE, 2012.

[11] Y. Guo, G. Ding, X. Jin, and J. Wang. Transductive zero-
shot recognition via shared model space learning. In AAAI,
volume 3, page 8, 2016.

[12] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning

for image recognition. pages 770–778, 2015.

[13] J. Hoffman, E. Tzeng, T. Park, J.-Y. Zhu, P. Isola, K. Saenko,
A. A. Efros, and T. Darrell. Cycada: Cycle-consistent adver-
sarial domain adaptation. arXiv preprint arXiv:1711.03213,
2017.

[14] M. Kampffmeyer, Y. Chen, X. Liang, H. Wang, Y. Zhang,
and E. P. Xing. Rethinking knowledge graph propagation for
zero-shot learning. arXiv preprint arXiv:1805.11724, 2018.
[15] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation
arXiv preprint arX-

with graph convolutional networks.
iv:1609.02907, 2016.

[16] E. Kodirov, T. Xiang, Z. Fu, and S. Gong. Unsupervised
In ICCV, pages

domain adaptation for zero-shot learning.
2452–2460, 2015.

[17] E. Kodirov, T. Xiang, and S. Gong. Semantic autoencoder for
zero-shot learning. arXiv preprint arXiv:1704.08345, 2017.

[18] W. Li, L. Wang, W. Li, E. Agustsson, and L. Van Gool. We-
bvision database: Visual learning and understanding from
web data. arXiv preprint arXiv:1708.02862, 2017.

[19] M.-Y. Liu and O. Tuzel. Coupled generative adversarial net-

works. In NIPS, pages 469–477, 2016.

[20] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning
transferable features with deep adaptation networks. arXiv
preprint arXiv:1502.02791, 2015.

[21] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Deep trans-
fer learning with joint adaptation networks. arXiv preprint
arXiv:1605.06636, 2016.

[22] G. A. Miller. Wordnet: a lexical database for english. Com-

munications of the ACM, 38(11):39–41, 1995.

[23] M. Norouzi, T. Mikolov, S. Bengio, Y. Singer, J. Shlens,
A. Frome, G. S. Corrado, and J. Dean. Zero-shot learning by
convex combination of semantic embeddings. arXiv preprint
arXiv:1312.5650, 2013.

[24] M. Palatucci, D. Pomerleau, G. E. Hinton, and T. M.
Mitchell. Zero-shot learning with semantic output codes. In
Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams,
and A. Culotta, editors, NIPS, pages 1410–1418. Curran As-
sociates, Inc., 2009.

[25] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain
adaptation via transfer component analysis. IEEE Transac-
tions on Neural Networks, 22(2):199–210, 2011.

[26] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. De-
Vito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer. Auto-
matic differentiation in pytorch. 2017.

[27] J. Pennington, R. Socher, and C. Manning. Glove: Global
vectors for word representation. In Conference on Empirical
Methods in Natural Language Processing, pages 1532–1543,
2014.

[28] M. Rohrbach, S. Ebert, and B. Schiele. Transfer learning in

a transductive setting. In NIPS, pages 46–54, 2013.

[29] B. Romera-Paredes and P. Torr. An embarrassingly simple
approach to zero-shot learning. In ICML, pages 2152–2161,
2015.

[30] R. Salakhutdinov, A. Torralba, and J. Tenenbaum. Learning
to share visual appearance for multiclass object detection. In
CVPR, pages 1481–1488. IEEE, 2011.

[31] R. Socher, M. Ganjoo, C. D. Manning, and A. Ng. Zero-shot
learning through cross-modal transfer.
In C. J. C. Burges,
L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberg-
er, editors, NIPS, pages 935–943. Curran Associates, Inc.,
2013.

[32] J. Song, C. Shen, Y. Yang, Y. Liu, and M. Song. Transductive
unbiased embedding for zero-shot learning. In ICCV, pages
1024–1033, 2018.

[33] B. Sun and K. Saenko. Deep coral: Correlation alignment for
deep domain adaptation. In ECCV, pages 443–450. Springer,
2016.

[34] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversar-
ial discriminative domain adaptation. In CVPR, volume 1,
page 4, 2017.

[35] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell.
Deep domain confusion: Maximizing for domain invariance.
Computer Science, 2014.

758

[36] R. Volpi, P. Morerio, S. Savarese, and V. Murino. Adversarial
feature augmentation for unsupervised domain adaptation. In
ICCV, pages 5495–5504, 2018.

[37] S. Wang, S. Jiang, Q. Huang, and Q. Tian. Multi-feature met-
ric learning with knowledge transfer among semantics and
social tagging. In CVPR, pages 2240–2247. IEEE, 2012.

[38] X. Wang, Y. Ye, and A. Gupta. Zero-shot recognition via se-
mantic embeddings and knowledge graphs. In CVPR, pages
6857–6866, 2018.

[39] Y. Xian, B. Schiele, and Z. Akata. Zero-shot learning-
arXiv preprint arX-

the bad and the ugly.

the good,
iv:1703.04394, 2017.

[40] J. Zhang, Z. Ding, W. Li, and P. Ogunbona.

Importance
weighted adversarial nets for partial domain adaptation. In
CVPR, pages 8156–8164, 2018.

[41] L. Zhang, T. Xiang, S. Gong, et al. Learning a deep embed-

ding model for zero-shot learning. 2017.

[42] J. Zhuo, S. Wang, W. Zhang, and Q. Huang. Deep unsuper-
In Proceedings of
vised convolutional domain adaptation.
the 2017 ACM on Multimedia Conference, pages 261–269.
ACM, 2017.

759

