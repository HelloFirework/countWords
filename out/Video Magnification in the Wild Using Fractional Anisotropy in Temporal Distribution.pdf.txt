Video Magniﬁcation in the Wild

Using Fractional Anisotropy in Temporal Distribution

Shoichiro Takeda1 Yasunori Akagi2 Kazuki Okami1 Megumi Isogai1 Hideaki Kimata1

1NTT Media Intelligence Laboratories

2NTT Service Evolution Laboratories

1-1 Hikarinooka, Yokosuka, Kanagawa, 239-0847 Japan

{shoichiro.takeda.us, yasunori.akagi.cu, kazuki.okami.ac, megumi.isogai.ks, hideaki.kimata.yu}@hco.ntt.co.jp

(a)
y

(c)

time

(b)

(d)

(a) Original

(b) Acceleration

(c) Jerk

(d) Ours

Figure 1: Top left: slam dunk video visualizing backboard deformations with ball trajectory by yellow arrow. Bottom left (a)-(d) show
spatio-temporal slices along the single red line at top left. Right (a)-(d) show backgrounds in the green square at top left. (b) Acceleration
method [24] produces messy artifacts due to quick ball motion. (c) Jerk method [17] magniﬁes meaningful subtle backboard deformations
but misdetects non-meaningful subtle distortions of background window caused by photographic noise (purple circle). (d) On the contrary,
our proposed method magniﬁes only meaningful subtle backboard deformations. See supplementary material for video results.

Abstract

1. Introduction

Video magniﬁcation methods can magnify and reveal
subtle changes invisible to the naked eye. However, in such
subtle changes, meaningful ones caused by physical and
natural phenomena are mixed with non-meaningful ones
caused by photographic noise. Therefore, current methods
often produce noisy and misleading magniﬁcation outputs
due to the non-meaningful subtle changes. For detecting
only meaningful subtle changes, several methods have been
proposed but require human manipulations, additional re-
sources, or input video scene limitations. In this paper, we
present a novel method using fractional anisotropy (FA) to
detect only meaningful subtle changes without the afore-
mentioned requirements. FA has been used in neuroscience
to evaluate anisotropic diffusion of water molecules in the
body. On the basis of our observation that temporal distri-
bution of meaningful subtle changes more clearly indicates
anisotropic diffusion than that of non-meaningful ones, we
used FA to design a fractional anisotropic ﬁlter that passes
only meaningful subtle changes. Using the ﬁlter enables our
method to obtain better and more impressive magniﬁcation
results than those obtained with state-of-the-art methods.

Physical and natural phenomena often cause meaningful
and attractive changes in a small world. For example, mus-
cles and skin are slightly deformed by impacts spreading
through our bodies, materials deform elastically to absorb
external force and thus prevent breakage and ensure safety,
and strumming ukulele strings produce complicated string
vibrations and result in generating wonderful sounds. How-
ever, these meaningful and attractive subtle changes are too
small to see with the naked eye.

To visualize such subtle motion or color changes, video
magniﬁcation methods have been proposed [22, 20, 21].
These methods are typically based on Eulerian approach
which can measure subtle motion or color changes pixel
by pixel. With recently developed spatio-temporal ﬁltering
[24, 17], current video magniﬁcation methods produce good
results for magnifying and revealing only subtle changes
under the presence of large motions of objects. However,
in such subtle changes, meaningful ones caused by physi-
cal and natural phenomena are mixed with non-meaningful
ones caused by noise introduced during the photographic
process (i.e. low light levels, high sensor gain, short expo-

1614

sure time, and so on). Therefore, current methods often pro-
duce noisy magniﬁcation outputs due to the non-meaningful
subtle changes; it is likely to lead users to incorrect insights
and conclusions for a small world.

For detecting only meaningful subtle changes, layer-
based methods have been developed [5, 7, 18]. These meth-
ods separate a target region to be magniﬁed from the back-
ground by manual segmentation [5, 18] or depth layers [7].
They can magnify only meaningful subtle changes if they
know where the changes are, but require burdensome in-
terventions such as complicated manual operation and ar-
ranged environment for using a depth sensor.

In contrast, several methods magnify only meaning-
ful subtle changes without the aforementioned interven-
tions. By focusing on meaningful motion changes appear-
ing around edges [14], edge-aware spatial smoothing meth-
ods have been proposed [20, 19]. These methods help to
remove non-meaningful subtle changes in ﬂat textured re-
gions but have limitations in that they can not be applied to
color magniﬁcation or to the removal of them around edges.
Alternatively, principal component analysis (PCA) has been
used for detecting only meaningful subtle changes [23] but
its limitation is that meaningful subtle changes need to be
larger than non-meaningful ones as the principal component
in input video scenes.

This paper presents a novel video magniﬁcation method
for detecting and magnifying only meaningful subtle color
or motion changes under the presence of photographic
noise, without additional interventions, resources, or in-
put video scene limitations. On the basis of our observa-
tion that temporal distribution of meaningful subtle changes
more clearly indicates anisotropic diffusion than that of
non-meaningful ones caused by photographic noise, we
considered that anisotropic diffusion in temporal distribu-
tion enables us to detect only meaningful subtle changes.
Therefore, we focused on fractional anisotropy (FA), which
is used in neuroscience to evaluate anisotropic diffusion of
water molecules in the body for revealing the shape of tiny
nerve cells [11, 2]. In developing our method, we used FA to
design a novel ﬁlter, which we call a fractional anisotropic
ﬁlter, that passes only meaningful subtle changes and ig-
nores non-meaningful ones. Our method, in which the frac-
tional anisotropic ﬁlter is applied to a state-of-the-art jerk-
aware method [17], produces impressive color or motion
magniﬁcation results in various input video scenes.

The main contributions of this paper are: (a) a success-
ful application of fractional anisotropy, a popular measure
in other research ﬁelds, to temporal analysis of video data,
(b) a novel ﬁlter for passing only meaningful subtle color or
motion changes under the presence of noise introduced dur-
ing photographic process in various input video scenes, (c)
a newly edge-aware regularization technique that incorpo-
rates strong normalization with hierarchical pyramid repre-

sentation for reﬁning motion information, and (d) showing
of the qualitative and quantitative effects our method has on
video magniﬁcation.

2. Related Work

2.1. Lagrangian Approach

Liu et al. [10] ﬁrst presented the concept of video mag-
niﬁcation with a Lagrangian approach. This approach uses
optical ﬂow to estimate the motion difference of frames.
Through spatial registration of background motions, it can
output a video in which subtle motion changes are magni-
ﬁed. However, estimating optical ﬂow in this approach is
computationally expensive and has been investigated as an
unsolved problem [16, 8, 14].

2.2. Learning-based Approach

Recently, a learning-based approach that uses a deep
neural network has been proposed [12]. The network takes
two frames as input with an ampliﬁcation factor and outputs
a new frame, in which subtle changes are magniﬁed. The
implicitly learned motion representations in the network en-
able better noise handling to be achieved than with previous
hand-crafted approaches. However, as this approach often
misses subtle changes due to a strong dependence on a train-
ing dataset, the application range is still limited.

2.3. Eulerian Approach

Unlike the above approaches, our method is based on
the most commonly used Eulerian approach [22, 20, 21, 24,
17]. Eulerian-based methods do not explicitly require ob-
ject tracking and can detect subtle motion changes, as well
as subtle color changes at a ﬁxed position over time. They
ﬁrst decompose image sequences into Gaussian pyramids
for color magniﬁcation [22, 24, 17] or complex-steerable
pyramids (or Riesz pyramids) for motion magniﬁcation
[20, 21, 24, 17], then the signals of each pixel at each pyra-
mid are temporally ﬁltered to detect subtle changes to be
magniﬁed. Although these methods can not distinguish sub-
tle changes and other large object motions in pixels, recently
developed spatio-temporal ﬁltering techniques [24, 17] can
isolate subtle changes from the large motions and selec-
tively magnify them. However, in such subtle changes,
meaningful ones caused by physical and natural phenom-
ena are mixed with non-meaningful ones caused by pho-
tographic noise. Therefore, current methods often produce
noisy and misleading magniﬁcation outputs due to the non-
meaningful subtle changes.

For detecting only meaningful subtle changes, layer-
based methods have been developed [5, 7, 18]. Elgharib
et al. [5] and Verma et al. [18] require a user to select a
region whose subtle changes are magniﬁed. Kooij et al. [7]
proposed a depth-weighted bilateral steerable ﬁlter for au-

1615

tomatically selecting a region to be magniﬁed at the same
depth layer. After the magniﬁcation process, these methods
synthesize the magniﬁed region and other regions to out-
put ﬁnal results. They can magnify only meaningful sub-
tle changes under the presence of photographic noise if a
user knows where they are. However, they require compli-
cated human interventions [5, 18] or an arranged environ-
ment suitable for a depth sensor [7]. Consequently, these
methods are time consuming and error prone.

In contrast, several methods magnify meaningful subtle
changes under the presence of photographic noise without
the aforementioned interventions. By focusing on meaning-
ful motion changes appearing around edges [14], Wadhwa
et al. [20] applied an edge-weighted Gaussian ﬁlter (EWG)
to motion changes spatially in each image pyramid, and
Verma et al. [19] used a local Laplacian ﬁlter (LLP) [13]
to improve pyramid decomposition in video magniﬁcation
methods in terms of edges and details. These methods help
to remove non-meaningful subtle changes in ﬂat textured re-
gions but have limitations in that they can not be applied to
color magniﬁcation or to the removal of them around edges.
Alternatively, Wu et al. [23] adopted PCA to video magniﬁ-
cation as a pre-processing approach. This method can mag-
nify only meaningful subtle changes in video sequences, but
for enabling PCA to work well, it has a limitation that mean-
ingful subtle changes need to be larger than non-meaningful
ones as the principal component in input video scenes.

Our proposed method is more advanced than the afore-
mentioned methods because it can magnify not only mean-
ingful subtle motion changes but also color changes under
the presence of photographic noise without the additional
requirements or input video scene limitations.

3. Methods

We now present the details of our method. First, we ex-
plain our problem deﬁnition and why FA is a useful index to
distinguish meaningful subtle changes and non-meaningful
ones caused by photographic noise. Second, we describe
how we designed our fractional anisotropic ﬁlter that passes
only meaningful subtle changes and ignore non-meaningful
ones. Finally, we show how we applied this ﬁlter to the cur-
rent color or motion magniﬁcation method. We also present
our edge-aware regularization in the motion magniﬁcation
subsection.

3.1. Problem Deﬁnition

Given an input image signal I(x, t) at an image position
x that denotes 2D pixel coordinates and a time t, video mag-
niﬁcation methods [22, 20, 24, 17] attempt to detect subtle
changes B(x, t). However, such subtle changes are often
contaminated by photographic noise as

B(x, t) = ˆB(x, t) + ˜B(x, t),

(1)

Figure 2: The temporal distributions of subtle intensity (top) and
phase changes that represent motion (bottom). When the mean-
ingful subtle intensity changes appear, they are correlated between
neighboring pixels (top green), but do not when photographic
noise only appears (top red). The meaningful subtle phase changes
occur in a vertical direction (bottom green) but in no direction if
they are not meaningful (bottom red). We noticed that temporal
distribution of meaningful subtle changes more clearly indicates
anisotropic diffusion than that of non-meaningful ones caused by
photographic noise (blue arrow representing the trend).

where ˆB(x, t) is meaningful subtle changes and ˜B(x, t) is
non-meaningful ones caused by photographic noise. There-
fore, current methods often produce noisy and misleading
magniﬁcation outputs due to the ˜B(x, t).

3.2. Fractional Anisotropy

Our key idea is based on our observation that temporal
distribution of meaningful subtle changes more clearly indi-
cates anisotropic diffusion than that of non-meaningful ones
because they are subject to the regularity of nature (Fig.2).
We considered that anisotropic diffusion in temporal distri-
bution enables us to detect only meaningful subtle changes
and focused on an index called fractional anisotropy (FA).

FA is used in neuroscience to evaluate anisotropic diffu-
sion of water molecules in the body [11, 2], and its deﬁni-
tion is based on the diffusion equation as

f (g) =

1

(2π)d/2|D|1/2 exp✓ 

1
2

g>D 1g◆ ,

(2)

where f (g) is a probability distribution of water molecules
in directions g 2 Rd, and D is a positive semi-deﬁnite
matrix that represents diffusion strength of the distribution
f (g) along or between directions g. To the best of our
knowledge, on the basis of f (g), FA is deﬁned in 3D case
but we generalize it for multi-dimensional case as

F A := r d

d   1

· qPd
i=1(λi   ¯λ)2
qPd

i=1 λ2
i

,

(3)

i=1 λi.

where (λ1, ..., λd) are eigenvalues of D and ¯λ =
d Pd
1
The eigenvalues of D indicate diffusion
strength to the direction of eigenvectors in original direc-
tions g. q d

d 1 normalizes the FA value between 0 and 1.

1616

phase (motion)change at θ= 0°θ= 90°θ= 180°θ= 270°θ= 0°θ= 90°θ= 180°θ= 270°intensty change (x2)0-0.20.2-0.200.2intensty change (x1)0-0.20.2-0.200.2Intensty changes in light bulb videoPhase changes in wood-splitting video0.20.4Anisotropic diﬀusionIsotropic diﬀusion00intensty change (x2)intensty change (x1)z

(λ1, λ2, λ3)

θ

(1, 1, 1)

O

x

y

Figure 3: Intuitive interpretation of FA in 3D case. FA is pro-
portional to sinθ, where θ is the angle between two vectors,
(λ1, λ2, λ3) which are eigenvalues of D, (1, 1, 1). If all the eigen-
values are equal such as (3, 3, 3), which means isotropic diffusion,
θ is 0 and the FA value is 0. If only one eigenvalue is high such
as (5, 0, 0), which means anisotropic diffusion, θ is maximum and
the FA value is 1.

Moreover, we found intuitive interpretation of FA as fol-
lows: let θ be the angle between two vectors, (λ1, ..., λd),
(1, ..., 1) 2 Rd, we can rewrite the deﬁnition of FA (Eq.3)
as

F A = r d

d   1

· sinθ.

(4)

For proof of this, see the supplementary material. This
equation implies that FA purely evaluates the degree of
match between the eigenvalues without depending on the
magnitude of them. Since the positive semi-deﬁnite matrix
of D makes all the eigenvalues positive, if only one eigen-
value is high, which means anisotropic diffusion, θ is maxi-
mum and FA value is 1, but if all the eigenvalues are equal,
which means isotropic diffusion, θ is 0 and FA value is 0
(Fig.3).

In neuroscience ﬁelds,

it is known that nerve axons
have high FA values due to anisotropic diffusion of water
molecules along their long stick structures, but if their ax-
onal structures injury occurs due to such as a trafﬁc acci-
dent or a neural disease, the probability distribution of water
molecules in the injured area indicates isotropic diffusion
and the FA value becomes lower [11, 2]. Thus, a changing
of FA value sensitively assesses the loss or recovery process
of the shape of nerve cells in humans or animals.

From these ﬁndings, we considered that FA values
strongly respond to meaningful subtle changes compared
with non-meaningful ones, due to the anisotropic diffusion
in temporal distribution of meaningful ones. To visualize
our hypothesis, we show FA values estimated by tempo-
ral distribution of subtle phase changes in ukulele-playing
video (Fig.4). Figure 4 indicates that the FA value is higher
when the meaningful subtle phase changes appear, such as
hand swaying and vibrations of ukulele strings.

3.3. Fractional Anisotropic Filter

On the basis of our knowledge of FA, we designed a
fractional anisotropic ﬁlter. This ﬁlter is designed using FA

High

 

F
A
v
a
u
e

l

Input video

Fractional anisotropy (FA)

Low

Figure 4: Visualizing fractional anisotropy (FA) values. FA values
are estimated by temporal distribution of subtle phase changes and
are high when the meaningful subtle phase changes appear such as
hand swaying and vibrations of ukulele strings.

estimated from diffusion in temporal distribution of subtle
changes so that it will pass only meaningful subtle color or
motion changes, which have high FA values.

First, we get FA value F A(x, t) as follows. Given an
image patch Px = {x1, . . . , xh⇥w} centered at x for a
time period T = {t1, . . . , tN } centered at t, let ytj be a
(h⇥w)-dimensional vector [B(x1, tj), . . . , B(xh⇥w, tj)]>
that represents subtle changes in Px at a time tj . We as-
sume that the N vectors yt1 , . . . , ytN are i.i.d samples from
a temporal distribution f (y) deﬁned as

f (y) =

1

(2π)h⇥w/2|D|1/2 exp✓ 

1
2

y>D 1y◆ .

(5)

Using maximum likelihood estimation method, we estimate
D representing diffusion strength of the temporal distribu-
tion f (y) along or between the image positions in Px as

D = cov ([yt1 , ..., ytN ]) ,

(6)

where cov(X) is the variance-covariance matrix of X.
Then, we get F A(x, t) by using Eq.(3) for Eq.(6).

After calculating F A(x, t), we design the fractional
anisotropic ﬁlter F AF (x, t) with a weight γ for adjusting
the ﬁlter response as

F AFσ,γ(x, t) = (N orm(Gσ ⌦ F A(x, t)))γ ,

(7)

where ⌦ is a convolution operator, Gσ is a 2D Gaussian
ﬁlter with a variance σ2 to smooth ﬁlter responses, and
N orm(X) normalizes X value from 0 to 1. This ﬁlter
has a high value only when anisotropic diffusion in tempo-
ral distribution of subtle changes appears, which means it
can pass only meaningful subtle changes and ignores non-
meaningful ones.

3.4. Video Color Magniﬁcation in the Wild

We present a novel color magniﬁcation method in which
the proposed fractional anisotropic ﬁlter is applied to the
jerk-aware color magniﬁcation method [17]. The jerk
method decomposes input video signal I(x, t) into I l(x, t)
at pyramid level l using a Gaussian pyramid and detects sub-
tle changes Bl

f (x, t) with a desired frequency f as

Bl

f (x, t) = J AF l

f (x, t)   (Hf (t) ⌦ I l(x, t)),

(8)

1617

Input video

Jerk-aware ﬁlter

Fractional anisotropic ﬁlter

Hierarchinal edge-aware regularization
high

F

i
l
t
e
r

r
e
s
p
o
n
c
e

(a) Acceleration

(b) Jerk

(c) Jerk w/ FAF

(d) Our method

(*) Jerk w/ HEAR

+φ

low

 (3.5)

 (3.5.1)

(
v
e
r
t
i
c
a
l
)

 

P
h
a
s
e
c
h
a
n
g
e

-φ

Figure 5: Our motion magniﬁcation method. (a) Acceleration method [24] misdetects quick hand strumming. (b) Jerk method [17] ignores
the quick motion but misdetects non-meaningful subtle phase changes caused by photographic noise. (c) By using fractional anisotropic
ﬁlter (FAF), we can detect only meaningful subtle phase changes of the ukulele strings but slightly misdetects non-meaningful ones in ﬂat
textured areas (purple quadrangles). (d) Our method further applies hierarchical edge-aware regularization (HEAR) to reﬁne them. (*)
Using only HEAR is insufﬁcient for complex areas (purple quadrangles). These results indicate both of FAF and HEAR are needed.

[24],
f (x, t) is the jerk-aware ﬁlter [17], and   is an

where Hf (t) is the temporal acceleration ﬁlter
J AF l
element-wise product. For details, see [17].

However,

these subtle changes often include non-
meaningful ones caused by photographic noise. To de-
tect only meaningful subtle color changes, we design a
fractional anisotropic ﬁlter F AF l
f (x, t)
through Eqs.(5)-(7). After this designing, we obtain the
color magniﬁcation signals ˆI l
f (x, t) with the ampliﬁcation
factor α at each pyramid level l as

f,σ,γ(x, t) from Bl

ˆI l
f (x, t) = I l(x, t) + α(F AF l

f,σ,γ(x, t)   Bl

f (x, t)).

(9)

This process enables us to produce good color magniﬁca-
tion results under the presence of photographic noise.

3.5. Video Motion Magniﬁcation in the Wild

For magnifying subtle motions, we used the jerk-aware
phase-based method [17]. This method is based on the use
of the local phase changes in video that represent local mo-
tion changes [6]. To obtain local phase information, com-
plex steerable ﬁlters ψl
ω,θ, which are sets of ﬁlters with a
motion orientation θ at each spatial scale ω and pyramid
level l, are applied to I(x, t) as

ψl
ω,θ ⌦ I(x, t) = Al

ω(x, θ, t)eiφl

ω(x,θ,t),

(10)

where Al

ω(x, θ, t) is amplitude and φl

ω(x, θ, t) is phase.

we design the fractional anisotropic ﬁlter F AF l
about the subtle phase changes C l

f,ω(x, θ, t) as follows.

f,ω,σ,γ(x, t)

We consider an image patch Px for a time period
T such as that described in Section 3.3 and orienta-
tions Θ = {θ1, . . . , θM }.
Since phase changes oc-
cur along or between the orientations in Θ and the sub-
tle phase changes C l
f,ω(x, θ, t) are similar within the
image patch Px,
let yxi,tj be a M -dimensional vector

f,ω(xi, θM , tj)i>

hC l
f,ω(xi, θ1, tj), . . . , C l

that represents
the subtle phase changes in a position xi 2 Px at a time tj .
We assume that the N ⇥h⇥w vectors yx1,t1 , . . . , yxh×w,tN
are i.i.d samples from a temporal distribution f (y) deﬁned
as Eq.(5). Then, using Eqs.(6)-(7), we design the phase-
based fractional anisotropic F AF l

f,ω,σ,γ(x, t).

After this designing, we can obtain the synthesis phase
information in which meaningful subtle phase changes are
only magniﬁed as

f,ω,σ,γ(x, t)   C l

f,ω(x, θ, t)). (12)

ˆφl
ω(x, θ, t) = φl
Figure 5 (c) shows that F AF l

ω(x, θ, t) + α(F AF l

f,ω,σ,γ(x, t) can pass only
meaningful phase subtle changes of ukulele strings and ig-
nore non-meaningful ones caused by photographic noise.
However, as the reliability of phase changes are low in ﬂat
textured areas [20, 19], F AF l
f,ω,σ,γ(x, t) has errors and
slightly misdetects non-meaningful subtle phase changes in
the ﬂat areas (Fig. 5 (c), purple quadrangles).

phase changes C l

After obtaining the phase information, we detect subtle
f,ω(x, θ, t) with a desired frequency f as
ω(x, θ, t)  ,

f,ω(x, θ, t)   Hf (t) ⌦ φl

(11)
f,ω(x, θ, t) is the jerk-aware ﬁlter with pyra-

f,ω(x, θ, t) = pJ AF l

where pJ AF l
mid correction [17]. For details, see [17].

C l

3.5.1 Hierarchical Edge-Aware Regularization

For reﬁning the subtle phase changes, we use amplitude
information Al
ω in the same way as the previous technique
[20]. However, since this technique [20] uses only ampli-
tude information at each pyramid level l, we develop hier-
archical amplitude correction via z-transform as

However,

these subtle phase changes include non-
meaningful ones. To detect only the meaningful ones,

1618

ˆAl

ω = max

 Nl5i5Nl

(Z(Al

ω), res(Z(Al+i

ω ), l)),

(13)

where Nl is the number of the pyramid level l used for this,
Z(A) converts A into z-scores that are comparable between
each pyramid level l, and res(Al+i, l) resizes the amplitude
information at the pyramid level l+i to that at pyramid level
l with bicubic interpolation.

Furthermore, as the previous technique [20] adopts
amplitude-based smoothing but is weak in regularizing ﬂat
textured areas due to its use of smoothing alone, we propose
a new strong regularization technique HEARσ(x, θ, t) as

HEARσ(x, θ, t) = N orm(Gσ ⌦ ˆAl

ω(x, θ, t)),

(14)

where N orm(X) and Gσ are the same functions in Eq.(7).
By applying this regularization to Eq.(12), we can reﬁne
meaningful subtle phase changes as shown in Figure 5 (d).

Video
Slam dunk
Ukulele
Face
Wood
Gun
Tennis
Synthetic ball
Golf
Drone

α
200
260
180
230
100
180
100
80
300

f
2
40
0.5
2
20
10
10
2
2

f s
120
240
60
120
480
600
60
60
60

β
1
1

0.001

3
0.5
1
1
0.8
1

γ
2
5
3
2
1
1
2
2
3

source

[1]
[17]
[22]
[1]
[17]
[1]
-
[1]
[17]

Table 1: Parameters for all videos: ampliﬁcation factor α in our
method (this parameter in other methods was adjusted to magnify
meaningful subtle changes as much as ours), target frequency f ,
sampling rate f s, large motions suppression parameter β in the
jerk method [17], and hyper parameter γ in Eq.(7).

4. Results

4.1. Experimental Setup

To evaluate the usefulness of our proposed method,
which magniﬁes only meaningful subtle changes under the
presence of photographic noise, we conducted experiments
on real videos and synthetic ones with ground-truth magni-
ﬁcation. We assessed the performance qualitatively for real
videos and quantitatively against ground-truth for synthetic
ones. We set the parameters for each experiment as listed
in Table 1, but σ in Eqs.(7, 14) are equal to the spatial ﬁlter
widths used to construct image pyramids. We show all the
magniﬁcation results in the supplementary material.

Color Magniﬁcation. We used a Gaussian pyramid to de-
compose each video frame into multi-scales and magniﬁed
the green color intensity changes on the ﬁfth pyramid level.

Motion Magniﬁcation. We performed each method in YIQ
color space. To obtain amplitude and phase information
from input video, we used a complex steerable pyramid [20]
with half-octave bandwidth ﬁlters and 8 orientations. We set
parameter N in jerk method [17] as 5 and Nl in Eq.(13) as
2. For designing a fractional anisotropic ﬁlter (Eq.(7)), we
set the size of Px as 5x5, and T as the same sampling time
used to detect subtle changes with the target frequency f .

4.2. Real Videos

We compared our proposed method with two state-of-
the-art methods, acceleration [24] and jerk methods [17],
both of which can perform color or motion magniﬁcation
without user annotations or additional information in the
same way as our method.

4.2.1 Comparison with Color Magniﬁcation

Figure 6 illustrates subtle face color changes due to
blood ﬂow through the face of a stationary man. Pro-

time

y

Original

(a) Acceleration

(b) Jerk

(c) Ours

Figure 6: Color magniﬁcation at blood ﬂow through the face of
a stationary man. Our proposed method magniﬁes only meaning-
ful subtle face color changes (bottom), while acceleration [24] and
jerk methods [17] misdetect and magnify non-meaningful back-
ground color ﬂuctuations caused by photographic noise (top).

cessing this video with acceleration [24] or jerk methods
[17] succeeds in magnifying meaningful subtle face color
changes on the face, but it also misdetects and magniﬁes
non-meaningful background color ﬂuctuations caused by
photographic noise. In contrast, our proposed method mag-
niﬁes only meaningful subtle face color changes.

4.2.2 Comparison with Motion Magniﬁcation

Figure 1 shows the motion magniﬁcation results from a
basketball video, to magnify and reveal the subtle deforma-
tions of the backboard when trying to absorb the impact of
a slam dunk for preventing breakage. Acceleration method
[24] does not work well due to the misdetection of the quick
ball motion. Jerk method [17] magniﬁes meaningful sub-
tle deformation of the backboard but also misdetects non-
meaningful subtle shape collapses of background window
caused by photographic noise.
In contrast, our proposed
method magniﬁes only meaningful subtle deformations of
the backboard without the effects of noise.

Figure 7 shows a video sequence on the ability of a
wood-splitting stand to absorb the shock from a hand axe
for preventing injury. Acceleration method [24] produces
messy result due to the quick downswing of the hand
axe. Jerk method [17] can magnify subtle deformations of
the wood-splitting stand but produces pixel intensity dis-
turbances due to non-meaningful background ﬂuctuations

1619

)
n
o
i
t
i
s
o
p
 
t
o
d
w
o

 

l
l

 

y
t
i
s
n
e
t
n

I
 
l

e
x
i
P

e
y
(

time

y

95

90

85

80

75

0

Original
Acceleration
Jerk
Ours

Original
Acceleration
Jerk
Ours

130

128

124

120

116

 

y
t
i
s
n
e
t
n

I
 
l

e
x
i
P

)
n
o
i
t
i
s
o
p
 
t
o
d
e
p
r
u
p
(

l

 

10

20

30

50

40
60
Frame Number

70

80

90

100

time

y

0

20

40

60

80

100

120

140

160

180

Frame Number

Original

(a) Acceleration

(b) Jerk

(c) Ours

Original

(a) Acceleration

(b) Jerk

(c) Ours

Figure 7: Wood-splitting video: visualizing deformations of a
wood-splitting stand. The graph shows pixel intensity changes
at yellow dot in top left. Our proposed method magniﬁes only
meaningful subtle deformations of the wood-splitting stand, while
acceleration method [24] misdetects the quick downswing of hand
axe (cyan circle) and jerk method [17] produces pixel intensity dis-
turbance due to non-meaningful background ﬂuctuations (graph).

time

r
o

x
y

Original

time

y

Original

Jerk

Learning

Ours

Jerk

Learning

Ours

Figure 8: Gun-shooting video: visualizing gun-shooting impact
spreading throughout body. Our method magniﬁes only mean-
ingful subtle arm deformations (left bottom) but jerk method [17]
misdetects background distortions caused by photographic noise
(right top) and learning method [12] induces disappearance of the
tip of the gun due to quick gun recoil motions (right bottom).

caused by photographic noise. Our method magniﬁes only
meaningful subtle deformations of the wood-splitting stand
under the presence of photographic noise.

Figure 8 shows a gun-shooting video. In this video, we
also tested a state-of-the-art learning method [12] with a
5⇥ dynamic mode.
Jerk method [17] misdetects distor-
tions of background caused by photographic noise. Learn-
ing method [12] also misdetects them slightly and induces
disappearance of the tip of the gun due to quick gun recoil
motions. Our method magniﬁes only meaningful subtle de-
formations of muscles and skin due to the gun-shooting im-
pact spreading throughout the body.

Figure 9 shows a ball-hitting video with magniﬁcation
of impact spreading throughout a tennis racket. Acceler-
ation method [24] produces racket shape collapse due to
the quick swing motion. Jerk method [17] magniﬁes subtle
racket deformations when the ball is hit but induces pixel
intensity disturbances due to non-meaningful background
ﬂuctuations caused by photographic noise. In contrast, our
method magniﬁes only meaningful deformations related to
sport activities under the presence of photographic noise.

Figure 9: Tennis video: visualizing impact spreading throughout a
tennis racket. Our method magniﬁes only meaningful subtle tennis
racket deformations, but acceleration [24] and jerk methods [17]
produce pixel intensity disturbance due to non-meaningful back-
ground ﬂuctuations caused by photographic noise (graph).

4.3. Controlled Experiments

In this section, we quantitatively assess the effective-
ness of our method using peak signal-to-noise ratio (PSNR)
between magniﬁed synthetic video by each magniﬁcation
method and the ground-truth. Figure 10 (top left) shows a
4-second synthetic ball video with background texture from
the Describable Textures Dataset [4]. The ball has vertical
meaningful subtle motions deﬁned as d = 0.5·sin(2π f
f s j),
where j is the frame number. When j reaches 80 frames,
the ball moves quickly and horizontally as dq = 100 ·
sin(2π 2
j), but after 20 frames the ball movement returns
fs
to what it was before. Moreover, Gaussian noise with an
average of 0 and standard deviation σn of 0–0.1 was added
to only the background in videos as the photographic noise
that causes non-meaningful subtle motions. To obtain the
ground-truth of meaningful subtle motion magniﬁcation,
we created magniﬁcation videos while changing d to 5 · d.
Note that to investigate the effectiveness of our proposed
method precisely, we prepared ﬁve additional methods: a
jerk method with EWG proposed by [20], a jerk method
with PCA, a jerk method with FAF, a jerk method with No-
hierarchical edge-aware regularization as EARσ(x, θ, t) =
N (Gσ ⌦ Al

ω(x, θ, t)), and a jerk method with HEAR.

Figure 10 right shows PSNR in each area and each back-
ground, at the real noise level σn = 0.005 estimated by [9].
In the ball area, Eulerian-based methods [19, 23], accel-
eration method [24] and learning method [12] suffer from
handling quick motion and produce low PSNR, but all jerk
based methods that contain our proposed method magnify
only meaningful subtle motion and have high PSNR except
for jerk method with PCA, which can not magnify mean-
ingful ones due to large non-meaningful ones regarded as
a principal component. On the other hand, in the noise
area, jerk method produces very low PSNR due to non-
meaningful ones magniﬁed by the large ampliﬁcation factor
compared with acceleration method [24]. Jerk method with
EWG [20], PCA, our proposed FAF, and HEAR ignore non-
meaningful ones and increase PSNR compared with jerk

1620

Background 1(BG 1)

noise area

ball area

noise area

eulerian w/ LLP
(Verma et al., 2018)
eulerian w/ PCA
(Wu et al., 2018)
learning
(dynamic mode)
acceleration
jerk
jerk w/ EWG
jerk w/ PCA
jerk w/ FAF
jerk w/ EAR
jerk w/ HEAR
ours

R
N
S
P

)
a
e
r
a

 
l
l

a
b
(

R
N
S
P

 

)
a
e
r
a
e
s
i
o
n
(

R
N
S
P

)
a
e
r
a

 
l

a
t
o
t
(

45

35

25

46

40

34

46

40

34

28

BG 1

BG 2

BG 3

BG 4

BG 5

BG 6

45

35

25

55

45

35

25

)
a
e
r
a

 
l
l

a
b
(
 
R
N
S
P

 

)
a
e
r
a
e
s
i
o
n
(
 
R
N
S
P

)
a
e
r
a

 
l

a
t
o
t
(
 
R
N
S
P

50

40

30

20

1e-1

0

real noise levels estimated 
by Liu et al. CVPR (2006)
{

eulerian w/ LLP
eulerian w/ PCA
learning
acceleration
jerk
jerk w/ EWG

jerk w/ PCA
jerk w/ FAF
jerk w/ EAR
jerk w/ HEAR
ours

1e-4

1e-3

1e-2
Noise Level (σn)

1e-1

0 1e-4

1e-3

1e-2

Noise Level (σn)

Figure 10: Left: synthetic ball video with background. The ball
has meaningful subtle motion (red arrow) and quick motion (yel-
low arrow). Noise is added only to background and causes non-
meaningful subtle motion. Right: PSNR at σn = 0.005. Our
proposed method magniﬁes only meaningful subtle ball motions
under the presence of noise and has the highest PSNR in the total
area despite the complex background textures.

method [17] but all of these are insufﬁcient. Our proposed
method, which considers anisotropic diffusion in tempo-
ral distribution by FAF and hierarchical amplitude informa-
tion by HEAR, ignores non-meaningful ones very well and
has high PSNR in the noise area. After all, our proposed
method magniﬁes only meaningful subtle ball motion un-
der the presence of noise and has the highest PSNR in the
total area despite the complex background textures.

Figure 11 shows the effect of noise variance σn on the
average of PSNR for all the background videos.
In the
ball area, each magniﬁcation method maintains almost the
same PSNR. However, jerk method with PCA can not do
so because the principal component in video is switched
from meaningful subtle motions to non-meaningful ones
when σn = 0.005. In the noise area, PSNR in all meth-
ods gets lower in proportion to the noise increase. How-
ever, if we compare each magniﬁcation method for the to-
tal area, our proposed method resists the effect of noise in-
crease and has the highest PSNR in the real noise situations
(σn = 0.005, 0.01). Thus, our method produces the best
meaningful and non-misleading magniﬁcation results.

5. Discussion and Limitations

Our proposed method expands the applicable range
of video magniﬁcation by detecting and magnifying only
meaningful subtle changes under the presence of photo-
graphic noise but has some limitations below.

Our proposed fractional anisotropic ﬁlter can detect only
meaningful subtle changes, but it relies on the assump-
tion that the temporal distribution of non-meaningful ones
caused by photographic noise indicates isotropic diffusion.
In real videos, such a characteristic like Gaussian distribu-

Figure 11: The effect of noise variance σn on PSNR for all the
background videos on average.
In the total area, our proposed
method resists noise increase and has the highest PSNR in the real
noise situations [9].

tion often occurs but other ones also need to be considered:
gamma, exponential, uniform, impulse, and so on [3]. Thus,
we should handle such characteristics to expand the appli-
cable range of video magniﬁcation in future work.

time, and pyramid level.

If an input video size is large, our method has slow
running time due to the eigen-decomposition at each po-
sition,
If one wants to pre-
cisely reveal meaningful subtle changes and show the re-
sults, our method should be used to prevent magniﬁed non-
meaningful changes that may be misleading. However, a
faster algorithm for our method needs to be developed.

Moreover, empirical estimation of covariance in FA of
our method is not robust to outliers under the Gaussian as-
sumption in Eq.(2). To increase the robustness, we consider
that a minimum covariance determinant approach [15] can
be useful. Even so, we should develop a simple and princi-
pled approach as a substitute for using FA in future work.

6. Conclusions

We proposed a novel video magniﬁcation method for de-
tecting and magnifying only meaningful subtle changes un-
der the presence of noise introduced during photographic
process, without the user annotations, additional informa-
tion, or input video scene limitations that previous meth-
ods required [5, 18, 7, 20, 19, 23].
In developing our
method, we presented a novel use of the index in neuro-
science called fractional anisotropy to detect only mean-
ingful subtle changes, and a hierarchical edge-aware reg-
ularization to reﬁne motion representations. Our proposed
method detects only meaningful subtle changes and ignores
non-meaningful ones caused by photographic noise, and
produces impressive magniﬁcation results exceeding those
obtained with state-of-the-art methods. The results we ob-
tained demonstrate that we succeeded in expanding the ap-
plicable range of ”video magniﬁcation in the wild.”

1621

[17] Shoichiro Takeda, Kazuki Okami, Dan Mikami, Megumi
Isogai, and Hideaki Kimata. Jerk-aware video acceleration
magniﬁcation. In The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2018. 1, 2, 3, 4, 5, 6, 7, 8
[18] Maninsha Verma and Shanmuganathan Raman. Interest re-

gion based motion magniﬁcation. ICIAP, 2017. 2, 3, 8

[19] Manisha Verma and Shanmuganathan Raman. Edge-aware
spatial ﬁltering-based motion magniﬁcation. In Proceedings
of 2nd International Conference on Computer Vision & Im-
age Processing, pages 117–128, Singapore, 2018. Springer
Singapore. 2, 3, 5, 7, 8

[20] Neal Wadhwa, Michael Rubinstein, Fr´edo Durand, and
William T Freeman. Phase-based video motion processing.
SIGGRAPH, 2013. 1, 2, 3, 5, 6, 7, 8

[21] Neal Wadhwa, Michael Rubinstein, Fr´edo Durand, and
William T. Freeman. Riesz pyramids for fast phase-based
video magniﬁcation. In The IEEE International Conference
on Computational Photography (ICCP), 2014. 1, 2

[22] Hao-Yu Wu, Michael Rubinstein, Eugene Shih, John Guttag,
Fr´edo Durand, and William Freeman. Eulerian video mag-
niﬁcation for revealing subtle changes in the world. SIG-
GRAPH, 2012. 1, 2, 3, 6

[23] Xiu Wu, Xuezhi Yang, Jing Jin, and Zhao Yang. Pca-based
magniﬁcation method for revealing small signals in video.
Signal, Image and Video Processing, 12:1293–1299, 2018.
2, 3, 7, 8

[24] Yichao Zhang, Silvia L. Pintea, and Jan C. van Gemert.
Video acceleration magniﬁcation. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), 2017.
1, 2, 3, 5, 6, 7

References

[1] www.videoblocks.com. 6

[2] Andrew L. Alexander, Jee Eun Lee, Mariana Lazar, and
Aaron S. Field. Diffusion tensor imaging of the brain. Neu-
rotherapeutics, 4(3):316–329, Jul 2007. 2, 3, 4

[3] Ajay Boyat and Brijendra Joshi. A review paper: Noise mod-
els in digital image processing. Signal and Image Processing
: An International Journal (SIPIJ), 2015. 8

[4] M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, , and A.
Vedaldi. Describing textures in the wild.
In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), 2014. 7

[5] Mohamed A. Elgharib, Mohamed Hefeeda, Fr´edo Durand,
and William T. Freeman. Video magniﬁcation in presence of
large motions. In The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2015. 2, 3, 8

[6] David J Fleet and Allan D Jepson. Computation of compo-
nent image velocity from local phase information. Interna-
tional journal of computer vision, 5(1):77–104, 1990. 5

[7] Julian FP Kooij and Jan C van Gemert. Depth-aware motion
In The European Conference on Computer

magniﬁcation.
Vision (ECCV), 2016. 2, 3, 8

[8] Till Kroeger, Radu Timofte, Dengxin Dai, and Luc Van Gool.
Fast optical ﬂow using dense inverse search. In The Euro-
pean Conference on Computer Vision (ECCV), 2016. 2

[9] Ce Liu, William T. Freeman, Richard Szeliski, and Sing Bing
Kang. Noise estimation from a single image. In The IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), 2006. 7, 8

[10] Ce Liu, Antonio Torralba, William T. Freeman, Fr´edo Du-
rand, and Edward H. Adelson. Motion magniﬁcation. SIG-
GRAPH, 2005. 2

[11] Susumu Mori and Jiangyang Zhang. Principles of diffusion
tensor imaging and its application to basic neuroscience re-
search. Neuron, 51:527–539, 2006. 2, 3, 4

[12] Tae-Hyun Oh, Ronnachai Jaroensri, Changil Kim, Mohamed
Elgharib, Fr´edo Durand, William T Freeman, and Wojciech
Matusik. Learning-based video motion magniﬁcation. In The
European Conference on Computer Vision (ECCV), 2018. 2,
7

[13] Sylvain Paris, Samuel W. Hasinoff, and Jan Kautz. Local
laplacian ﬁlters: Edge-aware image processing with a lapla-
cian pyramid. ACM Transactions on Graphics (ACM TOG).
3

[14] Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui,
Cordelia Schmid, Jerome Revaud, Philippe Weinzaepfel,
Zaid Harchaoui, and Cordelia Schmid Epicﬂow Edge.
Epicﬂow : Edge-preserving interpolation of correspondences
for optical ﬂow. In The IEEE Conference on Computer Vi-
sion and Pattern Recognition (CVPR), 2015. 2, 3

[15] Peter J. Rousseeuw. Least median of squares regression.

Journal of the American Statistical Association, 1984. 8

[16] Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz.
Pwc-net: Cnns for optical ﬂow using pyramid, warping, and
cost volume. In The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), June 2018. 2

1622

