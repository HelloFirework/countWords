FilterReg: Robust and Efﬁcient Probabilistic Point-Set Registration

using Gaussian Filter and Twist Parameterization

Wei Gao

Russ Tedrake

Massachusetts Institute of Technology

Massachusetts Institute of Technology

weigao@mit.edu

russt@mit.edu

Abstract

Probabilistic point-set registration methods have been
gaining more attention for their robustness to noise, out-
liers and occlusions. However, these methods tend to be
much slower than the popular iterative closest point (ICP)
algorithms, which severely limits their usability. In this pa-
per, we contribute a novel probabilistic registration method
that achieves state-of-the-art robustness as well as substan-
tially faster computational performance than modern ICP
implementations. This is achieved using a rigorous yet
computationally-efﬁcient probabilistic formulation. Point-
set registration is cast as a maximum likelihood estimation
and solved using the EM algorithm. We show that with a
simple augmentation, the E step can be formulated as a ﬁl-
tering problem, allowing us to leverage advances in efﬁcient
Gaussian ﬁltering methods. We also propose a customized
permutohedral ﬁlter [1] for improved efﬁciency while re-
taining sufﬁcient accuracy for our task. Additionally, we
present a simple and efﬁcient twist parameterization that
generalizes our method to the registration of articulated and
deformable objects. For articulated objects, the complexity
of our method is almost independent of the Degrees Of Free-
dom (DOFs). The results demonstrate the proposed method
consistently outperforms many competitive baselines on a
variety of registration tasks. The video demo and source
code are available on our project page.

1. Introduction

Point-set registration is the task of aligning two point
clouds by estimating their relative transformation. This
problem is an essential component for many practical vision
systems, such as SLAM [27], object pose estimation [20],
dense 3d reconstruction [40], and interactive tracking of ar-
ticulated [24] and deformable [12] objects.

The ICP [3] algorithm is the most widely used method
for this task. ICP alternatively establishes nearest-neighbor
correspondences and minimizes the point-pair distances.

With spatial indices such as the KD-tree, ICP provides rel-
atively fast performance. The literature contains many vari-
ants of the ICP algorithm; [28] and [29] provide a thorough
review and comparison.

Despite its popularity, the ICP algorithm is suscepti-
ble to noise, outliers and occlusions. These limitations
have been widely documented in the literature [9, 25, 15].
Thus, a great deal of research has been done on the use of
probabilistic models for point-set registration [25, 14, 13],
which can in principle provide better outlier-rejection. Ad-
ditionally,
is given a Gaussian variance,
the point cloud can be interpreted as a Gaussian Mixture
Model (GMM). Most statistical registration methods are
built on the GMM and empirically provide improved ro-
bustness [25, 15, 10]. However, these methods tend to be
much slower than the ICP and can hardly scale to large point
clouds, which severely limits their practical usability.

if each point

In this paper, we present a novel probabilistic registra-
tion algorithm that achieves state-of-the-art robustness as
well as substantially faster computational performance than
modern ICP implementations. To achieve it, we propose
a computationally-efﬁcient probabilistic model and cast the
registration as a maximum likelihood estimation, which can
be solved using the EM algorithm. With a simple augmen-
tation, we formulate the E step as a ﬁltering problem and
solve it using advances in efﬁcient Gaussian ﬁlters [1, 5, 2].
We also present a customized permutohedral ﬁlter [1] with
improved efﬁciency while retaining sufﬁcient accuracy for
our task. Empirically our method is as robust as state-of-
the-art GMM-based methods, such as [25]. In terms of the
speed, our method with CPU is 3-7 times faster than modern
ICP implementations and orders of magnitude faster than
typical robust GMM-based methods. Furthermore, the pro-
posed method can be GPU-parallelized and is 7 times faster
than the CPU implementation.

Additionally, we propose a simple and efﬁcient twist pa-
rameterization that extends our method to articulated and
node-graph [17] deformable objects. Our method is easy
to implement and achieves substantial speedup over direct
parameterization. For articulated objects, the complexity

111095

of our method is almost independent of the DOFs, which
makes it highly efﬁcient even for high-DOF systems. Com-
bining these components, we present a robust, efﬁcient and
general registration method that outperforms many compet-
itive baselines on a variety of registration tasks. The video
demo, supplemental document and source code are avail-
able on our project page.

2. Related Work

The problem of point set registration is extensively pur-
sued in computer vision and an exhaustive review is pro-
hibitive.
In the following text, we limit our discussion
to GMM-based probabilistic registration and review them
roughly according to their underlying probabilistic models.
The earliest statistical methods [30, 21, 23, 14] implic-
itly assumed the model points, which is controlled by the
motion parameters (such as the rigid transformation or joint
angles), induce a GMM distribution over the 3d space.
The observation points are independently sampled from this
distribution. Later, several contributions [25, 32, 15] de-
rived the EM procedure rigorously from the aforementioned
probabilistic model. This formulation has also been applied
to the registration of multi-rigid [10], articulated [42, 15]
and deformable [25, 32] objects.

Another type of algorithms is known as the correlation-
based methods [38, 16, 4, 33]. These algorithms treat both
observation points and model points as probabilistic dis-
tributions. The point-cloud registration can be interpreted
as minimizing some distance between distributions, for in-
stance the KL-divergence. To improve the efﬁciency, tech-
niques such as voxelization [33] or Support Vector Ma-
chine [4] are used to create compact GMM representations.
In this paper, we assume that the observation points
induce a probabilistic distribution over the space.
Intu-
itively, the registration is to move the model points to po-
sitions with large posterior probability, subject to kinematic
constraints. This formulation is related to several existing
works [9, 22, 25], and a more technical comparison is pre-
sented in Sec. 3.2. In addition to the formulation, the key
contribution of our work includes the introduction of the
ﬁlter-based correspondence and twist parameterization built
on the probabilistic model, as mentioned in Sec. 1. Combin-
ing these components, the proposed method is general, ro-
bust and efﬁcient that outperform various competitive base-
lines.

3. Probabilistic Model for Registration

3.1. Probabilistic Formulation

the motion parameter θ. Another point set Y is deﬁned as
the observation, which is ﬁxed during the registration.

We are interested in the joint distribution p(X, Y, θ). We
assume given model geometry X, the observation Y is in-
dependent of θ, and the joint distribution p(X, Y, θ) can be
factored as

p(X, Y, θ) ∝ φkinematic(X, θ)φgeometric(X, Y )

(1)

where φgeometric(X, Y ) is the potential function that encodes
the geometric relationship, and the potential φkinematic(X, θ)
encodes the kinematic model. The φkinematic(X, θ) can en-
code hard constraints such as X = X(θ) and/or soft motion
regularizers, for instance the smooth terms in [25, 26] and
the non-penetration term in [32].

We further assume the kinematic model φkinematic(X, θ)
has already captured the dependency within model points
X. Thus, conditioned on the motion parameter θ, the points
in X are independent of each other. The distribution can be
further factored as

p(X, Y, θ) ∝ φkinematic(X, θ)

M

Y

i=1

φgeometric(xi, Y )

(2)

A factor graph representation of our model is shown in
Fig. 1. With these factorization schemes, the conditional
distribution can be written as

p(X, θ|Y ) ∝ φkinematic(X, θ)

M

Y

i=1

φgeometric(xi|Y )

(3)

Following several existing work [9, 25], we let the geomet-
ric distribution of each model point φgeometric(xi|Y ) be a
GMM,

φgeometric(xi|Y ) =

N +1

X

j=1

P (yj)p(xi|yj)

(4)

where p(xi|yj) = N (xi; yj, Σxyz) is the Probability Den-
sity Function (PDF) of the Gaussian distribution, yj is the
Gaussian centroid and Σxyz = diag(σ2
z ) is the diag-
onal covariance matrix. An additional uniform distribution
p(xi|yN +1) = 1
M is added to account for the noise and out-
liers. Similar to [25], we use equal membership probabili-
ties P (yj) = 1
N for all GMM components, and introduce a
parameter 0 ≤ w ≤ 1 to represent the ratio of outliers.

x, σ2

y, σ2

We estimate the motion parameter θ and model points X

by maximizing the following log-likelihood,

L =

M

X

i=1

log(

N +1

X

j=1

P (yj)p(xi(θ)|yj))

(5)

In this subsection, we present our probabilistic model for
point-set registration. We use X, Y to denote the two point
sets, x1, x2, ..xM and y1, y2, ..., yN are points in X and Y .
We deﬁne the model X as the point set that is controlled by

here we restrict ourselves to the kinematic model X =
X(θ) and leave the general case to supplemental materi-
als. We use the EM [7] algorithm to solve this optimization.
The EM procedure is

11096

E step: For each xi, compute

M 0

M 1

xi = X
xi = X

yk

yk

N (xi(θold); yk, Σxyz)

N (xi(θold); yk, Σxyz)yk

M step: minimize the following objective function
M 1
xi
M 0
xi

M 0
xi
xi + c

xyz(xi(θ) −

M 1
xi
M 0
xi

(xi(θ) −

)T Σ−1

X

M 0

xi

(6)

)

(7)

where M 0
xi

and M 1
xi

are computed in the E step (6), c =
N
M is a constant, and w is the parameter that represents

w

1−w
the ratio of outliers.

The EM procedure is conceptually related to ICP. The
weight-averaged target point (M 1
xi ) replaces the near-
est neighbour in ICP, and each model point is weighted by

xi /M 0

M 0

Xi

Xi

+c . Intuitively, the averaged target provides robustness
M 0
to noise in observation, while the weight for each model
point should reject outliers in the model. Please refer to
supplemental materials for the complete derivation.

3.2. Discussion and Comparison

At a high level, the proposed formulation can be viewed
as an “inverse” of Coherent Point Drift (CPD) [25] and
many similar formulations [10, 32, 15], as shown in Fig. 1.
CPD [25] assumes the observation points are independently
distributed according to a GMM introduced by model
points, while the proposed formulation directly assumes the
observation points induce a GMM over the space. Empiri-
cally, both methods are very robust to noise and outliers and
signiﬁcantly outperform ICP.

On the perspective of computation, the proposed method
is much more simple and efﬁcient than CPD [25] and sim-
ilar formulations [10, 32, 15]. The proposed method only
requires sum over Y (6), while CPD [25] requires sum over
both Y and X. Moreover, if a spatial index is used to per-
form this sum, CPD [25] must rebuild the index every EM
iteration as the model points X are updated. In our formu-
lation, we only need to build the index once if the variance
is ﬁxed during EM iterations, which is sufﬁcient for many
applications [32, 39].

Several existing works [9, 22] also build a GMM rep-
resentation of the observation points. Compared with our
method, they do not explicitly account for the outlier dis-

M 0

Xi

Xi

M 0

tribution and miss the weight

+c . Furthermore, these
methods assume each model point is only correlated with
one or several “nearest” GMM centroids, while conceptu-
ally we assume each model point is correlated with all ob-
servation GMM centroids. Additionally, combined with the
ﬁlter-based correspondence and twist parameterization in
Sec. 4 and Sec. 5, our method tends to be much faster than
these works, as demonstrated by our experiments.

Figure 1. An illustration of the proposed probabilistic model. Top:
at a high level, the proposed formulation assumes the observation
Y introduces a probabilistic distribution, while CPD [25] assumes
the model X introduces a distribution controlled by the motion
parameter θ. Bottom: factor graph representations of both our
formulation and the formulation of CPD [25].

3.3. Several Extensions

The presented probabilistic formulation can be extended
to incorporate many well-established GMM-based registra-
tion techniques. Additionally, these extensions can be ef-
ﬁciently computed in a uniﬁed framework using the ﬁlter-
based E step in Sec. 4 and the twist-based M step in Sec. 5.
We select the optimized variance proposed in [25], feature
correspondence in [32] and point-to-plane residual in [6] as
three practically important examples, although many other
methods can also be integrated in a very similar way.

Features: Currently in the E step (6), only the 3d position
is used to measure the similarity between the model and ob-
servation points. Similar to [32], the E step can be extended
to incorporate features such as normal, SHOT [37], learned
features [31] or their concatenation. The E step for arbitrary
feature is

M 0

M 1

xi = X
xi = X

yk

yk

N (fxi ; fyk , Σf )

N (fxi ; fyk , Σf )yk

(8)

where fxi and fyk are the feature value for point xi and yk,
Σf is the diagonal covariance for the feature.

Optimized Variance: In our previous formulation, the vari-
ance of Gaussian kernel Σxyz is used as a ﬁxed parameter.
Similar to CPD [25], if Σxyz = diag(σ2, σ2, σ2), the vari-
ance σ can be interpreted as a decision variable and opti-
mized analytically. Please refer to supplemental materials
for the detailed formula and derivation.
Point-to-Plane Distance: The objective in our M step (7) is
similar to the point-to-point distance in ICP, which doesn’t
capture the planar structure. A simple solution is to com-
pute a normal direction to characterize the local planar

11097

structure in the vicinity of the target (M 1

xi )
N (xi; yk, Σxyz)Nyk )/M 0
xi

xi /M 0

Nxi = (X

yk

(9)

where Nyk is the normal of the observation point yk. The
objective in the M step is then a point-to-plane error

M 0
xi
xi + c

M 0

X

xi

dot(Nxi , xi(θ) −

M 1
xi
M 0
xi

)2

(10)

4. E Step: Filter-based Correspondence

4.1. General Formulation

In this section, we discuss the method to compute the E
step (6) and several extensions (8 and 9). These speciﬁc E
steps can be written into the following generalized form

G(fxi ) = X

yk

1

2 (fxi

−fyk )2

e−

vyk

(11)

and M 1
xi

where vyk generalizes the 3d position yk and the unit weight
in (6, 8) and the normal Nyk in (9). The G(fxi ) generalizes
M 0
in (6, 8) and the normal Nxi in (9). The
xi
features fxi and fyk generalize 3d positions xi and yk in the
Gaussian PDF N (xi; yk, Σxyz). The features fxi and fyk
are normalized to have identity covariance. We also omit
the normalization constant det(2πΣxyz)−
2 of the Guassian
PDF N (xi; yk, Σxyz) for notational simplicity.

1

Equ. (11) is known as the general Gaussian Transform
and the Improved Fast Gaussian Transform (IFGT) [41] is
proposed for it. However, IFGT [41] uses a k-means tree
internally and there would be too many k-means centroids
for typical parameters in the registration. Practically, [41]
is not much faster than brute-force evaluation for our task.

We instead propose to compute (11) using Gaussian ﬁl-
tering algorithms [5, 1, 2], which demonstrate promising
accuracy and efﬁciency on image processing. The ﬁltering
operation that these algorithms accelerated is

G(fyi ) = X

yk

1

2 (fyi

−fyk )2

e−

vyk

(12)

which is a subset of the general Gaussian transform:
the
feature fyi used to retrieve the ﬁltered value G(fyi ) must
be included in the input point set Y .

In our case, we would like to retrieve the value G(fxi )
using feature fxi from another point cloud X, which cannot
be directly expressed in (12). To resolve it, we propose the
following augmented input:

Fﬁlter-input = [FX , FY ]
Vﬁlter-input = [0,
VY ]

(13)

where FX = [fx1 , fx2 , ..., fxM ], FY = [fy1 , fy2 , ..., fyN ]
and VY = [vy1 , vy2 , ..., vyN ]. The new input feature
Fﬁlter-input and value Vﬁlter-input are suitable for these ﬁltering

Figure 2. An illustration of the permutohedral lattice ﬁlter [1].
Splat: The input features are interpolated to permutohedral lat-
tice using barycentric weights. Blur: lattice points exchange their
values with nearby lattice points. Slice: The ﬁltered signal is in-
terpolated back onto the input signal.

algorithms [5, 1, 2], and the ﬁltered output is
−fzk )2

2 (fxi

1

G(fxi ) = X

e−

zk ∈Fﬁlter-input

= X

yk ∈FY

1

2 (fxi

−fyk )2

e−

vyk

vzk

(14)

With this augmentation, we can apply these ﬁltering al-
gorithms [1, 2, 5] as a black box to our problem. However,
by exploiting the structure of these methods, we can make
them more efﬁcient for our tasks. In the following text, the
permutohedral lattice ﬁlter [1] is discussed as an example,
which is used in our experiments.

4.2. Permutohedral Lattice Filter

We brieﬂy review the ﬁltering process of [1], an illustra-
tion is shown in Fig. 2. The d-dimension feature f is ﬁrst
embedded in (d + 1)-dimensional space, where the permu-
tohedral lattice lives.
In the embedded space, each input
value v Splats onto the vertices of its enclosing simplex
with barycentric weights. Next, lattice points Blur their val-
ues with nearby lattice points. Finally, the space is Sliced
at each input position using the same barycentric weights to
interpolate output values.

Although the permutohedral ﬁlter [1] has demonstrated
promising performance on a variety of tasks, it is still not
optimal for our problem. In particular, the index building
in [1] can be inefﬁcient when the variance Σxyz is too small.
Additionally, naively apply [1] to the E step (6) requires re-
building the index every EM iteration as the model point X
is updated. To resolve these problems, we propose a cus-
tomization of the permutohedral ﬁlter [1] that is more efﬁ-
cient while retaining sufﬁcient accuracy for our task. The
detailed method is presented in the supplemental material.

5. M Step: Efﬁcient Twist Parameterization

In this section, we present methods to solve the optimiza-
tions (7, 10) with the twist parameterization. We ﬁrst dis-
cuss the twist in the general kinematic model, then special-
ize it to articulated and node-graph deformable objects.

11098

We focus on the following general kinematic model,

Algorithm 1 The A matrix for articulated kinematic

xi = Ti(θ)xi reference

(15)
where Ti(θ) ∈ SE(3) is a rigid transformation, xi reference is
the ﬁxed reference point for the xi. Note that Ti(θ) depends
on i and the kinematic model is not necessarily a global
rigid transformation.

Twist is a 6-vector that represents the locally linearized
“change” of SE(3). Let the twist ζi = (wi, ti) =
(αi, βi, γi, ai, bi, ci) be the local linearization of Ti, we
have

T new

i ≈




1
γi
−βi

0

−γi
1
αi
0

βi
−αi

1
0

ai
bi
ci
1




Ti

(16)

Thus, the Jacobian ∂xi
= [skew(xi), I3×3] is a 3×6 matrix,
∂ζi
where I3×3 is identity matrix, and skew(xi) is a 3×3 matrix
such that skew(xi)b = cross(xi, b) for arbitrary b ∈ R3.

The optimization (7, 10) are least squares problems, and

we focus on the following generalized form of them

rT
xi rxi

X

xi

(17)

where rxi is the concatenated least-squares residuals that
depends on xi. We use the Gauss-Newton (GN) algorithm
to solve (17). In each GN iteration we need to compute the
following A and b matrices by

A = X

xi

(

∂rxi
∂θ

)T ∂rxi
∂θ

,

b = X

xi

(

∂rxi
∂θ

)T (rxi )

(18)

and the update of the motion parameters is ∆θ = −A−1b.
Thus, the primary computational bottleneck is to assemble
the matrices A and b. In the following text, we only discuss
the computation of the A matrix, while the computation of
the b vector is similar and easier. The computation of the A
matrix can be written as
∂ζi
∂θ

A = X

)T ∂rxi
∂ζi

∂rxi
∂ζi

∂ζi
∂θ

)T ((

(19)

)(

(

)

xi

where ∂ζi
∂θ is the Jacobian that maps the change of motion
parameter θ to the change of the rigid transformation Ti,
while the change of Ti is expressed as its twist. Note that
is very easy to compute, as both
the term
∂rxi
∂xi

= ∂rxi
∂xi
are only dependent on xi.

∂rxi
∂ζi
and ∂xi
∂ζi

∂xi
∂ζi

If the kinematic model is a global rigid transformation,

∂θ = I6×6 and A = Pxi

we have ∂ζi
In
the following subsections, we proceed to the articulated and
node-graph deformable kinematic models.

)T ∂rxi
∂ζi

(( ∂rxi
∂ζi

).

5.1. Articulated Model

Articulated objects consist of rigid bodies connected
through joints in a kinematic tree. A broad set of real-world
objects, including human bodies, hands and robots are artic-
ulated objects. If the kinematic model (15) is an articulated

1: for all bodyj do
2:

J T J twist j = 06×6
for all point xi in bodyj do

⊲ can be parallelized

⊲ can be parallelized

J T J twist j += ( ∂rxi
∂ζi

)T ∂rxi
∂ζi

5: A = 0Njoint×Njoint
6: for all bodyj do
7:

⊲ The spatial velocity Jacobian can be computed
⊲ using off-the-shelf simulators such as [36, 34]
Jspatial j = spatial velocity Jacobian of bodyj
A += J T

spatial j(J T J twist j)Jspatial j

3:

4:

8:

9:

10:

model, the motion parameter θ ∈ RNjoint would be the joint
angles, where Njoint is the number of joints. The Ti(θ) is the
rigid transform of the rigid body that the point xi is attached
to. The computation of the A matrix can be factored as

A = X

bodyj

(

∂ζj
∂θ

)T ( X

xi in bodyj

(

∂rxi
∂ζi

)T ∂rxi
∂ζi

)(

∂ζj
∂θ

)

(20)

where ζj is the twist of rigid body j, and we have exploited
= I6×6 if point i is on rigid body j. Importantly, ∂ζj
∂ζi
∂ζj
∂θ
is known as the spatial velocity Jacobian and is provided by
many off-the-shelf rigid body simulators [34, 36, 19]. The
algorithm that uses (20) is shown in Algorithm 1.

The lines 1-4 of Algorithm 1 dominates the overall per-
formance and the complexity is O(62M ), where M is the
number of model points and usually M ≫ Njoint. Thus,
the complexity of this algorithm is almost independent of
Njoint. As a comparison, previous articulated registration
methods [19, 35] need O(N 2
jointM ) time to assemble the A
matrix, and Njoint is usually much larger than 6. Further-
more, lines 1-4 of Algorithm 1 is very simple to implement
and can be easily GPU parallelized. Combined with an off-
the-shelf simulator, the overall pipeline can achieve promis-
ing efﬁciency. On the contrary, previous methods [19, 35]
typically need a customized kinematic tree implementation
for real-time performance, while requires substantial soft-
ware engineering effort to realize.

5.2. Node Graph Deformable Model

To capture the motion of objects such as rope or cloth,
we need a kinematic model which allows large deforma-
tion while preventing unrealistic collapsing or distortion.
In this paper, we follow [17] to represent the general de-
formable kinematic model as a node graph. Intuitively, the
node graph deﬁnes a motion ﬁeld in the 3D space and the
reference vertex in Equ. (15) is deformed according to the
motion ﬁeld. More speciﬁcally, the node graph is deﬁned as
a set {[pj ∈ R3, Tj ∈ SE(3)]}, where j is the node index,
pj is the position of the jth node, and Tj is the SE(3) mo-
tion deﬁned on the jth node. The kinematic equation (15)

11099

can be written as

Ti(θ) = normalized(Σk∈Ni(xi reference)wkiTk)

(21)

where Ni(xi reference) is the nearest neighbor nodes of model
point xi reference, and wki is the ﬁxed skinning weight. The
interpolation of the rigid transformation Tk is performed us-
ing the DualQuaternion [18] representation of the SE(3).

The A matrices for this kinematic model can be con-
structed using an algorithm very similar to Algorithm 1.
The detailed method is provided in supplemental materials.

6. Results

We conduct a variety of experiments to test the robust-
ness, accuracy and efﬁciency of the proposed method. Our
hardware platform is an Intel i7-3960X CPU except for
Sec. 6.5, where the proposed method is implemented with
CUDA on a Nivida Titan Xp GPU. The video demo and the
source code are available on our project page.

Figure 3. A comparison of the robustness of various algorithms
with respect to outliers. Top: (a) shows an example initialization
with 0.2 outlier ratio; (b) and (c) are the ﬁnal alignment by the
proposed method and TrICP [6] initialized from (a), respectively.
Bottom: the alignment error (22) of each algorithm for different
numbers of outliers.

6.1. Robustness Test on Synthetic Data

We follow CPD [25] to setup an experiment on syn-
thetic data. We use a subsampled Stanford bunny with 3500
points. The initial rotation discrepancy is 50 degrees with a
random axis. The proposed method is compared with two
baselines: CPD [25], a representative GMM-based algo-
rithm; TrICP [6], a widely used robust ICP variant. Param-
eters for all methods are well tuned and provided in supple-
mental materials. We use the following metric to measure
the pose estimation error

error(T ) =

1
M

ΣM

i=1|(T − Tgt)xi reference|2

(22)

where Tgt is the known ground truth pose, xi reference deﬁned
in (15) is the reference position. We terminate the algo-
rithm when the twist (change of transformation) is less than
a threshold. In this way, the ﬁnal alignment error (22) is
about 1 [mm] for all methods. All of the statistical results
are the averaged value of 30 independent runs.

Fig. 3 shows the robustness of different algorithms with
respect to outliers in the point sets. We add different num-
ber of points randomly to both the model and observation
clouds. An example of such point sets with initial align-
ment is shown in Fig. 3 (a), the converged alignment by the
proposed method and TrICP [6] are shown in Fig. 3 (b) and
Fig. 3 (c), respectively. The proposed method and CPD [25]
signiﬁcantly outperform the robust ICP.

Fig. 4 shows the robustness of different algorithms with
respect to noise in the point sets. We corrupt each point in
both model and observation clouds with a Gaussian noise.
The unit of the noise is the diameter of the Bunny. An ex-
ample of such point sets with initial alignment are shown in
Fig. 4 (a). Fig. 4 (b) and (c) are the ﬁnal alignment by the
proposed method and TrICP [6] initialized from (a). Note

time[ms]

per iteration

#iterations

overall
time[ms]

Proposed
ﬁxed σ
Proposed
updated σ

CPD

Robust ICP

0.96

1.16

228
3.10

40.4

27.6

26.8
70.2

38.4

32.1

6110
217.6

Table 1. The performance of different algorithms for the registra-
tion of the Stanford Bunny.

that we use clean point clouds for better visualization. Our
method and CPD [25] are more accurate than the robust ICP.
Table. 6.1 summarizes the computational performance of
each method. The running time is measured on clean point
cloud. Our method is about 7 times faster than TrICP [6]
and two orders of magnitude faster than CPD [25]. The pro-
posed method with ﬁxed σ is faster per iteration, but need
more iterations to converge. Overall the proposed method is
as robust as the state-of-the-art statistical registration algo-
rithm CPD [25], and runs substantially faster than the mod-
ern ICP implementation.

6.2. Rigid Registration on Real World Data

We follow [9] to setup this experiment:

the algorithm
is used to compute the frame-to-frame rigid transformation
on the Stanford Lounge dataset [43]. We register every 5th
frame for the ﬁrst 400 frames, each downsampled to about
5000 points. The average Euler angle deviation from the
ground truth is used as the estimation error.

Fig. 5 (a) shows an example registration by the proposed
method. Fig. 5 (b) shows the accuracy and speed of vari-
ous algorithms. The results of baseline methods are from

11100

Figure 4. A comparison of the robustness of various algorithms
with respect to noise. Top: (a) shows an example initialization
with 0.03 relative noise; (b) and (c) are the ﬁnal alignment by the
proposed method and TrICP [6] initialized from (a). Note that
we use clean point clouds for better visualization. Bottom: the
alignment error (22) of each algorithm for different levels of noise.

Figure 5. Rigid registration on the Stanford Lounge dataset [43].
The results for most baselines are from [9]. (a) shows an example
registration by the proposed method. (b) shows the accuracy and
performance of various algorithms.

[9]1 except for CPD [25]. For CPD [25] we use σinit =
20 [cm] instead of the data-based initialization of [25], with
which we observed improved performance. As the point-to-
point error doesn’t capture the planar structure, the point-
to-point version of the proposed method as well as many
other point-to-point algorithms [25, 22, 3, 6] are less accu-
rate on this dataset. The proposed method with point-to-

1Our CPU (i7-3960X) is slightly inferior to [9] (i7-5920K), and we
observe similar accuracy and slightly worse speed using CPD [25] and
TrICP [6]. Thus, we think our speed result are comparable to [9] despite
hardware difference.

Figure 6. A feature-based global registration under ambiguous
outliers and strong occlusion. (a) shows the initialization of the
registration colored by the feature [11]. (b) and (c) are the feature-
based registration by our method and the baseline. (d) and (e) show
the ﬁnal alignment using 3d local reﬁnement initialized from (b)
and (c). The proposed method converges to the correct pose while
the baseline method is trapped to bad alignment.

plane error achieves state-of-the-art accuracy. On the per-
spective of computation, the proposed method signiﬁcantly
outperforms all the baselines, including GMMTree [9] and
EMICP [14] that rely on a high-end Titan X GPU.

6.3. Global Pose Estimation using Learned Features

We demonstrate global pose estimation using motion-
invariant features. The task is to align a pre-built geomet-
ric model to observation clouds from RGBD images, where
both the model and observation clouds are colored by the
learned feature [11]. We use the proposed method with
feature correspondence in Sec. 3.3 and ﬁxed σ = 0.05 as
the feature has unit norm. The proposed method is com-
pared with a modiﬁed TrICP [6]:
the nearest neighbour
is searched in feature space (instead of 3d-space). After
feature-based registration, we apply 3d-space local reﬁne-
ment to get the ﬁnal alignment.

Fig. 6 shows an example registration. Note that we treat
the background as outliers. As shown in Fig. 6 (a), the
observation (RGBD cloud) is under severe occlusion and
contains very ambiguous outliers. Fig. 6 (b) and (c) show
feature-based registration by our method and the “feature”
TrICP. The proposed method is more robust to the outliers
and occlusion. Fig. 6 (d) and (e) show the ﬁnal alignment
using local reﬁnement initialized from (b) and (c). The pro-
posed method converges to correct pose while the baseline
is trapped to bad alignment. Table. 2 summaries the suc-
cess rate of both methods on 30 RGBD images with differ-
ent view points and lighting conditions. Our method has a
higher success rate and is more efﬁcient than the baseline.

11101

success rate

time [ms]

Proposed

Feature ICP

29/30
25/30

13
34

Table 2. The success rate and speed on the feature-based global
registration.

6.4. Articulated Tracking

The proposed method with articulated kinematic model
is used to track a robot manipulating a box. The robot and
box model has 20 DOFs (12 for the ﬂoating bases of the box
and the robot, 8 for robot joints). We use drake [34] for the
kinematic computation in (20). We use ﬁxed σ = 1 [cm]
and set the maximum EM iterations to be 15. Our template
has 7500 points and the depth cloud has about 10000 points.
Fig. 7 (a) shows the snapshots of the tracked manipula-
tion scenario. Fig. 7 (b) shows the live geometric model
and the observation clouds. Points from observation are in
black, while the geometric model is colored according to
rigid bodies. Note that points from the table are treated as
outliers. Fig. 7 (c) summaries the averaged per-frame per-
formance of various algorithms. The proposed twist param-
eterization is an order of magnitude faster than direct pa-
rameterization. Combining the ﬁlter-based correspondence
and twist parameterization leads to a real-time tracking al-
gorithm and substantial performance improvement over ar-
ticulated ICP and [42].

6.5. Application to Dynamic Reconstruction

The proposed method with node-graph deformable kine-
matic is implemented on GPU and used as the internal non-
rigid tracker of DynamicFusion [26] (our implementation).
The proposed method is compared with the projective ICP,
the original non-rigid tracker of [26]. We use ﬁxed σ = 2
[cm]. Fig. 8 shows both methods operate on a RGBD se-
quence with relative fast motions. The proposed method
tracks it correctly, while the projective ICP fails to track the
right hand of the actor. The proposed method is more robust
to fast and tangential motion than the projective ICP.

To test the efﬁciency of the proposed twist parameteriza-
tion on node-graph deformable objects, we compare it with
Opt [8], a highly optimized GPU least squares solver using
direct parameterization. The per-frame computational per-
formance of various algorithms is summarized in Table. 3.
The GPU parallelization of our ﬁlter-based E step achieves
8 times speedup over the CPU version, and the proposed
twist parameterization is about 20 times faster than [8].

Proposed

(GPU)

E step [ms]
M step [ms]

7.8
21.6

Proposed

(CPU)

62

Not implemented

Proposed
(Opt [8])

7.8
382

Table 3. The per-frame performance of various algorithms for
deformable tracking on the sequence in Fig. 8.

Figure 7. The proposed method is applied to track a robot ma-
nipulating a box. (a): the snapshots of the tracked manipulation
scenario. (b) the observation point clouds (black) and the live ge-
ometric model (colored according to rigid bodies). (c): the per-
frame performance of various algorithms on this dataset. Ye &
Yang stands for our CPU implementation of [42].

Figure 8. The proposed method with node-graph deformable kine-
matic is implemented on GPU and used as the internal non-rigid
tracker of DynamicFusion [26]. For a relative fast motion, the pro-
posed method tracks it correctly while the projective ICP used by
DynamicFusion [26] fails to track the right hand of the actor.

7. Conclusion

To conclude, we present a probabilistic registration
method that achieves state-of-the-art robustness, accuracy
and efﬁciency. We show that the correspondence search
can be formulated as a ﬁltering problem, and employ ad-
vances in efﬁcient Gaussian ﬁltering methods to solve it.
In addition, we present a simple and efﬁcient twist param-
eterization that generalizes our method to articulated and
deformable objects. Extensive empirical evaluation demon-
strates the effectiveness our method.

Acknowledgments This work was supported by NSF Award IIS-1427050

and Amazon Research Award. The views expressed in this paper are those

of the authors themselves and are not endorsed by the funding agencies.

11102

References

[1] A. Adams, J. Baek, and M. A. Davis. Fast high-dimensional
ﬁltering using the permutohedral
In Computer
Graphics Forum, volume 29, pages 753–762. Wiley Online
Library, 2010. 1, 4

lattice.

[2] A. Adams, N. Gelfand, J. Dolson, and M. Levoy. Gaussian
kd-trees for fast high-dimensional ﬁltering. In ACM Trans-
actions on Graphics (ToG), volume 28, page 21. ACM, 2009.
1, 4

[3] P. J. Besl and N. D. McKay. Method for registration of 3-d
shapes. In Sensor Fusion IV: Control Paradigms and Data
Structures, volume 1611, pages 586–607. International Soci-
ety for Optics and Photonics, 1992. 1, 7

[4] D. Campbell and L. Petersson. An adaptive data represen-
tation for robust point-set registration and merging. In Pro-
ceedings of the IEEE International Conference on Computer
Vision, pages 4292–4300, 2015. 2

[5] J. Chen, S. Paris, and F. Durand. Real-time edge-aware im-
age processing with the bilateral grid. In ACM Transactions
on Graphics (TOG), volume 26, page 103. ACM, 2007. 1, 4

[6] D. Chetverikov, D. Stepanov, and P. Krsek. Robust euclidean
alignment of 3d point sets: the trimmed iterative closest point
algorithm.
Image and Vision Computing, 23(3):299–309,
2005. 3, 6, 7

[7] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum
likelihood from incomplete data via the em algorithm. Jour-
nal of the royal statistical society. Series B (methodological),
pages 1–38, 1977. 2

[8] Z. DeVito, M. Mara, M. Zollh¨ofer, G. Bernstein, J. Ragan-
Kelley, C. Theobalt, P. Hanrahan, M. Fisher, and M. Nießner.
Opt: A domain speciﬁc language for non-linear least squares
optimization in graphics and imaging. ACM Transactions on
Graphics (TOG), 36(5):171, 2017. 8

[9] B. Eckart, K. Kim, and J. Kautz. Fast and accurate point
cloud registration using trees of gaussian mixtures. arXiv
preprint arXiv:1807.02587, 2018. 1, 2, 3, 6, 7

[10] G. D. Evangelidis, D. Kounades-Bastian, R. Horaud, and
E. Z. Psarakis. A generative model for the joint registration
of multiple point sets. In European Conference on Computer
Vision, pages 109–122. Springer, 2014. 1, 2, 3

[11] P. R. Florence, L. Manuelli, and R. Tedrake. Dense ob-
ject nets: Learning dense visual object descriptors by and
for robotic manipulation. arXiv preprint arXiv:1806.08756,
2018. 7

[12] W. Gao and R. Tedrake.

Surfelwarp: Efﬁcient non-

volumetric single view dynamic reconstruction. 1

[13] S. Gold, A. Rangarajan, C.-P. Lu, S. Pappu, and E. Mjol-
sness. New algorithms for 2d and 3d point matching:
Pose estimation and correspondence. Pattern recognition,
31(8):1019–1031, 1998. 1

[14] S. Granger and X. Pennec. Multi-scale em-icp: A fast and
robust approach for surface registration. In European Con-
ference on Computer Vision, pages 418–432. Springer, 2002.
1, 2, 7

[15] R. Horaud, F. Forbes, M. Yguel, G. Dewaele, and J. Zhang.
Rigid and articulated point registration with expectation con-

ditional maximization. IEEE Transactions on Pattern Anal-
ysis and Machine Intelligence, 33(3):587–602, 2011. 1, 2,
3

[16] B. Jian and B. C. Vemuri. A robust algorithm for point set
registration using mixture of gaussians. In Computer Vision,
2005. ICCV 2005. Tenth IEEE International Conference on,
volume 2, pages 1246–1251. IEEE, 2005. 2

[17] L. Kavan, S. Collins, C. OSullivan, and J. Zara. Dual quater-

nions for rigid transformation blending. 1, 5

[18] L. Kavan, S. Collins, J. ˇZ´ara, and C. O’Sullivan. Geometric
skinning with approximate dual quaternion blending. ACM
Transactions on Graphics (TOG), 27(4):105, 2008. 6

[19] J. Lee, M. X. Grey, S. Ha, T. Kunz, S. Jain, Y. Ye, S. S. Srini-
vasa, M. Stilman, and C. K. Liu. Dart: Dynamic animation
and robotics toolkit. The Journal of Open Source Software,
3(22):500, 2018. 5

[20] F. Lu and E. Milios. Robot pose estimation in unknown envi-
ronments by matching 2d range scans. Journal of Intelligent
and Robotic systems, 18(3):249–275, 1997. 1

[21] B. Luo and E. R. Hancock. A uniﬁed framework for align-
ment and correspondence. Computer Vision and Image Un-
derstanding, 92(1):26–55, 2003. 2

[22] M. Magnusson. The three-dimensional normal-distributions
transform: an efﬁcient representation for registration, sur-
face analysis, and loop detection. PhD thesis, ¨Orebro uni-
versitet, 2009. 2, 3, 7

[23] G. McNeill and S. Vijayakumar. A probabilistic approach
to robust shape matching. In Image Processing, 2006 IEEE
International Conference on, pages 937–940. IEEE, 2006. 2
[24] L. Mundermann, S. Corazza, and T. P. Andriacchi. Accu-
rately measuring human movement using articulated icp with
soft-joint constraints and a repository of articulated mod-
els.
In Computer Vision and Pattern Recognition, 2007.
CVPR’07. IEEE Conference on, pages 1–6. IEEE, 2007. 1

[25] A. Myronenko and X. Song. Point set registration: Coherent
point drift. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 32(12):2262–2275, Dec 2010. 1, 2, 3, 6,
7

[26] R. A. Newcombe, D. Fox, and S. M. Seitz. Dynamicfusion:
Reconstruction and tracking of non-rigid scenes in real-time.
In Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 343–352, 2015. 2, 8

[27] A. N¨uchter, K. Lingemann, J. Hertzberg, and H. Surmann.
6d slam3d mapping outdoor environments. Journal of Field
Robotics, 24(8-9):699–722, 2007. 1

[28] F. Pomerleau, F. Colas, R. Siegwart, et al. A review of point
cloud registration algorithms for mobile robotics. Founda-
tions and Trends R(cid:13) in Robotics, 4(1):1–104, 2015. 1

[29] F. Pomerleau, F. Colas, R. Siegwart, and S. Magnenat. Com-
paring ICP Variants on Real-World Data Sets. Autonomous
Robots, 34(3):133–148, Feb. 2013. 1

[30] A. Rangarajan, H. Chui, E. Mjolsness, S. Pappu, L. Davachi,
P. Goldman-Rakic, and J. Duncan. A robust point-matching
algorithm for autoradiograph alignment. Medical image
analysis, 1(4):379–398, 1997. 2

[31] T. Schmidt, R. Newcombe, and D. Fox. Self-supervised
visual descriptor learning for dense correspondence. IEEE
Robotics and Automation Letters, 2(2):420–427, 2017. 3

11103

[32] J. Schulman, A. Lee, J. Ho, and P. Abbeel. Tracking de-
formable objects with point clouds. In Robotics and Automa-
tion (ICRA), 2013 IEEE International Conference on, pages
1130–1137. IEEE, 2013. 2, 3

[33] T. Stoyanov, M. Magnusson, and A. J. Lilienthal. Point set
registration through minimization of the l2 distance between
3d-ndt models. 2

[34] R. Tedrake and the Drake Development Team. Drake: A
planning, control, and analysis toolbox for nonlinear dynam-
ical systems, 2016. 5, 8

[35] A. Tkach, M. Pauly, and A. Tagliasacchi. Sphere-meshes for
real-time hand modeling and tracking. ACM Transactions on
Graphics (TOG), 35(6):222, 2016. 5

[36] E. Todorov, T. Erez, and Y. Tassa. Mujoco: A physics engine
for model-based control. In Intelligent Robots and Systems
(IROS), 2012 IEEE/RSJ International Conference on, pages
5026–5033. IEEE, 2012. 5

[37] F. Tombari, S. Salti, and L. Di Stefano. Unique signatures of
histograms for local surface description. In European con-
ference on computer vision, pages 356–369. Springer, 2010.
3

[38] Y. Tsin and T. Kanade. A correlation-based approach to ro-
bust point set registration. In European conference on com-
puter vision, pages 558–569. Springer, 2004. 2

[39] B. Wang, L. Wu, K. Yin, U. Ascher, L. Liu, and H. Huang.
Deformation capture and modeling of soft objects. ACM
Transactions on Graphics (TOG), 34(4):94, 2015. 3

[40] T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison,
and S. Leutenegger. Elasticfusion: Real-time dense slam
and light source estimation. The International Journal of
Robotics Research, 35(14):1697–1716, 2016. 1

[41] C. Yang, R. Duraiswami, N. A. Gumerov, and L. Davis. Im-
proved fast gauss transform and efﬁcient kernel density esti-
mation. In null, page 464. IEEE, 2003. 4

[42] M. Ye and R. Yang. Real-time simultaneous pose and shape
estimation for articulated objects using a single depth cam-
era.
In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 2345–2352, 2014. 2,
8

[43] Q.-Y. Zhou and V. Koltun. Dense scene reconstruction with
points of interest. ACM Transactions on Graphics (ToG),
32(4):112, 2013. 6, 7

11104

